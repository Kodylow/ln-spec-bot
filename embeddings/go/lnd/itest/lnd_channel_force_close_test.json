{
  "filepath": "../implementations/go/lnd/itest/lnd_channel_force_close_test.go",
  "package": "itest",
  "sections": [
    {
      "slug": "func testCommitmentTransactionDeadline(ht *lntest.HarnessTest) {",
      "content": "func testCommitmentTransactionDeadline(ht *lntest.HarnessTest) {\n\t// Get the default max fee rate used in sweeping the commitment\n\t// transaction.\n\tdefaultMax := lnwallet.DefaultAnchorsCommitMaxFeeRateSatPerVByte\n\tmaxPerKw := chainfee.SatPerKVByte(defaultMax * 1000).FeePerKWeight()\n\n\tconst (\n\t\t// feeRateConfDefault(sat/kw) is used when no conf target is\n\t\t// set. This value will be returned by the fee estimator but\n\t\t// won't be used because our commitment fee rate is capped by\n\t\t// DefaultAnchorsCommitMaxFeeRateSatPerVByte.\n\t\tfeeRateDefault = 20000\n\n\t\t// finalCTLV is used when Alice sends payment to Bob.\n\t\tfinalCTLV = 144\n\n\t\t// deadline is used when Alice sweep the anchor. Notice there\n\t\t// is a block padding of 3 added, such that the value of\n\t\t// deadline is 147.\n\t\tdeadline = uint32(finalCTLV + routing.BlockPadding)\n\t)\n\n\t// feeRateSmall(sat/kw) is used when we want to skip the CPFP\n\t// on anchor transactions. When the fee rate is smaller than\n\t// the parent's (commitment transaction) fee rate, the CPFP\n\t// will be skipped. Atm, the parent tx's fee rate is roughly\n\t// 2500 sat/kw in this test.\n\tfeeRateSmall := maxPerKw / 2\n\n\t// feeRateLarge(sat/kw) is used when we want to use the anchor\n\t// transaction to CPFP our commitment transaction.\n\tfeeRateLarge := maxPerKw * 2\n\n\t// Before we start, set up the default fee rate and we will test the\n\t// actual fee rate against it to decide whether we are using the\n\t// deadline to perform fee estimation.\n\tht.SetFeeEstimate(feeRateDefault)\n\n\t// setupNode creates a new node and sends 1 btc to the node.\n\tsetupNode := func(name string) *node.HarnessNode {\n\t\t// Create the node.\n\t\targs := []string{\"--hodl.exit-settle\"}\n\t\targs = append(args, lntest.NodeArgsForCommitType(\n\t\t\tlnrpc.CommitmentType_ANCHORS)...,\n\t\t)\n\t\tnode := ht.NewNode(name, args)\n\n\t\t// Send some coins to the node.\n\t\tht.FundCoins(btcutil.SatoshiPerBitcoin, node)\n\n\t\t// For neutrino backend, we need one additional UTXO to create\n\t\t// the sweeping tx for the remote anchor.\n\t\tif ht.IsNeutrinoBackend() {\n\t\t\tht.FundCoins(btcutil.SatoshiPerBitcoin, node)\n\t\t}\n\n\t\treturn node\n\t}\n\n\t// calculateSweepFeeRate runs multiple steps to calculate the fee rate\n\t// used in sweeping the transactions.\n\tcalculateSweepFeeRate := func(expectedSweepTxNum int) int64 {\n\t\t// Create two nodes, Alice and Bob.\n\t\talice := setupNode(\"Alice\")\n\t\tdefer ht.Shutdown(alice)\n\n\t\tbob := setupNode(\"Bob\")\n\t\tdefer ht.Shutdown(bob)\n\n\t\t// Connect Alice to Bob.\n\t\tht.ConnectNodes(alice, bob)\n\n\t\t// Open a channel between Alice and Bob.\n\t\tchanPoint := ht.OpenChannel(\n\t\t\talice, bob, lntest.OpenChannelParams{\n\t\t\t\tAmt:     10e6,\n\t\t\t\tPushAmt: 5e6,\n\t\t\t},\n\t\t)\n\n\t\t// Send a payment with a specified finalCTLVDelta, which will\n\t\t// be used as our deadline later on when Alice force closes the\n\t\t// channel.\n\t\treq := &routerrpc.SendPaymentRequest{\n\t\t\tDest:           bob.PubKey[:],\n\t\t\tAmt:            10e4,\n\t\t\tPaymentHash:    ht.Random32Bytes(),\n\t\t\tFinalCltvDelta: finalCTLV,\n\t\t\tTimeoutSeconds: 60,\n\t\t\tFeeLimitMsat:   noFeeLimitMsat,\n\t\t}\n\t\talice.RPC.SendPayment(req)\n\n\t\t// Once the HTLC has cleared, all the nodes in our mini network\n\t\t// should show that the HTLC has been locked in.\n\t\tht.AssertNumActiveHtlcs(alice, 1)\n\t\tht.AssertNumActiveHtlcs(bob, 1)\n\n\t\t// Alice force closes the channel.\n\t\tht.CloseChannelAssertPending(alice, chanPoint, true)\n\n\t\t// Now that the channel has been force closed, it should show\n\t\t// up in the PendingChannels RPC under the waiting close\n\t\t// section.\n\t\tht.AssertChannelWaitingClose(alice, chanPoint)\n\n\t\t// Check our sweep transactions can be found in mempool.\n\t\tsweepTxns := ht.Miner.GetNumTxsFromMempool(expectedSweepTxNum)\n\n\t\t// Mine a block to confirm these transactions such that they\n\t\t// don't remain in the mempool for any subsequent tests.\n\t\tht.MineBlocks(1)\n\n\t\t// Calculate the fee rate used.\n\t\tfeeRate := ht.CalculateTxesFeeRate(sweepTxns)\n\n\t\treturn feeRate\n\t}\n\n\t// Setup our fee estimation for the deadline. Because the fee rate is\n\t// smaller than the parent tx's fee rate, this value won't be used and\n\t// we should see only one sweep tx in the mempool.\n\tht.SetFeeEstimateWithConf(feeRateSmall, deadline)\n\n\t// Calculate fee rate used.\n\tfeeRate := calculateSweepFeeRate(1)\n\n\t// We expect the default max fee rate is used. Allow some deviation\n\t// because weight estimates during tx generation are estimates.\n\trequire.InEpsilonf(\n\t\tht, int64(maxPerKw), feeRate, 0.01,\n\t\t\"expected fee rate:%d, got fee rate:%d\", maxPerKw, feeRate,\n\t)\n\n\t// Setup our fee estimation for the deadline. Because the fee rate is\n\t// greater than the parent tx's fee rate, this value will be used to\n\t// sweep the anchor transaction and we should see two sweep\n\t// transactions in the mempool.\n\tht.SetFeeEstimateWithConf(feeRateLarge, deadline)\n\n\t// Calculate fee rate used.\n\tfeeRate = calculateSweepFeeRate(2)\n\n\t// We expect the anchor to be swept with the deadline, which has the\n\t// fee rate of feeRateLarge.\n\trequire.InEpsilonf(\n\t\tht, int64(feeRateLarge), feeRate, 0.01,\n\t\t\"expected fee rate:%d, got fee rate:%d\", feeRateLarge, feeRate,\n\t)\n}\n\n// testChannelForceClosure performs a test to exercise the behavior of \"force\"\n// closing a channel or unilaterally broadcasting the latest local commitment\n// state on-chain. The test creates a new channel between Alice and Carol, then\n// force closes the channel after some cursory assertions. Within the test, a\n// total of 3 + n transactions will be broadcast, representing the commitment\n// transaction, a transaction sweeping the local CSV delayed output, a\n// transaction sweeping the CSV delayed 2nd-layer htlcs outputs, and n\n// htlc timeout transactions, where n is the number of payments Alice attempted\n// to send to Carol.  This test includes several restarts to ensure that the\n// transaction output states are persisted throughout the forced closure\n// process.\n//\n// TODO(roasbeef): also add an unsettled HTLC before force closing.",
      "length": 5668,
      "tokens": 816,
      "embedding": []
    },
    {
      "slug": "func testChannelForceClosure(ht *lntest.HarnessTest) {",
      "content": "func testChannelForceClosure(ht *lntest.HarnessTest) {\n\t// We'll test the scenario for some of the commitment types, to ensure\n\t// outputs can be swept.\n\tcommitTypes := []lnrpc.CommitmentType{\n\t\tlnrpc.CommitmentType_LEGACY,\n\t\tlnrpc.CommitmentType_ANCHORS,\n\t}\n\n\tfor _, channelType := range commitTypes {\n\t\ttestName := fmt.Sprintf(\"committype=%v\", channelType)\n\n\t\tchannelType := channelType\n\t\tsuccess := ht.Run(testName, func(t *testing.T) {\n\t\t\tst := ht.Subtest(t)\n\n\t\t\targs := lntest.NodeArgsForCommitType(channelType)\n\t\t\talice := st.NewNode(\"Alice\", args)\n\t\t\tdefer st.Shutdown(alice)\n\n\t\t\t// Since we'd like to test failure scenarios with\n\t\t\t// outstanding htlcs, we'll introduce another node into\n\t\t\t// our test network: Carol.\n\t\t\tcarolArgs := []string{\"--hodl.exit-settle\"}\n\t\t\tcarolArgs = append(carolArgs, args...)\n\t\t\tcarol := st.NewNode(\"Carol\", carolArgs)\n\t\t\tdefer st.Shutdown(carol)\n\n\t\t\t// Each time, we'll send Alice  new set of coins in\n\t\t\t// order to fund the channel.\n\t\t\tst.FundCoins(btcutil.SatoshiPerBitcoin, alice)\n\n\t\t\t// Also give Carol some coins to allow her to sweep her\n\t\t\t// anchor.\n\t\t\tst.FundCoins(btcutil.SatoshiPerBitcoin, carol)\n\n\t\t\tchannelForceClosureTest(st, alice, carol, channelType)\n\t\t})\n\t\tif !success {\n\t\t\treturn\n\t\t}\n\t}\n}\n",
      "length": 1153,
      "tokens": 138,
      "embedding": []
    },
    {
      "slug": "func channelForceClosureTest(ht *lntest.HarnessTest,",
      "content": "func channelForceClosureTest(ht *lntest.HarnessTest,\n\talice, carol *node.HarnessNode, channelType lnrpc.CommitmentType) {\n\n\tconst (\n\t\tchanAmt     = btcutil.Amount(10e6)\n\t\tpushAmt     = btcutil.Amount(5e6)\n\t\tpaymentAmt  = 100000\n\t\tnumInvoices = 6\n\t)\n\n\tconst commitFeeRate = 20000\n\tht.SetFeeEstimate(commitFeeRate)\n\n\t// TODO(roasbeef): should check default value in config here\n\t// instead, or make delay a param\n\tdefaultCLTV := uint32(chainreg.DefaultBitcoinTimeLockDelta)\n\n\t// We must let Alice have an open channel before she can send a node\n\t// announcement, so we open a channel with Carol,\n\tht.ConnectNodes(alice, carol)\n\n\t// We need one additional UTXO for sweeping the remote anchor.\n\tht.FundCoins(btcutil.SatoshiPerBitcoin, alice)\n\n\t// Before we start, obtain Carol's current wallet balance, we'll check\n\t// to ensure that at the end of the force closure by Alice, Carol\n\t// recognizes his new on-chain output.\n\tcarolBalResp := carol.RPC.WalletBalance()\n\tcarolStartingBalance := carolBalResp.ConfirmedBalance\n\n\tchanPoint := ht.OpenChannel(\n\t\talice, carol, lntest.OpenChannelParams{\n\t\t\tAmt:     chanAmt,\n\t\t\tPushAmt: pushAmt,\n\t\t},\n\t)\n\n\t// Send payments from Alice to Carol, since Carol is htlchodl mode, the\n\t// htlc outputs should be left unsettled, and should be swept by the\n\t// utxo nursery.\n\tcarolPubKey := carol.PubKey[:]\n\tfor i := 0; i < numInvoices; i++ {\n\t\treq := &routerrpc.SendPaymentRequest{\n\t\t\tDest:           carolPubKey,\n\t\t\tAmt:            int64(paymentAmt),\n\t\t\tPaymentHash:    ht.Random32Bytes(),\n\t\t\tFinalCltvDelta: chainreg.DefaultBitcoinTimeLockDelta,\n\t\t\tTimeoutSeconds: 60,\n\t\t\tFeeLimitMsat:   noFeeLimitMsat,\n\t\t}\n\t\talice.RPC.SendPayment(req)\n\t}\n\n\t// Once the HTLC has cleared, all the nodes n our mini network should\n\t// show that the HTLC has been locked in.\n\tht.AssertNumActiveHtlcs(alice, numInvoices)\n\tht.AssertNumActiveHtlcs(carol, numInvoices)\n\n\t// Fetch starting height of this test so we can compute the block\n\t// heights we expect certain events to take place.\n\t_, curHeight := ht.Miner.GetBestBlock()\n\n\t// Using the current height of the chain, derive the relevant heights\n\t// for incubating two-stage htlcs.\n\tvar (\n\t\tstartHeight           = uint32(curHeight)\n\t\tcommCsvMaturityHeight = startHeight + 1 + defaultCSV\n\t\thtlcExpiryHeight      = padCLTV(startHeight + defaultCLTV)\n\t\thtlcCsvMaturityHeight = padCLTV(\n\t\t\tstartHeight + defaultCLTV + 1 + defaultCSV,\n\t\t)\n\t)\n\n\t// If we are dealing with an anchor channel type, the sweeper will\n\t// sweep the HTLC second level output one block earlier (than the\n\t// nursery that waits an additional block, and handles non-anchor\n\t// channels). So we set a maturity height that is one less.\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\thtlcCsvMaturityHeight = padCLTV(\n\t\t\tstartHeight + defaultCLTV + defaultCSV,\n\t\t)\n\t}\n\n\taliceChan := ht.QueryChannelByChanPoint(alice, chanPoint)\n\trequire.NotZero(ht, aliceChan.NumUpdates,\n\t\t\"alice should see at least one update to her channel\")\n\n\t// Now that the channel is open and we have unsettled htlcs, immediately\n\t// execute a force closure of the channel. This will also assert that\n\t// the commitment transaction was immediately broadcast in order to\n\t// fulfill the force closure request.\n\tconst actualFeeRate = 30000\n\tht.SetFeeEstimate(actualFeeRate)\n\n\tht.CloseChannelAssertPending(alice, chanPoint, true)\n\n\t// Now that the channel has been force closed, it should show up in the\n\t// PendingChannels RPC under the waiting close section.\n\twaitingClose := ht.AssertChannelWaitingClose(alice, chanPoint)\n\n\t// Immediately after force closing, all of the funds should be in\n\t// limbo.\n\trequire.NotZero(ht, waitingClose.LimboBalance,\n\t\t\"all funds should still be in limbo\")\n\n\t// Create a map of outpoints to expected resolutions for alice and\n\t// carol which we will add reports to as we sweep outputs.\n\tvar (\n\t\taliceReports = make(map[string]*lnrpc.Resolution)\n\t\tcarolReports = make(map[string]*lnrpc.Resolution)\n\t)\n\n\t// The several restarts in this test are intended to ensure that when a\n\t// channel is force-closed, the UTXO nursery has persisted the state of\n\t// the channel in the closure process and will recover the correct\n\t// state when the system comes back on line. This restart tests state\n\t// persistence at the beginning of the process, when the commitment\n\t// transaction has been broadcast but not yet confirmed in a block.\n\tht.RestartNode(alice)\n\n\t// To give the neutrino backend some time to catch up with the chain, we\n\t// wait here until we have enough UTXOs to actually sweep the local and\n\t// remote anchor.\n\tconst expectedUtxos = 2\n\tht.AssertNumUTXOs(alice, expectedUtxos)\n\n\t// Mine a block which should confirm the commitment transaction\n\t// broadcast as a result of the force closure. If there are anchors, we\n\t// also expect the anchor sweep tx to be in the mempool.\n\texpectedTxes := 1\n\texpectedFeeRate := commitFeeRate\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\texpectedTxes = 2\n\t\texpectedFeeRate = actualFeeRate\n\t}\n\n\tsweepTxns := ht.Miner.GetNumTxsFromMempool(expectedTxes)\n\n\t// Verify fee rate of the commitment tx plus anchor if present.\n\tfeeRate := ht.CalculateTxesFeeRate(sweepTxns)\n\n\t// Allow some deviation because weight estimates during tx generation\n\t// are estimates.\n\trequire.InEpsilon(ht, expectedFeeRate, feeRate, 0.005)\n\n\t// Find alice's commit sweep and anchor sweep (if present) in the\n\t// mempool.\n\taliceCloseTx := waitingClose.Commitments.LocalTxid\n\t_, aliceAnchor := ht.FindCommitAndAnchor(sweepTxns, aliceCloseTx)\n\n\t// If we expect anchors, add alice's anchor to our expected set of\n\t// reports.\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\taliceReports[aliceAnchor.OutPoint.String()] = &lnrpc.Resolution{\n\t\t\tResolutionType: lnrpc.ResolutionType_ANCHOR,\n\t\t\tOutcome:        lnrpc.ResolutionOutcome_CLAIMED,\n\t\t\tSweepTxid:      aliceAnchor.SweepTx.TxHash().String(),\n\t\t\tOutpoint: &lnrpc.OutPoint{\n\t\t\t\tTxidBytes:   aliceAnchor.OutPoint.Hash[:],\n\t\t\t\tTxidStr:     aliceAnchor.OutPoint.Hash.String(),\n\t\t\t\tOutputIndex: aliceAnchor.OutPoint.Index,\n\t\t\t},\n\t\t\tAmountSat: uint64(anchorSize),\n\t\t}\n\t}\n\n\tht.MineBlocks(1)\n\n\t// Now that the commitment has been confirmed, the channel should be\n\t// marked as force closed.\n\terr := wait.NoError(func() error {\n\t\tforceClose := ht.AssertChannelPendingForceClose(\n\t\t\talice, chanPoint,\n\t\t)\n\n\t\t// Now that the channel has been force closed, it should now\n\t\t// have the height and number of blocks to confirm populated.\n\t\terr := checkCommitmentMaturity(\n\t\t\tforceClose, commCsvMaturityHeight, int32(defaultCSV),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// None of our outputs have been swept, so they should all be in\n\t\t// limbo. For anchors, we expect the anchor amount to be\n\t\t// recovered.\n\t\tif forceClose.LimboBalance == 0 {\n\t\t\treturn errors.New(\"all funds should still be in \" +\n\t\t\t\t\"limbo\")\n\t\t}\n\t\texpectedRecoveredBalance := int64(0)\n\t\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\t\texpectedRecoveredBalance = anchorSize\n\t\t}\n\t\tif forceClose.RecoveredBalance != expectedRecoveredBalance {\n\t\t\treturn errors.New(\"no funds should yet be shown \" +\n\t\t\t\t\"as recovered\")\n\t\t}\n\n\t\treturn nil\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout while checking force closed channel\")\n\n\t// The following restart is intended to ensure that outputs from the\n\t// force close commitment transaction have been persisted once the\n\t// transaction has been confirmed, but before the outputs are spendable\n\t// (the \"kindergarten\" bucket.)\n\tht.RestartNode(alice)\n\n\t// Carol's sweep tx should be in the mempool already, as her output is\n\t// not timelocked. If there are anchors, we also expect Carol's anchor\n\t// sweep now.\n\tsweepTxns = ht.Miner.GetNumTxsFromMempool(expectedTxes)\n\n\t// Calculate the total fee Carol paid.\n\tvar totalFeeCarol btcutil.Amount\n\tfor _, tx := range sweepTxns {\n\t\tfee := ht.CalculateTxFee(tx)\n\t\ttotalFeeCarol += fee\n\t}\n\n\t// We look up the sweep txns we have found in mempool and create\n\t// expected resolutions for carol.\n\tcarolCommit, carolAnchor := ht.FindCommitAndAnchor(\n\t\tsweepTxns, aliceCloseTx,\n\t)\n\n\t// If we have anchors, add an anchor resolution for carol.\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\tcarolReports[carolAnchor.OutPoint.String()] = &lnrpc.Resolution{\n\t\t\tResolutionType: lnrpc.ResolutionType_ANCHOR,\n\t\t\tOutcome:        lnrpc.ResolutionOutcome_CLAIMED,\n\t\t\tSweepTxid:      carolAnchor.SweepTx.TxHash().String(),\n\t\t\tAmountSat:      anchorSize,\n\t\t\tOutpoint: &lnrpc.OutPoint{\n\t\t\t\tTxidBytes:   carolAnchor.OutPoint.Hash[:],\n\t\t\t\tTxidStr:     carolAnchor.OutPoint.Hash.String(),\n\t\t\t\tOutputIndex: carolAnchor.OutPoint.Index,\n\t\t\t},\n\t\t}\n\t}\n\n\t// Currently within the codebase, the default CSV is 4 relative blocks.\n\t// For the persistence test, we generate two blocks, then trigger\n\t// a restart and then generate the final block that should trigger\n\t// the creation of the sweep transaction.\n\tht.MineBlocks(defaultCSV - 2)\n\n\t// The following restart checks to ensure that outputs in the\n\t// kindergarten bucket are persisted while waiting for the required\n\t// number of confirmations to be reported.\n\tht.RestartNode(alice)\n\n\t// Alice should see the channel in her set of pending force closed\n\t// channels with her funds still in limbo.\n\tvar aliceBalance int64\n\tvar closingTxID *chainhash.Hash\n\terr = wait.NoError(func() error {\n\t\tforceClose := ht.AssertChannelPendingForceClose(\n\t\t\talice, chanPoint,\n\t\t)\n\n\t\t// Get the closing txid.\n\t\ttxid, err := chainhash.NewHashFromStr(forceClose.ClosingTxid)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tclosingTxID = txid\n\n\t\t// Make a record of the balances we expect for alice and carol.\n\t\taliceBalance = forceClose.Channel.LocalBalance\n\n\t\t// At this point, the nursery should show that the commitment\n\t\t// output has 2 block left before its CSV delay expires. In\n\t\t// total, we have mined exactly defaultCSV blocks, so the htlc\n\t\t// outputs should also reflect that this many blocks have\n\t\t// passed.\n\t\terr = checkCommitmentMaturity(\n\t\t\tforceClose, commCsvMaturityHeight, 2,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// All funds should still be shown in limbo.\n\t\tif forceClose.LimboBalance == 0 {\n\t\t\treturn errors.New(\"all funds should still be in \" +\n\t\t\t\t\"limbo\")\n\t\t}\n\t\texpectedRecoveredBalance := int64(0)\n\t\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\t\texpectedRecoveredBalance = anchorSize\n\t\t}\n\t\tif forceClose.RecoveredBalance != expectedRecoveredBalance {\n\t\t\treturn errors.New(\"no funds should yet be shown \" +\n\t\t\t\t\"as recovered\")\n\t\t}\n\n\t\treturn nil\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout while checking force closed channel\")\n\n\t// Generate an additional block, which should cause the CSV delayed\n\t// output from the commitment txn to expire.\n\tht.MineBlocks(1)\n\n\t// At this point, the CSV will expire in the next block, meaning that\n\t// the sweeping transaction should now be broadcast. So we fetch the\n\t// node's mempool to ensure it has been properly broadcast.\n\tsweepingTXID := ht.Miner.AssertNumTxsInMempool(1)[0]\n\n\t// Fetch the sweep transaction, all input it's spending should be from\n\t// the commitment transaction which was broadcast on-chain.\n\tsweepTx := ht.Miner.GetRawTransaction(sweepingTXID)\n\tfor _, txIn := range sweepTx.MsgTx().TxIn {\n\t\trequire.Equal(ht, &txIn.PreviousOutPoint.Hash, closingTxID,\n\t\t\t\"sweep transaction not spending from commit\")\n\t}\n\n\t// We expect a resolution which spends our commit output.\n\toutput := sweepTx.MsgTx().TxIn[0].PreviousOutPoint\n\taliceReports[output.String()] = &lnrpc.Resolution{\n\t\tResolutionType: lnrpc.ResolutionType_COMMIT,\n\t\tOutcome:        lnrpc.ResolutionOutcome_CLAIMED,\n\t\tSweepTxid:      sweepingTXID.String(),\n\t\tOutpoint: &lnrpc.OutPoint{\n\t\t\tTxidBytes:   output.Hash[:],\n\t\t\tTxidStr:     output.Hash.String(),\n\t\t\tOutputIndex: output.Index,\n\t\t},\n\t\tAmountSat: uint64(aliceBalance),\n\t}\n\n\tcarolReports[carolCommit.OutPoint.String()] = &lnrpc.Resolution{\n\t\tResolutionType: lnrpc.ResolutionType_COMMIT,\n\t\tOutcome:        lnrpc.ResolutionOutcome_CLAIMED,\n\t\tOutpoint: &lnrpc.OutPoint{\n\t\t\tTxidBytes:   carolCommit.OutPoint.Hash[:],\n\t\t\tTxidStr:     carolCommit.OutPoint.Hash.String(),\n\t\t\tOutputIndex: carolCommit.OutPoint.Index,\n\t\t},\n\t\tAmountSat: uint64(pushAmt),\n\t\tSweepTxid: carolCommit.SweepTx.TxHash().String(),\n\t}\n\n\t// Check that we can find the commitment sweep in our set of known\n\t// sweeps, using the simple transaction id ListSweeps output.\n\tht.AssertSweepFound(alice, sweepingTXID.String(), false)\n\n\t// Restart Alice to ensure that she resumes watching the finalized\n\t// commitment sweep txid.\n\tht.RestartNode(alice)\n\n\t// Next, we mine an additional block which should include the sweep\n\t// transaction as the input scripts and the sequence locks on the\n\t// inputs should be properly met.\n\tblock := ht.MineBlocks(1)[0]\n\tht.Miner.AssertTxInBlock(block, sweepTx.Hash())\n\n\t// Update current height\n\t_, curHeight = ht.Miner.GetBestBlock()\n\n\t// checkForceClosedChannelNumHtlcs verifies that a force closed channel\n\t// has the proper number of htlcs.\n\tcheckPendingChannelNumHtlcs := func(\n\t\tforceClose lntest.PendingForceClose) error {\n\n\t\tif len(forceClose.PendingHtlcs) != numInvoices {\n\t\t\treturn fmt.Errorf(\"expected force closed channel to \"+\n\t\t\t\t\"have %d pending htlcs, found %d instead\",\n\t\t\t\tnumInvoices, len(forceClose.PendingHtlcs))\n\t\t}\n\n\t\treturn nil\n\t}\n\n\terr = wait.NoError(func() error {\n\t\t// Now that the commit output has been fully swept, check to\n\t\t// see that the channel remains open for the pending htlc\n\t\t// outputs.\n\t\tforceClose := ht.AssertChannelPendingForceClose(\n\t\t\talice, chanPoint,\n\t\t)\n\n\t\t// The commitment funds will have been recovered after the\n\t\t// commit txn was included in the last block. The htlc funds\n\t\t// will be shown in limbo.\n\t\terr := checkPendingChannelNumHtlcs(forceClose)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = checkPendingHtlcStageAndMaturity(\n\t\t\tforceClose, 1, htlcExpiryHeight,\n\t\t\tint32(htlcExpiryHeight)-curHeight,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif forceClose.LimboBalance == 0 {\n\t\t\treturn fmt.Errorf(\"expected funds in limbo, found 0\")\n\t\t}\n\n\t\treturn nil\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout checking pending \"+\n\t\t\"force close channel\")\n\n\t// Compute the height preceding that which will cause the htlc CLTV\n\t// timeouts will expire. The outputs entered at the same height as the\n\t// output spending from the commitment txn, so we must deduct the\n\t// number of blocks we have generated since adding it to the nursery,\n\t// and take an additional block off so that we end up one block shy of\n\t// the expiry height, and add the block padding.\n\tcltvHeightDelta := padCLTV(defaultCLTV - defaultCSV - 1 - 1)\n\n\t// Advance the blockchain until just before the CLTV expires, nothing\n\t// exciting should have happened during this time.\n\tht.MineBlocks(cltvHeightDelta)\n\n\t// We now restart Alice, to ensure that she will broadcast the presigned\n\t// htlc timeout txns after the delay expires after experiencing a while\n\t// waiting for the htlc outputs to incubate.\n\tht.RestartNode(alice)\n\n\t// Alice should now see the channel in her set of pending force closed\n\t// channels with one pending HTLC.\n\terr = wait.NoError(func() error {\n\t\tforceClose := ht.AssertChannelPendingForceClose(\n\t\t\talice, chanPoint,\n\t\t)\n\n\t\t// We should now be at the block just before the utxo nursery\n\t\t// will attempt to broadcast the htlc timeout transactions.\n\t\terr = checkPendingChannelNumHtlcs(forceClose)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = checkPendingHtlcStageAndMaturity(\n\t\t\tforceClose, 1, htlcExpiryHeight, 1,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Now that our commitment confirmation depth has been\n\t\t// surpassed, we should now see a non-zero recovered balance.\n\t\t// All htlc outputs are still left in limbo, so it should be\n\t\t// non-zero as well.\n\t\tif forceClose.LimboBalance == 0 {\n\t\t\treturn errors.New(\"htlc funds should still be in \" +\n\t\t\t\t\"limbo\")\n\t\t}\n\n\t\treturn nil\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout while checking force closed channel\")\n\n\t// Now, generate the block which will cause Alice to broadcast the\n\t// presigned htlc timeout txns.\n\tht.MineBlocks(1)\n\n\t// Since Alice had numInvoices (6) htlcs extended to Carol before force\n\t// closing, we expect Alice to broadcast an htlc timeout txn for each\n\t// one.\n\texpectedTxes = numInvoices\n\n\t// In case of anchors, the timeout txs will be aggregated into one.\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\texpectedTxes = 1\n\t}\n\n\t// Wait for them all to show up in the mempool.\n\thtlcTxIDs := ht.Miner.AssertNumTxsInMempool(expectedTxes)\n\n\t// Retrieve each htlc timeout txn from the mempool, and ensure it is\n\t// well-formed. This entails verifying that each only spends from\n\t// output, and that output is from the commitment txn. In case this is\n\t// an anchor channel, the transactions are aggregated by the sweeper\n\t// into one.\n\tnumInputs := 1\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\tnumInputs = numInvoices + 1\n\t}\n\n\t// Construct a map of the already confirmed htlc timeout outpoints,\n\t// that will count the number of times each is spent by the sweep txn.\n\t// We prepopulate it in this way so that we can later detect if we are\n\t// spending from an output that was not a confirmed htlc timeout txn.\n\tvar htlcTxOutpointSet = make(map[wire.OutPoint]int)\n\n\tvar htlcLessFees uint64\n\tfor _, htlcTxID := range htlcTxIDs {\n\t\t// Fetch the sweep transaction, all input it's spending should\n\t\t// be from the commitment transaction which was broadcast\n\t\t// on-chain. In case of an anchor type channel, we expect one\n\t\t// extra input that is not spending from the commitment, that\n\t\t// is added for fees.\n\t\thtlcTx := ht.Miner.GetRawTransaction(htlcTxID)\n\n\t\t// Ensure the htlc transaction has the expected number of\n\t\t// inputs.\n\t\tinputs := htlcTx.MsgTx().TxIn\n\t\trequire.Len(ht, inputs, numInputs, \"num inputs mismatch\")\n\n\t\t// The number of outputs should be the same.\n\t\toutputs := htlcTx.MsgTx().TxOut\n\t\trequire.Len(ht, outputs, numInputs, \"num outputs mismatch\")\n\n\t\t// Ensure all the htlc transaction inputs are spending from the\n\t\t// commitment transaction, except if this is an extra input\n\t\t// added to pay for fees for anchor channels.\n\t\tnonCommitmentInputs := 0\n\t\tfor i, txIn := range inputs {\n\t\t\tif !closingTxID.IsEqual(&txIn.PreviousOutPoint.Hash) {\n\t\t\t\tnonCommitmentInputs++\n\n\t\t\t\trequire.Lessf(ht, nonCommitmentInputs, 2,\n\t\t\t\t\t\"htlc transaction not \"+\n\t\t\t\t\t\t\"spending from commit \"+\n\t\t\t\t\t\t\"tx %v, instead spending %v\",\n\t\t\t\t\tclosingTxID, txIn.PreviousOutPoint)\n\n\t\t\t\t// This was an extra input added to pay fees,\n\t\t\t\t// continue to the next one.\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// For each htlc timeout transaction, we expect a\n\t\t\t// resolver report recording this on chain resolution\n\t\t\t// for both alice and carol.\n\t\t\toutpoint := txIn.PreviousOutPoint\n\t\t\tresolutionOutpoint := &lnrpc.OutPoint{\n\t\t\t\tTxidBytes:   outpoint.Hash[:],\n\t\t\t\tTxidStr:     outpoint.Hash.String(),\n\t\t\t\tOutputIndex: outpoint.Index,\n\t\t\t}\n\n\t\t\t// We expect alice to have a timeout tx resolution with\n\t\t\t// an amount equal to the payment amount.\n\t\t\taliceReports[outpoint.String()] = &lnrpc.Resolution{\n\t\t\t\tResolutionType: lnrpc.ResolutionType_OUTGOING_HTLC,\n\t\t\t\tOutcome:        lnrpc.ResolutionOutcome_FIRST_STAGE,\n\t\t\t\tSweepTxid:      htlcTx.Hash().String(),\n\t\t\t\tOutpoint:       resolutionOutpoint,\n\t\t\t\tAmountSat:      uint64(paymentAmt),\n\t\t\t}\n\n\t\t\t// We expect carol to have a resolution with an\n\t\t\t// incoming htlc timeout which reflects the full amount\n\t\t\t// of the htlc. It has no spend tx, because carol stops\n\t\t\t// monitoring the htlc once it has timed out.\n\t\t\tcarolReports[outpoint.String()] = &lnrpc.Resolution{\n\t\t\t\tResolutionType: lnrpc.ResolutionType_INCOMING_HTLC,\n\t\t\t\tOutcome:        lnrpc.ResolutionOutcome_TIMEOUT,\n\t\t\t\tSweepTxid:      \"\",\n\t\t\t\tOutpoint:       resolutionOutpoint,\n\t\t\t\tAmountSat:      uint64(paymentAmt),\n\t\t\t}\n\n\t\t\t// Recorf the HTLC outpoint, such that we can later\n\t\t\t// check whether it gets swept\n\t\t\top := wire.OutPoint{\n\t\t\t\tHash:  *htlcTxID,\n\t\t\t\tIndex: uint32(i),\n\t\t\t}\n\t\t\thtlcTxOutpointSet[op] = 0\n\t\t}\n\n\t\t// We record the htlc amount less fees here, so that we know\n\t\t// what value to expect for the second stage of our htlc\n\t\t// resolution.\n\t\thtlcLessFees = uint64(outputs[0].Value)\n\t}\n\n\t// With the htlc timeout txns still in the mempool, we restart Alice to\n\t// verify that she can resume watching the htlc txns she broadcasted\n\t// before crashing.\n\tht.RestartNode(alice)\n\n\t// Generate a block that mines the htlc timeout txns. Doing so now\n\t// activates the 2nd-stage CSV delayed outputs.\n\tht.MineBlocks(1)\n\n\t// Alice is restarted here to ensure that she promptly moved the crib\n\t// outputs to the kindergarten bucket after the htlc timeout txns were\n\t// confirmed.\n\tht.RestartNode(alice)\n\n\t// Advance the chain until just before the 2nd-layer CSV delays expire.\n\t// For anchor channels thhis is one block earlier.\n\tnumBlocks := uint32(defaultCSV - 1)\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\tnumBlocks = defaultCSV - 2\n\t}\n\tht.MineBlocks(numBlocks)\n\n\t// Restart Alice to ensure that she can recover from a failure before\n\t// having graduated the htlc outputs in the kindergarten bucket.\n\tht.RestartNode(alice)\n\n\t// Now that the channel has been fully swept, it should no longer show\n\t// incubated, check to see that Alice's node still reports the channel\n\t// as pending force closed.\n\terr = wait.NoError(func() error {\n\t\tforceClose := ht.AssertChannelPendingForceClose(\n\t\t\talice, chanPoint,\n\t\t)\n\n\t\tif forceClose.LimboBalance == 0 {\n\t\t\treturn fmt.Errorf(\"htlc funds should still be in limbo\")\n\t\t}\n\n\t\treturn checkPendingChannelNumHtlcs(forceClose)\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout while checking force closed channel\")\n\n\t// Generate a block that causes Alice to sweep the htlc outputs in the\n\t// kindergarten bucket.\n\tht.MineBlocks(1)\n\n\t// Wait for the single sweep txn to appear in the mempool.\n\thtlcSweepTxID := ht.Miner.AssertNumTxsInMempool(1)[0]\n\n\t// Fetch the htlc sweep transaction from the mempool.\n\thtlcSweepTx := ht.Miner.GetRawTransaction(htlcSweepTxID)\n\n\t// Ensure the htlc sweep transaction only has one input for each htlc\n\t// Alice extended before force closing.\n\trequire.Len(ht, htlcSweepTx.MsgTx().TxIn, numInvoices,\n\t\t\"htlc transaction has wrong num of inputs\")\n\trequire.Len(ht, htlcSweepTx.MsgTx().TxOut, 1,\n\t\t\"htlc sweep transaction should have one output\")\n\n\t// Ensure that each output spends from exactly one htlc timeout output.\n\tfor _, txIn := range htlcSweepTx.MsgTx().TxIn {\n\t\toutpoint := txIn.PreviousOutPoint\n\t\t// Check that the input is a confirmed htlc timeout txn.\n\t\t_, ok := htlcTxOutpointSet[outpoint]\n\t\trequire.Truef(ht, ok, \"htlc sweep output not spending from \"+\n\t\t\t\"htlc tx, instead spending output %v\", outpoint)\n\n\t\t// Increment our count for how many times this output was spent.\n\t\thtlcTxOutpointSet[outpoint]++\n\n\t\t// Check that each is only spent once.\n\t\trequire.Lessf(ht, htlcTxOutpointSet[outpoint], 2,\n\t\t\t\"htlc sweep tx has multiple spends from \"+\n\t\t\t\t\"outpoint %v\", outpoint)\n\n\t\t// Since we have now swept our htlc timeout tx, we expect to\n\t\t// have timeout resolutions for each of our htlcs.\n\t\toutput := txIn.PreviousOutPoint\n\t\taliceReports[output.String()] = &lnrpc.Resolution{\n\t\t\tResolutionType: lnrpc.ResolutionType_OUTGOING_HTLC,\n\t\t\tOutcome:        lnrpc.ResolutionOutcome_TIMEOUT,\n\t\t\tSweepTxid:      htlcSweepTx.Hash().String(),\n\t\t\tOutpoint: &lnrpc.OutPoint{\n\t\t\t\tTxidBytes:   output.Hash[:],\n\t\t\t\tTxidStr:     output.Hash.String(),\n\t\t\t\tOutputIndex: output.Index,\n\t\t\t},\n\t\t\tAmountSat: htlcLessFees,\n\t\t}\n\t}\n\n\t// Check that each HTLC output was spent exactly once.\n\tfor op, num := range htlcTxOutpointSet {\n\t\trequire.Equalf(ht, 1, num,\n\t\t\t\"HTLC outpoint:%s was spent times\", op)\n\t}\n\n\t// Check that we can find the htlc sweep in our set of sweeps using\n\t// the verbose output of the listsweeps output.\n\tht.AssertSweepFound(alice, htlcSweepTx.Hash().String(), true)\n\n\t// The following restart checks to ensure that the nursery store is\n\t// storing the txid of the previously broadcast htlc sweep txn, and that\n\t// it begins watching that txid after restarting.\n\tht.RestartNode(alice)\n\n\t// Now that the channel has been fully swept, it should no longer show\n\t// incubated, check to see that Alice's node still reports the channel\n\t// as pending force closed.\n\terr = wait.NoError(func() error {\n\t\tforceClose := ht.AssertChannelPendingForceClose(\n\t\t\talice, chanPoint,\n\t\t)\n\t\terr := checkPendingChannelNumHtlcs(forceClose)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = checkPendingHtlcStageAndMaturity(\n\t\t\tforceClose, 2, htlcCsvMaturityHeight, 0,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn nil\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout while checking force closed channel\")\n\n\t// Generate the final block that sweeps all htlc funds into the user's\n\t// wallet, and make sure the sweep is in this block.\n\tblock = ht.MineBlocksAndAssertNumTxes(1, 1)[0]\n\tht.Miner.AssertTxInBlock(block, htlcSweepTxID)\n\n\t// Now that the channel has been fully swept, it should no longer show\n\t// up within the pending channels RPC.\n\terr = wait.NoError(func() error {\n\t\tht.AssertNumPendingForceClose(alice, 0)\n\t\t// In addition to there being no pending channels, we verify\n\t\t// that pending channels does not report any money still in\n\t\t// limbo.\n\t\tpendingChanResp := alice.RPC.PendingChannels()\n\t\tif pendingChanResp.TotalLimboBalance != 0 {\n\t\t\treturn errors.New(\"no user funds should be left \" +\n\t\t\t\t\"in limbo after incubation\")\n\t\t}\n\n\t\treturn nil\n\t}, defaultTimeout)\n\trequire.NoError(ht, err, \"timeout checking limbo balance\")\n\n\t// At this point, Carol should now be aware of her new immediately\n\t// spendable on-chain balance, as it was Alice who broadcast the\n\t// commitment transaction.\n\tcarolBalResp = carol.RPC.WalletBalance()\n\n\t// Carol's expected balance should be its starting balance plus the\n\t// push amount sent by Alice and minus the miner fee paid.\n\tcarolExpectedBalance := btcutil.Amount(carolStartingBalance) +\n\t\tpushAmt - totalFeeCarol\n\n\t// In addition, if this is an anchor-enabled channel, further add the\n\t// anchor size.\n\tif channelType == lnrpc.CommitmentType_ANCHORS {\n\t\tcarolExpectedBalance += btcutil.Amount(anchorSize)\n\t}\n\n\trequire.Equal(ht, carolExpectedBalance,\n\t\tbtcutil.Amount(carolBalResp.ConfirmedBalance),\n\t\t\"carol's balance is incorrect\")\n\n\t// Finally, we check that alice and carol have the set of resolutions\n\t// we expect.\n\tassertReports(ht, alice, chanPoint, aliceReports)\n\tassertReports(ht, carol, chanPoint, carolReports)\n}\n\n// padCLTV is a small helper function that pads a cltv value with a block\n// padding.",
      "length": 25615,
      "tokens": 3449,
      "embedding": []
    },
    {
      "slug": "func padCLTV(cltv uint32) uint32 {",
      "content": "func padCLTV(cltv uint32) uint32 {\n\treturn cltv + uint32(routing.BlockPadding)\n}\n\n// testFailingChannel tests that we will fail the channel by force closing it\n// in the case where a counterparty tries to settle an HTLC with the wrong\n// preimage.",
      "length": 207,
      "tokens": 35,
      "embedding": []
    },
    {
      "slug": "func testFailingChannel(ht *lntest.HarnessTest) {",
      "content": "func testFailingChannel(ht *lntest.HarnessTest) {\n\tconst paymentAmt = 10000\n\n\tchanAmt := lnd.MaxFundingAmount\n\n\t// We'll introduce Carol, which will settle any incoming invoice with a\n\t// totally unrelated preimage.\n\tcarol := ht.NewNode(\"Carol\", []string{\"--hodl.bogus-settle\"})\n\n\talice := ht.Alice\n\tht.ConnectNodes(alice, carol)\n\n\t// Let Alice connect and open a channel to Carol,\n\tht.OpenChannel(alice, carol, lntest.OpenChannelParams{Amt: chanAmt})\n\n\t// With the channel open, we'll create a invoice for Carol that Alice\n\t// will attempt to pay.\n\tpreimage := bytes.Repeat([]byte{byte(192)}, 32)\n\tinvoice := &lnrpc.Invoice{\n\t\tMemo:      \"testing\",\n\t\tRPreimage: preimage,\n\t\tValue:     paymentAmt,\n\t}\n\tresp := carol.RPC.AddInvoice(invoice)\n\n\t// Send the payment from Alice to Carol. We expect Carol to attempt to\n\t// settle this payment with the wrong preimage.\n\t//\n\t// NOTE: cannot use `CompletePaymentRequestsNoWait` here as the channel\n\t// will be force closed, so the num of updates check in that function\n\t// won't work as the channel cannot be found.\n\treq := &routerrpc.SendPaymentRequest{\n\t\tPaymentRequest: resp.PaymentRequest,\n\t\tTimeoutSeconds: 60,\n\t\tFeeLimitMsat:   noFeeLimitMsat,\n\t}\n\tht.SendPaymentAndAssertStatus(alice, req, lnrpc.Payment_IN_FLIGHT)\n\n\t// Since Alice detects that Carol is trying to trick her by providing a\n\t// fake preimage, she should fail and force close the channel.\n\tht.AssertNumWaitingClose(alice, 1)\n\n\t// Mine a block to confirm the broadcasted commitment.\n\tblock := ht.MineBlocksAndAssertNumTxes(1, 1)[0]\n\trequire.Len(ht, block.Transactions, 2, \"transaction wasn't mined\")\n\n\t// The channel should now show up as force closed both for Alice and\n\t// Carol.\n\tht.AssertNumPendingForceClose(alice, 1)\n\tht.AssertNumPendingForceClose(carol, 1)\n\n\t// Carol will use the correct preimage to resolve the HTLC on-chain.\n\tht.Miner.AssertNumTxsInMempool(1)\n\n\t// Mine enough blocks for Alice to sweep her funds from the force\n\t// closed channel.\n\tht.MineBlocks(defaultCSV - 1)\n\n\t// Wait for the sweeping tx to be broadcast.\n\tht.Miner.AssertNumTxsInMempool(1)\n\n\t// Mine the sweep.\n\tht.MineBlocks(1)\n\n\t// No pending channels should be left.\n\tht.AssertNumPendingForceClose(alice, 0)\n}\n\n// assertReports checks that the count of resolutions we have present per\n// type matches a set of expected resolutions.\n//\n// NOTE: only used in current test file.",
      "length": 2249,
      "tokens": 301,
      "embedding": []
    },
    {
      "slug": "func assertReports(ht *lntest.HarnessTest, hn *node.HarnessNode,",
      "content": "func assertReports(ht *lntest.HarnessTest, hn *node.HarnessNode,\n\tchanPoint *lnrpc.ChannelPoint, expected map[string]*lnrpc.Resolution) {\n\n\top := ht.OutPointFromChannelPoint(chanPoint)\n\n\t// Get our node's closed channels.\n\treq := &lnrpc.ClosedChannelsRequest{Abandoned: false}\n\tclosed := hn.RPC.ClosedChannels(req)\n\n\tvar resolutions []*lnrpc.Resolution\n\tfor _, close := range closed.Channels {\n\t\tif close.ChannelPoint == op.String() {\n\t\t\tresolutions = close.Resolutions\n\t\t\tbreak\n\t\t}\n\t}\n\n\trequire.NotNil(ht, resolutions)\n\trequire.Equal(ht, len(expected), len(resolutions))\n\n\tfor _, res := range resolutions {\n\t\toutPointStr := fmt.Sprintf(\"%v:%v\", res.Outpoint.TxidStr,\n\t\t\tres.Outpoint.OutputIndex)\n\n\t\texpected, ok := expected[outPointStr]\n\t\trequire.True(ht, ok)\n\t\trequire.Equal(ht, expected, res)\n\t}\n}\n\n// checkCommitmentMaturity checks that both the maturity height and blocks\n// maturity height are as expected.\n//\n// NOTE: only used in current test file.",
      "length": 859,
      "tokens": 95,
      "embedding": []
    },
    {
      "slug": "func checkCommitmentMaturity(forceClose lntest.PendingForceClose,",
      "content": "func checkCommitmentMaturity(forceClose lntest.PendingForceClose,\n\tmaturityHeight uint32, blocksTilMaturity int32) error {\n\n\tif forceClose.MaturityHeight != maturityHeight {\n\t\treturn fmt.Errorf(\"expected commitment maturity height to be \"+\n\t\t\t\"%d, found %d instead\", maturityHeight,\n\t\t\tforceClose.MaturityHeight)\n\t}\n\tif forceClose.BlocksTilMaturity != blocksTilMaturity {\n\t\treturn fmt.Errorf(\"expected commitment blocks til maturity to \"+\n\t\t\t\"be %d, found %d instead\", blocksTilMaturity,\n\t\t\tforceClose.BlocksTilMaturity)\n\t}\n\n\treturn nil\n}\n\n// checkPendingHtlcStageAndMaturity uniformly tests all pending htlc's belonging\n// to a force closed channel, testing for the expected stage number, blocks till\n// maturity, and the maturity height.\n//\n// NOTE: only used in current test file.",
      "length": 697,
      "tokens": 87,
      "embedding": []
    },
    {
      "slug": "func checkPendingHtlcStageAndMaturity(",
      "content": "func checkPendingHtlcStageAndMaturity(\n\tforceClose *lnrpc.PendingChannelsResponse_ForceClosedChannel,\n\tstage, maturityHeight uint32, blocksTillMaturity int32) error {\n\n\tfor _, pendingHtlc := range forceClose.PendingHtlcs {\n\t\tif pendingHtlc.Stage != stage {\n\t\t\treturn fmt.Errorf(\"expected pending htlc to be stage \"+\n\t\t\t\t\"%d, found %d\", stage, pendingHtlc.Stage)\n\t\t}\n\t\tif pendingHtlc.MaturityHeight != maturityHeight {\n\t\t\treturn fmt.Errorf(\"expected pending htlc maturity \"+\n\t\t\t\t\"height to be %d, instead has %d\",\n\t\t\t\tmaturityHeight, pendingHtlc.MaturityHeight)\n\t\t}\n\t\tif pendingHtlc.BlocksTilMaturity != blocksTillMaturity {\n\t\t\treturn fmt.Errorf(\"expected pending htlc blocks til \"+\n\t\t\t\t\"maturity to be %d, instead has %d\",\n\t\t\t\tblocksTillMaturity,\n\t\t\t\tpendingHtlc.BlocksTilMaturity)\n\t\t}\n\t}\n\n\treturn nil\n}\n",
      "length": 742,
      "tokens": 82,
      "embedding": []
    }
  ]
}