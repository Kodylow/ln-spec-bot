{
  "filepath": "../implementations/go/lnd/batch/scheduler.go",
  "package": "batch",
  "sections": [
    {
      "slug": "type TimeScheduler struct {",
      "content": "type TimeScheduler struct {\n\tdb       kvdb.Backend\n\tlocker   sync.Locker\n\tduration time.Duration\n\n\tmu sync.Mutex\n\tb  *batch\n}\n\n// NewTimeScheduler initializes a new TimeScheduler with a fixed duration at\n// which to schedule batches. If the operation needs to modify a higher-level\n// cache, the cache's lock should be provided to so that external consistency\n// can be maintained, as successful db operations will cause a request's\n// OnCommit method to be executed while holding this lock.",
      "length": 451,
      "tokens": 70,
      "embedding": []
    },
    {
      "slug": "func NewTimeScheduler(db kvdb.Backend, locker sync.Locker,",
      "content": "func NewTimeScheduler(db kvdb.Backend, locker sync.Locker,\n\tduration time.Duration) *TimeScheduler {\n\n\treturn &TimeScheduler{\n\t\tdb:       db,\n\t\tlocker:   locker,\n\t\tduration: duration,\n\t}\n}\n\n// Execute schedules the provided request for batch execution along with other\n// concurrent requests. The request will be executed within a fixed horizon,\n// parameterizeed by the duration of the scheduler. The error from the\n// underlying operation is returned to the caller.\n//\n// NOTE: Part of the Scheduler interface.",
      "length": 439,
      "tokens": 66,
      "embedding": []
    },
    {
      "slug": "func (s *TimeScheduler) Execute(r *Request) error {",
      "content": "func (s *TimeScheduler) Execute(r *Request) error {\n\treq := request{\n\t\tRequest: r,\n\t\terrChan: make(chan error, 1),\n\t}\n\n\t// Add the request to the current batch. If the batch has been cleared\n\t// or no batch exists, create a new one.\n\ts.mu.Lock()\n\tif s.b == nil {\n\t\ts.b = &batch{\n\t\t\tdb:     s.db,\n\t\t\tclear:  s.clear,\n\t\t\tlocker: s.locker,\n\t\t}\n\t\ttime.AfterFunc(s.duration, s.b.trigger)\n\t}\n\ts.b.reqs = append(s.b.reqs, &req)\n\n\t// If this is a non-lazy request, we'll execute the batch immediately.\n\tif !r.lazy {\n\t\tgo s.b.trigger()\n\t}\n\n\ts.mu.Unlock()\n\n\t// Wait for the batch to process the request. If the batch didn't\n\t// ask us to execute the request individually, simply return the error.\n\terr := <-req.errChan\n\tif err != errSolo {\n\t\treturn err\n\t}\n\n\t// Obtain exclusive access to the cache if this scheduler needs to\n\t// modify the cache in OnCommit.\n\tif s.locker != nil {\n\t\ts.locker.Lock()\n\t\tdefer s.locker.Unlock()\n\t}\n\n\t// Otherwise, run the request on its own.\n\tcommitErr := kvdb.Update(s.db, req.Update, func() {\n\t\tif req.Reset != nil {\n\t\t\treq.Reset()\n\t\t}\n\t})\n\n\t// Finally, return the commit error directly or execute the OnCommit\n\t// closure with the commit error if present.\n\tif req.OnCommit != nil {\n\t\treturn req.OnCommit(commitErr)\n\t}\n\n\treturn commitErr\n}\n\n// clear resets the scheduler's batch to nil so that no more requests can be\n// added.",
      "length": 1241,
      "tokens": 207,
      "embedding": []
    },
    {
      "slug": "func (s *TimeScheduler) clear(b *batch) {",
      "content": "func (s *TimeScheduler) clear(b *batch) {\n\ts.mu.Lock()\n\tif s.b == b {\n\t\ts.b = nil\n\t}\n\ts.mu.Unlock()\n}\n",
      "length": 54,
      "tokens": 12,
      "embedding": []
    }
  ]
}