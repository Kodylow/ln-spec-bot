{
  "filepath": "../implementations/go/lnd/batch/batch.go",
  "package": "batch",
  "sections": [
    {
      "slug": "type request struct {",
      "content": "type request struct {\n\t*Request\n\terrChan chan error\n}\n",
      "length": 29,
      "tokens": 5,
      "embedding": []
    },
    {
      "slug": "type batch struct {",
      "content": "type batch struct {\n\tdb     kvdb.Backend\n\tstart  sync.Once\n\treqs   []*request\n\tclear  func(b *batch)\n\tlocker sync.Locker\n}\n\n// trigger is the entry point for the batch and ensures that run is started at\n// most once.",
      "length": 188,
      "tokens": 31,
      "embedding": []
    },
    {
      "slug": "func (b *batch) trigger() {",
      "content": "func (b *batch) trigger() {\n\tb.start.Do(b.run)\n}\n\n// run executes the current batch of requests. If any individual requests fail\n// alongside others they will be retried by the caller.",
      "length": 152,
      "tokens": 25,
      "embedding": []
    },
    {
      "slug": "func (b *batch) run() {",
      "content": "func (b *batch) run() {\n\t// Clear the batch from its scheduler, ensuring that no new requests are\n\t// added to this batch.\n\tb.clear(b)\n\n\t// If a cache lock was provided, hold it until the this method returns.\n\t// This is critical for ensuring external consistency of the operation,\n\t// so that caches don't get out of sync with the on disk state.\n\tif b.locker != nil {\n\t\tb.locker.Lock()\n\t\tdefer b.locker.Unlock()\n\t}\n\n\t// Apply the batch until a subset succeeds or all of them fail. Requests\n\t// that fail will be retried individually.\n\tfor len(b.reqs) > 0 {\n\t\tvar failIdx = -1\n\t\terr := kvdb.Update(b.db, func(tx kvdb.RwTx) error {\n\t\t\tfor i, req := range b.reqs {\n\t\t\t\terr := req.Update(tx)\n\t\t\t\tif err != nil {\n\t\t\t\t\tfailIdx = i\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t}, func() {\n\t\t\tfor _, req := range b.reqs {\n\t\t\t\tif req.Reset != nil {\n\t\t\t\t\treq.Reset()\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\n\t\t// If a request's Update failed, extract it and re-run the\n\t\t// batch. The removed request will be retried individually by\n\t\t// the caller.\n\t\tif failIdx >= 0 {\n\t\t\treq := b.reqs[failIdx]\n\n\t\t\t// It's safe to shorten b.reqs here because the\n\t\t\t// scheduler's batch no longer points to us.\n\t\t\tb.reqs[failIdx] = b.reqs[len(b.reqs)-1]\n\t\t\tb.reqs = b.reqs[:len(b.reqs)-1]\n\n\t\t\t// Tell the submitter re-run it solo, continue with the\n\t\t\t// rest of the batch.\n\t\t\treq.errChan <- errSolo\n\t\t\tcontinue\n\t\t}\n\n\t\t// None of the remaining requests failed, process the errors\n\t\t// using each request's OnCommit closure and return the error\n\t\t// to the requester. If no OnCommit closure is provided, simply\n\t\t// return the error directly.\n\t\tfor _, req := range b.reqs {\n\t\t\tif req.OnCommit != nil {\n\t\t\t\treq.errChan <- req.OnCommit(err)\n\t\t\t} else {\n\t\t\t\treq.errChan <- err\n\t\t\t}\n\t\t}\n\n\t\treturn\n\t}\n}\n",
      "length": 1658,
      "tokens": 284,
      "embedding": []
    }
  ]
}