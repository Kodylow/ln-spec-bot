{
  "filepath": "../implementations/go/lnd/routing/probability_apriori_test.go",
  "package": "routing",
  "sections": [
    {
      "slug": "type estimatorTestContext struct {",
      "content": "type estimatorTestContext struct {\n\tt         *testing.T\n\testimator *AprioriEstimator\n\n\t// results contains a list of last results. Every element in the list\n\t// corresponds to the last result towards a node. The list index equals\n\t// the node id. So the first element in the list is the result towards\n\t// node 0.\n\tresults map[int]TimedPairResult\n}\n",
      "length": 306,
      "tokens": 51,
      "embedding": []
    },
    {
      "slug": "func newEstimatorTestContext(t *testing.T) *estimatorTestContext {",
      "content": "func newEstimatorTestContext(t *testing.T) *estimatorTestContext {\n\treturn &estimatorTestContext{\n\t\tt: t,\n\t\testimator: &AprioriEstimator{\n\t\t\tAprioriConfig: AprioriConfig{\n\t\t\t\tAprioriHopProbability: aprioriHopProb,\n\t\t\t\tAprioriWeight:         aprioriWeight,\n\t\t\t\tPenaltyHalfLife:       time.Hour,\n\t\t\t\tCapacityFraction:      testCapacityFraction,\n\t\t\t},\n\t\t\tprevSuccessProbability: aprioriPrevSucProb,\n\t\t},\n\t}\n}\n\n// assertPairProbability asserts that the calculated success probability is\n// correct.",
      "length": 412,
      "tokens": 33,
      "embedding": []
    },
    {
      "slug": "func (c *estimatorTestContext) assertPairProbability(now time.Time,",
      "content": "func (c *estimatorTestContext) assertPairProbability(now time.Time,\n\ttoNode byte, amt lnwire.MilliSatoshi, capacity btcutil.Amount,\n\texpectedProb float64) {\n\n\tc.t.Helper()\n\n\tresults := make(NodeResults)\n\tfor i, r := range c.results {\n\t\tresults[route.Vertex{byte(i)}] = r\n\t}\n\n\tconst tolerance = 0.01\n\n\tp := c.estimator.PairProbability(\n\t\tnow, results, route.Vertex{toNode}, amt, capacity,\n\t)\n\tdiff := p - expectedProb\n\tif diff > tolerance || diff < -tolerance {\n\t\tc.t.Fatalf(\"expected probability %v for node %v, but got %v\",\n\t\t\texpectedProb, toNode, p)\n\t}\n}\n\n// TestProbabilityEstimatorNoResults tests the probability estimation when no\n// results are available.",
      "length": 571,
      "tokens": 77,
      "embedding": []
    },
    {
      "slug": "func TestProbabilityEstimatorNoResults(t *testing.T) {",
      "content": "func TestProbabilityEstimatorNoResults(t *testing.T) {\n\tt.Parallel()\n\n\tctx := newEstimatorTestContext(t)\n\n\t// A zero amount does not trigger capacity rescaling.\n\tctx.assertPairProbability(\n\t\ttestTime, 0, 0, testCapacity, aprioriHopProb,\n\t)\n\n\t// We expect a reduced probability when a higher amount is used.\n\texpected := aprioriHopProb * capFactor\n\tctx.assertPairProbability(\n\t\ttestTime, 0, testAmount, testCapacity, expected,\n\t)\n}\n\n// TestProbabilityEstimatorOneSuccess tests the probability estimation for nodes\n// that have a single success result.",
      "length": 478,
      "tokens": 60,
      "embedding": []
    },
    {
      "slug": "func TestProbabilityEstimatorOneSuccess(t *testing.T) {",
      "content": "func TestProbabilityEstimatorOneSuccess(t *testing.T) {\n\tt.Parallel()\n\n\tctx := newEstimatorTestContext(t)\n\n\tctx.results = map[int]TimedPairResult{\n\t\tnode1: {\n\t\t\tSuccessAmt: testAmount,\n\t\t},\n\t}\n\n\t// Because of the previous success, this channel keep reporting a high\n\t// probability.\n\tctx.assertPairProbability(\n\t\ttestTime, node1, 100, testCapacity, aprioriPrevSucProb,\n\t)\n\n\t// The apriori success probability indicates that in the past we were\n\t// able to send the full amount. We don't want to reduce this\n\t// probability with the capacity factor, which is tested here.\n\tctx.assertPairProbability(\n\t\ttestTime, node1, testAmount, testCapacity, aprioriPrevSucProb,\n\t)\n\n\t// Untried channels are also influenced by the success. With a\n\t// aprioriWeight of 0.75, the a priori probability is assigned weight 3.\n\texpectedP := (3*aprioriHopProb + 1*aprioriPrevSucProb) / 4\n\tctx.assertPairProbability(\n\t\ttestTime, untriedNode, 100, testCapacity, expectedP,\n\t)\n\n\t// Check that the correct probability is computed for larger amounts.\n\tapriori := aprioriHopProb * capFactor\n\n\texpectedP = (3*apriori + 1*aprioriPrevSucProb) / 4\n\tctx.assertPairProbability(\n\t\ttestTime, untriedNode, testAmount, testCapacity, expectedP,\n\t)\n}\n\n// TestProbabilityEstimatorOneFailure tests the probability estimation for nodes\n// that have a single failure.",
      "length": 1227,
      "tokens": 158,
      "embedding": []
    },
    {
      "slug": "func TestProbabilityEstimatorOneFailure(t *testing.T) {",
      "content": "func TestProbabilityEstimatorOneFailure(t *testing.T) {\n\tt.Parallel()\n\n\tctx := newEstimatorTestContext(t)\n\n\tctx.results = map[int]TimedPairResult{\n\t\tnode1: {\n\t\t\tFailTime: testTime.Add(-time.Hour),\n\t\t\tFailAmt:  lnwire.MilliSatoshi(50),\n\t\t},\n\t}\n\n\t// For an untried node, we expected the node probability. The weight for\n\t// the failure after one hour is 0.5. This makes the node probability\n\t// 0.51:\n\texpectedNodeProb := (3*aprioriHopProb + 0.5*0) / 3.5\n\tctx.assertPairProbability(\n\t\ttestTime, untriedNode, 100, testCapacity, expectedNodeProb,\n\t)\n\n\t// The pair probability decays back to the node probability. With the\n\t// weight at 0.5, we expected a pair probability of 0.5 * 0.51 = 0.25.\n\tctx.assertPairProbability(\n\t\ttestTime, node1, 100, testCapacity, expectedNodeProb/2,\n\t)\n}\n\n// TestProbabilityEstimatorMix tests the probability estimation for nodes for\n// which a mix of successes and failures is recorded.",
      "length": 830,
      "tokens": 111,
      "embedding": []
    },
    {
      "slug": "func TestProbabilityEstimatorMix(t *testing.T) {",
      "content": "func TestProbabilityEstimatorMix(t *testing.T) {\n\tt.Parallel()\n\n\tctx := newEstimatorTestContext(t)\n\n\tctx.results = map[int]TimedPairResult{\n\t\tnode1: {\n\t\t\tSuccessAmt: lnwire.MilliSatoshi(1000),\n\t\t},\n\t\tnode2: {\n\t\t\tFailTime: testTime.Add(-2 * time.Hour),\n\t\t\tFailAmt:  lnwire.MilliSatoshi(50),\n\t\t},\n\t\tnode3: {\n\t\t\tFailTime: testTime.Add(-3 * time.Hour),\n\t\t\tFailAmt:  lnwire.MilliSatoshi(50),\n\t\t},\n\t}\n\n\t// We expect the probability for a previously successful channel to\n\t// remain high.\n\tctx.assertPairProbability(\n\t\ttestTime, node1, 100, testCapacity, prevSuccessProbability,\n\t)\n\n\t// For an untried node, we expected the node probability to be returned.\n\t// This is a weighted average of the results above and the a priori\n\t// probability: 0.62.\n\texpectedNodeProb := (3*aprioriHopProb + 1*prevSuccessProbability) /\n\t\t(3 + 1 + 0.25 + 0.125)\n\n\tctx.assertPairProbability(\n\t\ttestTime, untriedNode, 100, testCapacity, expectedNodeProb,\n\t)\n\n\t// For the previously failed connection with node 1, we expect 0.75 *\n\t// the node probability = 0.47.\n\tctx.assertPairProbability(\n\t\ttestTime, node2, 100, testCapacity, expectedNodeProb*0.75,\n\t)\n}\n\n// TestCapacityCutoff tests the mathematical expression and limits for the\n// capacity factor.",
      "length": 1133,
      "tokens": 142,
      "embedding": []
    },
    {
      "slug": "func TestCapacityCutoff(t *testing.T) {",
      "content": "func TestCapacityCutoff(t *testing.T) {\n\tt.Parallel()\n\n\tcapacitySat := 1_000_000\n\tcapacityMSat := capacitySat * 1000\n\n\ttests := []struct {\n\t\tname             string\n\t\tcapacityFraction float64\n\t\tamountMsat       int\n\t\texpectedFactor   float64\n\t}{\n\t\t// Minimal CapacityFraction of 0.75.\n\t\t{\n\t\t\tname:             \"zero amount\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\texpectedFactor:   1,\n\t\t},\n\t\t{\n\t\t\tname:             \"low amount\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\tamountMsat:       capacityMSat / 10,\n\t\t\texpectedFactor:   1,\n\t\t},\n\t\t{\n\t\t\tname:             \"half amount\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\tamountMsat:       capacityMSat / 2,\n\t\t\texpectedFactor:   1,\n\t\t},\n\t\t{\n\t\t\tname:             \"cutoff amount\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\tamountMsat: int(\n\t\t\t\t0.75 * float64(capacityMSat),\n\t\t\t),\n\t\t\texpectedFactor: 0.75,\n\t\t},\n\t\t{\n\t\t\tname:             \"high amount\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\tamountMsat:       capacityMSat * 80 / 100,\n\t\t\texpectedFactor:   0.560,\n\t\t},\n\t\t{\n\t\t\t// Even when we spend the full capacity, we still want\n\t\t\t// to have some residual probability to not throw away\n\t\t\t// routes due to a min probability requirement of the\n\t\t\t// whole path.\n\t\t\tname:             \"full amount\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\tamountMsat:       capacityMSat,\n\t\t\texpectedFactor:   0.5,\n\t\t},\n\t\t{\n\t\t\tname:             \"more than capacity\",\n\t\t\tcapacityFraction: 0.75,\n\t\t\tamountMsat:       capacityMSat + 1,\n\t\t\texpectedFactor:   0.0,\n\t\t},\n\t\t// Default CapacityFactor of 0.9999.\n\t\t{\n\t\t\tname:             \"zero amount\",\n\t\t\tcapacityFraction: 0.9999,\n\t\t\tamountMsat:       0,\n\t\t\texpectedFactor:   1.00,\n\t\t},\n\t\t{\n\t\t\tname:             \"90% of the channel capacity\",\n\t\t\tcapacityFraction: 0.9999,\n\t\t\tamountMsat:       capacityMSat * 90 / 100,\n\t\t\texpectedFactor:   0.990,\n\t\t},\n\t\t{\n\t\t\t// We won't saturate at 0.5 as in the other case but at\n\t\t\t// a higher value of 0.75 due to the smearing, this\n\t\t\t// translates to a penalty increase of a factor of 1.33.\n\t\t\tname:             \"full amount\",\n\t\t\tcapacityFraction: 0.9999,\n\t\t\tamountMsat:       capacityMSat,\n\t\t\texpectedFactor:   0.75,\n\t\t},\n\t\t// Inactive capacity factor.\n\t\t{\n\t\t\tname:             \"inactive capacity factor\",\n\t\t\tcapacityFraction: 1.0,\n\t\t\tamountMsat:       capacityMSat,\n\t\t\texpectedFactor:   1.00,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\ttest := test\n\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tgot := capacityFactor(\n\t\t\t\tlnwire.MilliSatoshi(test.amountMsat),\n\t\t\t\tbtcutil.Amount(capacitySat),\n\t\t\t\ttest.capacityFraction,\n\t\t\t)\n\t\t\trequire.InDelta(t, test.expectedFactor, got, 0.001)\n\t\t})\n\t}\n}\n",
      "length": 2399,
      "tokens": 277,
      "embedding": []
    }
  ]
}