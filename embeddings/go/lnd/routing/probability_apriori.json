{
  "filepath": "../implementations/go/lnd/routing/probability_apriori.go",
  "package": "routing",
  "sections": [
    {
      "slug": "type AprioriConfig struct {",
      "content": "type AprioriConfig struct {\n\t// PenaltyHalfLife defines after how much time a penalized node or\n\t// channel is back at 50% probability.\n\tPenaltyHalfLife time.Duration\n\n\t// AprioriHopProbability is the assumed success probability of a hop in\n\t// a route when no other information is available.\n\tAprioriHopProbability float64\n\n\t// AprioriWeight is a value in the range [0, 1] that defines to what\n\t// extent historical results should be extrapolated to untried\n\t// connections. Setting it to one will completely ignore historical\n\t// results and always assume the configured a priori probability for\n\t// untried connections. A value of zero will ignore the a priori\n\t// probability completely and only base the probability on historical\n\t// results, unless there are none available.\n\tAprioriWeight float64\n\n\t// CapacityFraction is the fraction of a channel's capacity that we\n\t// consider to have liquidity. For amounts that come close to or exceed\n\t// the fraction, an additional penalty is applied. A value of 1.0\n\t// disables the capacityFactor.\n\tCapacityFraction float64\n}\n\n// validate checks the configuration of the estimator for allowed values.",
      "length": 1097,
      "tokens": 171,
      "embedding": []
    },
    {
      "slug": "func (p AprioriConfig) validate() error {",
      "content": "func (p AprioriConfig) validate() error {\n\tif p.PenaltyHalfLife < 0 {\n\t\treturn ErrInvalidHalflife\n\t}\n\n\tif p.AprioriHopProbability < 0 || p.AprioriHopProbability > 1 {\n\t\treturn ErrInvalidHopProbability\n\t}\n\n\tif p.AprioriWeight < 0 || p.AprioriWeight > 1 {\n\t\treturn ErrInvalidAprioriWeight\n\t}\n\n\tif p.CapacityFraction < minCapacityFraction || p.CapacityFraction > 1 {\n\t\treturn ErrInvalidCapacityFraction\n\t}\n\n\treturn nil\n}\n\n// DefaultAprioriConfig returns the default configuration for the estimator.",
      "length": 434,
      "tokens": 56,
      "embedding": []
    },
    {
      "slug": "func DefaultAprioriConfig() AprioriConfig {",
      "content": "func DefaultAprioriConfig() AprioriConfig {\n\treturn AprioriConfig{\n\t\tPenaltyHalfLife:       DefaultPenaltyHalfLife,\n\t\tAprioriHopProbability: DefaultAprioriHopProbability,\n\t\tAprioriWeight:         DefaultAprioriWeight,\n\t\tCapacityFraction:      DefaultCapacityFraction,\n\t}\n}\n\n// AprioriEstimator returns node and pair probabilities based on historical\n// payment results. It uses a preconfigured success probability value for\n// untried hops (AprioriHopProbability) and returns a high success probability\n// for hops that could previously conduct a payment (prevSuccessProbability).\n// Successful edges are retried until proven otherwise. Recently failed hops are\n// penalized by an exponential time decay (PenaltyHalfLife), after which they\n// are reconsidered for routing. If information was learned about a forwarding\n// node, the information is taken into account to estimate a per node\n// probability that mixes with the a priori probability (AprioriWeight).",
      "length": 901,
      "tokens": 111,
      "embedding": []
    },
    {
      "slug": "type AprioriEstimator struct {",
      "content": "type AprioriEstimator struct {\n\t// AprioriConfig contains configuration options for our estimator.\n\tAprioriConfig\n\n\t// prevSuccessProbability is the assumed probability for node pairs that\n\t// successfully relayed the previous attempt.\n\tprevSuccessProbability float64\n}\n\n// NewAprioriEstimator creates a new AprioriEstimator.",
      "length": 286,
      "tokens": 34,
      "embedding": []
    },
    {
      "slug": "func NewAprioriEstimator(cfg AprioriConfig) (*AprioriEstimator, error) {",
      "content": "func NewAprioriEstimator(cfg AprioriConfig) (*AprioriEstimator, error) {\n\tif err := cfg.validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &AprioriEstimator{\n\t\tAprioriConfig:          cfg,\n\t\tprevSuccessProbability: prevSuccessProbability,\n\t}, nil\n}\n\n// Compile-time checks that interfaces are implemented.\nvar _ Estimator = (*AprioriEstimator)(nil)\nvar _ estimatorConfig = (*AprioriConfig)(nil)\n\n// Config returns the estimator's configuration.",
      "length": 361,
      "tokens": 44,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) Config() estimatorConfig {",
      "content": "func (p *AprioriEstimator) Config() estimatorConfig {\n\treturn p.AprioriConfig\n}\n\n// String returns the estimator's configuration as a string representation.",
      "length": 99,
      "tokens": 13,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) String() string {",
      "content": "func (p *AprioriEstimator) String() string {\n\treturn fmt.Sprintf(\"estimator type: %v, penalty halflife time: %v, \"+\n\t\t\"apriori hop probability: %v, apriori weight: %v, previous \"+\n\t\t\"success probability: %v, capacity fraction: %v\",\n\t\tAprioriEstimatorName, p.PenaltyHalfLife,\n\t\tp.AprioriHopProbability, p.AprioriWeight,\n\t\tp.prevSuccessProbability, p.CapacityFraction)\n}\n\n// getNodeProbability calculates the probability for connections from a node\n// that have not been tried before. The results parameter is a list of last\n// payment results for that node.",
      "length": 501,
      "tokens": 62,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) getNodeProbability(now time.Time,",
      "content": "func (p *AprioriEstimator) getNodeProbability(now time.Time,\n\tresults NodeResults, amt lnwire.MilliSatoshi,\n\tcapacity btcutil.Amount) float64 {\n\n\t// We reduce the apriori hop probability if the amount comes close to\n\t// the capacity.\n\tapriori := p.AprioriHopProbability * capacityFactor(\n\t\tamt, capacity, p.CapacityFraction,\n\t)\n\n\t// If the channel history is not to be taken into account, we can return\n\t// early here with the configured a priori probability.\n\tif p.AprioriWeight == 1 {\n\t\treturn apriori\n\t}\n\n\t// If there is no channel history, our best estimate is still the a\n\t// priori probability.\n\tif len(results) == 0 {\n\t\treturn apriori\n\t}\n\n\t// The value of the apriori weight is in the range [0, 1]. Convert it to\n\t// a factor that properly expresses the intention of the weight in the\n\t// following weight average calculation. When the apriori weight is 0,\n\t// the apriori factor is also 0. This means it won't have any effect on\n\t// the weighted average calculation below. When the apriori weight\n\t// approaches 1, the apriori factor goes to infinity. It will heavily\n\t// outweigh any observations that have been collected.\n\taprioriFactor := 1/(1-p.AprioriWeight) - 1\n\n\t// Calculate a weighted average consisting of the apriori probability\n\t// and historical observations. This is the part that incentivizes nodes\n\t// to make sure that all (not just some) of their channels are in good\n\t// shape. Senders will steer around nodes that have shown a few\n\t// failures, even though there may be many channels still untried.\n\t//\n\t// If there is just a single observation and the apriori weight is 0,\n\t// this single observation will totally determine the node probability.\n\t// The node probability is returned for all other channels of the node.\n\t// This means that one failure will lead to the success probability\n\t// estimates for all other channels being 0 too. The probability for the\n\t// channel that was tried will not even recover, because it is\n\t// recovering to the node probability (which is zero). So one failure\n\t// effectively prunes all channels of the node forever. This is the most\n\t// aggressive way in which we can penalize nodes and unlikely to yield\n\t// good results in a real network.\n\tprobabilitiesTotal := apriori * aprioriFactor\n\ttotalWeight := aprioriFactor\n\n\tfor _, result := range results {\n\t\tswitch {\n\t\t// Weigh success with a constant high weight of 1. There is no\n\t\t// decay. Amt is never zero, so this clause is never executed\n\t\t// when result.SuccessAmt is zero.\n\t\tcase amt <= result.SuccessAmt:\n\t\t\ttotalWeight++\n\t\t\tprobabilitiesTotal += p.prevSuccessProbability\n\n\t\t// Weigh failures in accordance with their age. The base\n\t\t// probability of a failure is considered zero, so nothing needs\n\t\t// to be added to probabilitiesTotal.\n\t\tcase !result.FailTime.IsZero() && amt >= result.FailAmt:\n\t\t\tage := now.Sub(result.FailTime)\n\t\t\ttotalWeight += p.getWeight(age)\n\t\t}\n\t}\n\n\treturn probabilitiesTotal / totalWeight\n}\n\n// getWeight calculates a weight in the range [0, 1] that should be assigned to\n// a payment result. Weight follows an exponential curve that starts at 1 when\n// the result is fresh and asymptotically approaches zero over time. The rate at\n// which this happens is controlled by the penaltyHalfLife parameter.",
      "length": 3120,
      "tokens": 513,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) getWeight(age time.Duration) float64 {",
      "content": "func (p *AprioriEstimator) getWeight(age time.Duration) float64 {\n\texp := -age.Hours() / p.PenaltyHalfLife.Hours()\n\treturn math.Pow(2, exp)\n}\n\n// capacityFactor is a multiplier that can be used to reduce the probability\n// depending on how much of the capacity is sent. In other words, the factor\n// sorts out channels that don't provide enough liquidity. Effectively, this\n// leads to usage of larger channels in total to increase success probability,\n// but it may also increase fees. The limits are 1 for amt == 0 and\n// minCapacityFactor for amt >> capacityCutoffFraction. The function drops\n// significantly when amt reaches cutoffMsat. smearingMsat determines over which\n// scale the reduction takes place.",
      "length": 635,
      "tokens": 102,
      "embedding": []
    },
    {
      "slug": "func capacityFactor(amt lnwire.MilliSatoshi, capacity btcutil.Amount,",
      "content": "func capacityFactor(amt lnwire.MilliSatoshi, capacity btcutil.Amount,\n\tcapacityCutoffFraction float64) float64 {\n\n\t// The special value of 1.0 for capacityFactor disables any effect from\n\t// this factor.\n\tif capacityCutoffFraction == 1 {\n\t\treturn 1.0\n\t}\n\n\t// If we don't have information about the capacity, which can be the\n\t// case for hop hints or local channels, we return unity to not alter\n\t// anything.\n\tif capacity == 0 {\n\t\treturn 1.0\n\t}\n\n\tcapMsat := float64(lnwire.NewMSatFromSatoshis(capacity))\n\tamtMsat := float64(amt)\n\n\tif amtMsat > capMsat {\n\t\treturn 0\n\t}\n\n\tcutoffMsat := capacityCutoffFraction * capMsat\n\tsmearingMsat := capacitySmearingFraction * capMsat\n\n\t// We compute a logistic function mirrored around the y axis, centered\n\t// at cutoffMsat, decaying over the smearingMsat scale.\n\tdenominator := 1 + math.Exp(-(amtMsat-cutoffMsat)/smearingMsat)\n\n\t// The numerator decides what the minimal value of this function will\n\t// be. The minimal value is set by minCapacityFactor.\n\tnumerator := 1 - minCapacityFactor\n\n\treturn 1 - numerator/denominator\n}\n\n// PairProbability estimates the probability of successfully traversing to\n// toNode based on historical payment outcomes for the from node. Those outcomes\n// are passed in via the results parameter.",
      "length": 1157,
      "tokens": 174,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) PairProbability(now time.Time,",
      "content": "func (p *AprioriEstimator) PairProbability(now time.Time,\n\tresults NodeResults, toNode route.Vertex, amt lnwire.MilliSatoshi,\n\tcapacity btcutil.Amount) float64 {\n\n\tnodeProbability := p.getNodeProbability(now, results, amt, capacity)\n\n\treturn p.calculateProbability(\n\t\tnow, results, nodeProbability, toNode, amt,\n\t)\n}\n\n// LocalPairProbability estimates the probability of successfully traversing\n// our own local channels to toNode.",
      "length": 362,
      "tokens": 40,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) LocalPairProbability(",
      "content": "func (p *AprioriEstimator) LocalPairProbability(\n\tnow time.Time, results NodeResults, toNode route.Vertex) float64 {\n\n\t// For local channels that have never been tried before, we assume them\n\t// to be successful. We have accurate balance and online status\n\t// information on our own channels, so when we select them in a route it\n\t// is close to certain that those channels will work.\n\tnodeProbability := p.prevSuccessProbability\n\n\treturn p.calculateProbability(\n\t\tnow, results, nodeProbability, toNode, lnwire.MaxMilliSatoshi,\n\t)\n}\n\n// calculateProbability estimates the probability of successfully traversing to\n// toNode based on historical payment outcomes and a fall-back node probability.",
      "length": 631,
      "tokens": 90,
      "embedding": []
    },
    {
      "slug": "func (p *AprioriEstimator) calculateProbability(",
      "content": "func (p *AprioriEstimator) calculateProbability(\n\tnow time.Time, results NodeResults,\n\tnodeProbability float64, toNode route.Vertex,\n\tamt lnwire.MilliSatoshi) float64 {\n\n\t// Retrieve the last pair outcome.\n\tlastPairResult, ok := results[toNode]\n\n\t// If there is no history for this pair, return the node probability\n\t// that is a probability estimate for untried channel.\n\tif !ok {\n\t\treturn nodeProbability\n\t}\n\n\t// For successes, we have a fixed (high) probability. Those pairs will\n\t// be assumed good until proven otherwise. Amt is never zero, so this\n\t// clause is never executed when lastPairResult.SuccessAmt is zero.\n\tif amt <= lastPairResult.SuccessAmt {\n\t\treturn p.prevSuccessProbability\n\t}\n\n\t// Take into account a minimum penalize amount. For balance errors, a\n\t// failure may be reported with such a minimum to prevent too aggressive\n\t// penalization. If the current amount is smaller than the amount that\n\t// previously triggered a failure, we act as if this is an untried\n\t// channel.\n\tif lastPairResult.FailTime.IsZero() || amt < lastPairResult.FailAmt {\n\t\treturn nodeProbability\n\t}\n\n\ttimeSinceLastFailure := now.Sub(lastPairResult.FailTime)\n\n\t// Calculate success probability based on the weight of the last\n\t// failure. When the failure is fresh, its weight is 1 and we'll return\n\t// probability 0. Over time the probability recovers to the node\n\t// probability. It would be as if this channel was never tried before.\n\tweight := p.getWeight(timeSinceLastFailure)\n\tprobability := nodeProbability * (1 - weight)\n\n\treturn probability\n}\n",
      "length": 1460,
      "tokens": 219,
      "embedding": []
    }
  ]
}