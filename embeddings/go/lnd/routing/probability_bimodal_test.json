{
  "filepath": "../implementations/go/lnd/routing/probability_bimodal_test.go",
  "package": "routing",
  "sections": [
    {
      "slug": "func TestSuccessProbability(t *testing.T) {",
      "content": "func TestSuccessProbability(t *testing.T) {\n\tt.Parallel()\n\n\ttests := []struct {\n\t\tname                string\n\t\texpectedProbability float64\n\t\ttolerance           float64\n\t\tsuccessAmount       lnwire.MilliSatoshi\n\t\tfailAmount          lnwire.MilliSatoshi\n\t\tamount              lnwire.MilliSatoshi\n\t\tcapacity            lnwire.MilliSatoshi\n\t}{\n\t\t// We can't send more than the capacity.\n\t\t{\n\t\t\tname:                \"no info, larger than capacity\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       0,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              capacity + 1,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t// With the current model we don't prefer any channels if the\n\t\t// send amount is large compared to the scale but small compared\n\t\t// to the capacity.\n\t\t{\n\t\t\tname:                \"no info, large amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       0,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              largeAmount,\n\t\t\texpectedProbability: 0.5,\n\t\t},\n\t\t// We always expect to be able to \"send\" an amount of 0.\n\t\t{\n\t\t\tname:                \"no info, zero amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       0,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              0,\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t// We can't send the whole capacity.\n\t\t{\n\t\t\tname:                \"no info, full capacity\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       0,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              capacity,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t// Sending a small amount will have a higher probability to go\n\t\t// through than a large amount.\n\t\t{\n\t\t\tname:                \"no info, small amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       0,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              smallAmount,\n\t\t\texpectedProbability: 0.684,\n\t\t\ttolerance:           0.001,\n\t\t},\n\t\t// If we had an unsettled success, we are sure we can send a\n\t\t// lower amount.\n\t\t{\n\t\t\tname:                \"previous success, lower amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       largeAmount,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              smallAmount,\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t// If we had an unsettled success, we are sure we can send the\n\t\t// same amount.\n\t\t{\n\t\t\tname:                \"previous success, success amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       largeAmount,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              largeAmount,\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t// If we had an unsettled success with a small amount, we know\n\t\t// with increased probability that we can send a comparable\n\t\t// higher amount.\n\t\t{\n\t\t\tname:                \"previous success, larger amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       smallAmount / 2,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              smallAmount,\n\t\t\texpectedProbability: 0.851,\n\t\t\ttolerance:           0.001,\n\t\t},\n\t\t// If we had a large unsettled success before, we know we can\n\t\t// send even larger payments with high probability.\n\t\t{\n\t\t\tname: \"previous large success, larger \" +\n\t\t\t\t\"amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tsuccessAmount:       largeAmount / 2,\n\t\t\tfailAmount:          capacity,\n\t\t\tamount:              largeAmount,\n\t\t\texpectedProbability: 0.998,\n\t\t\ttolerance:           0.001,\n\t\t},\n\t\t// If we had a failure before, we can't send with the fail\n\t\t// amount.\n\t\t{\n\t\t\tname:                \"previous failure, fail amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tamount:              largeAmount,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t// We can't send a higher amount than the fail amount either.\n\t\t{\n\t\t\tname: \"previous failure, larger fail \" +\n\t\t\t\t\"amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tamount:              largeAmount + smallAmount,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t// We expect a diminished non-zero probability if we try to send\n\t\t// an amount that's lower than the last fail amount.\n\t\t{\n\t\t\tname: \"previous failure, lower than fail \" +\n\t\t\t\t\"amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tamount:              smallAmount,\n\t\t\texpectedProbability: 0.368,\n\t\t\ttolerance:           0.001,\n\t\t},\n\t\t// From here on we deal with mixed previous successes and\n\t\t// failures.\n\t\t// We expect to be always able to send a tiny amount.\n\t\t{\n\t\t\tname:                \"previous f/s, very small amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tsuccessAmount:       smallAmount,\n\t\t\tamount:              0,\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t// We expect to be able to send up to the previous success\n\t\t// amount will full certainty.\n\t\t{\n\t\t\tname:                \"previous f/s, success amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tsuccessAmount:       smallAmount,\n\t\t\tamount:              smallAmount,\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t// This tests a random value between small amount and large\n\t\t// amount.\n\t\t{\n\t\t\tname:                \"previous f/s, between f/s\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tsuccessAmount:       smallAmount,\n\t\t\tamount:              smallAmount + largeAmount/10,\n\t\t\texpectedProbability: 0.287,\n\t\t\ttolerance:           0.001,\n\t\t},\n\t\t// We still can't send the fail amount.\n\t\t{\n\t\t\tname:                \"previous f/s, fail amount\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tsuccessAmount:       smallAmount,\n\t\t\tamount:              largeAmount,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t// Same success and failure amounts (illogical).\n\t\t{\n\t\t\tname:                \"previous f/s, same\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          largeAmount,\n\t\t\tsuccessAmount:       largeAmount,\n\t\t\tamount:              largeAmount,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t// Higher success than failure amount (illogical).\n\t\t{\n\t\t\tname:                \"previous f/s, higher success\",\n\t\t\tcapacity:            capacity,\n\t\t\tfailAmount:          smallAmount,\n\t\t\tsuccessAmount:       largeAmount,\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t}\n\n\testimator := BimodalEstimator{\n\t\tBimodalConfig: BimodalConfig{BimodalScaleMsat: scale},\n\t}\n\n\tfor _, test := range tests {\n\t\ttest := test\n\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tp, err := estimator.probabilityFormula(\n\t\t\t\ttest.capacity, test.successAmount,\n\t\t\t\ttest.failAmount, test.amount,\n\t\t\t)\n\t\t\trequire.InDelta(t, test.expectedProbability, p,\n\t\t\t\ttest.tolerance)\n\t\t\trequire.NoError(t, err)\n\t\t})\n\t}\n}\n\n// TestIntegral tests certain limits of the probability distribution integral.",
      "length": 6360,
      "tokens": 682,
      "embedding": []
    },
    {
      "slug": "func TestIntegral(t *testing.T) {",
      "content": "func TestIntegral(t *testing.T) {\n\tt.Parallel()\n\n\tdefaultScale := lnwire.NewMSatFromSatoshis(300_000)\n\n\ttests := []struct {\n\t\tname     string\n\t\tcapacity float64\n\t\tlower    float64\n\t\tupper    float64\n\t\tscale    lnwire.MilliSatoshi\n\t\texpected float64\n\t}{\n\t\t{\n\t\t\tname:     \"all zero\",\n\t\t\texpected: math.NaN(),\n\t\t\tscale:    defaultScale,\n\t\t},\n\t\t{\n\t\t\tname:     \"all same\",\n\t\t\tcapacity: 1,\n\t\t\tlower:    1,\n\t\t\tupper:    1,\n\t\t\tscale:    defaultScale,\n\t\t},\n\t\t{\n\t\t\tname:     \"large numbers, low lower\",\n\t\t\tcapacity: 21e17,\n\t\t\tlower:    0,\n\t\t\tupper:    21e17,\n\t\t\texpected: 1,\n\t\t\tscale:    defaultScale,\n\t\t},\n\t\t{\n\t\t\tname:     \"large numbers, high lower\",\n\t\t\tcapacity: 21e17,\n\t\t\tlower:    21e17,\n\t\t\tupper:    21e17,\n\t\t\tscale:    defaultScale,\n\t\t},\n\t\t{\n\t\t\tname:     \"same scale and capacity\",\n\t\t\tcapacity: 21e17,\n\t\t\tlower:    21e17,\n\t\t\tupper:    21e17,\n\t\t\tscale:    21e17,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\ttest := test\n\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\testimator := BimodalEstimator{\n\t\t\t\tBimodalConfig: BimodalConfig{\n\t\t\t\t\tBimodalScaleMsat: test.scale,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tp := estimator.integral(\n\t\t\t\ttest.capacity, test.lower, test.upper,\n\t\t\t)\n\t\t\trequire.InDelta(t, test.expected, p, 0.001)\n\t\t})\n\t}\n}\n\n// TestCanSend tests that the success amount drops to zero over time.",
      "length": 1188,
      "tokens": 141,
      "embedding": []
    },
    {
      "slug": "func TestCanSend(t *testing.T) {",
      "content": "func TestCanSend(t *testing.T) {\n\tt.Parallel()\n\n\tsuccessAmount := lnwire.MilliSatoshi(1_000_000)\n\tsuccessTime := time.Unix(1_000, 0)\n\tnow := time.Unix(2_000, 0)\n\tdecayTime := time.Duration(1_000) * time.Second\n\tinfinity := time.Unix(10_000_000_000, 0)\n\n\t// Test an immediate retry.\n\trequire.Equal(t, successAmount, canSend(\n\t\tsuccessAmount, successTime, successTime, decayTime,\n\t))\n\n\t// Test that after the decay time, the successAmount is 1/e of its\n\t// value.\n\tdecayAmount := lnwire.MilliSatoshi(float64(successAmount) / math.E)\n\trequire.Equal(t, decayAmount, canSend(\n\t\tsuccessAmount, now, successTime, decayTime,\n\t))\n\n\t// After a long time, we want the amount to approach 0.\n\trequire.Equal(t, lnwire.MilliSatoshi(0), canSend(\n\t\tsuccessAmount, infinity, successTime, decayTime,\n\t))\n}\n\n// TestCannotSend tests that the fail amount approaches the capacity over time.",
      "length": 808,
      "tokens": 95,
      "embedding": []
    },
    {
      "slug": "func TestCannotSend(t *testing.T) {",
      "content": "func TestCannotSend(t *testing.T) {\n\tt.Parallel()\n\n\tfailAmount := lnwire.MilliSatoshi(1_000_000)\n\tfailTime := time.Unix(1_000, 0)\n\tnow := time.Unix(2_000, 0)\n\tdecayTime := time.Duration(1_000) * time.Second\n\tinfinity := time.Unix(10_000_000_000, 0)\n\tcapacity := lnwire.MilliSatoshi(3_000_000)\n\n\t// Test immediate retry.\n\trequire.EqualValues(t, failAmount, cannotSend(\n\t\tfailAmount, capacity, failTime, failTime, decayTime,\n\t))\n\n\t// After the decay time we want to be between the fail amount and\n\t// the capacity.\n\tsummand := lnwire.MilliSatoshi(float64(capacity-failAmount) / math.E)\n\texpected := capacity - summand\n\trequire.Equal(t, expected, cannotSend(\n\t\tfailAmount, capacity, now, failTime, decayTime,\n\t))\n\n\t// After a long time, we want the amount to approach the capacity.\n\trequire.Equal(t, capacity, cannotSend(\n\t\tfailAmount, capacity, infinity, failTime, decayTime,\n\t))\n}\n\n// TestComputeProbability tests the inclusion of previous forwarding results of\n// other channels of the node into the total probability.",
      "length": 953,
      "tokens": 116,
      "embedding": []
    },
    {
      "slug": "func TestComputeProbability(t *testing.T) {",
      "content": "func TestComputeProbability(t *testing.T) {\n\tt.Parallel()\n\n\tnodeWeight := 1 / 5.\n\ttoNode := route.Vertex{10}\n\ttolerance := 0.01\n\tdecayTime := time.Duration(1) * time.Hour * 24\n\n\t// makeNodeResults prepares forwarding data for the other channels of\n\t// the node.\n\tmakeNodeResults := func(successes []bool, now time.Time) NodeResults {\n\t\tresults := make(NodeResults, len(successes))\n\n\t\tfor i, s := range successes {\n\t\t\tvertex := route.Vertex{byte(i)}\n\n\t\t\tresults[vertex] = TimedPairResult{\n\t\t\t\tFailTime: now, FailAmt: 1,\n\t\t\t}\n\t\t\tif s {\n\t\t\t\tresults[vertex] = TimedPairResult{\n\t\t\t\t\tSuccessTime: now, SuccessAmt: 1,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn results\n\t}\n\n\ttests := []struct {\n\t\tname                string\n\t\tdirectProbability   float64\n\t\totherResults        []bool\n\t\texpectedProbability float64\n\t\tdelay               time.Duration\n\t}{\n\t\t// If no other information is available, use the direct\n\t\t// probability.\n\t\t{\n\t\t\tname:                \"unknown, only direct\",\n\t\t\tdirectProbability:   0.5,\n\t\t\texpectedProbability: 0.5,\n\t\t},\n\t\t// If there was a single success, expect increased success\n\t\t// probability.\n\t\t{\n\t\t\tname:                \"unknown, single success\",\n\t\t\tdirectProbability:   0.5,\n\t\t\totherResults:        []bool{true},\n\t\t\texpectedProbability: 0.583,\n\t\t},\n\t\t// If there were many successes, expect even higher success\n\t\t// probability.\n\t\t{\n\t\t\tname:              \"unknown, many successes\",\n\t\t\tdirectProbability: 0.5,\n\t\t\totherResults: []bool{\n\t\t\t\ttrue, true, true, true, true,\n\t\t\t},\n\t\t\texpectedProbability: 0.75,\n\t\t},\n\t\t// If there was a single failure, we expect a slightly decreased\n\t\t// probability.\n\t\t{\n\t\t\tname:                \"unknown, single failure\",\n\t\t\tdirectProbability:   0.5,\n\t\t\totherResults:        []bool{false},\n\t\t\texpectedProbability: 0.416,\n\t\t},\n\t\t// If there were many failures, we expect a strongly decreased\n\t\t// probability.\n\t\t{\n\t\t\tname:              \"unknown, many failures\",\n\t\t\tdirectProbability: 0.5,\n\t\t\totherResults: []bool{\n\t\t\t\tfalse, false, false, false, false,\n\t\t\t},\n\t\t\texpectedProbability: 0.25,\n\t\t},\n\t\t// A success and a failure neutralize themselves.\n\t\t{\n\t\t\tname:                \"unknown, mixed even\",\n\t\t\tdirectProbability:   0.5,\n\t\t\totherResults:        []bool{true, false},\n\t\t\texpectedProbability: 0.5,\n\t\t},\n\t\t// A mixed result history leads to increase/decrease of the most\n\t\t// experienced successes/failures.\n\t\t{\n\t\t\tname:              \"unknown, mixed uneven\",\n\t\t\tdirectProbability: 0.5,\n\t\t\totherResults: []bool{\n\t\t\t\ttrue, true, false, false, false,\n\t\t\t},\n\t\t\texpectedProbability: 0.45,\n\t\t},\n\t\t// Many successes don't elevate the probability above 1.\n\t\t{\n\t\t\tname:              \"success, successes\",\n\t\t\tdirectProbability: 1.0,\n\t\t\totherResults: []bool{\n\t\t\t\ttrue, true, true, true, true,\n\t\t\t},\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t// Five failures on a very certain channel will lower its\n\t\t// success probability to the unknown probability.\n\t\t{\n\t\t\tname:              \"success, failures\",\n\t\t\tdirectProbability: 1.0,\n\t\t\totherResults: []bool{\n\t\t\t\tfalse, false, false, false, false,\n\t\t\t},\n\t\t\texpectedProbability: 0.5,\n\t\t},\n\t\t// If we are sure that the channel can send, a single failure\n\t\t// will not decrease the outcome significantly.\n\t\t{\n\t\t\tname:                \"success, single failure\",\n\t\t\tdirectProbability:   1.0,\n\t\t\totherResults:        []bool{false},\n\t\t\texpectedProbability: 0.8333,\n\t\t},\n\t\t{\n\t\t\tname:              \"success, many failures\",\n\t\t\tdirectProbability: 1.0,\n\t\t\totherResults: []bool{\n\t\t\t\tfalse, false, false, false, false, false, false,\n\t\t\t},\n\t\t\texpectedProbability: 0.416,\n\t\t},\n\t\t// Failures won't decrease the probability below zero.\n\t\t{\n\t\t\tname:                \"fail, failures\",\n\t\t\tdirectProbability:   0.0,\n\t\t\totherResults:        []bool{false, false, false},\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t{\n\t\t\tname:              \"fail, successes\",\n\t\t\tdirectProbability: 0.0,\n\t\t\totherResults: []bool{\n\t\t\t\ttrue, true, true, true, true,\n\t\t\t},\n\t\t\texpectedProbability: 0.5,\n\t\t},\n\t\t// We test forgetting information with the time decay.\n\t\t// A past success won't alter the certain success probability.\n\t\t{\n\t\t\tname: \"success, single success, decay \" +\n\t\t\t\t\"time\",\n\t\t\tdirectProbability:   1.0,\n\t\t\totherResults:        []bool{true},\n\t\t\tdelay:               decayTime,\n\t\t\texpectedProbability: 1.00,\n\t\t},\n\t\t// A failure that was experienced some time ago won't influence\n\t\t// as much as a recent one.\n\t\t{\n\t\t\tname:                \"success, single fail, decay time\",\n\t\t\tdirectProbability:   1.0,\n\t\t\totherResults:        []bool{false},\n\t\t\tdelay:               decayTime,\n\t\t\texpectedProbability: 0.9314,\n\t\t},\n\t\t// Information from a long time ago doesn't have any effect.\n\t\t{\n\t\t\tname:                \"success, single fail, long ago\",\n\t\t\tdirectProbability:   1.0,\n\t\t\totherResults:        []bool{false},\n\t\t\tdelay:               10 * decayTime,\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t{\n\t\t\tname:              \"fail, successes decay time\",\n\t\t\tdirectProbability: 0.0,\n\t\t\totherResults: []bool{\n\t\t\t\ttrue, true, true, true, true,\n\t\t\t},\n\t\t\tdelay:               decayTime,\n\t\t\texpectedProbability: 0.269,\n\t\t},\n\t\t// Very recent info approaches the case with no time decay.\n\t\t{\n\t\t\tname:              \"unknown, successes close\",\n\t\t\tdirectProbability: 0.5,\n\t\t\totherResults: []bool{\n\t\t\t\ttrue, true, true, true, true,\n\t\t\t},\n\t\t\tdelay:               decayTime / 10,\n\t\t\texpectedProbability: 0.741,\n\t\t},\n\t}\n\n\testimator := BimodalEstimator{\n\t\tBimodalConfig: BimodalConfig{\n\t\t\tBimodalScaleMsat: scale, BimodalNodeWeight: nodeWeight,\n\t\t\tBimodalDecayTime: decayTime,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\ttest := test\n\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tthen := time.Unix(0, 0)\n\t\t\tresults := makeNodeResults(test.otherResults, then)\n\t\t\tnow := then.Add(test.delay)\n\n\t\t\tp := estimator.calculateProbability(\n\t\t\t\ttest.directProbability, now, results, toNode,\n\t\t\t)\n\n\t\t\trequire.InDelta(t, test.expectedProbability, p,\n\t\t\t\ttolerance)\n\t\t})\n\t}\n}\n\n// TestLocalPairProbability tests that we reduce probability for failed direct\n// neighbors.",
      "length": 5684,
      "tokens": 651,
      "embedding": []
    },
    {
      "slug": "func TestLocalPairProbability(t *testing.T) {",
      "content": "func TestLocalPairProbability(t *testing.T) {\n\tt.Parallel()\n\n\tdecayTime := time.Hour\n\tnow := time.Unix(1000000000, 0)\n\ttoNode := route.Vertex{1}\n\n\tcreateFailedResult := func(timeAgo time.Duration) NodeResults {\n\t\treturn NodeResults{\n\t\t\ttoNode: TimedPairResult{\n\t\t\t\tFailTime: now.Add(-timeAgo),\n\t\t\t},\n\t\t}\n\t}\n\n\ttests := []struct {\n\t\tname                string\n\t\texpectedProbability float64\n\t\tresults             NodeResults\n\t}{\n\t\t{\n\t\t\tname:                \"no results\",\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t\t{\n\t\t\tname:                \"recent failure\",\n\t\t\tresults:             createFailedResult(0),\n\t\t\texpectedProbability: 0.0,\n\t\t},\n\t\t{\n\t\t\tname:                \"after decay time\",\n\t\t\tresults:             createFailedResult(decayTime),\n\t\t\texpectedProbability: 1 - 1/math.E,\n\t\t},\n\t\t{\n\t\t\tname:                \"long ago\",\n\t\t\tresults:             createFailedResult(10 * decayTime),\n\t\t\texpectedProbability: 1.0,\n\t\t},\n\t}\n\n\testimator := BimodalEstimator{\n\t\tBimodalConfig: BimodalConfig{BimodalDecayTime: decayTime},\n\t}\n\n\tfor _, test := range tests {\n\t\ttest := test\n\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tp := estimator.LocalPairProbability(\n\t\t\t\tnow, test.results, toNode,\n\t\t\t)\n\t\t\trequire.InDelta(t, test.expectedProbability, p, 0.001)\n\t\t})\n\t}\n}\n\n// FuzzProbability checks that we don't encounter errors related to NaNs.",
      "length": 1227,
      "tokens": 124,
      "embedding": []
    },
    {
      "slug": "func FuzzProbability(f *testing.F) {",
      "content": "func FuzzProbability(f *testing.F) {\n\testimator := BimodalEstimator{\n\t\tBimodalConfig: BimodalConfig{BimodalScaleMsat: scale},\n\t}\n\tf.Add(uint64(0), uint64(0), uint64(0), uint64(0))\n\n\tf.Fuzz(func(t *testing.T, capacity, successAmt, failAmt, amt uint64) {\n\t\t_, err := estimator.probabilityFormula(\n\t\t\tlnwire.MilliSatoshi(capacity),\n\t\t\tlnwire.MilliSatoshi(successAmt),\n\t\t\tlnwire.MilliSatoshi(failAmt), lnwire.MilliSatoshi(amt),\n\t\t)\n\n\t\trequire.NoError(t, err, \"c: %v s: %v f: %v a: %v\", capacity,\n\t\t\tsuccessAmt, failAmt, amt)\n\t})\n}\n",
      "length": 474,
      "tokens": 44,
      "embedding": []
    }
  ]
}