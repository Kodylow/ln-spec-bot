{
  "filepath": "../implementations/go/lnd/lncfg/db.go",
  "package": "lncfg",
  "sections": [
    {
      "slug": "type DB struct {",
      "content": "type DB struct {\n\tBackend string `long:\"backend\" description:\"The selected database backend.\"`\n\n\tBatchCommitInterval time.Duration `long:\"batch-commit-interval\" description:\"The maximum duration the channel graph batch schedulers will wait before attempting to commit a batch of pending updates. This can be tradeoff database contenion for commit latency.\"`\n\n\tEtcd *etcd.Config `group:\"etcd\" namespace:\"etcd\" description:\"Etcd settings.\"`\n\n\tBolt *kvdb.BoltConfig `group:\"bolt\" namespace:\"bolt\" description:\"Bolt settings.\"`\n\n\tPostgres *postgres.Config `group:\"postgres\" namespace:\"postgres\" description:\"Postgres settings.\"`\n\n\tSqlite *sqlite.Config `group:\"sqlite\" namespace:\"sqlite\" description:\"Sqlite settings.\"`\n\n\tNoGraphCache bool `long:\"no-graph-cache\" description:\"Don't use the in-memory graph cache for path finding. Much slower but uses less RAM. Can only be used with a bolt database backend.\"`\n\n\tPruneRevocation bool `long:\"prune-revocation\" description:\"Run the optional migration that prunes the revocation logs to save disk space.\"`\n\n\tNoRevLogAmtData bool `long:\"no-rev-log-amt-data\" description:\"If set, the to-local and to-remote output amounts of revoked commitment transactions will not be stored in the revocation log. Note that once this data is lost, a watchtower client will not be able to back up the revoked state.\"`\n}\n\n// DefaultDB creates and returns a new default DB config.",
      "length": 1366,
      "tokens": 159,
      "embedding": []
    },
    {
      "slug": "func DefaultDB() *DB {",
      "content": "func DefaultDB() *DB {\n\treturn &DB{\n\t\tBackend:             BoltBackend,\n\t\tBatchCommitInterval: DefaultBatchCommitInterval,\n\t\tBolt: &kvdb.BoltConfig{\n\t\t\tNoFreelistSync:    true,\n\t\t\tAutoCompactMinAge: kvdb.DefaultBoltAutoCompactMinAge,\n\t\t\tDBTimeout:         kvdb.DefaultDBTimeout,\n\t\t},\n\t\tEtcd: &etcd.Config{\n\t\t\t// Allow at most 32 MiB messages by default.\n\t\t\tMaxMsgSize: 32768 * 1024,\n\t\t},\n\t\tPostgres: &postgres.Config{\n\t\t\tMaxConnections: defaultPostgresMaxConnections,\n\t\t},\n\t\tSqlite: &sqlite.Config{\n\t\t\tMaxConnections: defaultSqliteMaxConnections,\n\t\t\tBusyTimeout:    defaultSqliteBusyTimeout,\n\t\t},\n\t}\n}\n\n// Validate validates the DB config.",
      "length": 594,
      "tokens": 51,
      "embedding": []
    },
    {
      "slug": "func (db *DB) Validate() error {",
      "content": "func (db *DB) Validate() error {\n\tswitch db.Backend {\n\tcase BoltBackend, SqliteBackend:\n\tcase PostgresBackend:\n\t\tif db.Postgres.Dsn == \"\" {\n\t\t\treturn fmt.Errorf(\"postgres dsn must be set\")\n\t\t}\n\n\tcase EtcdBackend:\n\t\tif !db.Etcd.Embedded && db.Etcd.Host == \"\" {\n\t\t\treturn fmt.Errorf(\"etcd host must be set\")\n\t\t}\n\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown backend, must be either '%v', \"+\n\t\t\t\"'%v', '%v' or '%v'\", BoltBackend, EtcdBackend,\n\t\t\tPostgresBackend, SqliteBackend)\n\t}\n\n\t// The path finding uses a manual read transaction that's open for a\n\t// potentially long time. That works fine with the locking model of\n\t// bbolt but can lead to locks or rolled back transactions with etcd or\n\t// postgres. And since we already have a smaller memory footprint for\n\t// remote database setups (due to not needing to memory-map the bbolt DB\n\t// files), we can keep the graph in memory instead. But for mobile\n\t// devices the tradeoff between a smaller memory footprint and the\n\t// longer time needed for path finding might be a desirable one.\n\tif db.NoGraphCache && db.Backend != BoltBackend {\n\t\treturn fmt.Errorf(\"cannot use no-graph-cache with database \"+\n\t\t\t\"backend '%v'\", db.Backend)\n\t}\n\n\treturn nil\n}\n\n// Init should be called upon start to pre-initialize database access dependent\n// on configuration.",
      "length": 1229,
      "tokens": 190,
      "embedding": []
    },
    {
      "slug": "func (db *DB) Init(ctx context.Context, dbPath string) error {",
      "content": "func (db *DB) Init(ctx context.Context, dbPath string) error {\n\t// Start embedded etcd server if requested.\n\tswitch {\n\tcase db.Backend == EtcdBackend && db.Etcd.Embedded:\n\t\tcfg, _, err := kvdb.StartEtcdTestBackend(\n\t\t\tdbPath, db.Etcd.EmbeddedClientPort,\n\t\t\tdb.Etcd.EmbeddedPeerPort, db.Etcd.EmbeddedLogFile,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Override the original config with the config for\n\t\t// the embedded instance.\n\t\tdb.Etcd = cfg\n\n\tcase db.Backend == PostgresBackend:\n\t\tsqlbase.Init(db.Postgres.MaxConnections)\n\n\tcase db.Backend == SqliteBackend:\n\t\tsqlbase.Init(db.Sqlite.MaxConnections)\n\t}\n\n\treturn nil\n}\n\n// DatabaseBackends is a two-tuple that holds the set of active database\n// backends for the daemon. The two backends we expose are the graph database\n// backend, and the channel state backend.",
      "length": 727,
      "tokens": 96,
      "embedding": []
    },
    {
      "slug": "type DatabaseBackends struct {",
      "content": "type DatabaseBackends struct {\n\t// GraphDB points to the database backend that contains the less\n\t// critical data that is accessed often, such as the channel graph and\n\t// chain height hints.\n\tGraphDB kvdb.Backend\n\n\t// ChanStateDB points to a possibly networked replicated backend that\n\t// contains the critical channel state related data.\n\tChanStateDB kvdb.Backend\n\n\t// HeightHintDB points to a possibly networked replicated backend that\n\t// contains the chain height hint related data.\n\tHeightHintDB kvdb.Backend\n\n\t// MacaroonDB points to a database backend that stores the macaroon root\n\t// keys.\n\tMacaroonDB kvdb.Backend\n\n\t// DecayedLogDB points to a database backend that stores the decayed log\n\t// data.\n\tDecayedLogDB kvdb.Backend\n\n\t// TowerClientDB points to a database backend that stores the watchtower\n\t// client data. This might be nil if the watchtower client is disabled.\n\tTowerClientDB kvdb.Backend\n\n\t// TowerServerDB points to a database backend that stores the watchtower\n\t// server data. This might be nil if the watchtower server is disabled.\n\tTowerServerDB kvdb.Backend\n\n\t// WalletDB is an option that instructs the wallet loader where to load\n\t// the underlying wallet database from.\n\tWalletDB btcwallet.LoaderOption\n\n\t// Remote indicates whether the database backends are remote, possibly\n\t// replicated instances or local bbolt or sqlite backed databases.\n\tRemote bool\n\n\t// CloseFuncs is a map of close functions for each of the initialized\n\t// DB backends keyed by their namespace name.\n\tCloseFuncs map[string]func() error\n}\n\n// GetBackends returns a set of kvdb.Backends as set in the DB config.",
      "length": 1547,
      "tokens": 235,
      "embedding": []
    },
    {
      "slug": "func (db *DB) GetBackends(ctx context.Context, chanDBPath,",
      "content": "func (db *DB) GetBackends(ctx context.Context, chanDBPath,\n\twalletDBPath, towerServerDBPath string, towerClientEnabled,\n\ttowerServerEnabled bool, logger btclog.Logger) (*DatabaseBackends,\n\terror) {\n\n\t// We keep track of all the kvdb backends we actually open and return a\n\t// reference to their close function so they can be cleaned up properly\n\t// on error or shutdown.\n\tcloseFuncs := make(map[string]func() error)\n\n\t// If we need to return early because of an error, we invoke any close\n\t// function that has been initialized so far.\n\treturnEarly := true\n\tdefer func() {\n\t\tif !returnEarly {\n\t\t\treturn\n\t\t}\n\n\t\tfor _, closeFunc := range closeFuncs {\n\t\t\t_ = closeFunc()\n\t\t}\n\t}()\n\n\tswitch db.Backend {\n\tcase EtcdBackend:\n\t\t// As long as the graph data, channel state and height hint\n\t\t// cache are all still in the channel.db file in bolt, we\n\t\t// replicate the same behavior here and use the same etcd\n\t\t// backend for those three sub DBs. But we namespace it properly\n\t\t// to make such a split even easier in the future. This will\n\t\t// break lnd for users that ran on etcd with 0.13.x since that\n\t\t// code used the root namespace. We assume that nobody used etcd\n\t\t// for mainnet just yet since that feature was clearly marked as\n\t\t// experimental in 0.13.x.\n\t\tetcdBackend, err := kvdb.Open(\n\t\t\tkvdb.EtcdBackendName, ctx,\n\t\t\tdb.Etcd.CloneWithSubNamespace(NSChannelDB),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening etcd DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSChannelDB] = etcdBackend.Close\n\n\t\tetcdMacaroonBackend, err := kvdb.Open(\n\t\t\tkvdb.EtcdBackendName, ctx,\n\t\t\tdb.Etcd.CloneWithSubNamespace(NSMacaroonDB),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening etcd macaroon \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSMacaroonDB] = etcdMacaroonBackend.Close\n\n\t\tetcdDecayedLogBackend, err := kvdb.Open(\n\t\t\tkvdb.EtcdBackendName, ctx,\n\t\t\tdb.Etcd.CloneWithSubNamespace(NSDecayedLogDB),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening etcd decayed \"+\n\t\t\t\t\"log DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSDecayedLogDB] = etcdDecayedLogBackend.Close\n\n\t\tetcdTowerClientBackend, err := kvdb.Open(\n\t\t\tkvdb.EtcdBackendName, ctx,\n\t\t\tdb.Etcd.CloneWithSubNamespace(NSTowerClientDB),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening etcd tower \"+\n\t\t\t\t\"client DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerClientDB] = etcdTowerClientBackend.Close\n\n\t\tetcdTowerServerBackend, err := kvdb.Open(\n\t\t\tkvdb.EtcdBackendName, ctx,\n\t\t\tdb.Etcd.CloneWithSubNamespace(NSTowerServerDB),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening etcd tower \"+\n\t\t\t\t\"server DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerServerDB] = etcdTowerServerBackend.Close\n\n\t\tetcdWalletBackend, err := kvdb.Open(\n\t\t\tkvdb.EtcdBackendName, ctx,\n\t\t\tdb.Etcd.\n\t\t\t\tCloneWithSubNamespace(NSWalletDB).\n\t\t\t\tCloneWithSingleWriter(),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening etcd macaroon \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSWalletDB] = etcdWalletBackend.Close\n\n\t\treturnEarly = false\n\n\t\treturn &DatabaseBackends{\n\t\t\tGraphDB:       etcdBackend,\n\t\t\tChanStateDB:   etcdBackend,\n\t\t\tHeightHintDB:  etcdBackend,\n\t\t\tMacaroonDB:    etcdMacaroonBackend,\n\t\t\tDecayedLogDB:  etcdDecayedLogBackend,\n\t\t\tTowerClientDB: etcdTowerClientBackend,\n\t\t\tTowerServerDB: etcdTowerServerBackend,\n\t\t\t// The wallet loader will attempt to use/create the\n\t\t\t// wallet in the replicated remote DB if we're running\n\t\t\t// in a clustered environment. This will ensure that all\n\t\t\t// members of the cluster have access to the same wallet\n\t\t\t// state.\n\t\t\tWalletDB: btcwallet.LoaderWithExternalWalletDB(\n\t\t\t\tetcdWalletBackend,\n\t\t\t),\n\t\t\tRemote:     true,\n\t\t\tCloseFuncs: closeFuncs,\n\t\t}, nil\n\n\tcase PostgresBackend:\n\t\tpostgresBackend, err := kvdb.Open(\n\t\t\tkvdb.PostgresBackendName, ctx,\n\t\t\tdb.Postgres, NSChannelDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening postgres graph \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSChannelDB] = postgresBackend.Close\n\n\t\tpostgresMacaroonBackend, err := kvdb.Open(\n\t\t\tkvdb.PostgresBackendName, ctx,\n\t\t\tdb.Postgres, NSMacaroonDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening postgres \"+\n\t\t\t\t\"macaroon DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSMacaroonDB] = postgresMacaroonBackend.Close\n\n\t\tpostgresDecayedLogBackend, err := kvdb.Open(\n\t\t\tkvdb.PostgresBackendName, ctx,\n\t\t\tdb.Postgres, NSDecayedLogDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening postgres \"+\n\t\t\t\t\"decayed log DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSDecayedLogDB] = postgresDecayedLogBackend.Close\n\n\t\tpostgresTowerClientBackend, err := kvdb.Open(\n\t\t\tkvdb.PostgresBackendName, ctx,\n\t\t\tdb.Postgres, NSTowerClientDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening postgres tower \"+\n\t\t\t\t\"client DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerClientDB] = postgresTowerClientBackend.Close\n\n\t\tpostgresTowerServerBackend, err := kvdb.Open(\n\t\t\tkvdb.PostgresBackendName, ctx,\n\t\t\tdb.Postgres, NSTowerServerDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening postgres tower \"+\n\t\t\t\t\"server DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerServerDB] = postgresTowerServerBackend.Close\n\n\t\tpostgresWalletBackend, err := kvdb.Open(\n\t\t\tkvdb.PostgresBackendName, ctx,\n\t\t\tdb.Postgres, NSWalletDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening postgres macaroon \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSWalletDB] = postgresWalletBackend.Close\n\n\t\t// Warn if the user is trying to switch over to a Postgres DB\n\t\t// while there is a wallet or channel bbolt DB still present.\n\t\twarnExistingBoltDBs(\n\t\t\tlogger, \"postgres\", walletDBPath, WalletDBName,\n\t\t)\n\t\twarnExistingBoltDBs(\n\t\t\tlogger, \"postgres\", chanDBPath, ChannelDBName,\n\t\t)\n\n\t\treturnEarly = false\n\n\t\treturn &DatabaseBackends{\n\t\t\tGraphDB:       postgresBackend,\n\t\t\tChanStateDB:   postgresBackend,\n\t\t\tHeightHintDB:  postgresBackend,\n\t\t\tMacaroonDB:    postgresMacaroonBackend,\n\t\t\tDecayedLogDB:  postgresDecayedLogBackend,\n\t\t\tTowerClientDB: postgresTowerClientBackend,\n\t\t\tTowerServerDB: postgresTowerServerBackend,\n\t\t\t// The wallet loader will attempt to use/create the\n\t\t\t// wallet in the replicated remote DB if we're running\n\t\t\t// in a clustered environment. This will ensure that all\n\t\t\t// members of the cluster have access to the same wallet\n\t\t\t// state.\n\t\t\tWalletDB: btcwallet.LoaderWithExternalWalletDB(\n\t\t\t\tpostgresWalletBackend,\n\t\t\t),\n\t\t\tRemote:     true,\n\t\t\tCloseFuncs: closeFuncs,\n\t\t}, nil\n\n\tcase SqliteBackend:\n\t\t// Note that for sqlite, we put kv tables for the channel.db,\n\t\t// wtclient.db and sphinxreplay.db all in the channel.sqlite db.\n\t\t// The tables for wallet.db and macaroon.db are in the\n\t\t// chain.sqlite db and watchtower.db tables are in the\n\t\t// watchtower.sqlite db. The reason for the multiple sqlite dbs\n\t\t// is twofold. The first reason is that it maintains the file\n\t\t// structure that users are used to. The second reason is the\n\t\t// fact that sqlite only supports one writer at a time which\n\t\t// would cause deadlocks in the code due to the wallet db often\n\t\t// being accessed during a write to another db.\n\t\tsqliteBackend, err := kvdb.Open(\n\t\t\tkvdb.SqliteBackendName, ctx, db.Sqlite, chanDBPath,\n\t\t\tSqliteChannelDBName, NSChannelDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening sqlite graph \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSChannelDB] = sqliteBackend.Close\n\n\t\tsqliteMacaroonBackend, err := kvdb.Open(\n\t\t\tkvdb.SqliteBackendName, ctx, db.Sqlite, walletDBPath,\n\t\t\tSqliteChainDBName, NSMacaroonDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening sqlite \"+\n\t\t\t\t\"macaroon DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSMacaroonDB] = sqliteMacaroonBackend.Close\n\n\t\tsqliteDecayedLogBackend, err := kvdb.Open(\n\t\t\tkvdb.SqliteBackendName, ctx, db.Sqlite, chanDBPath,\n\t\t\tSqliteChannelDBName, NSDecayedLogDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening sqlite decayed \"+\n\t\t\t\t\"log DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSDecayedLogDB] = sqliteDecayedLogBackend.Close\n\n\t\tsqliteTowerClientBackend, err := kvdb.Open(\n\t\t\tkvdb.SqliteBackendName, ctx, db.Sqlite, chanDBPath,\n\t\t\tSqliteChannelDBName, NSTowerClientDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening sqlite tower \"+\n\t\t\t\t\"client DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerClientDB] = sqliteTowerClientBackend.Close\n\n\t\tsqliteTowerServerBackend, err := kvdb.Open(\n\t\t\tkvdb.SqliteBackendName, ctx, db.Sqlite,\n\t\t\ttowerServerDBPath, SqliteTowerDBName, NSTowerServerDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening sqlite tower \"+\n\t\t\t\t\"server DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerServerDB] = sqliteTowerServerBackend.Close\n\n\t\tsqliteWalletBackend, err := kvdb.Open(\n\t\t\tkvdb.SqliteBackendName, ctx, db.Sqlite, walletDBPath,\n\t\t\tSqliteChainDBName, NSWalletDB,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening sqlite macaroon \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSWalletDB] = sqliteWalletBackend.Close\n\n\t\t// Warn if the user is trying to switch over to a sqlite DB\n\t\t// while there is a wallet or channel bbolt DB still present.\n\t\twarnExistingBoltDBs(\n\t\t\tlogger, \"sqlite\", walletDBPath, WalletDBName,\n\t\t)\n\t\twarnExistingBoltDBs(\n\t\t\tlogger, \"sqlite\", chanDBPath, ChannelDBName,\n\t\t)\n\n\t\treturnEarly = false\n\n\t\treturn &DatabaseBackends{\n\t\t\tGraphDB:       sqliteBackend,\n\t\t\tChanStateDB:   sqliteBackend,\n\t\t\tHeightHintDB:  sqliteBackend,\n\t\t\tMacaroonDB:    sqliteMacaroonBackend,\n\t\t\tDecayedLogDB:  sqliteDecayedLogBackend,\n\t\t\tTowerClientDB: sqliteTowerClientBackend,\n\t\t\tTowerServerDB: sqliteTowerServerBackend,\n\t\t\t// The wallet loader will attempt to use/create the\n\t\t\t// wallet in the replicated remote DB if we're running\n\t\t\t// in a clustered environment. This will ensure that all\n\t\t\t// members of the cluster have access to the same wallet\n\t\t\t// state.\n\t\t\tWalletDB: btcwallet.LoaderWithExternalWalletDB(\n\t\t\t\tsqliteWalletBackend,\n\t\t\t),\n\t\t\tCloseFuncs: closeFuncs,\n\t\t}, nil\n\t}\n\n\t// We're using all bbolt based databases by default.\n\tboltBackend, err := kvdb.GetBoltBackend(&kvdb.BoltBackendConfig{\n\t\tDBPath:            chanDBPath,\n\t\tDBFileName:        ChannelDBName,\n\t\tDBTimeout:         db.Bolt.DBTimeout,\n\t\tNoFreelistSync:    db.Bolt.NoFreelistSync,\n\t\tAutoCompact:       db.Bolt.AutoCompact,\n\t\tAutoCompactMinAge: db.Bolt.AutoCompactMinAge,\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error opening bolt DB: %v\", err)\n\t}\n\tcloseFuncs[NSChannelDB] = boltBackend.Close\n\n\tmacaroonBackend, err := kvdb.GetBoltBackend(&kvdb.BoltBackendConfig{\n\t\tDBPath:            walletDBPath,\n\t\tDBFileName:        MacaroonDBName,\n\t\tDBTimeout:         db.Bolt.DBTimeout,\n\t\tNoFreelistSync:    db.Bolt.NoFreelistSync,\n\t\tAutoCompact:       db.Bolt.AutoCompact,\n\t\tAutoCompactMinAge: db.Bolt.AutoCompactMinAge,\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error opening macaroon DB: %v\", err)\n\t}\n\tcloseFuncs[NSMacaroonDB] = macaroonBackend.Close\n\n\tdecayedLogBackend, err := kvdb.GetBoltBackend(&kvdb.BoltBackendConfig{\n\t\tDBPath:            chanDBPath,\n\t\tDBFileName:        DecayedLogDbName,\n\t\tDBTimeout:         db.Bolt.DBTimeout,\n\t\tNoFreelistSync:    db.Bolt.NoFreelistSync,\n\t\tAutoCompact:       db.Bolt.AutoCompact,\n\t\tAutoCompactMinAge: db.Bolt.AutoCompactMinAge,\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error opening decayed log DB: %v\", err)\n\t}\n\tcloseFuncs[NSDecayedLogDB] = decayedLogBackend.Close\n\n\t// The tower client is optional and might not be enabled by the user. We\n\t// handle it being nil properly in the main server.\n\tvar towerClientBackend kvdb.Backend\n\tif towerClientEnabled {\n\t\ttowerClientBackend, err = kvdb.GetBoltBackend(\n\t\t\t&kvdb.BoltBackendConfig{\n\t\t\t\tDBPath:            chanDBPath,\n\t\t\t\tDBFileName:        TowerClientDBName,\n\t\t\t\tDBTimeout:         db.Bolt.DBTimeout,\n\t\t\t\tNoFreelistSync:    db.Bolt.NoFreelistSync,\n\t\t\t\tAutoCompact:       db.Bolt.AutoCompact,\n\t\t\t\tAutoCompactMinAge: db.Bolt.AutoCompactMinAge,\n\t\t\t},\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening tower client \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerClientDB] = towerClientBackend.Close\n\t}\n\n\t// The tower server is optional and might not be enabled by the user. We\n\t// handle it being nil properly in the main server.\n\tvar towerServerBackend kvdb.Backend\n\tif towerServerEnabled {\n\t\ttowerServerBackend, err = kvdb.GetBoltBackend(\n\t\t\t&kvdb.BoltBackendConfig{\n\t\t\t\tDBPath:            towerServerDBPath,\n\t\t\t\tDBFileName:        TowerServerDBName,\n\t\t\t\tDBTimeout:         db.Bolt.DBTimeout,\n\t\t\t\tNoFreelistSync:    db.Bolt.NoFreelistSync,\n\t\t\t\tAutoCompact:       db.Bolt.AutoCompact,\n\t\t\t\tAutoCompactMinAge: db.Bolt.AutoCompactMinAge,\n\t\t\t},\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error opening tower server \"+\n\t\t\t\t\"DB: %v\", err)\n\t\t}\n\t\tcloseFuncs[NSTowerServerDB] = towerServerBackend.Close\n\t}\n\n\treturnEarly = false\n\n\treturn &DatabaseBackends{\n\t\tGraphDB:       boltBackend,\n\t\tChanStateDB:   boltBackend,\n\t\tHeightHintDB:  boltBackend,\n\t\tMacaroonDB:    macaroonBackend,\n\t\tDecayedLogDB:  decayedLogBackend,\n\t\tTowerClientDB: towerClientBackend,\n\t\tTowerServerDB: towerServerBackend,\n\t\t// When \"running locally\", LND will use the bbolt wallet.db to\n\t\t// store the wallet located in the chain data dir, parametrized\n\t\t// by the active network. The wallet loader has its own cleanup\n\t\t// method so we don't need to add anything to our map (in fact\n\t\t// nothing is opened just yet).\n\t\tWalletDB: btcwallet.LoaderWithLocalWalletDB(\n\t\t\twalletDBPath, db.Bolt.NoFreelistSync, db.Bolt.DBTimeout,\n\t\t),\n\t\tCloseFuncs: closeFuncs,\n\t}, nil\n}\n\n// warnExistingBoltDBs checks if there is an existing bbolt database in the\n// given location and logs a warning if so.",
      "length": 12955,
      "tokens": 1476,
      "embedding": []
    },
    {
      "slug": "func warnExistingBoltDBs(log btclog.Logger, dbType, dir, fileName string) {",
      "content": "func warnExistingBoltDBs(log btclog.Logger, dbType, dir, fileName string) {\n\tif lnrpc.FileExists(filepath.Join(dir, fileName)) {\n\t\tlog.Warnf(\"Found existing bbolt database file in %s/%s while \"+\n\t\t\t\"using database type %s. Existing data will NOT be \"+\n\t\t\t\"migrated to %s automatically!\", dir, fileName, dbType,\n\t\t\tdbType)\n\t}\n}\n\n// Compile-time constraint to ensure Workers implements the Validator interface.\nvar _ Validator = (*DB)(nil)\n",
      "length": 352,
      "tokens": 48,
      "embedding": []
    }
  ]
}