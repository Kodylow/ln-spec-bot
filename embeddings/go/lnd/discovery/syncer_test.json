{
  "filepath": "../implementations/go/lnd/discovery/syncer_test.go",
  "package": "discovery",
  "sections": [
    {
      "slug": "type horizonQuery struct {",
      "content": "type horizonQuery struct {\n\tchain chainhash.Hash\n\tstart time.Time\n\tend   time.Time\n}",
      "length": 54,
      "tokens": 7,
      "embedding": []
    },
    {
      "slug": "type filterRangeReq struct {",
      "content": "type filterRangeReq struct {\n\tstartHeight, endHeight uint32\n}\n",
      "length": 31,
      "tokens": 4,
      "embedding": []
    },
    {
      "slug": "type mockChannelGraphTimeSeries struct {",
      "content": "type mockChannelGraphTimeSeries struct {\n\thighestID lnwire.ShortChannelID\n\n\thorizonReq  chan horizonQuery\n\thorizonResp chan []lnwire.Message\n\n\tfilterReq  chan []lnwire.ShortChannelID\n\tfilterResp chan []lnwire.ShortChannelID\n\n\tfilterRangeReqs chan filterRangeReq\n\tfilterRangeResp chan []lnwire.ShortChannelID\n\n\tannReq  chan []lnwire.ShortChannelID\n\tannResp chan []lnwire.Message\n\n\tupdateReq  chan lnwire.ShortChannelID\n\tupdateResp chan []*lnwire.ChannelUpdate\n}\n",
      "length": 403,
      "tokens": 33,
      "embedding": []
    },
    {
      "slug": "func newMockChannelGraphTimeSeries(",
      "content": "func newMockChannelGraphTimeSeries(\n\thID lnwire.ShortChannelID) *mockChannelGraphTimeSeries {\n\n\treturn &mockChannelGraphTimeSeries{\n\t\thighestID: hID,\n\n\t\thorizonReq:  make(chan horizonQuery, 1),\n\t\thorizonResp: make(chan []lnwire.Message, 1),\n\n\t\tfilterReq:  make(chan []lnwire.ShortChannelID, 1),\n\t\tfilterResp: make(chan []lnwire.ShortChannelID, 1),\n\n\t\tfilterRangeReqs: make(chan filterRangeReq, 1),\n\t\tfilterRangeResp: make(chan []lnwire.ShortChannelID, 1),\n\n\t\tannReq:  make(chan []lnwire.ShortChannelID, 1),\n\t\tannResp: make(chan []lnwire.Message, 1),\n\n\t\tupdateReq:  make(chan lnwire.ShortChannelID, 1),\n\t\tupdateResp: make(chan []*lnwire.ChannelUpdate, 1),\n\t}\n}\n",
      "length": 603,
      "tokens": 50,
      "embedding": []
    },
    {
      "slug": "func (m *mockChannelGraphTimeSeries) HighestChanID(chain chainhash.Hash) (*lnwire.ShortChannelID, error) {",
      "content": "func (m *mockChannelGraphTimeSeries) HighestChanID(chain chainhash.Hash) (*lnwire.ShortChannelID, error) {\n\treturn &m.highestID, nil\n}",
      "length": 26,
      "tokens": 4,
      "embedding": []
    },
    {
      "slug": "func (m *mockChannelGraphTimeSeries) UpdatesInHorizon(chain chainhash.Hash,",
      "content": "func (m *mockChannelGraphTimeSeries) UpdatesInHorizon(chain chainhash.Hash,\n\tstartTime time.Time, endTime time.Time) ([]lnwire.Message, error) {\n\n\tm.horizonReq <- horizonQuery{\n\t\tchain, startTime, endTime,\n\t}\n\n\treturn <-m.horizonResp, nil\n}",
      "length": 157,
      "tokens": 18,
      "embedding": []
    },
    {
      "slug": "func (m *mockChannelGraphTimeSeries) FilterKnownChanIDs(chain chainhash.Hash,",
      "content": "func (m *mockChannelGraphTimeSeries) FilterKnownChanIDs(chain chainhash.Hash,\n\tsuperSet []lnwire.ShortChannelID) ([]lnwire.ShortChannelID, error) {\n\n\tm.filterReq <- superSet\n\n\treturn <-m.filterResp, nil\n}",
      "length": 121,
      "tokens": 12,
      "embedding": []
    },
    {
      "slug": "func (m *mockChannelGraphTimeSeries) FilterChannelRange(chain chainhash.Hash,",
      "content": "func (m *mockChannelGraphTimeSeries) FilterChannelRange(chain chainhash.Hash,\n\tstartHeight, endHeight uint32) ([]channeldb.BlockChannelRange, error) {\n\n\tm.filterRangeReqs <- filterRangeReq{startHeight, endHeight}\n\treply := <-m.filterRangeResp\n\n\tchannelsPerBlock := make(map[uint32][]lnwire.ShortChannelID)\n\tfor _, cid := range reply {\n\t\tchannelsPerBlock[cid.BlockHeight] = append(\n\t\t\tchannelsPerBlock[cid.BlockHeight], cid,\n\t\t)\n\t}\n\n\t// Return the channel ranges in ascending block height order.\n\tblocks := make([]uint32, 0, len(channelsPerBlock))\n\tfor block := range channelsPerBlock {\n\t\tblocks = append(blocks, block)\n\t}\n\tsort.Slice(blocks, func(i, j int) bool {\n\t\treturn blocks[i] < blocks[j]\n\t})\n\n\tchannelRanges := make([]channeldb.BlockChannelRange, 0, len(channelsPerBlock))\n\tfor _, block := range blocks {\n\t\tchannelRanges = append(channelRanges, channeldb.BlockChannelRange{\n\t\t\tHeight:   block,\n\t\t\tChannels: channelsPerBlock[block],\n\t\t})\n\t}\n\n\treturn channelRanges, nil\n}",
      "length": 868,
      "tokens": 93,
      "embedding": []
    },
    {
      "slug": "func (m *mockChannelGraphTimeSeries) FetchChanAnns(chain chainhash.Hash,",
      "content": "func (m *mockChannelGraphTimeSeries) FetchChanAnns(chain chainhash.Hash,\n\tshortChanIDs []lnwire.ShortChannelID) ([]lnwire.Message, error) {\n\n\tm.annReq <- shortChanIDs\n\n\treturn <-m.annResp, nil\n}",
      "length": 116,
      "tokens": 12,
      "embedding": []
    },
    {
      "slug": "func (m *mockChannelGraphTimeSeries) FetchChanUpdates(chain chainhash.Hash,",
      "content": "func (m *mockChannelGraphTimeSeries) FetchChanUpdates(chain chainhash.Hash,\n\tshortChanID lnwire.ShortChannelID) ([]*lnwire.ChannelUpdate, error) {\n\n\tm.updateReq <- shortChanID\n\n\treturn <-m.updateResp, nil\n}\n\nvar _ ChannelGraphTimeSeries = (*mockChannelGraphTimeSeries)(nil)\n\n// newTestSyncer creates a new test instance of a GossipSyncer. A buffered\n// message channel is returned for intercepting messages sent from the syncer,\n// in addition to a mock channel series which allows the test to control which\n// messages the syncer knows of or wishes to filter out. The variadic flags are\n// treated as positional arguments where the first index signals that the syncer\n// should spawn a channelGraphSyncer and second index signals that the syncer\n// should spawn a replyHandler. Any flags beyond the first two are currently\n// ignored. If no flags are provided, both a channelGraphSyncer and replyHandler\n// will be spawned by default.",
      "length": 842,
      "tokens": 127,
      "embedding": []
    },
    {
      "slug": "func newTestSyncer(hID lnwire.ShortChannelID,",
      "content": "func newTestSyncer(hID lnwire.ShortChannelID,\n\tencodingType lnwire.ShortChanIDEncoding, chunkSize int32,\n\tflags ...bool) (chan []lnwire.Message,\n\t*GossipSyncer, *mockChannelGraphTimeSeries) {\n\n\tsyncChannels := true\n\treplyQueries := true\n\tif len(flags) > 0 {\n\t\tsyncChannels = flags[0]\n\t}\n\tif len(flags) > 1 {\n\t\treplyQueries = flags[1]\n\t}\n\n\tmsgChan := make(chan []lnwire.Message, 20)\n\tcfg := gossipSyncerCfg{\n\t\tchannelSeries:  newMockChannelGraphTimeSeries(hID),\n\t\tencodingType:   encodingType,\n\t\tchunkSize:      chunkSize,\n\t\tbatchSize:      chunkSize,\n\t\tnoSyncChannels: !syncChannels,\n\t\tnoReplyQueries: !replyQueries,\n\t\tsendToPeer: func(msgs ...lnwire.Message) error {\n\t\t\tmsgChan <- msgs\n\t\t\treturn nil\n\t\t},\n\t\tsendToPeerSync: func(msgs ...lnwire.Message) error {\n\t\t\tmsgChan <- msgs\n\t\t\treturn nil\n\t\t},\n\t\tdelayedQueryReplyInterval: 2 * time.Second,\n\t\tbestHeight: func() uint32 {\n\t\t\treturn latestKnownHeight\n\t\t},\n\t\tmarkGraphSynced:          func() {},\n\t\tmaxQueryChanRangeReplies: maxQueryChanRangeReplies,\n\t}\n\tsyncer := newGossipSyncer(cfg)\n\n\treturn msgChan, syncer, cfg.channelSeries.(*mockChannelGraphTimeSeries)\n}\n\n// TestGossipSyncerFilterGossipMsgsNoHorizon tests that if the remote peer\n// doesn't have a horizon set, then we won't send any incoming messages to it.",
      "length": 1178,
      "tokens": 125,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerFilterGossipMsgsNoHorizon(t *testing.T) {",
      "content": "func TestGossipSyncerFilterGossipMsgsNoHorizon(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, _ := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\t// With the syncer created, we'll create a set of messages to filter\n\t// through the gossiper to the target peer.\n\tmsgs := []msgWithSenders{\n\t\t{\n\t\t\tmsg: &lnwire.NodeAnnouncement{Timestamp: uint32(time.Now().Unix())},\n\t\t},\n\t\t{\n\t\t\tmsg: &lnwire.NodeAnnouncement{Timestamp: uint32(time.Now().Unix())},\n\t\t},\n\t}\n\n\t// We'll then attempt to filter the set of messages through the target\n\t// peer.\n\tsyncer.FilterGossipMsgs(msgs...)\n\n\t// As the remote peer doesn't yet have a gossip timestamp set, we\n\t// shouldn't receive any outbound messages.\n\tselect {\n\tcase msg := <-msgChan:\n\t\tt.Fatalf(\"received message but shouldn't have: %v\",\n\t\t\tspew.Sdump(msg))\n\n\tcase <-time.After(time.Millisecond * 10):\n\t}\n}\n",
      "length": 923,
      "tokens": 120,
      "embedding": []
    },
    {
      "slug": "func unixStamp(a int64) uint32 {",
      "content": "func unixStamp(a int64) uint32 {\n\tt := time.Unix(a, 0)\n\treturn uint32(t.Unix())\n}\n\n// TestGossipSyncerFilterGossipMsgsAll tests that we're able to properly filter\n// out a set of incoming messages based on the set remote update horizon for a\n// peer. We tests all messages type, and all time straddling. We'll also send a\n// channel ann that already has a channel update on disk.",
      "length": 339,
      "tokens": 58,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerFilterGossipMsgsAllInMemory(t *testing.T) {",
      "content": "func TestGossipSyncerFilterGossipMsgsAllInMemory(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\t// We'll create then apply a remote horizon for the target peer with a\n\t// set of manually selected timestamps.\n\tremoteHorizon := &lnwire.GossipTimestampRange{\n\t\tFirstTimestamp: unixStamp(25000),\n\t\tTimestampRange: uint32(1000),\n\t}\n\tsyncer.remoteUpdateHorizon = remoteHorizon\n\n\t// With the syncer created, we'll create a set of messages to filter\n\t// through the gossiper to the target peer. Our message will consist of\n\t// one node announcement above the horizon, one below. Additionally,\n\t// we'll include a chan ann with an update below the horizon, one\n\t// with an update timestamp above the horizon, and one without any\n\t// channel updates at all.\n\tmsgs := []msgWithSenders{\n\t\t{\n\t\t\t// Node ann above horizon.\n\t\t\tmsg: &lnwire.NodeAnnouncement{Timestamp: unixStamp(25001)},\n\t\t},\n\t\t{\n\t\t\t// Node ann below horizon.\n\t\t\tmsg: &lnwire.NodeAnnouncement{Timestamp: unixStamp(5)},\n\t\t},\n\t\t{\n\t\t\t// Node ann above horizon.\n\t\t\tmsg: &lnwire.NodeAnnouncement{Timestamp: unixStamp(999999)},\n\t\t},\n\t\t{\n\t\t\t// Ann tuple below horizon.\n\t\t\tmsg: &lnwire.ChannelAnnouncement{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(10),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmsg: &lnwire.ChannelUpdate{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(10),\n\t\t\t\tTimestamp:      unixStamp(5),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t// Ann tuple above horizon.\n\t\t\tmsg: &lnwire.ChannelAnnouncement{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(15),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmsg: &lnwire.ChannelUpdate{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(15),\n\t\t\t\tTimestamp:      unixStamp(25002),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t// Ann tuple beyond horizon.\n\t\t\tmsg: &lnwire.ChannelAnnouncement{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(20),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmsg: &lnwire.ChannelUpdate{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(20),\n\t\t\t\tTimestamp:      unixStamp(999999),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t// Ann w/o an update at all, the update in the DB will\n\t\t\t// be below the horizon.\n\t\t\tmsg: &lnwire.ChannelAnnouncement{\n\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(25),\n\t\t\t},\n\t\t},\n\t}\n\n\t// Before we send off the query, we'll ensure we send the missing\n\t// channel update for that final ann. It will be below the horizon, so\n\t// shouldn't be sent anyway.\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query received\")\n\t\t\treturn\n\t\tcase query := <-chanSeries.updateReq:\n\t\t\t// It should be asking for the chan updates of short\n\t\t\t// chan ID 25.\n\t\t\texpectedID := lnwire.NewShortChanIDFromInt(25)\n\t\t\tif expectedID != query {\n\t\t\t\terrCh <- fmt.Errorf(\"wrong query id: expected %v, got %v\",\n\t\t\t\t\texpectedID, query)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// If so, then we'll send back the missing update.\n\t\t\tchanSeries.updateResp <- []*lnwire.ChannelUpdate{\n\t\t\t\t{\n\t\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(25),\n\t\t\t\t\tTimestamp:      unixStamp(5),\n\t\t\t\t},\n\t\t\t}\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\n\t// We'll then instruct the gossiper to filter this set of messages.\n\tsyncer.FilterGossipMsgs(msgs...)\n\n\t// Out of all the messages we sent in, we should only get 2 of them\n\t// back.\n\tselect {\n\tcase <-time.After(time.Second * 15):\n\t\tt.Fatalf(\"no msgs received\")\n\n\tcase msgs := <-msgChan:\n\t\tif len(msgs) != 3 {\n\t\t\tt.Fatalf(\"expected 3 messages instead got %v \"+\n\t\t\t\t\"messages: %v\", len(msgs), spew.Sdump(msgs))\n\t\t}\n\t}\n\n\t// Wait for error from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerApplyNoHistoricalGossipFilter tests that once a gossip filter\n// is applied for the remote peer, then we don't send the peer all known\n// messages which are within their desired time horizon.",
      "length": 3821,
      "tokens": 493,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerApplyNoHistoricalGossipFilter(t *testing.T) {",
      "content": "func TestGossipSyncerApplyNoHistoricalGossipFilter(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\t_, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\tsyncer.cfg.ignoreHistoricalFilters = true\n\n\t// We'll apply this gossip horizon for the remote peer.\n\tremoteHorizon := &lnwire.GossipTimestampRange{\n\t\tFirstTimestamp: unixStamp(25000),\n\t\tTimestampRange: uint32(1000),\n\t}\n\n\t// After applying the gossip filter, the chan series should not be\n\t// queried using the updated horizon.\n\terrChan := make(chan error, 1)\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\n\t\tselect {\n\t\t// No query received, success.\n\t\tcase <-time.After(3 * time.Second):\n\t\t\terrChan <- nil\n\n\t\t// Unexpected query received.\n\t\tcase <-chanSeries.horizonReq:\n\t\t\terrChan <- errors.New(\"chan series should not have been \" +\n\t\t\t\t\"queried\")\n\t\t}\n\t}()\n\n\t// We'll now attempt to apply the gossip filter for the remote peer.\n\tsyncer.ApplyGossipFilter(remoteHorizon)\n\n\t// Ensure that the syncer's remote horizon was properly updated.\n\tif !reflect.DeepEqual(syncer.remoteUpdateHorizon, remoteHorizon) {\n\t\tt.Fatalf(\"expected remote horizon: %v, got: %v\",\n\t\t\tremoteHorizon, syncer.remoteUpdateHorizon)\n\t}\n\n\t// Wait for the query check to finish.\n\twg.Wait()\n\n\t// Assert that no query was made as a result of applying the gossip\n\t// filter.\n\terr := <-errChan\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n}\n\n// TestGossipSyncerApplyGossipFilter tests that once a gossip filter is applied\n// for the remote peer, then we send the peer all known messages which are\n// within their desired time horizon.",
      "length": 1623,
      "tokens": 221,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerApplyGossipFilter(t *testing.T) {",
      "content": "func TestGossipSyncerApplyGossipFilter(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\t// We'll apply this gossip horizon for the remote peer.\n\tremoteHorizon := &lnwire.GossipTimestampRange{\n\t\tFirstTimestamp: unixStamp(25000),\n\t\tTimestampRange: uint32(1000),\n\t}\n\n\t// Before we apply the horizon, we'll dispatch a response to the query\n\t// that the syncer will issue.\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query recvd\")\n\t\t\treturn\n\t\tcase query := <-chanSeries.horizonReq:\n\t\t\t// The syncer should have translated the time range\n\t\t\t// into the proper star time.\n\t\t\tif remoteHorizon.FirstTimestamp != uint32(query.start.Unix()) {\n\t\t\t\terrCh <- fmt.Errorf(\"wrong query stamp: expected %v, got %v\",\n\t\t\t\t\tremoteHorizon.FirstTimestamp, query.start)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// For this first response, we'll send back an empty\n\t\t\t// set of messages. As result, we shouldn't send any\n\t\t\t// messages.\n\t\t\tchanSeries.horizonResp <- []lnwire.Message{}\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\n\t// We'll now attempt to apply the gossip filter for the remote peer.\n\terr := syncer.ApplyGossipFilter(remoteHorizon)\n\trequire.NoError(t, err, \"unable to apply filter\")\n\n\t// There should be no messages in the message queue as we didn't send\n\t// the syncer and messages within the horizon.\n\tselect {\n\tcase msgs := <-msgChan:\n\t\tt.Fatalf(\"expected no msgs, instead got %v\", spew.Sdump(msgs))\n\tdefault:\n\t}\n\n\t// Wait for error result from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\t// If we repeat the process, but give the syncer a set of valid\n\t// messages, then these should be sent to the remote peer.\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query recvd\")\n\t\t\treturn\n\t\tcase query := <-chanSeries.horizonReq:\n\t\t\t// The syncer should have translated the time range\n\t\t\t// into the proper star time.\n\t\t\tif remoteHorizon.FirstTimestamp != uint32(query.start.Unix()) {\n\t\t\t\terrCh <- fmt.Errorf(\"wrong query stamp: expected %v, got %v\",\n\t\t\t\t\tremoteHorizon.FirstTimestamp, query.start)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// For this first response, we'll send back a proper\n\t\t\t// set of messages that should be echoed back.\n\t\t\tchanSeries.horizonResp <- []lnwire.Message{\n\t\t\t\t&lnwire.ChannelUpdate{\n\t\t\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(25),\n\t\t\t\t\tTimestamp:      unixStamp(5),\n\t\t\t\t},\n\t\t\t}\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\terr = syncer.ApplyGossipFilter(remoteHorizon)\n\trequire.NoError(t, err, \"unable to apply filter\")\n\n\t// We should get back the exact same message.\n\tselect {\n\tcase <-time.After(time.Second * 15):\n\t\tt.Fatalf(\"no msgs received\")\n\n\tcase msgs := <-msgChan:\n\t\tif len(msgs) != 1 {\n\t\t\tt.Fatalf(\"wrong messages: expected %v, got %v\",\n\t\t\t\t1, len(msgs))\n\t\t}\n\t}\n\n\t// Wait for error result from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerQueryChannelRangeWrongChainHash tests that if we receive a\n// channel range query for the wrong chain, then we send back a response with no\n// channels and complete=0.",
      "length": 3345,
      "tokens": 464,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerQueryChannelRangeWrongChainHash(t *testing.T) {",
      "content": "func TestGossipSyncerQueryChannelRangeWrongChainHash(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, _ := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\t// We'll now ask the syncer to reply to a channel range query, but for a\n\t// chain that it isn't aware of.\n\tquery := &lnwire.QueryChannelRange{\n\t\tChainHash:        *chaincfg.SimNetParams.GenesisHash,\n\t\tFirstBlockHeight: 0,\n\t\tNumBlocks:        math.MaxUint32,\n\t}\n\terr := syncer.replyChanRangeQuery(query)\n\trequire.NoError(t, err, \"unable to process short chan ID's\")\n\n\tselect {\n\tcase <-time.After(time.Second * 15):\n\t\tt.Fatalf(\"no msgs received\")\n\n\tcase msgs := <-msgChan:\n\t\t// We should get back exactly one message, that's a\n\t\t// ReplyChannelRange with a matching query, and a complete value\n\t\t// of zero.\n\t\tif len(msgs) != 1 {\n\t\t\tt.Fatalf(\"wrong messages: expected %v, got %v\",\n\t\t\t\t1, len(msgs))\n\t\t}\n\n\t\tmsg, ok := msgs[0].(*lnwire.ReplyChannelRange)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected lnwire.ReplyChannelRange, got %T\", msg)\n\t\t}\n\n\t\tif msg.ChainHash != query.ChainHash {\n\t\t\tt.Fatalf(\"wrong chain hash: expected %v got %v\",\n\t\t\t\tquery.ChainHash, msg.ChainHash)\n\t\t}\n\t\tif msg.Complete != 0 {\n\t\t\tt.Fatalf(\"expected complete set to 0, got %v\",\n\t\t\t\tmsg.Complete)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerReplyShortChanIDsWrongChainHash tests that if we get a chan\n// ID query for the wrong chain, then we send back only a short ID end with\n// complete=0.",
      "length": 1448,
      "tokens": 197,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerReplyShortChanIDsWrongChainHash(t *testing.T) {",
      "content": "func TestGossipSyncerReplyShortChanIDsWrongChainHash(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, _ := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\t// We'll now ask the syncer to reply to a chan ID query, but for a\n\t// chain that it isn't aware of.\n\terr := syncer.replyShortChanIDs(&lnwire.QueryShortChanIDs{\n\t\tChainHash: *chaincfg.SimNetParams.GenesisHash,\n\t})\n\trequire.NoError(t, err, \"unable to process short chan ID's\")\n\n\tselect {\n\tcase <-time.After(time.Second * 15):\n\t\tt.Fatalf(\"no msgs received\")\n\tcase msgs := <-msgChan:\n\n\t\t// We should get back exactly one message, that's a\n\t\t// ReplyShortChanIDsEnd with a matching chain hash, and a\n\t\t// complete value of zero.\n\t\tif len(msgs) != 1 {\n\t\t\tt.Fatalf(\"wrong messages: expected %v, got %v\",\n\t\t\t\t1, len(msgs))\n\t\t}\n\n\t\tmsg, ok := msgs[0].(*lnwire.ReplyShortChanIDsEnd)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected lnwire.ReplyShortChanIDsEnd \"+\n\t\t\t\t\"instead got %T\", msg)\n\t\t}\n\n\t\tif msg.ChainHash != *chaincfg.SimNetParams.GenesisHash {\n\t\t\tt.Fatalf(\"wrong chain hash: expected %v, got %v\",\n\t\t\t\tmsg.ChainHash, chaincfg.SimNetParams.GenesisHash)\n\t\t}\n\t\tif msg.Complete != 0 {\n\t\t\tt.Fatalf(\"complete set incorrectly\")\n\t\t}\n\t}\n}\n\n// TestGossipSyncerReplyShortChanIDs tests that in the case of a known chain\n// hash for a QueryShortChanIDs, we'll return the set of matching\n// announcements, as well as an ending ReplyShortChanIDsEnd message.",
      "length": 1442,
      "tokens": 191,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerReplyShortChanIDs(t *testing.T) {",
      "content": "func TestGossipSyncerReplyShortChanIDs(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\tqueryChanIDs := []lnwire.ShortChannelID{\n\t\tlnwire.NewShortChanIDFromInt(1),\n\t\tlnwire.NewShortChanIDFromInt(2),\n\t\tlnwire.NewShortChanIDFromInt(3),\n\t}\n\n\tqueryReply := []lnwire.Message{\n\t\t&lnwire.ChannelAnnouncement{\n\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(20),\n\t\t},\n\t\t&lnwire.ChannelUpdate{\n\t\t\tShortChannelID: lnwire.NewShortChanIDFromInt(20),\n\t\t\tTimestamp:      unixStamp(999999),\n\t\t},\n\t\t&lnwire.NodeAnnouncement{Timestamp: unixStamp(25001)},\n\t}\n\n\t// We'll then craft a reply to the upcoming query for all the matching\n\t// channel announcements for a particular set of short channel ID's.\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query recvd\")\n\t\t\treturn\n\t\tcase chanIDs := <-chanSeries.annReq:\n\t\t\t// The set of chan ID's should match exactly.\n\t\t\tif !reflect.DeepEqual(chanIDs, queryChanIDs) {\n\t\t\t\terrCh <- fmt.Errorf(\"wrong chan IDs: expected %v, got %v\",\n\t\t\t\t\tqueryChanIDs, chanIDs)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// If they do, then we'll send back a response with\n\t\t\t// some canned messages.\n\t\t\tchanSeries.annResp <- queryReply\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\n\t// With our set up above complete, we'll now attempt to obtain a reply\n\t// from the channel syncer for our target chan ID query.\n\terr := syncer.replyShortChanIDs(&lnwire.QueryShortChanIDs{\n\t\tShortChanIDs: queryChanIDs,\n\t})\n\trequire.NoError(t, err, \"unable to query for chan IDs\")\n\n\tfor i := 0; i < len(queryReply)+1; i++ {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\tt.Fatalf(\"no msgs received\")\n\n\t\t// We should get back exactly 4 messages. The first 3 are the\n\t\t// same messages we sent above, and the query end message.\n\t\tcase msgs := <-msgChan:\n\t\t\tif len(msgs) != 1 {\n\t\t\t\tt.Fatalf(\"wrong number of messages: \"+\n\t\t\t\t\t\"expected %v, got %v\", 1, len(msgs))\n\t\t\t}\n\n\t\t\tisQueryReply := i < len(queryReply)\n\t\t\tfinalMsg, ok := msgs[0].(*lnwire.ReplyShortChanIDsEnd)\n\n\t\t\tswitch {\n\t\t\tcase isQueryReply &&\n\t\t\t\t!reflect.DeepEqual(queryReply[i], msgs[0]):\n\n\t\t\t\tt.Fatalf(\"wrong message: expected %v, got %v\",\n\t\t\t\t\tspew.Sdump(queryReply[i]),\n\t\t\t\t\tspew.Sdump(msgs[0]))\n\n\t\t\tcase !isQueryReply && !ok:\n\t\t\t\tt.Fatalf(\"expected lnwire.ReplyShortChanIDsEnd\"+\n\t\t\t\t\t\" instead got %T\", msgs[3])\n\n\t\t\tcase !isQueryReply && finalMsg.Complete != 1:\n\t\t\t\tt.Fatalf(\"complete wasn't set\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Wait for error from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerReplyChanRangeQuery tests that if we receive a\n// QueryChannelRange message, then we'll properly send back a chunked reply to\n// the remote peer.",
      "length": 2851,
      "tokens": 357,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerReplyChanRangeQuery(t *testing.T) {",
      "content": "func TestGossipSyncerReplyChanRangeQuery(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll use a smaller chunk size so we can easily test all the edge\n\t// cases.\n\tconst chunkSize = 2\n\n\t// We'll now create our test gossip syncer that will shortly respond to\n\t// our canned query.\n\tmsgChan, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding, chunkSize,\n\t)\n\n\t// Next, we'll craft a query to ask for all the new chan ID's after\n\t// block 100.\n\tconst startingBlockHeight = 100\n\tconst numBlocks = 50\n\tconst endingBlockHeight = startingBlockHeight + numBlocks - 1\n\tquery := &lnwire.QueryChannelRange{\n\t\tFirstBlockHeight: uint32(startingBlockHeight),\n\t\tNumBlocks:        uint32(numBlocks),\n\t}\n\n\t// We'll then launch a goroutine to reply to the query with a set of 5\n\t// responses. This will ensure we get two full chunks, and one partial\n\t// chunk.\n\tqueryResp := []lnwire.ShortChannelID{\n\t\t{\n\t\t\tBlockHeight: uint32(startingBlockHeight),\n\t\t},\n\t\t{\n\t\t\tBlockHeight: 102,\n\t\t},\n\t\t{\n\t\t\tBlockHeight: 104,\n\t\t},\n\t\t{\n\t\t\tBlockHeight: 106,\n\t\t},\n\t\t{\n\t\t\tBlockHeight: 108,\n\t\t},\n\t}\n\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query recvd\")\n\t\t\treturn\n\t\tcase filterReq := <-chanSeries.filterRangeReqs:\n\t\t\t// We should be querying for block 100 to 150.\n\t\t\tif filterReq.startHeight != startingBlockHeight &&\n\t\t\t\tfilterReq.endHeight != endingBlockHeight {\n\n\t\t\t\terrCh <- fmt.Errorf(\"wrong height range: %v\",\n\t\t\t\t\tspew.Sdump(filterReq))\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// If the proper request was sent, then we'll respond\n\t\t\t// with our set of short channel ID's.\n\t\t\tchanSeries.filterRangeResp <- queryResp\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\n\t// With our goroutine active, we'll now issue the query.\n\tif err := syncer.replyChanRangeQuery(query); err != nil {\n\t\tt.Fatalf(\"unable to issue query: %v\", err)\n\t}\n\n\t// At this point, we'll now wait for the syncer to send the chunked\n\t// reply. We should get three sets of messages as two of them should be\n\t// full, while the other is the final fragment.\n\tconst numExpectedChunks = 3\n\tvar prevResp *lnwire.ReplyChannelRange\n\trespMsgs := make([]lnwire.ShortChannelID, 0, 5)\n\tfor i := 0; i < numExpectedChunks; i++ {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\tt.Fatalf(\"no msgs received\")\n\n\t\tcase msg := <-msgChan:\n\t\t\tresp := msg[0]\n\t\t\trangeResp, ok := resp.(*lnwire.ReplyChannelRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"expected ReplyChannelRange instead got %T\", msg)\n\t\t\t}\n\n\t\t\t// We'll determine the correct values of each field in\n\t\t\t// each response based on the order that they were sent.\n\t\t\tvar (\n\t\t\t\texpectedFirstBlockHeight uint32\n\t\t\t\texpectedNumBlocks        uint32\n\t\t\t\texpectedComplete         uint8\n\t\t\t)\n\n\t\t\tswitch {\n\t\t\t// The first reply should range from our starting block\n\t\t\t// height until it reaches its maximum capacity of\n\t\t\t// channels.\n\t\t\tcase i == 0:\n\t\t\t\texpectedFirstBlockHeight = startingBlockHeight\n\t\t\t\texpectedNumBlocks = 4\n\n\t\t\t// The last reply should range starting from the next\n\t\t\t// block of our previous reply up until the ending\n\t\t\t// height of the query. It should also have the Complete\n\t\t\t// bit set.\n\t\t\tcase i == numExpectedChunks-1:\n\t\t\t\texpectedFirstBlockHeight = prevResp.LastBlockHeight() + 1\n\t\t\t\texpectedNumBlocks = endingBlockHeight - expectedFirstBlockHeight + 1\n\t\t\t\texpectedComplete = 1\n\n\t\t\t// Any intermediate replies should range starting from\n\t\t\t// the next block of our previous reply up until it\n\t\t\t// reaches its maximum capacity of channels.\n\t\t\tdefault:\n\t\t\t\texpectedFirstBlockHeight = prevResp.LastBlockHeight() + 1\n\t\t\t\texpectedNumBlocks = 4\n\t\t\t}\n\n\t\t\tswitch {\n\t\t\tcase rangeResp.FirstBlockHeight != expectedFirstBlockHeight:\n\t\t\t\tt.Fatalf(\"FirstBlockHeight in resp #%d \"+\n\t\t\t\t\t\"incorrect: expected %v, got %v\", i+1,\n\t\t\t\t\texpectedFirstBlockHeight,\n\t\t\t\t\trangeResp.FirstBlockHeight)\n\n\t\t\tcase rangeResp.NumBlocks != expectedNumBlocks:\n\t\t\t\tt.Fatalf(\"NumBlocks in resp #%d incorrect: \"+\n\t\t\t\t\t\"expected %v, got %v\", i+1,\n\t\t\t\t\texpectedNumBlocks, rangeResp.NumBlocks)\n\n\t\t\tcase rangeResp.Complete != expectedComplete:\n\t\t\t\tt.Fatalf(\"Complete in resp #%d incorrect: \"+\n\t\t\t\t\t\"expected %v, got %v\", i+1,\n\t\t\t\t\texpectedComplete, rangeResp.Complete)\n\t\t\t}\n\n\t\t\tprevResp = rangeResp\n\t\t\trespMsgs = append(respMsgs, rangeResp.ShortChanIDs...)\n\t\t}\n\t}\n\n\t// We should get back exactly 5 short chan ID's, and they should match\n\t// exactly the ID's we sent as a reply.\n\tif len(respMsgs) != len(queryResp) {\n\t\tt.Fatalf(\"expected %v chan ID's, instead got %v\",\n\t\t\tlen(queryResp), spew.Sdump(respMsgs))\n\t}\n\tif !reflect.DeepEqual(queryResp, respMsgs) {\n\t\tt.Fatalf(\"mismatched response: expected %v, got %v\",\n\t\t\tspew.Sdump(queryResp), spew.Sdump(respMsgs))\n\t}\n\n\t// Wait for error from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerReplyChanRangeQuery tests a variety of\n// QueryChannelRange messages to ensure the underlying queries are\n// executed with the correct block range.",
      "length": 4822,
      "tokens": 657,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerReplyChanRangeQueryBlockRange(t *testing.T) {",
      "content": "func TestGossipSyncerReplyChanRangeQueryBlockRange(t *testing.T) {\n\tt.Parallel()\n\n\t// First create our test gossip syncer that will handle and\n\t// respond to the test queries\n\t_, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding, math.MaxInt32,\n\t)\n\n\t// Next construct test queries with various startBlock and endBlock\n\t// ranges\n\tqueryReqs := []*lnwire.QueryChannelRange{\n\t\t// full range example\n\t\t{\n\t\t\tFirstBlockHeight: uint32(0),\n\t\t\tNumBlocks:        uint32(math.MaxUint32),\n\t\t},\n\n\t\t// small query example that does not overflow\n\t\t{\n\t\t\tFirstBlockHeight: uint32(1000),\n\t\t\tNumBlocks:        uint32(100),\n\t\t},\n\n\t\t// overflow example\n\t\t{\n\t\t\tFirstBlockHeight: uint32(1000),\n\t\t\tNumBlocks:        uint32(math.MaxUint32),\n\t\t},\n\t}\n\n\t// Next construct the expected filterRangeReq startHeight and endHeight\n\t// values that we will compare to the captured values\n\texpFilterReqs := []filterRangeReq{\n\t\t{\n\t\t\tstartHeight: uint32(0),\n\t\t\tendHeight:   uint32(math.MaxUint32 - 1),\n\t\t},\n\t\t{\n\t\t\tstartHeight: uint32(1000),\n\t\t\tendHeight:   uint32(1099),\n\t\t},\n\t\t{\n\t\t\tstartHeight: uint32(1000),\n\t\t\tendHeight:   uint32(math.MaxUint32),\n\t\t},\n\t}\n\n\t// We'll then launch a goroutine to capture the filterRangeReqs for\n\t// each request and return those results once all queries have been\n\t// received\n\tresultsCh := make(chan []filterRangeReq, 1)\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\t// We will capture the values supplied to the chanSeries here\n\t\t// and return the results once all the requests have been\n\t\t// collected\n\t\tcapFilterReqs := []filterRangeReq{}\n\n\t\tfor filterReq := range chanSeries.filterRangeReqs {\n\t\t\t// capture the filter request so we can compare to the\n\t\t\t// expected values later\n\t\t\tcapFilterReqs = append(capFilterReqs, filterReq)\n\n\t\t\t// Reply with an empty result for each query to allow\n\t\t\t// unblock the caller\n\t\t\tqueryResp := []lnwire.ShortChannelID{}\n\t\t\tchanSeries.filterRangeResp <- queryResp\n\n\t\t\t// Once we have collected all results send the results\n\t\t\t// back to the main thread and terminate the goroutine\n\t\t\tif len(capFilterReqs) == len(expFilterReqs) {\n\t\t\t\tresultsCh <- capFilterReqs\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\t// We'll launch a goroutine to send the query sequentially. This\n\t// goroutine ensures that the timeout logic below on the mainthread\n\t// will be reached\n\tgo func() {\n\t\tfor _, query := range queryReqs {\n\t\t\tif err := syncer.replyChanRangeQuery(query); err != nil {\n\t\t\t\terrCh <- fmt.Errorf(\"unable to issue query: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Wait for the results to be collected and validate that the\n\t// collected results match the expected results, the timeout to\n\t// expire, or an error to occur\n\tselect {\n\tcase capFilterReq := <-resultsCh:\n\t\tif !reflect.DeepEqual(expFilterReqs, capFilterReq) {\n\t\t\tt.Fatalf(\"mismatched filter reqs: expected %v, got %v\",\n\t\t\t\tspew.Sdump(expFilterReqs), spew.Sdump(capFilterReq))\n\t\t}\n\tcase <-time.After(time.Second * 10):\n\t\tt.Fatalf(\"goroutine did not return within 10 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerReplyChanRangeQueryNoNewChans tests that if we issue a reply\n// for a channel range query, and we don't have any new channels, then we send\n// back a single response that signals completion.",
      "length": 3084,
      "tokens": 424,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerReplyChanRangeQueryNoNewChans(t *testing.T) {",
      "content": "func TestGossipSyncerReplyChanRangeQueryNoNewChans(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll now create our test gossip syncer that will shortly respond to\n\t// our canned query.\n\tmsgChan, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\t// Next, we'll craft a query to ask for all the new chan ID's after\n\t// block 100.\n\tquery := &lnwire.QueryChannelRange{\n\t\tFirstBlockHeight: 100,\n\t\tNumBlocks:        50,\n\t}\n\n\t// We'll then launch a goroutine to reply to the query no new channels.\n\tresp := []lnwire.ShortChannelID{}\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query recvd\")\n\t\t\treturn\n\t\tcase filterReq := <-chanSeries.filterRangeReqs:\n\t\t\t// We should be querying for block 100 to 150.\n\t\t\tif filterReq.startHeight != 100 && filterReq.endHeight != 150 {\n\t\t\t\terrCh <- fmt.Errorf(\"wrong height range: %v\",\n\t\t\t\t\tspew.Sdump(filterReq))\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// If the proper request was sent, then we'll respond\n\t\t\t// with our blank set of short chan ID's.\n\t\t\tchanSeries.filterRangeResp <- resp\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\n\t// With our goroutine active, we'll now issue the query.\n\tif err := syncer.replyChanRangeQuery(query); err != nil {\n\t\tt.Fatalf(\"unable to issue query: %v\", err)\n\t}\n\n\t// We should get back exactly one message, and the message should\n\t// indicate that this is the final in the series.\n\tselect {\n\tcase <-time.After(time.Second * 15):\n\t\tt.Fatalf(\"no msgs received\")\n\n\tcase msg := <-msgChan:\n\t\tresp := msg[0]\n\t\trangeResp, ok := resp.(*lnwire.ReplyChannelRange)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected ReplyChannelRange instead got %T\", msg)\n\t\t}\n\n\t\tif len(rangeResp.ShortChanIDs) != 0 {\n\t\t\tt.Fatalf(\"expected no chan ID's, instead \"+\n\t\t\t\t\"got: %v\", spew.Sdump(rangeResp.ShortChanIDs))\n\t\t}\n\t\tif rangeResp.Complete != 1 {\n\t\t\tt.Fatalf(\"complete wasn't set\")\n\t\t}\n\t}\n\n\t// Wait for error from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerGenChanRangeQuery tests that given the current best known\n// channel ID, we properly generate an correct initial channel range response.",
      "length": 2122,
      "tokens": 304,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerGenChanRangeQuery(t *testing.T) {",
      "content": "func TestGossipSyncerGenChanRangeQuery(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tconst startingHeight = 200\n\t_, syncer, _ := newTestSyncer(\n\t\tlnwire.ShortChannelID{BlockHeight: startingHeight},\n\t\tdefaultEncoding, defaultChunkSize,\n\t)\n\n\t// If we now ask the syncer to generate an initial range query, it\n\t// should return a start height that's back chanRangeQueryBuffer\n\t// blocks.\n\trangeQuery, err := syncer.genChanRangeQuery(false)\n\trequire.NoError(t, err, \"unable to resp\")\n\n\tfirstHeight := uint32(startingHeight - chanRangeQueryBuffer)\n\tif rangeQuery.FirstBlockHeight != firstHeight {\n\t\tt.Fatalf(\"incorrect chan range query: expected %v, %v\",\n\t\t\trangeQuery.FirstBlockHeight,\n\t\t\tstartingHeight-chanRangeQueryBuffer)\n\t}\n\tif rangeQuery.NumBlocks != latestKnownHeight-firstHeight {\n\t\tt.Fatalf(\"wrong num blocks: expected %v, got %v\",\n\t\t\tlatestKnownHeight-firstHeight, rangeQuery.NumBlocks)\n\t}\n\n\t// Generating a historical range query should result in a start height\n\t// of 0.\n\trangeQuery, err = syncer.genChanRangeQuery(true)\n\trequire.NoError(t, err, \"unable to resp\")\n\tif rangeQuery.FirstBlockHeight != 0 {\n\t\tt.Fatalf(\"incorrect chan range query: expected %v, %v\", 0,\n\t\t\trangeQuery.FirstBlockHeight)\n\t}\n\tif rangeQuery.NumBlocks != latestKnownHeight {\n\t\tt.Fatalf(\"wrong num blocks: expected %v, got %v\",\n\t\t\tlatestKnownHeight, rangeQuery.NumBlocks)\n\t}\n}\n\n// TestGossipSyncerProcessChanRangeReply tests that we'll properly buffer\n// replied channel replies until we have the complete version.",
      "length": 1515,
      "tokens": 177,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerProcessChanRangeReply(t *testing.T) {",
      "content": "func TestGossipSyncerProcessChanRangeReply(t *testing.T) {\n\tt.Parallel()\n\n\tt.Run(\"legacy\", func(t *testing.T) {\n\t\ttestGossipSyncerProcessChanRangeReply(t, true)\n\t})\n\tt.Run(\"block ranges\", func(t *testing.T) {\n\t\ttestGossipSyncerProcessChanRangeReply(t, false)\n\t})\n}\n\n// testGossipSyncerProcessChanRangeReply tests that we'll properly buffer\n// replied channel replies until we have the complete version. The legacy\n// option, if set, uses the Complete field of the reply to determine when we've\n// received all expected replies. Otherwise, it looks at the block ranges of\n// each reply instead.",
      "length": 520,
      "tokens": 68,
      "embedding": []
    },
    {
      "slug": "func testGossipSyncerProcessChanRangeReply(t *testing.T, legacy bool) {",
      "content": "func testGossipSyncerProcessChanRangeReply(t *testing.T, legacy bool) {\n\tt.Parallel()\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\thighestID := lnwire.ShortChannelID{\n\t\tBlockHeight: latestKnownHeight,\n\t}\n\t_, syncer, chanSeries := newTestSyncer(\n\t\thighestID, defaultEncoding, defaultChunkSize,\n\t)\n\n\tstartingState := syncer.state\n\n\tquery, err := syncer.genChanRangeQuery(true)\n\trequire.NoError(t, err, \"unable to generate channel range query\")\n\n\t// When interpreting block ranges, the first reply should start from\n\t// our requested first block, and the last should end at our requested\n\t// last block.\n\treplies := []*lnwire.ReplyChannelRange{\n\t\t{\n\t\t\tFirstBlockHeight: 0,\n\t\t\tNumBlocks:        11,\n\t\t\tShortChanIDs: []lnwire.ShortChannelID{\n\t\t\t\t{\n\t\t\t\t\tBlockHeight: 10,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tFirstBlockHeight: 11,\n\t\t\tNumBlocks:        1,\n\t\t\tShortChanIDs: []lnwire.ShortChannelID{\n\t\t\t\t{\n\t\t\t\t\tBlockHeight: 11,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tFirstBlockHeight: 12,\n\t\t\tNumBlocks:        query.NumBlocks - 12,\n\t\t\tComplete:         1,\n\t\t\tShortChanIDs: []lnwire.ShortChannelID{\n\t\t\t\t{\n\t\t\t\t\tBlockHeight: 12,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// Each reply query is the same as the original query in the legacy\n\t// mode.\n\tif legacy {\n\t\treplies[0].FirstBlockHeight = query.FirstBlockHeight\n\t\treplies[0].NumBlocks = query.NumBlocks\n\n\t\treplies[1].FirstBlockHeight = query.FirstBlockHeight\n\t\treplies[1].NumBlocks = query.NumBlocks\n\n\t\treplies[2].FirstBlockHeight = query.FirstBlockHeight\n\t\treplies[2].NumBlocks = query.NumBlocks\n\t}\n\n\t// We'll begin by sending the syncer a set of non-complete channel\n\t// range replies.\n\tif err := syncer.processChanRangeReply(replies[0]); err != nil {\n\t\tt.Fatalf(\"unable to process reply: %v\", err)\n\t}\n\tif err := syncer.processChanRangeReply(replies[1]); err != nil {\n\t\tt.Fatalf(\"unable to process reply: %v\", err)\n\t}\n\n\t// At this point, we should still be in our starting state as the query\n\t// hasn't finished.\n\tif syncer.state != startingState {\n\t\tt.Fatalf(\"state should not have transitioned\")\n\t}\n\n\texpectedReq := []lnwire.ShortChannelID{\n\t\t{\n\t\t\tBlockHeight: 10,\n\t\t},\n\t\t{\n\t\t\tBlockHeight: 11,\n\t\t},\n\t\t{\n\t\t\tBlockHeight: 12,\n\t\t},\n\t}\n\n\t// As we're about to send the final response, we'll launch a goroutine\n\t// to respond back with a filtered set of chan ID's.\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\terrCh <- errors.New(\"no query received\")\n\t\t\treturn\n\n\t\tcase req := <-chanSeries.filterReq:\n\t\t\t// We should get a request for the entire range of short\n\t\t\t// chan ID's.\n\t\t\tif !reflect.DeepEqual(expectedReq, req) {\n\t\t\t\terrCh <- fmt.Errorf(\"wrong request: expected %v, got %v\",\n\t\t\t\t\texpectedReq, req)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// We'll send back only the last two to simulate filtering.\n\t\t\tchanSeries.filterResp <- expectedReq[1:]\n\t\t\terrCh <- nil\n\t\t}\n\t}()\n\n\t// If we send the final message, then we should transition to\n\t// queryNewChannels as we've sent a non-empty set of new channels.\n\tif err := syncer.processChanRangeReply(replies[2]); err != nil {\n\t\tt.Fatalf(\"unable to process reply: %v\", err)\n\t}\n\n\tif syncer.syncState() != queryNewChannels {\n\t\tt.Fatalf(\"wrong state: expected %v instead got %v\",\n\t\t\tqueryNewChannels, syncer.state)\n\t}\n\tif !reflect.DeepEqual(syncer.newChansToQuery, expectedReq[1:]) {\n\t\tt.Fatalf(\"wrong set of chans to query: expected %v, got %v\",\n\t\t\tsyncer.newChansToQuery, expectedReq[1:])\n\t}\n\n\t// Wait for error from goroutine.\n\tselect {\n\tcase <-time.After(time.Second * 30):\n\t\tt.Fatalf(\"goroutine did not return within 30 seconds\")\n\tcase err := <-errCh:\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n}\n\n// TestGossipSyncerSynchronizeChanIDs tests that we properly request chunks of\n// the short chan ID's which were unknown to us. We'll ensure that we request\n// chunk by chunk, and after the last chunk, we return true indicating that we\n// can transition to the synced stage.",
      "length": 3719,
      "tokens": 500,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerSynchronizeChanIDs(t *testing.T) {",
      "content": "func TestGossipSyncerSynchronizeChanIDs(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll modify the chunk size to be a smaller value, so we can ensure\n\t// our chunk parsing works properly. With this value we should get 3\n\t// queries: two full chunks, and one lingering chunk.\n\tconst chunkSize = 2\n\n\t// First, we'll create a GossipSyncer instance with a canned sendToPeer\n\t// message to allow us to intercept their potential sends.\n\tmsgChan, syncer, _ := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding, chunkSize,\n\t)\n\n\t// Next, we'll construct a set of chan ID's that we should query for,\n\t// and set them as newChansToQuery within the state machine.\n\tnewChanIDs := []lnwire.ShortChannelID{\n\t\tlnwire.NewShortChanIDFromInt(1),\n\t\tlnwire.NewShortChanIDFromInt(2),\n\t\tlnwire.NewShortChanIDFromInt(3),\n\t\tlnwire.NewShortChanIDFromInt(4),\n\t\tlnwire.NewShortChanIDFromInt(5),\n\t}\n\tsyncer.newChansToQuery = newChanIDs\n\n\tfor i := 0; i < chunkSize*2; i += 2 {\n\t\t// With our set up complete, we'll request a sync of chan ID's.\n\t\tdone, err := syncer.synchronizeChanIDs()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to sync chan IDs: %v\", err)\n\t\t}\n\n\t\t// At this point, we shouldn't yet be done as only 2 items\n\t\t// should have been queried for.\n\t\tif done {\n\t\t\tt.Fatalf(\"syncer shown as done, but shouldn't be!\")\n\t\t}\n\n\t\t// We should've received a new message from the syncer.\n\t\tselect {\n\t\tcase <-time.After(time.Second * 15):\n\t\t\tt.Fatalf(\"no msgs received\")\n\n\t\tcase msg := <-msgChan:\n\t\t\tqueryMsg, ok := msg[0].(*lnwire.QueryShortChanIDs)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"expected QueryShortChanIDs instead \"+\n\t\t\t\t\t\"got %T\", msg)\n\t\t\t}\n\n\t\t\t// The query message should have queried for the first\n\t\t\t// two chan ID's, and nothing more.\n\t\t\tif !reflect.DeepEqual(queryMsg.ShortChanIDs, newChanIDs[i:i+chunkSize]) {\n\t\t\t\tt.Fatalf(\"wrong query: expected %v, got %v\",\n\t\t\t\t\tspew.Sdump(newChanIDs[i:i+chunkSize]),\n\t\t\t\t\tqueryMsg.ShortChanIDs)\n\t\t\t}\n\t\t}\n\n\t\t// With the proper message sent out, the internal state of the\n\t\t// syncer should reflect that it still has more channels to\n\t\t// query for.\n\t\tif !reflect.DeepEqual(syncer.newChansToQuery, newChanIDs[i+chunkSize:]) {\n\t\t\tt.Fatalf(\"incorrect chans to query for: expected %v, got %v\",\n\t\t\t\tspew.Sdump(newChanIDs[i+chunkSize:]),\n\t\t\t\tsyncer.newChansToQuery)\n\t\t}\n\t}\n\n\t// At this point, only one more channel should be lingering for the\n\t// syncer to query for.\n\tif !reflect.DeepEqual(newChanIDs[chunkSize*2:], syncer.newChansToQuery) {\n\t\tt.Fatalf(\"wrong chans to query: expected %v, got %v\",\n\t\t\tnewChanIDs[chunkSize*2:], syncer.newChansToQuery)\n\t}\n\n\t// If we issue another query, the syncer should tell us that it's done.\n\tdone, err := syncer.synchronizeChanIDs()\n\trequire.NoError(t, err, \"unable to sync chan IDs\")\n\tif done {\n\t\tt.Fatalf(\"syncer should be finished!\")\n\t}\n\n\tselect {\n\tcase <-time.After(time.Second * 15):\n\t\tt.Fatalf(\"no msgs received\")\n\n\tcase msg := <-msgChan:\n\t\tqueryMsg, ok := msg[0].(*lnwire.QueryShortChanIDs)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected QueryShortChanIDs instead \"+\n\t\t\t\t\"got %T\", msg)\n\t\t}\n\n\t\t// The query issued should simply be the last item.\n\t\tif !reflect.DeepEqual(queryMsg.ShortChanIDs, newChanIDs[chunkSize*2:]) {\n\t\t\tt.Fatalf(\"wrong query: expected %v, got %v\",\n\t\t\t\tspew.Sdump(newChanIDs[chunkSize*2:]),\n\t\t\t\tqueryMsg.ShortChanIDs)\n\t\t}\n\n\t\t// There also should be no more channels to query.\n\t\tif len(syncer.newChansToQuery) != 0 {\n\t\t\tt.Fatalf(\"should be no more chans to query for, \"+\n\t\t\t\t\"instead have %v\",\n\t\t\t\tspew.Sdump(syncer.newChansToQuery))\n\t\t}\n\t}\n}\n\n// TestGossipSyncerDelayDOS tests that the gossip syncer will begin delaying\n// queries after its prescribed allotment of undelayed query responses. Once\n// this happens, all query replies should be delayed by the configurated\n// interval.",
      "length": 3572,
      "tokens": 474,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerDelayDOS(t *testing.T) {",
      "content": "func TestGossipSyncerDelayDOS(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll modify the chunk size to be a smaller value, since we'll be\n\t// sending a modest number of queries. After exhausting our undelayed\n\t// gossip queries, we'll send two extra queries and ensure that they are\n\t// delayed properly.\n\tconst chunkSize = 2\n\tconst numDelayedQueries = 2\n\tconst delayTolerance = time.Millisecond * 200\n\n\t// First, we'll create two GossipSyncer instances with a canned\n\t// sendToPeer message to allow us to intercept their potential sends.\n\thighestID := lnwire.ShortChannelID{\n\t\tBlockHeight: 1144,\n\t}\n\tmsgChan1, syncer1, chanSeries1 := newTestSyncer(\n\t\thighestID, defaultEncoding, chunkSize, true, false,\n\t)\n\tsyncer1.Start()\n\tdefer syncer1.Stop()\n\n\tmsgChan2, syncer2, chanSeries2 := newTestSyncer(\n\t\thighestID, defaultEncoding, chunkSize, false, true,\n\t)\n\tsyncer2.Start()\n\tdefer syncer2.Stop()\n\n\t// Record the delayed query reply interval used by each syncer.\n\tdelayedQueryInterval := syncer1.cfg.delayedQueryReplyInterval\n\n\t// Record the number of undelayed queries allowed by the syncers.\n\tnumUndelayedQueries := syncer1.cfg.maxUndelayedQueryReplies\n\n\t// We will send enough queries to exhaust the undelayed responses, and\n\t// then send two more queries which should be delayed. An additional one\n\t// is subtracted from the total since undelayed message will be consumed\n\t// by the initial QueryChannelRange.\n\tnumQueryResponses := numUndelayedQueries + numDelayedQueries - 1\n\n\t// The total number of responses must include the initial reply each\n\t// syncer will make to QueryChannelRange.\n\tnumTotalQueries := 1 + numQueryResponses\n\n\t// The total number of channels each syncer needs to request must be\n\t// scaled by the chunk size being used.\n\tnumTotalChans := numQueryResponses * chunkSize\n\n\t// Construct enough channels so that all of the queries will have enough\n\t// channels. Since syncer1 won't know of any channels, their sets are\n\t// inherently disjoint.\n\tvar syncer2Chans []lnwire.ShortChannelID\n\tfor i := 0; i < numTotalChans; i++ {\n\t\tsyncer2Chans = append([]lnwire.ShortChannelID{\n\t\t\t{\n\t\t\t\tBlockHeight: highestID.BlockHeight - uint32(i) - 1,\n\t\t\t\tTxIndex:     uint32(i),\n\t\t\t},\n\t\t}, syncer2Chans...)\n\t}\n\n\t// We'll kick off the test by asserting syncer1 sends over the\n\t// QueryChannelRange message the other node.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\tcase msgs := <-msgChan1:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a QueryChannelRange message.\n\t\t\t_, ok := msg.(*lnwire.QueryChannelRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer2.queryMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n\n\t// At this point, we'll need to a response from syncer2's channel\n\t// series. This will cause syncer1 to simply request the entire set of\n\t// channels from syncer2. This will count as the first undelayed\n\t// response for sycner2.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries2.filterRangeReqs:\n\t\t// We'll send back all the channels that it should know of.\n\t\tchanSeries2.filterRangeResp <- syncer2Chans\n\t}\n\n\t// At this point, we'll assert that the ReplyChannelRange message is\n\t// sent by sycner2.\n\tfor i := 0; i < numQueryResponses; i++ {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 2):\n\t\t\tt.Fatalf(\"didn't get msg from syncer2\")\n\n\t\tcase msgs := <-msgChan2:\n\t\t\tfor _, msg := range msgs {\n\t\t\t\t// The message MUST be a ReplyChannelRange message.\n\t\t\t\t_, ok := msg.(*lnwire.ReplyChannelRange)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\t\tcase syncer1.gossipMsgs <- msg:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// We'll now have syncer1 process the received sids from syncer2.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries1.filterReq:\n\t\tchanSeries1.filterResp <- syncer2Chans\n\t}\n\n\t// At this point, syncer1 should start to send out initial requests to\n\t// query the chan IDs of the remote party. We'll keep track of the\n\t// number of queries made using the iterated value, which starts at one\n\t// due the initial contribution of the QueryChannelRange msgs.\n\tfor i := 1; i < numTotalQueries; i++ {\n\t\texpDelayResponse := i >= numUndelayedQueries\n\t\tqueryBatch(t,\n\t\t\tmsgChan1, msgChan2,\n\t\t\tsyncer1, syncer2,\n\t\t\tchanSeries2,\n\t\t\texpDelayResponse,\n\t\t\tdelayedQueryInterval,\n\t\t\tdelayTolerance,\n\t\t)\n\t}\n}\n\n// queryBatch is a helper method that will query for a single batch of channels\n// from a peer and assert the responses. The method can also be used to assert\n// the same transition happens, but is delayed by the remote peer's DOS\n// rate-limiting. The provided chanSeries should belong to syncer2.\n//\n// The state transition performed is the following:\n//\n//\tsyncer1  -- QueryShortChanIDs -->   syncer2\n//\t                                    chanSeries.FetchChanAnns()\n//\tsyncer1 <-- ReplyShortChanIDsEnd -- syncer2\n//\n// If expDelayResponse is true, this method will assert that the call the\n// FetchChanAnns happens between:\n//\n//\t[delayedQueryInterval-delayTolerance, delayedQueryInterval+delayTolerance].",
      "length": 5121,
      "tokens": 731,
      "embedding": []
    },
    {
      "slug": "func queryBatch(t *testing.T,",
      "content": "func queryBatch(t *testing.T,\n\tmsgChan1, msgChan2 chan []lnwire.Message,\n\tsyncer1, syncer2 *GossipSyncer,\n\tchanSeries *mockChannelGraphTimeSeries,\n\texpDelayResponse bool,\n\tdelayedQueryInterval, delayTolerance time.Duration) {\n\n\tt.Helper()\n\n\t// First, we'll assert that syncer1 sends a QueryShortChanIDs message to\n\t// the remote peer.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer2\")\n\n\tcase msgs := <-msgChan1:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a QueryShortChanIDs message.\n\t\t\t_, ok := msg.(*lnwire.QueryShortChanIDs)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryShortChanIDs for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer2.queryMsgs <- msg:\n\t\t\t}\n\t\t}\n\t}\n\n\t// We'll then respond to with an empty set of replies (as it doesn't\n\t// affect the test).\n\tswitch {\n\n\t// If this query has surpassed the undelayed query threshold, we will\n\t// impose stricter timing constraints on the response times. We'll first\n\t// test that syncer2's chanSeries doesn't immediately receive a query,\n\t// and then check that the query hasn't gone unanswered entirely.\n\tcase expDelayResponse:\n\t\t// Create a before and after timeout to test, our test\n\t\t// will ensure the messages are delivered to the peer\n\t\t// in this timeframe.\n\t\tbefore := time.After(\n\t\t\tdelayedQueryInterval - delayTolerance,\n\t\t)\n\t\tafter := time.After(\n\t\t\tdelayedQueryInterval + delayTolerance,\n\t\t)\n\n\t\t// First, ensure syncer2 doesn't try to respond up until the\n\t\t// before time fires.\n\t\tselect {\n\t\tcase <-before:\n\t\t\t// Query is delayed, proceed.\n\n\t\tcase <-chanSeries.annReq:\n\t\t\tt.Fatalf(\"DOSy query was not delayed\")\n\t\t}\n\n\t\t// If syncer2 doesn't attempt a response within the allowed\n\t\t// interval, then the messages are probably lost.\n\t\tselect {\n\t\tcase <-after:\n\t\t\tt.Fatalf(\"no delayed query received\")\n\n\t\tcase <-chanSeries.annReq:\n\t\t\tchanSeries.annResp <- []lnwire.Message{}\n\t\t}\n\n\t// Otherwise, syncer2 should query its chanSeries promtly.\n\tdefault:\n\t\tselect {\n\t\tcase <-time.After(50 * time.Millisecond):\n\t\t\tt.Fatalf(\"no query recvd\")\n\n\t\tcase <-chanSeries.annReq:\n\t\t\tchanSeries.annResp <- []lnwire.Message{}\n\t\t}\n\t}\n\n\t// Finally, assert that syncer2 replies to syncer1 with a\n\t// ReplyShortChanIDsEnd.\n\tselect {\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatalf(\"didn't get msg from syncer2\")\n\n\tcase msgs := <-msgChan2:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a ReplyShortChanIDsEnd message.\n\t\t\t_, ok := msg.(*lnwire.ReplyShortChanIDsEnd)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"ReplyShortChanIDsEnd for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer1.gossipMsgs <- msg:\n\t\t\t}\n\t\t}\n\t}\n}\n\n// TestGossipSyncerRoutineSync tests all state transitions of the main syncer\n// goroutine. This ensures that given an encounter with a peer that has a set\n// of distinct channels, then we'll properly synchronize our channel state with\n// them.",
      "length": 2908,
      "tokens": 405,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerRoutineSync(t *testing.T) {",
      "content": "func TestGossipSyncerRoutineSync(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll modify the chunk size to be a smaller value, so we can ensure\n\t// our chunk parsing works properly. With this value we should get 3\n\t// queries: two full chunks, and one lingering chunk.\n\tconst chunkSize = 2\n\n\t// First, we'll create two GossipSyncer instances with a canned\n\t// sendToPeer message to allow us to intercept their potential sends.\n\thighestID := lnwire.ShortChannelID{\n\t\tBlockHeight: 1144,\n\t}\n\tmsgChan1, syncer1, chanSeries1 := newTestSyncer(\n\t\thighestID, defaultEncoding, chunkSize, true, false,\n\t)\n\tsyncer1.Start()\n\tdefer syncer1.Stop()\n\n\tmsgChan2, syncer2, chanSeries2 := newTestSyncer(\n\t\thighestID, defaultEncoding, chunkSize, false, true,\n\t)\n\tsyncer2.Start()\n\tdefer syncer2.Stop()\n\n\t// Although both nodes are at the same height, syncer will have 3 chan\n\t// ID's that syncer1 doesn't know of.\n\tsyncer2Chans := []lnwire.ShortChannelID{\n\t\t{BlockHeight: highestID.BlockHeight - 3},\n\t\t{BlockHeight: highestID.BlockHeight - 2},\n\t\t{BlockHeight: highestID.BlockHeight - 1},\n\t}\n\n\t// We'll kick off the test by passing over the QueryChannelRange\n\t// messages from syncer1 to syncer2.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\tcase msgs := <-msgChan1:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a QueryChannelRange message.\n\t\t\t_, ok := msg.(*lnwire.QueryChannelRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer2.queryMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n\n\t// At this point, we'll need to send a response from syncer2 to syncer1\n\t// using syncer2's channels This will cause syncer1 to simply request\n\t// the entire set of channels from the other.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries2.filterRangeReqs:\n\t\t// We'll send back all the channels that it should know of.\n\t\tchanSeries2.filterRangeResp <- syncer2Chans\n\t}\n\n\t// At this point, we'll assert that syncer2 replies with the\n\t// ReplyChannelRange messages. Two replies are expected since the chunk\n\t// size is 2, and we need to query for 3 channels.\n\tfor i := 0; i < chunkSize; i++ {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 2):\n\t\t\tt.Fatalf(\"didn't get msg from syncer2\")\n\n\t\tcase msgs := <-msgChan2:\n\t\t\tfor _, msg := range msgs {\n\t\t\t\t// The message MUST be a ReplyChannelRange message.\n\t\t\t\t_, ok := msg.(*lnwire.ReplyChannelRange)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\t\tcase syncer1.gossipMsgs <- msg:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// We'll now send back a chunked response from syncer2 back to sycner1.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries1.filterReq:\n\t\tchanSeries1.filterResp <- syncer2Chans\n\t}\n\n\t// At this point, syncer1 should start to send out initial requests to\n\t// query the chan IDs of the remote party. As the chunk size is 2,\n\t// they'll need 2 rounds in order to fully reconcile the state.\n\tfor i := 0; i < chunkSize; i++ {\n\t\tqueryBatch(t,\n\t\t\tmsgChan1, msgChan2,\n\t\t\tsyncer1, syncer2,\n\t\t\tchanSeries2,\n\t\t\tfalse, 0, 0,\n\t\t)\n\t}\n\n\t// At this stage syncer1 should now be sending over its initial\n\t// GossipTimestampRange messages as it should be fully synced.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\tcase msgs := <-msgChan1:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a GossipTimestampRange message.\n\t\t\t_, ok := msg.(*lnwire.GossipTimestampRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer2.gossipMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n}\n\n// TestGossipSyncerAlreadySynced tests that if we attempt to synchronize two\n// syncers that have the exact same state, then they'll skip straight to the\n// final state and not perform any channel queries.",
      "length": 3980,
      "tokens": 590,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerAlreadySynced(t *testing.T) {",
      "content": "func TestGossipSyncerAlreadySynced(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll modify the chunk size to be a smaller value, so we can ensure\n\t// our chunk parsing works properly. With this value we should get 3\n\t// queries: two full chunks, and one lingering chunk.\n\tconst chunkSize = 2\n\tconst numChans = 3\n\n\t// First, we'll create two GossipSyncer instances with a canned\n\t// sendToPeer message to allow us to intercept their potential sends.\n\thighestID := lnwire.ShortChannelID{\n\t\tBlockHeight: 1144,\n\t}\n\tmsgChan1, syncer1, chanSeries1 := newTestSyncer(\n\t\thighestID, defaultEncoding, chunkSize,\n\t)\n\tsyncer1.Start()\n\tdefer syncer1.Stop()\n\n\tmsgChan2, syncer2, chanSeries2 := newTestSyncer(\n\t\thighestID, defaultEncoding, chunkSize,\n\t)\n\tsyncer2.Start()\n\tdefer syncer2.Stop()\n\n\t// The channel state of both syncers will be identical. They should\n\t// recognize this, and skip the sync phase below.\n\tvar syncer1Chans, syncer2Chans []lnwire.ShortChannelID\n\tfor i := numChans; i > 0; i-- {\n\t\tshortChanID := lnwire.ShortChannelID{\n\t\t\tBlockHeight: highestID.BlockHeight - uint32(i),\n\t\t}\n\t\tsyncer1Chans = append(syncer1Chans, shortChanID)\n\t\tsyncer2Chans = append(syncer2Chans, shortChanID)\n\t}\n\n\t// We'll now kick off the test by allowing both side to send their\n\t// QueryChannelRange messages to each other.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\tcase msgs := <-msgChan1:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a QueryChannelRange message.\n\t\t\t_, ok := msg.(*lnwire.QueryChannelRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer2.queryMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer2\")\n\n\tcase msgs := <-msgChan2:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a QueryChannelRange message.\n\t\t\t_, ok := msg.(*lnwire.QueryChannelRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer1.queryMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n\n\t// We'll now send back the range each side should send over: the set of\n\t// channels they already know about.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries1.filterRangeReqs:\n\t\t// We'll send all the channels that it should know of.\n\t\tchanSeries1.filterRangeResp <- syncer1Chans\n\t}\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries2.filterRangeReqs:\n\t\t// We'll send back all the channels that it should know of.\n\t\tchanSeries2.filterRangeResp <- syncer2Chans\n\t}\n\n\t// Next, we'll thread through the replies of both parties. As the chunk\n\t// size is 2, and they both know of 3 channels, it'll take two around\n\t// and two chunks.\n\tfor i := 0; i < chunkSize; i++ {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 2):\n\t\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\t\tcase msgs := <-msgChan1:\n\t\t\tfor _, msg := range msgs {\n\t\t\t\t// The message MUST be a ReplyChannelRange message.\n\t\t\t\t_, ok := msg.(*lnwire.ReplyChannelRange)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\t\tcase syncer2.gossipMsgs <- msg:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor i := 0; i < chunkSize; i++ {\n\t\tselect {\n\t\tcase <-time.After(time.Second * 2):\n\t\t\tt.Fatalf(\"didn't get msg from syncer2\")\n\n\t\tcase msgs := <-msgChan2:\n\t\t\tfor _, msg := range msgs {\n\t\t\t\t// The message MUST be a ReplyChannelRange message.\n\t\t\t\t_, ok := msg.(*lnwire.ReplyChannelRange)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\t\tcase syncer1.gossipMsgs <- msg:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now that both sides have the full responses, we'll send over the\n\t// channels that they need to filter out. As both sides have the exact\n\t// same set of channels, they should skip to the final state.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries1.filterReq:\n\t\tchanSeries1.filterResp <- []lnwire.ShortChannelID{}\n\t}\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"no query recvd\")\n\n\tcase <-chanSeries2.filterReq:\n\t\tchanSeries2.filterResp <- []lnwire.ShortChannelID{}\n\t}\n\n\t// As both parties are already synced, the next message they send to\n\t// each other should be the GossipTimestampRange message.\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\tcase msgs := <-msgChan1:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a GossipTimestampRange message.\n\t\t\t_, ok := msg.(*lnwire.GossipTimestampRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer2.gossipMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n\tselect {\n\tcase <-time.After(time.Second * 2):\n\t\tt.Fatalf(\"didn't get msg from syncer1\")\n\n\tcase msgs := <-msgChan2:\n\t\tfor _, msg := range msgs {\n\t\t\t// The message MUST be a GossipTimestampRange message.\n\t\t\t_, ok := msg.(*lnwire.GossipTimestampRange)\n\t\t\tif !ok {\n\t\t\t\tt.Fatalf(\"wrong message: expected \"+\n\t\t\t\t\t\"QueryChannelRange for %T\", msg)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Second * 2):\n\t\t\t\tt.Fatalf(\"node 2 didn't read msg\")\n\n\t\t\tcase syncer1.gossipMsgs <- msg:\n\n\t\t\t}\n\t\t}\n\t}\n}\n\n// TestGossipSyncerSyncTransitions ensures that the gossip syncer properly\n// carries out its duties when accepting a new sync transition request.",
      "length": 5558,
      "tokens": 789,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerSyncTransitions(t *testing.T) {",
      "content": "func TestGossipSyncerSyncTransitions(t *testing.T) {\n\tt.Parallel()\n\n\tassertMsgSent := func(t *testing.T, msgChan chan []lnwire.Message,\n\t\tmsg lnwire.Message) {\n\n\t\tt.Helper()\n\n\t\tvar msgSent lnwire.Message\n\t\tselect {\n\t\tcase msgs := <-msgChan:\n\t\t\tif len(msgs) != 1 {\n\t\t\t\tt.Fatalf(\"expected to send a single message at \"+\n\t\t\t\t\t\"a time, got %d\", len(msgs))\n\t\t\t}\n\t\t\tmsgSent = msgs[0]\n\t\tcase <-time.After(time.Second):\n\t\t\tt.Fatalf(\"expected to send %T message\", msg)\n\t\t}\n\n\t\tif !reflect.DeepEqual(msgSent, msg) {\n\t\t\tt.Fatalf(\"expected to send message: %v\\ngot: %v\",\n\t\t\t\tspew.Sdump(msg), spew.Sdump(msgSent))\n\t\t}\n\t}\n\n\ttests := []struct {\n\t\tname          string\n\t\tentrySyncType SyncerType\n\t\tfinalSyncType SyncerType\n\t\tassert        func(t *testing.T, msgChan chan []lnwire.Message,\n\t\t\tsyncer *GossipSyncer)\n\t}{\n\t\t{\n\t\t\tname:          \"active to passive\",\n\t\t\tentrySyncType: ActiveSync,\n\t\t\tfinalSyncType: PassiveSync,\n\t\t\tassert: func(t *testing.T, msgChan chan []lnwire.Message,\n\t\t\t\tg *GossipSyncer) {\n\n\t\t\t\t// When transitioning from active to passive, we\n\t\t\t\t// should expect to see a new local update\n\t\t\t\t// horizon sent to the remote peer indicating\n\t\t\t\t// that it would not like to receive any future\n\t\t\t\t// updates.\n\t\t\t\tassertMsgSent(t, msgChan, &lnwire.GossipTimestampRange{\n\t\t\t\t\tFirstTimestamp: uint32(zeroTimestamp.Unix()),\n\t\t\t\t\tTimestampRange: 0,\n\t\t\t\t})\n\n\t\t\t\tsyncState := g.syncState()\n\t\t\t\tif syncState != chansSynced {\n\t\t\t\t\tt.Fatalf(\"expected syncerState %v, \"+\n\t\t\t\t\t\t\"got %v\", chansSynced, syncState)\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:          \"passive to active\",\n\t\t\tentrySyncType: PassiveSync,\n\t\t\tfinalSyncType: ActiveSync,\n\t\t\tassert: func(t *testing.T, msgChan chan []lnwire.Message,\n\t\t\t\tg *GossipSyncer) {\n\n\t\t\t\t// When transitioning from historical to active,\n\t\t\t\t// we should expect to see a new local update\n\t\t\t\t// horizon sent to the remote peer indicating\n\t\t\t\t// that it would like to receive any future\n\t\t\t\t// updates.\n\t\t\t\tfirstTimestamp := uint32(time.Now().Unix())\n\t\t\t\tassertMsgSent(t, msgChan, &lnwire.GossipTimestampRange{\n\t\t\t\t\tFirstTimestamp: firstTimestamp,\n\t\t\t\t\tTimestampRange: math.MaxUint32,\n\t\t\t\t})\n\n\t\t\t\tsyncState := g.syncState()\n\t\t\t\tif syncState != chansSynced {\n\t\t\t\t\tt.Fatalf(\"expected syncerState %v, \"+\n\t\t\t\t\t\t\"got %v\", chansSynced, syncState)\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\t// We'll start each test by creating our syncer. We'll\n\t\t\t// initialize it with a state of chansSynced, as that's\n\t\t\t// the only time when it can process sync transitions.\n\t\t\tmsgChan, syncer, _ := newTestSyncer(\n\t\t\t\tlnwire.ShortChannelID{\n\t\t\t\t\tBlockHeight: latestKnownHeight,\n\t\t\t\t},\n\t\t\t\tdefaultEncoding, defaultChunkSize,\n\t\t\t)\n\t\t\tsyncer.setSyncState(chansSynced)\n\n\t\t\t// We'll set the initial syncType to what the test\n\t\t\t// demands.\n\t\t\tsyncer.setSyncType(test.entrySyncType)\n\n\t\t\t// We'll then start the syncer in order to process the\n\t\t\t// request.\n\t\t\tsyncer.Start()\n\t\t\tdefer syncer.Stop()\n\n\t\t\tsyncer.ProcessSyncTransition(test.finalSyncType)\n\n\t\t\t// The syncer should now have the expected final\n\t\t\t// SyncerType that the test expects.\n\t\t\tsyncType := syncer.SyncType()\n\t\t\tif syncType != test.finalSyncType {\n\t\t\t\tt.Fatalf(\"expected syncType %v, got %v\",\n\t\t\t\t\ttest.finalSyncType, syncType)\n\t\t\t}\n\n\t\t\t// Finally, we'll run a set of assertions for each test\n\t\t\t// to ensure the syncer performed its expected duties\n\t\t\t// after processing its sync transition.\n\t\t\ttest.assert(t, msgChan, syncer)\n\t\t})\n\t}\n}\n\n// TestGossipSyncerHistoricalSync tests that a gossip syncer can perform a\n// historical sync with the remote peer.",
      "length": 3407,
      "tokens": 417,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerHistoricalSync(t *testing.T) {",
      "content": "func TestGossipSyncerHistoricalSync(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll create a new gossip syncer and manually override its state to\n\t// chansSynced. This is necessary as the syncer can only process\n\t// historical sync requests in this state.\n\tmsgChan, syncer, _ := newTestSyncer(\n\t\tlnwire.ShortChannelID{BlockHeight: latestKnownHeight},\n\t\tdefaultEncoding, defaultChunkSize,\n\t)\n\tsyncer.setSyncType(PassiveSync)\n\tsyncer.setSyncState(chansSynced)\n\n\tsyncer.Start()\n\tdefer syncer.Stop()\n\n\tsyncer.historicalSync()\n\n\t// We should expect to see a single lnwire.QueryChannelRange message be\n\t// sent to the remote peer with a FirstBlockHeight of 0.\n\texpectedMsg := &lnwire.QueryChannelRange{\n\t\tFirstBlockHeight: 0,\n\t\tNumBlocks:        latestKnownHeight,\n\t}\n\n\tselect {\n\tcase msgs := <-msgChan:\n\t\tif len(msgs) != 1 {\n\t\t\tt.Fatalf(\"expected to send a single \"+\n\t\t\t\t\"lnwire.QueryChannelRange message, got %d\",\n\t\t\t\tlen(msgs))\n\t\t}\n\t\tif !reflect.DeepEqual(msgs[0], expectedMsg) {\n\t\t\tt.Fatalf(\"expected to send message: %v\\ngot: %v\",\n\t\t\t\tspew.Sdump(expectedMsg), spew.Sdump(msgs[0]))\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatalf(\"expected to send a lnwire.QueryChannelRange message\")\n\t}\n}\n\n// TestGossipSyncerSyncedSignal ensures that we receive a signal when a gossip\n// syncer reaches its terminal chansSynced state.",
      "length": 1217,
      "tokens": 142,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerSyncedSignal(t *testing.T) {",
      "content": "func TestGossipSyncerSyncedSignal(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll create a new gossip syncer and manually override its state to\n\t// chansSynced.\n\t_, syncer, _ := newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\tsyncer.setSyncState(chansSynced)\n\n\t// We'll go ahead and request a signal to be notified of when it reaches\n\t// this state.\n\tsignalChan := syncer.ResetSyncedSignal()\n\n\t// Starting the gossip syncer should cause the signal to be delivered.\n\tsyncer.Start()\n\n\tselect {\n\tcase <-signalChan:\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"expected to receive chansSynced signal\")\n\t}\n\n\tsyncer.Stop()\n\n\t// We'll try this again, but this time we'll request the signal after\n\t// the syncer is active and has already reached its chansSynced state.\n\t_, syncer, _ = newTestSyncer(\n\t\tlnwire.NewShortChanIDFromInt(10), defaultEncoding,\n\t\tdefaultChunkSize,\n\t)\n\n\tsyncer.setSyncState(chansSynced)\n\n\tsyncer.Start()\n\tdefer syncer.Stop()\n\n\tsignalChan = syncer.ResetSyncedSignal()\n\n\t// The signal should be delivered immediately.\n\tselect {\n\tcase <-signalChan:\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"expected to receive chansSynced signal\")\n\t}\n}\n\n// TestGossipSyncerMaxChannelRangeReplies ensures that a gossip syncer\n// transitions its state after receiving the maximum possible number of replies\n// for a single QueryChannelRange message, and that any further replies after\n// said limit are not processed.",
      "length": 1350,
      "tokens": 171,
      "embedding": []
    },
    {
      "slug": "func TestGossipSyncerMaxChannelRangeReplies(t *testing.T) {",
      "content": "func TestGossipSyncerMaxChannelRangeReplies(t *testing.T) {\n\tt.Parallel()\n\n\tmsgChan, syncer, chanSeries := newTestSyncer(\n\t\tlnwire.ShortChannelID{BlockHeight: latestKnownHeight},\n\t\tdefaultEncoding, defaultChunkSize,\n\t)\n\n\t// We'll tune the maxQueryChanRangeReplies to a more sensible value for\n\t// the sake of testing.\n\tsyncer.cfg.maxQueryChanRangeReplies = 100\n\n\tsyncer.Start()\n\tdefer syncer.Stop()\n\n\t// Upon initialization, the syncer should submit a QueryChannelRange\n\t// request.\n\tvar query *lnwire.QueryChannelRange\n\tselect {\n\tcase msgs := <-msgChan:\n\t\trequire.Len(t, msgs, 1)\n\t\trequire.IsType(t, &lnwire.QueryChannelRange{}, msgs[0])\n\t\tquery = msgs[0].(*lnwire.QueryChannelRange)\n\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"expected query channel range request msg\")\n\t}\n\n\t// We'll send the maximum number of replies allowed to a\n\t// QueryChannelRange request with each reply consuming only one block in\n\t// order to transition the syncer's state.\n\tfor i := uint32(0); i < syncer.cfg.maxQueryChanRangeReplies; i++ {\n\t\treply := &lnwire.ReplyChannelRange{\n\t\t\tChainHash:        query.ChainHash,\n\t\t\tFirstBlockHeight: query.FirstBlockHeight,\n\t\t\tNumBlocks:        query.NumBlocks,\n\t\t\tShortChanIDs: []lnwire.ShortChannelID{\n\t\t\t\t{\n\t\t\t\t\tBlockHeight: query.FirstBlockHeight + i,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\treply.FirstBlockHeight = query.FirstBlockHeight + i\n\t\treply.NumBlocks = 1\n\t\trequire.NoError(t, syncer.ProcessQueryMsg(reply, nil))\n\t}\n\n\t// We should receive a filter request for the syncer's local channels\n\t// after processing all of the replies. We'll send back a nil response\n\t// indicating that no new channels need to be synced, so it should\n\t// transition to its final chansSynced state.\n\tselect {\n\tcase <-chanSeries.filterReq:\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"expected local filter request of known channels\")\n\t}\n\tselect {\n\tcase chanSeries.filterResp <- nil:\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timed out sending filter response\")\n\t}\n\tassertSyncerStatus(t, syncer, chansSynced, ActiveSync)\n\n\t// Finally, attempting to process another reply for the same query\n\t// should result in an error.\n\trequire.Error(t, syncer.ProcessQueryMsg(&lnwire.ReplyChannelRange{\n\t\tChainHash:        query.ChainHash,\n\t\tFirstBlockHeight: query.FirstBlockHeight,\n\t\tNumBlocks:        query.NumBlocks,\n\t\tShortChanIDs: []lnwire.ShortChannelID{\n\t\t\t{\n\t\t\t\tBlockHeight: query.LastBlockHeight() + 1,\n\t\t\t},\n\t\t},\n\t}, nil))\n}\n",
      "length": 2274,
      "tokens": 254,
      "embedding": []
    }
  ]
}