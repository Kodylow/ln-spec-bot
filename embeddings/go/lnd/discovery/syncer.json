{
  "filepath": "../implementations/go/lnd/discovery/syncer.go",
  "package": "discovery",
  "sections": [
    {
      "slug": "type SyncerType uint8",
      "content": "type SyncerType uint8\n\nconst (\n\t// ActiveSync denotes that a gossip syncer:\n\t//\n\t// 1. Should not attempt to synchronize with the remote peer for\n\t//    missing channels.\n\t// 2. Should respond to queries from the remote peer.\n\t// 3. Should receive new updates from the remote peer.\n\t//\n\t// They are started in a chansSynced state in order to accomplish their\n\t// responsibilities above.\n\tActiveSync SyncerType = iota\n\n\t// PassiveSync denotes that a gossip syncer:\n\t//\n\t// 1. Should not attempt to synchronize with the remote peer for\n\t//    missing channels.\n\t// 2. Should respond to queries from the remote peer.\n\t// 3. Should not receive new updates from the remote peer.\n\t//\n\t// They are started in a chansSynced state in order to accomplish their\n\t// responsibilities above.\n\tPassiveSync\n\n\t// PinnedSync denotes an ActiveSync that doesn't count towards the\n\t// default active syncer limits and is always active throughout the\n\t// duration of the peer's connection. Each pinned syncer will begin by\n\t// performing a historical sync to ensure we are well synchronized with\n\t// their routing table.\n\tPinnedSync\n)\n\n// String returns a human readable string describing the target SyncerType.",
      "length": 1136,
      "tokens": 190,
      "embedding": []
    },
    {
      "slug": "func (t SyncerType) String() string {",
      "content": "func (t SyncerType) String() string {\n\tswitch t {\n\tcase ActiveSync:\n\t\treturn \"ActiveSync\"\n\tcase PassiveSync:\n\t\treturn \"PassiveSync\"\n\tcase PinnedSync:\n\t\treturn \"PinnedSync\"\n\tdefault:\n\t\treturn fmt.Sprintf(\"unknown sync type %d\", t)\n\t}\n}\n\n// IsActiveSync returns true if the SyncerType should set a GossipTimestampRange\n// allowing new gossip messages to be received from the peer.",
      "length": 327,
      "tokens": 46,
      "embedding": []
    },
    {
      "slug": "func (t SyncerType) IsActiveSync() bool {",
      "content": "func (t SyncerType) IsActiveSync() bool {\n\tswitch t {\n\tcase ActiveSync, PinnedSync:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\n// syncerState is an enum that represents the current state of the GossipSyncer.\n// As the syncer is a state machine, we'll gate our actions based off of the\n// current state and the next incoming message.",
      "length": 282,
      "tokens": 50,
      "embedding": []
    },
    {
      "slug": "type syncerState uint32",
      "content": "type syncerState uint32\n\nconst (\n\t// syncingChans is the default state of the GossipSyncer. We start in\n\t// this state when a new peer first connects and we don't yet know if\n\t// we're fully synchronized.\n\tsyncingChans syncerState = iota\n\n\t// waitingQueryRangeReply is the second main phase of the GossipSyncer.\n\t// We enter this state after we send out our first QueryChannelRange\n\t// reply. We'll stay in this state until the remote party sends us a\n\t// ReplyShortChanIDsEnd message that indicates they've responded to our\n\t// query entirely. After this state, we'll transition to\n\t// waitingQueryChanReply after we send out requests for all the new\n\t// chan ID's to us.\n\twaitingQueryRangeReply\n\n\t// queryNewChannels is the third main phase of the GossipSyncer.  In\n\t// this phase we'll send out all of our QueryShortChanIDs messages in\n\t// response to the new channels that we don't yet know about.\n\tqueryNewChannels\n\n\t// waitingQueryChanReply is the fourth main phase of the GossipSyncer.\n\t// We enter this phase once we've sent off a query chink to the remote\n\t// peer.  We'll stay in this phase until we receive a\n\t// ReplyShortChanIDsEnd message which indicates that the remote party\n\t// has responded to all of our requests.\n\twaitingQueryChanReply\n\n\t// chansSynced is the terminal stage of the GossipSyncer. Once we enter\n\t// this phase, we'll send out our update horizon, which filters out the\n\t// set of channel updates that we're interested in. In this state,\n\t// we'll be able to accept any outgoing messages from the\n\t// AuthenticatedGossiper, and decide if we should forward them to our\n\t// target peer based on its update horizon.\n\tchansSynced\n\n\t// syncerIdle is a state in which the gossip syncer can handle external\n\t// requests to transition or perform historical syncs. It is used as the\n\t// initial state for pinned syncers, as well as a fallthrough case for\n\t// chansSynced allowing fully synced peers to facilitate requests.\n\tsyncerIdle\n)\n\n// String returns a human readable string describing the target syncerState.",
      "length": 1971,
      "tokens": 327,
      "embedding": []
    },
    {
      "slug": "func (s syncerState) String() string {",
      "content": "func (s syncerState) String() string {\n\tswitch s {\n\tcase syncingChans:\n\t\treturn \"syncingChans\"\n\n\tcase waitingQueryRangeReply:\n\t\treturn \"waitingQueryRangeReply\"\n\n\tcase queryNewChannels:\n\t\treturn \"queryNewChannels\"\n\n\tcase waitingQueryChanReply:\n\t\treturn \"waitingQueryChanReply\"\n\n\tcase chansSynced:\n\t\treturn \"chansSynced\"\n\n\tcase syncerIdle:\n\t\treturn \"syncerIdle\"\n\n\tdefault:\n\t\treturn \"UNKNOWN STATE\"\n\t}\n}\n\nconst (\n\t// DefaultMaxUndelayedQueryReplies specifies how many gossip queries we\n\t// will respond to immediately before starting to delay responses.\n\tDefaultMaxUndelayedQueryReplies = 10\n\n\t// DefaultDelayedQueryReplyInterval is the length of time we will wait\n\t// before responding to gossip queries after replying to\n\t// maxUndelayedQueryReplies queries.\n\tDefaultDelayedQueryReplyInterval = 5 * time.Second\n\n\t// maxQueryChanRangeReplies specifies the default limit of replies to\n\t// process for a single QueryChannelRange request.\n\tmaxQueryChanRangeReplies = 500\n\n\t// maxQueryChanRangeRepliesZlibFactor specifies the factor applied to\n\t// the maximum number of replies allowed for zlib encoded replies.\n\tmaxQueryChanRangeRepliesZlibFactor = 4\n\n\t// chanRangeQueryBuffer is the number of blocks back that we'll go when\n\t// asking the remote peer for their any channels they know of beyond\n\t// our highest known channel ID.\n\tchanRangeQueryBuffer = 144\n\n\t// syncTransitionTimeout is the default timeout in which we'll wait up\n\t// to when attempting to perform a sync transition.\n\tsyncTransitionTimeout = 5 * time.Second\n\n\t// requestBatchSize is the maximum number of channels we will query the\n\t// remote peer for in a QueryShortChanIDs message.\n\trequestBatchSize = 500\n)\n\nvar (\n\t// encodingTypeToChunkSize maps an encoding type, to the max number of\n\t// short chan ID's using the encoding type that we can fit into a\n\t// single message safely.\n\tencodingTypeToChunkSize = map[lnwire.ShortChanIDEncoding]int32{\n\t\tlnwire.EncodingSortedPlain: 8000,\n\t}\n\n\t// ErrGossipSyncerExiting signals that the syncer has been killed.\n\tErrGossipSyncerExiting = errors.New(\"gossip syncer exiting\")\n\n\t// ErrSyncTransitionTimeout is an error returned when we've timed out\n\t// attempting to perform a sync transition.\n\tErrSyncTransitionTimeout = errors.New(\"timed out attempting to \" +\n\t\t\"transition sync type\")\n\n\t// zeroTimestamp is the timestamp we'll use when we want to indicate to\n\t// peers that we do not want to receive any new graph updates.\n\tzeroTimestamp time.Time\n)\n\n// syncTransitionReq encapsulates a request for a gossip syncer sync transition.",
      "length": 2420,
      "tokens": 325,
      "embedding": []
    },
    {
      "slug": "type syncTransitionReq struct {",
      "content": "type syncTransitionReq struct {\n\tnewSyncType SyncerType\n\terrChan     chan error\n}\n\n// historicalSyncReq encapsulates a request for a gossip syncer to perform a\n// historical sync.",
      "length": 142,
      "tokens": 21,
      "embedding": []
    },
    {
      "slug": "type historicalSyncReq struct {",
      "content": "type historicalSyncReq struct {\n\t// doneChan is a channel that serves as a signal and is closed to ensure\n\t// the historical sync is attempted by the time we return to the caller.\n\tdoneChan chan struct{}\n}\n\n// gossipSyncerCfg is a struct that packages all the information a GossipSyncer\n// needs to carry out its duties.",
      "length": 282,
      "tokens": 52,
      "embedding": []
    },
    {
      "slug": "type gossipSyncerCfg struct {",
      "content": "type gossipSyncerCfg struct {\n\t// chainHash is the chain that this syncer is responsible for.\n\tchainHash chainhash.Hash\n\n\t// peerPub is the public key of the peer we're syncing with, serialized\n\t// in compressed format.\n\tpeerPub [33]byte\n\n\t// channelSeries is the primary interface that we'll use to generate\n\t// our queries and respond to the queries of the remote peer.\n\tchannelSeries ChannelGraphTimeSeries\n\n\t// encodingType is the current encoding type we're aware of. Requests\n\t// with different encoding types will be rejected.\n\tencodingType lnwire.ShortChanIDEncoding\n\n\t// chunkSize is the max number of short chan IDs using the syncer's\n\t// encoding type that we can fit into a single message safely.\n\tchunkSize int32\n\n\t// batchSize is the max number of channels the syncer will query from\n\t// the remote node in a single QueryShortChanIDs request.\n\tbatchSize int32\n\n\t// sendToPeer sends a variadic number of messages to the remote peer.\n\t// This method should not block while waiting for sends to be written\n\t// to the wire.\n\tsendToPeer func(...lnwire.Message) error\n\n\t// sendToPeerSync sends a variadic number of messages to the remote\n\t// peer, blocking until all messages have been sent successfully or a\n\t// write error is encountered.\n\tsendToPeerSync func(...lnwire.Message) error\n\n\t// maxUndelayedQueryReplies specifies how many gossip queries we will\n\t// respond to immediately before starting to delay responses.\n\tmaxUndelayedQueryReplies int\n\n\t// delayedQueryReplyInterval is the length of time we will wait before\n\t// responding to gossip queries after replying to\n\t// maxUndelayedQueryReplies queries.\n\tdelayedQueryReplyInterval time.Duration\n\n\t// noSyncChannels will prevent the GossipSyncer from spawning a\n\t// channelGraphSyncer, meaning we will not try to reconcile unknown\n\t// channels with the remote peer.\n\tnoSyncChannels bool\n\n\t// noReplyQueries will prevent the GossipSyncer from spawning a\n\t// replyHandler, meaning we will not reply to queries from our remote\n\t// peer.\n\tnoReplyQueries bool\n\n\t// ignoreHistoricalFilters will prevent syncers from replying with\n\t// historical data when the remote peer sets a gossip_timestamp_range.\n\t// This prevents ranges with old start times from causing us to dump the\n\t// graph on connect.\n\tignoreHistoricalFilters bool\n\n\t// bestHeight returns the latest height known of the chain.\n\tbestHeight func() uint32\n\n\t// markGraphSynced updates the SyncManager's perception of whether we\n\t// have completed at least one historical sync.\n\tmarkGraphSynced func()\n\n\t// maxQueryChanRangeReplies is the maximum number of replies we'll allow\n\t// for a single QueryChannelRange request.\n\tmaxQueryChanRangeReplies uint32\n}\n\n// GossipSyncer is a struct that handles synchronizing the channel graph state\n// with a remote peer. The GossipSyncer implements a state machine that will\n// progressively ensure we're synchronized with the channel state of the remote\n// node. Once both nodes have been synchronized, we'll use an update filter to\n// filter out which messages should be sent to a remote peer based on their\n// update horizon. If the update horizon isn't specified, then we won't send\n// them any channel updates at all.",
      "length": 3074,
      "tokens": 463,
      "embedding": []
    },
    {
      "slug": "type GossipSyncer struct {",
      "content": "type GossipSyncer struct {\n\tstarted sync.Once\n\tstopped sync.Once\n\n\t// state is the current state of the GossipSyncer.\n\t//\n\t// NOTE: This variable MUST be used atomically.\n\tstate uint32\n\n\t// syncType denotes the SyncerType the gossip syncer is currently\n\t// exercising.\n\t//\n\t// NOTE: This variable MUST be used atomically.\n\tsyncType uint32\n\n\t// remoteUpdateHorizon is the update horizon of the remote peer. We'll\n\t// use this to properly filter out any messages.\n\tremoteUpdateHorizon *lnwire.GossipTimestampRange\n\n\t// localUpdateHorizon is our local update horizon, we'll use this to\n\t// determine if we've already sent out our update.\n\tlocalUpdateHorizon *lnwire.GossipTimestampRange\n\n\t// syncTransitions is a channel through which new sync type transition\n\t// requests will be sent through. These requests should only be handled\n\t// when the gossip syncer is in a chansSynced state to ensure its state\n\t// machine behaves as expected.\n\tsyncTransitionReqs chan *syncTransitionReq\n\n\t// historicalSyncReqs is a channel that serves as a signal for the\n\t// gossip syncer to perform a historical sync. These can only be done\n\t// once the gossip syncer is in a chansSynced state to ensure its state\n\t// machine behaves as expected.\n\thistoricalSyncReqs chan *historicalSyncReq\n\n\t// genHistoricalChanRangeQuery when true signals to the gossip syncer\n\t// that it should request the remote peer for all of its known channel\n\t// IDs starting from the genesis block of the chain. This can only\n\t// happen if the gossip syncer receives a request to attempt a\n\t// historical sync. It can be unset if the syncer ever transitions from\n\t// PassiveSync to ActiveSync.\n\tgenHistoricalChanRangeQuery bool\n\n\t// gossipMsgs is a channel that all responses to our queries from the\n\t// target peer will be sent over, these will be read by the\n\t// channelGraphSyncer.\n\tgossipMsgs chan lnwire.Message\n\n\t// queryMsgs is a channel that all queries from the remote peer will be\n\t// received over, these will be read by the replyHandler.\n\tqueryMsgs chan lnwire.Message\n\n\t// curQueryRangeMsg keeps track of the latest QueryChannelRange message\n\t// we've sent to a peer to ensure we've consumed all expected replies.\n\t// This field is primarily used within the waitingQueryChanReply state.\n\tcurQueryRangeMsg *lnwire.QueryChannelRange\n\n\t// prevReplyChannelRange keeps track of the previous ReplyChannelRange\n\t// message we've received from a peer to ensure they've fully replied to\n\t// our query by ensuring they covered our requested block range. This\n\t// field is primarily used within the waitingQueryChanReply state.\n\tprevReplyChannelRange *lnwire.ReplyChannelRange\n\n\t// bufferedChanRangeReplies is used in the waitingQueryChanReply to\n\t// buffer all the chunked response to our query.\n\tbufferedChanRangeReplies []lnwire.ShortChannelID\n\n\t// numChanRangeRepliesRcvd is used to track the number of replies\n\t// received as part of a QueryChannelRange. This field is primarily used\n\t// within the waitingQueryChanReply state.\n\tnumChanRangeRepliesRcvd uint32\n\n\t// newChansToQuery is used to pass the set of channels we should query\n\t// for from the waitingQueryChanReply state to the queryNewChannels\n\t// state.\n\tnewChansToQuery []lnwire.ShortChannelID\n\n\tcfg gossipSyncerCfg\n\n\t// rateLimiter dictates the frequency with which we will reply to gossip\n\t// queries from a peer. This is used to delay responses to peers to\n\t// prevent DOS vulnerabilities if they are spamming with an unreasonable\n\t// number of queries.\n\trateLimiter *rate.Limiter\n\n\t// syncedSignal is a channel that, if set, will be closed when the\n\t// GossipSyncer reaches its terminal chansSynced state.\n\tsyncedSignal chan struct{}\n\n\tsync.Mutex\n\n\tquit chan struct{}\n\twg   sync.WaitGroup\n}\n\n// newGossipSyncer returns a new instance of the GossipSyncer populated using\n// the passed config.",
      "length": 3696,
      "tokens": 550,
      "embedding": []
    },
    {
      "slug": "func newGossipSyncer(cfg gossipSyncerCfg) *GossipSyncer {",
      "content": "func newGossipSyncer(cfg gossipSyncerCfg) *GossipSyncer {\n\t// If no parameter was specified for max undelayed query replies, set it\n\t// to the default of 5 queries.\n\tif cfg.maxUndelayedQueryReplies <= 0 {\n\t\tcfg.maxUndelayedQueryReplies = DefaultMaxUndelayedQueryReplies\n\t}\n\n\t// If no parameter was specified for delayed query reply interval, set\n\t// to the default of 5 seconds.\n\tif cfg.delayedQueryReplyInterval <= 0 {\n\t\tcfg.delayedQueryReplyInterval = DefaultDelayedQueryReplyInterval\n\t}\n\n\t// Construct a rate limiter that will govern how frequently we reply to\n\t// gossip queries from this peer. The limiter will automatically adjust\n\t// during periods of quiescence, and increase the reply interval under\n\t// load.\n\tinterval := rate.Every(cfg.delayedQueryReplyInterval)\n\trateLimiter := rate.NewLimiter(\n\t\tinterval, cfg.maxUndelayedQueryReplies,\n\t)\n\n\treturn &GossipSyncer{\n\t\tcfg:                cfg,\n\t\trateLimiter:        rateLimiter,\n\t\tsyncTransitionReqs: make(chan *syncTransitionReq),\n\t\thistoricalSyncReqs: make(chan *historicalSyncReq),\n\t\tgossipMsgs:         make(chan lnwire.Message, 100),\n\t\tqueryMsgs:          make(chan lnwire.Message, 100),\n\t\tquit:               make(chan struct{}),\n\t}\n}\n\n// Start starts the GossipSyncer and any goroutines that it needs to carry out\n// its duties.",
      "length": 1203,
      "tokens": 145,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) Start() {",
      "content": "func (g *GossipSyncer) Start() {\n\tg.started.Do(func() {\n\t\tlog.Debugf(\"Starting GossipSyncer(%x)\", g.cfg.peerPub[:])\n\n\t\t// TODO(conner): only spawn channelGraphSyncer if remote\n\t\t// supports gossip queries, and only spawn replyHandler if we\n\t\t// advertise support\n\t\tif !g.cfg.noSyncChannels {\n\t\t\tg.wg.Add(1)\n\t\t\tgo g.channelGraphSyncer()\n\t\t}\n\t\tif !g.cfg.noReplyQueries {\n\t\t\tg.wg.Add(1)\n\t\t\tgo g.replyHandler()\n\t\t}\n\t})\n}\n\n// Stop signals the GossipSyncer for a graceful exit, then waits until it has\n// exited.",
      "length": 455,
      "tokens": 57,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) Stop() {",
      "content": "func (g *GossipSyncer) Stop() {\n\tg.stopped.Do(func() {\n\t\tlog.Debugf(\"Stopping GossipSyncer(%x)\", g.cfg.peerPub[:])\n\t\tdefer log.Debugf(\"GossipSyncer(%x) stopped\", g.cfg.peerPub[:])\n\n\t\tclose(g.quit)\n\t\tg.wg.Wait()\n\t})\n}\n\n// channelGraphSyncer is the main goroutine responsible for ensuring that we\n// properly channel graph state with the remote peer, and also that we only\n// send them messages which actually pass their defined update horizon.",
      "length": 399,
      "tokens": 49,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) channelGraphSyncer() {",
      "content": "func (g *GossipSyncer) channelGraphSyncer() {\n\tdefer g.wg.Done()\n\n\tfor {\n\t\tstate := g.syncState()\n\t\tsyncType := g.SyncType()\n\n\t\tlog.Debugf(\"GossipSyncer(%x): state=%v, type=%v\",\n\t\t\tg.cfg.peerPub[:], state, syncType)\n\n\t\tswitch state {\n\t\t// When we're in this state, we're trying to synchronize our\n\t\t// view of the network with the remote peer. We'll kick off\n\t\t// this sync by asking them for the set of channels they\n\t\t// understand, as we'll as responding to any other queries by\n\t\t// them.\n\t\tcase syncingChans:\n\t\t\t// If we're in this state, then we'll send the remote\n\t\t\t// peer our opening QueryChannelRange message.\n\t\t\tqueryRangeMsg, err := g.genChanRangeQuery(\n\t\t\t\tg.genHistoricalChanRangeQuery,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"Unable to gen chan range \"+\n\t\t\t\t\t\"query: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\terr = g.cfg.sendToPeer(queryRangeMsg)\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"Unable to send chan range \"+\n\t\t\t\t\t\"query: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// With the message sent successfully, we'll transition\n\t\t\t// into the next state where we wait for their reply.\n\t\t\tg.setSyncState(waitingQueryRangeReply)\n\n\t\t// In this state, we've sent out our initial channel range\n\t\t// query and are waiting for the final response from the remote\n\t\t// peer before we perform a diff to see with channels they know\n\t\t// of that we don't.\n\t\tcase waitingQueryRangeReply:\n\t\t\t// We'll wait to either process a new message from the\n\t\t\t// remote party, or exit due to the gossiper exiting,\n\t\t\t// or us being signalled to do so.\n\t\t\tselect {\n\t\t\tcase msg := <-g.gossipMsgs:\n\t\t\t\t// The remote peer is sending a response to our\n\t\t\t\t// initial query, we'll collate this response,\n\t\t\t\t// and see if it's the final one in the series.\n\t\t\t\t// If so, we can then transition to querying\n\t\t\t\t// for the new channels.\n\t\t\t\tqueryReply, ok := msg.(*lnwire.ReplyChannelRange)\n\t\t\t\tif ok {\n\t\t\t\t\terr := g.processChanRangeReply(queryReply)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Errorf(\"Unable to \"+\n\t\t\t\t\t\t\t\"process chan range \"+\n\t\t\t\t\t\t\t\"query: %v\", err)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tlog.Warnf(\"Unexpected message: %T in state=%v\",\n\t\t\t\t\tmsg, state)\n\n\t\t\tcase <-g.quit:\n\t\t\t\treturn\n\t\t\t}\n\n\t\t// We'll enter this state once we've discovered which channels\n\t\t// the remote party knows of that we don't yet know of\n\t\t// ourselves.\n\t\tcase queryNewChannels:\n\t\t\t// First, we'll attempt to continue our channel\n\t\t\t// synchronization by continuing to send off another\n\t\t\t// query chunk.\n\t\t\tdone, err := g.synchronizeChanIDs()\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"Unable to sync chan IDs: %v\", err)\n\t\t\t}\n\n\t\t\t// If this wasn't our last query, then we'll need to\n\t\t\t// transition to our waiting state.\n\t\t\tif !done {\n\t\t\t\tg.setSyncState(waitingQueryChanReply)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If we're fully synchronized, then we can transition\n\t\t\t// to our terminal state.\n\t\t\tg.setSyncState(chansSynced)\n\n\t\t\t// Ensure that the sync manager becomes aware that the\n\t\t\t// historical sync completed so synced_to_graph is\n\t\t\t// updated over rpc.\n\t\t\tg.cfg.markGraphSynced()\n\n\t\t// In this state, we've just sent off a new query for channels\n\t\t// that we don't yet know of. We'll remain in this state until\n\t\t// the remote party signals they've responded to our query in\n\t\t// totality.\n\t\tcase waitingQueryChanReply:\n\t\t\t// Once we've sent off our query, we'll wait for either\n\t\t\t// an ending reply, or just another query from the\n\t\t\t// remote peer.\n\t\t\tselect {\n\t\t\tcase msg := <-g.gossipMsgs:\n\t\t\t\t// If this is the final reply to one of our\n\t\t\t\t// queries, then we'll loop back into our query\n\t\t\t\t// state to send of the remaining query chunks.\n\t\t\t\t_, ok := msg.(*lnwire.ReplyShortChanIDsEnd)\n\t\t\t\tif ok {\n\t\t\t\t\tg.setSyncState(queryNewChannels)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tlog.Warnf(\"Unexpected message: %T in state=%v\",\n\t\t\t\t\tmsg, state)\n\n\t\t\tcase <-g.quit:\n\t\t\t\treturn\n\t\t\t}\n\n\t\t// This is our final terminal state where we'll only reply to\n\t\t// any further queries by the remote peer.\n\t\tcase chansSynced:\n\t\t\tg.Lock()\n\t\t\tif g.syncedSignal != nil {\n\t\t\t\tclose(g.syncedSignal)\n\t\t\t\tg.syncedSignal = nil\n\t\t\t}\n\t\t\tg.Unlock()\n\n\t\t\t// If we haven't yet sent out our update horizon, and\n\t\t\t// we want to receive real-time channel updates, we'll\n\t\t\t// do so now.\n\t\t\tif g.localUpdateHorizon == nil &&\n\t\t\t\tsyncType.IsActiveSync() {\n\n\t\t\t\terr := g.sendGossipTimestampRange(\n\t\t\t\t\ttime.Now(), math.MaxUint32,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Errorf(\"Unable to send update \"+\n\t\t\t\t\t\t\"horizon to %x: %v\",\n\t\t\t\t\t\tg.cfg.peerPub, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\t// With our horizon set, we'll simply reply to any new\n\t\t\t// messages or process any state transitions and exit if\n\t\t\t// needed.\n\t\t\tfallthrough\n\n\t\t// Pinned peers will begin in this state, since they will\n\t\t// immediately receive a request to perform a historical sync.\n\t\t// Otherwise, we fall through after ending in chansSynced to\n\t\t// facilitate new requests.\n\t\tcase syncerIdle:\n\t\t\tselect {\n\t\t\tcase req := <-g.syncTransitionReqs:\n\t\t\t\treq.errChan <- g.handleSyncTransition(req)\n\n\t\t\tcase req := <-g.historicalSyncReqs:\n\t\t\t\tg.handleHistoricalSync(req)\n\n\t\t\tcase <-g.quit:\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\n// replyHandler is an event loop whose sole purpose is to reply to the remote\n// peers queries. Our replyHandler will respond to messages generated by their\n// channelGraphSyncer, and vice versa. Each party's channelGraphSyncer drives\n// the other's replyHandler, allowing the replyHandler to operate independently\n// from the state machine maintained on the same node.\n//\n// NOTE: This method MUST be run as a goroutine.",
      "length": 5244,
      "tokens": 788,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) replyHandler() {",
      "content": "func (g *GossipSyncer) replyHandler() {\n\tdefer g.wg.Done()\n\n\tfor {\n\t\tselect {\n\t\tcase msg := <-g.queryMsgs:\n\t\t\terr := g.replyPeerQueries(msg)\n\t\t\tswitch {\n\t\t\tcase err == ErrGossipSyncerExiting:\n\t\t\t\treturn\n\n\t\t\tcase err == lnpeer.ErrPeerExiting:\n\t\t\t\treturn\n\n\t\t\tcase err != nil:\n\t\t\t\tlog.Errorf(\"Unable to reply to peer \"+\n\t\t\t\t\t\"query: %v\", err)\n\t\t\t}\n\n\t\tcase <-g.quit:\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// sendGossipTimestampRange constructs and sets a GossipTimestampRange for the\n// syncer and sends it to the remote peer.",
      "length": 439,
      "tokens": 63,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) sendGossipTimestampRange(firstTimestamp time.Time,",
      "content": "func (g *GossipSyncer) sendGossipTimestampRange(firstTimestamp time.Time,\n\ttimestampRange uint32) error {\n\n\tendTimestamp := firstTimestamp.Add(\n\t\ttime.Duration(timestampRange) * time.Second,\n\t)\n\n\tlog.Infof(\"GossipSyncer(%x): applying gossipFilter(start=%v, end=%v)\",\n\t\tg.cfg.peerPub[:], firstTimestamp, endTimestamp)\n\n\tlocalUpdateHorizon := &lnwire.GossipTimestampRange{\n\t\tChainHash:      g.cfg.chainHash,\n\t\tFirstTimestamp: uint32(firstTimestamp.Unix()),\n\t\tTimestampRange: timestampRange,\n\t}\n\n\tif err := g.cfg.sendToPeer(localUpdateHorizon); err != nil {\n\t\treturn err\n\t}\n\n\tif firstTimestamp == zeroTimestamp && timestampRange == 0 {\n\t\tg.localUpdateHorizon = nil\n\t} else {\n\t\tg.localUpdateHorizon = localUpdateHorizon\n\t}\n\n\treturn nil\n}\n\n// synchronizeChanIDs is called by the channelGraphSyncer when we need to query\n// the remote peer for its known set of channel IDs within a particular block\n// range. This method will be called continually until the entire range has\n// been queried for with a response received. We'll chunk our requests as\n// required to ensure they fit into a single message. We may re-renter this\n// state in the case that chunking is required.",
      "length": 1059,
      "tokens": 137,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) synchronizeChanIDs() (bool, error) {",
      "content": "func (g *GossipSyncer) synchronizeChanIDs() (bool, error) {\n\t// If we're in this state yet there are no more new channels to query\n\t// for, then we'll transition to our final synced state and return true\n\t// to signal that we're fully synchronized.\n\tif len(g.newChansToQuery) == 0 {\n\t\tlog.Infof(\"GossipSyncer(%x): no more chans to query\",\n\t\t\tg.cfg.peerPub[:])\n\t\treturn true, nil\n\t}\n\n\t// Otherwise, we'll issue our next chunked query to receive replies\n\t// for.\n\tvar queryChunk []lnwire.ShortChannelID\n\n\t// If the number of channels to query for is less than the chunk size,\n\t// then we can issue a single query.\n\tif int32(len(g.newChansToQuery)) < g.cfg.batchSize {\n\t\tqueryChunk = g.newChansToQuery\n\t\tg.newChansToQuery = nil\n\n\t} else {\n\t\t// Otherwise, we'll need to only query for the next chunk.\n\t\t// We'll slice into our query chunk, then slide down our main\n\t\t// pointer down by the chunk size.\n\t\tqueryChunk = g.newChansToQuery[:g.cfg.batchSize]\n\t\tg.newChansToQuery = g.newChansToQuery[g.cfg.batchSize:]\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): querying for %v new channels\",\n\t\tg.cfg.peerPub[:], len(queryChunk))\n\n\t// With our chunk obtained, we'll send over our next query, then return\n\t// false indicating that we're net yet fully synced.\n\terr := g.cfg.sendToPeer(&lnwire.QueryShortChanIDs{\n\t\tChainHash:    g.cfg.chainHash,\n\t\tEncodingType: lnwire.EncodingSortedPlain,\n\t\tShortChanIDs: queryChunk,\n\t})\n\n\treturn false, err\n}\n\n// isLegacyReplyChannelRange determines where a ReplyChannelRange message is\n// considered legacy. There was a point where lnd used to include the same query\n// over multiple replies, rather than including the portion of the query the\n// reply is handling. We'll use this as a way of detecting whether we are\n// communicating with a legacy node so we can properly sync with them.",
      "length": 1695,
      "tokens": 249,
      "embedding": []
    },
    {
      "slug": "func isLegacyReplyChannelRange(query *lnwire.QueryChannelRange,",
      "content": "func isLegacyReplyChannelRange(query *lnwire.QueryChannelRange,\n\treply *lnwire.ReplyChannelRange) bool {\n\n\treturn (reply.ChainHash == query.ChainHash &&\n\t\treply.FirstBlockHeight == query.FirstBlockHeight &&\n\t\treply.NumBlocks == query.NumBlocks)\n}\n\n// processChanRangeReply is called each time the GossipSyncer receives a new\n// reply to the initial range query to discover new channels that it didn't\n// previously know of.",
      "length": 350,
      "tokens": 46,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) processChanRangeReply(msg *lnwire.ReplyChannelRange) error {",
      "content": "func (g *GossipSyncer) processChanRangeReply(msg *lnwire.ReplyChannelRange) error {\n\t// If we're not communicating with a legacy node, we'll apply some\n\t// further constraints on their reply to ensure it satisfies our query.\n\tif !isLegacyReplyChannelRange(g.curQueryRangeMsg, msg) {\n\t\t// The first block should be within our original request.\n\t\tif msg.FirstBlockHeight < g.curQueryRangeMsg.FirstBlockHeight {\n\t\t\treturn fmt.Errorf(\"reply includes channels for height \"+\n\t\t\t\t\"%v prior to query %v\", msg.FirstBlockHeight,\n\t\t\t\tg.curQueryRangeMsg.FirstBlockHeight)\n\t\t}\n\n\t\t// The last block should also be. We don't need to check the\n\t\t// intermediate ones because they should already be in sorted\n\t\t// order.\n\t\treplyLastHeight := msg.LastBlockHeight()\n\t\tqueryLastHeight := g.curQueryRangeMsg.LastBlockHeight()\n\t\tif replyLastHeight > queryLastHeight {\n\t\t\treturn fmt.Errorf(\"reply includes channels for height \"+\n\t\t\t\t\"%v after query %v\", replyLastHeight,\n\t\t\t\tqueryLastHeight)\n\t\t}\n\n\t\t// If we've previously received a reply for this query, look at\n\t\t// its last block to ensure the current reply properly follows\n\t\t// it.\n\t\tif g.prevReplyChannelRange != nil {\n\t\t\tprevReply := g.prevReplyChannelRange\n\t\t\tprevReplyLastHeight := prevReply.LastBlockHeight()\n\n\t\t\t// The current reply can either start from the previous\n\t\t\t// reply's last block, if there are still more channels\n\t\t\t// for the same block, or the block after.\n\t\t\tif msg.FirstBlockHeight != prevReplyLastHeight &&\n\t\t\t\tmsg.FirstBlockHeight != prevReplyLastHeight+1 {\n\n\t\t\t\treturn fmt.Errorf(\"first block of reply %v \"+\n\t\t\t\t\t\"does not continue from last block of \"+\n\t\t\t\t\t\"previous %v\", msg.FirstBlockHeight,\n\t\t\t\t\tprevReplyLastHeight)\n\t\t\t}\n\t\t}\n\t}\n\n\tg.prevReplyChannelRange = msg\n\tg.bufferedChanRangeReplies = append(\n\t\tg.bufferedChanRangeReplies, msg.ShortChanIDs...,\n\t)\n\tswitch g.cfg.encodingType {\n\tcase lnwire.EncodingSortedPlain:\n\t\tg.numChanRangeRepliesRcvd++\n\tcase lnwire.EncodingSortedZlib:\n\t\tg.numChanRangeRepliesRcvd += maxQueryChanRangeRepliesZlibFactor\n\tdefault:\n\t\treturn fmt.Errorf(\"unhandled encoding type %v\", g.cfg.encodingType)\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): buffering chan range reply of size=%v\",\n\t\tg.cfg.peerPub[:], len(msg.ShortChanIDs))\n\n\t// If this isn't the last response and we can continue to receive more,\n\t// then we can exit as we've already buffered the latest portion of the\n\t// streaming reply.\n\tmaxReplies := g.cfg.maxQueryChanRangeReplies\n\tswitch {\n\t// If we're communicating with a legacy node, we'll need to look at the\n\t// complete field.\n\tcase isLegacyReplyChannelRange(g.curQueryRangeMsg, msg):\n\t\tif msg.Complete == 0 && g.numChanRangeRepliesRcvd < maxReplies {\n\t\t\treturn nil\n\t\t}\n\n\t// Otherwise, we'll look at the reply's height range.\n\tdefault:\n\t\treplyLastHeight := msg.LastBlockHeight()\n\t\tqueryLastHeight := g.curQueryRangeMsg.LastBlockHeight()\n\n\t\t// TODO(wilmer): This might require some padding if the remote\n\t\t// node is not aware of the last height we sent them, i.e., is\n\t\t// behind a few blocks from us.\n\t\tif replyLastHeight < queryLastHeight &&\n\t\t\tg.numChanRangeRepliesRcvd < maxReplies {\n\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): filtering through %v chans\",\n\t\tg.cfg.peerPub[:], len(g.bufferedChanRangeReplies))\n\n\t// Otherwise, this is the final response, so we'll now check to see\n\t// which channels they know of that we don't.\n\tnewChans, err := g.cfg.channelSeries.FilterKnownChanIDs(\n\t\tg.cfg.chainHash, g.bufferedChanRangeReplies,\n\t)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to filter chan ids: %v\", err)\n\t}\n\n\t// As we've received the entirety of the reply, we no longer need to\n\t// hold on to the set of buffered replies or the original query that\n\t// prompted the replies, so we'll let that be garbage collected now.\n\tg.curQueryRangeMsg = nil\n\tg.prevReplyChannelRange = nil\n\tg.bufferedChanRangeReplies = nil\n\tg.numChanRangeRepliesRcvd = 0\n\n\t// If there aren't any channels that we don't know of, then we can\n\t// switch straight to our terminal state.\n\tif len(newChans) == 0 {\n\t\tlog.Infof(\"GossipSyncer(%x): remote peer has no new chans\",\n\t\t\tg.cfg.peerPub[:])\n\n\t\tg.setSyncState(chansSynced)\n\n\t\t// Ensure that the sync manager becomes aware that the\n\t\t// historical sync completed so synced_to_graph is updated over\n\t\t// rpc.\n\t\tg.cfg.markGraphSynced()\n\t\treturn nil\n\t}\n\n\t// Otherwise, we'll set the set of channels that we need to query for\n\t// the next state, and also transition our state.\n\tg.newChansToQuery = newChans\n\tg.setSyncState(queryNewChannels)\n\n\tlog.Infof(\"GossipSyncer(%x): starting query for %v new chans\",\n\t\tg.cfg.peerPub[:], len(newChans))\n\n\treturn nil\n}\n\n// genChanRangeQuery generates the initial message we'll send to the remote\n// party when we're kicking off the channel graph synchronization upon\n// connection. The historicalQuery boolean can be used to generate a query from\n// the genesis block of the chain.",
      "length": 4628,
      "tokens": 612,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) genChanRangeQuery(",
      "content": "func (g *GossipSyncer) genChanRangeQuery(\n\thistoricalQuery bool) (*lnwire.QueryChannelRange, error) {\n\n\t// First, we'll query our channel graph time series for its highest\n\t// known channel ID.\n\tnewestChan, err := g.cfg.channelSeries.HighestChanID(g.cfg.chainHash)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Once we have the chan ID of the newest, we'll obtain the block height\n\t// of the channel, then subtract our default horizon to ensure we don't\n\t// miss any channels. By default, we go back 1 day from the newest\n\t// channel, unless we're attempting a historical sync, where we'll\n\t// actually start from the genesis block instead.\n\tvar startHeight uint32\n\tswitch {\n\tcase historicalQuery:\n\t\tfallthrough\n\tcase newestChan.BlockHeight <= chanRangeQueryBuffer:\n\t\tstartHeight = 0\n\tdefault:\n\t\tstartHeight = uint32(newestChan.BlockHeight - chanRangeQueryBuffer)\n\t}\n\n\t// Determine the number of blocks to request based on our best height.\n\t// We'll take into account any potential underflows and explicitly set\n\t// numBlocks to its minimum value of 1 if so.\n\tbestHeight := g.cfg.bestHeight()\n\tnumBlocks := bestHeight - startHeight\n\tif int64(numBlocks) < 1 {\n\t\tnumBlocks = 1\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): requesting new chans from height=%v \"+\n\t\t\"and %v blocks after\", g.cfg.peerPub[:], startHeight, numBlocks)\n\n\t// Finally, we'll craft the channel range query, using our starting\n\t// height, then asking for all known channels to the foreseeable end of\n\t// the main chain.\n\tquery := &lnwire.QueryChannelRange{\n\t\tChainHash:        g.cfg.chainHash,\n\t\tFirstBlockHeight: startHeight,\n\t\tNumBlocks:        numBlocks,\n\t}\n\tg.curQueryRangeMsg = query\n\n\treturn query, nil\n}\n\n// replyPeerQueries is called in response to any query by the remote peer.\n// We'll examine our state and send back our best response.",
      "length": 1709,
      "tokens": 250,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) replyPeerQueries(msg lnwire.Message) error {",
      "content": "func (g *GossipSyncer) replyPeerQueries(msg lnwire.Message) error {\n\treservation := g.rateLimiter.Reserve()\n\tdelay := reservation.Delay()\n\n\t// If we've already replied a handful of times, we will start to delay\n\t// responses back to the remote peer. This can help prevent DOS attacks\n\t// where the remote peer spams us endlessly.\n\tif delay > 0 {\n\t\tlog.Infof(\"GossipSyncer(%x): rate limiting gossip replies, \"+\n\t\t\t\"responding in %s\", g.cfg.peerPub[:], delay)\n\n\t\tselect {\n\t\tcase <-time.After(delay):\n\t\tcase <-g.quit:\n\t\t\treturn ErrGossipSyncerExiting\n\t\t}\n\t}\n\n\tswitch msg := msg.(type) {\n\n\t// In this state, we'll also handle any incoming channel range queries\n\t// from the remote peer as they're trying to sync their state as well.\n\tcase *lnwire.QueryChannelRange:\n\t\treturn g.replyChanRangeQuery(msg)\n\n\t// If the remote peer skips straight to requesting new channels that\n\t// they don't know of, then we'll ensure that we also handle this case.\n\tcase *lnwire.QueryShortChanIDs:\n\t\treturn g.replyShortChanIDs(msg)\n\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown message: %T\", msg)\n\t}\n}\n\n// replyChanRangeQuery will be dispatched in response to a channel range query\n// by the remote node. We'll query the channel time series for channels that\n// meet the channel range, then chunk our responses to the remote node. We also\n// ensure that our final fragment carries the \"complete\" bit to indicate the\n// end of our streaming response.",
      "length": 1314,
      "tokens": 200,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) replyChanRangeQuery(query *lnwire.QueryChannelRange) error {",
      "content": "func (g *GossipSyncer) replyChanRangeQuery(query *lnwire.QueryChannelRange) error {\n\t// Before responding, we'll check to ensure that the remote peer is\n\t// querying for the same chain that we're on. If not, we'll send back a\n\t// response with a complete value of zero to indicate we're on a\n\t// different chain.\n\tif g.cfg.chainHash != query.ChainHash {\n\t\tlog.Warnf(\"Remote peer requested QueryChannelRange for \"+\n\t\t\t\"chain=%v, we're on chain=%v\", query.ChainHash,\n\t\t\tg.cfg.chainHash)\n\n\t\treturn g.cfg.sendToPeerSync(&lnwire.ReplyChannelRange{\n\t\t\tChainHash:        query.ChainHash,\n\t\t\tFirstBlockHeight: query.FirstBlockHeight,\n\t\t\tNumBlocks:        query.NumBlocks,\n\t\t\tComplete:         0,\n\t\t\tEncodingType:     g.cfg.encodingType,\n\t\t\tShortChanIDs:     nil,\n\t\t})\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): filtering chan range: start_height=%v, \"+\n\t\t\"num_blocks=%v\", g.cfg.peerPub[:], query.FirstBlockHeight,\n\t\tquery.NumBlocks)\n\n\t// Next, we'll consult the time series to obtain the set of known\n\t// channel ID's that match their query.\n\tstartBlock := query.FirstBlockHeight\n\tendBlock := query.LastBlockHeight()\n\tchannelRanges, err := g.cfg.channelSeries.FilterChannelRange(\n\t\tquery.ChainHash, startBlock, endBlock,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// TODO(roasbeef): means can't send max uint above?\n\t//  * or make internal 64\n\n\t// We'll send our response in a streaming manner, chunk-by-chunk. We do\n\t// this as there's a transport message size limit which we'll need to\n\t// adhere to. We also need to make sure all of our replies cover the\n\t// expected range of the query.\n\tsendReplyForChunk := func(channelChunk []lnwire.ShortChannelID,\n\t\tfirstHeight, lastHeight uint32, finalChunk bool) error {\n\n\t\t// The number of blocks contained in the current chunk (the\n\t\t// total span) is the difference between the last channel ID and\n\t\t// the first in the range. We add one as even if all channels\n\t\t// returned are in the same block, we need to count that.\n\t\tnumBlocks := lastHeight - firstHeight + 1\n\t\tcomplete := uint8(0)\n\t\tif finalChunk {\n\t\t\tcomplete = 1\n\t\t}\n\n\t\treturn g.cfg.sendToPeerSync(&lnwire.ReplyChannelRange{\n\t\t\tChainHash:        query.ChainHash,\n\t\t\tNumBlocks:        numBlocks,\n\t\t\tFirstBlockHeight: firstHeight,\n\t\t\tComplete:         complete,\n\t\t\tEncodingType:     g.cfg.encodingType,\n\t\t\tShortChanIDs:     channelChunk,\n\t\t})\n\t}\n\n\tvar (\n\t\tfirstHeight  = query.FirstBlockHeight\n\t\tlastHeight   uint32\n\t\tchannelChunk []lnwire.ShortChannelID\n\t)\n\tfor _, channelRange := range channelRanges {\n\t\tchannels := channelRange.Channels\n\t\tnumChannels := int32(len(channels))\n\t\tnumLeftToAdd := g.cfg.chunkSize - int32(len(channelChunk))\n\n\t\t// Include the current block in the ongoing chunk if it can fit\n\t\t// and move on to the next block.\n\t\tif numChannels <= numLeftToAdd {\n\t\t\tchannelChunk = append(channelChunk, channels...)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Otherwise, we need to send our existing channel chunk as is\n\t\t// as its own reply and start a new one for the current block.\n\t\t// We'll mark the end of our current chunk as the height before\n\t\t// the current block to ensure the whole query range is replied\n\t\t// to.\n\t\tlog.Infof(\"GossipSyncer(%x): sending range chunk of size=%v\",\n\t\t\tg.cfg.peerPub[:], len(channelChunk))\n\t\tlastHeight = channelRange.Height - 1\n\t\terr := sendReplyForChunk(\n\t\t\tchannelChunk, firstHeight, lastHeight, false,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// With the reply constructed, we'll start tallying channels for\n\t\t// our next one keeping in mind our chunk size. This may result\n\t\t// in channels for this block being left out from the reply, but\n\t\t// this isn't an issue since we'll randomly shuffle them and we\n\t\t// assume a historical gossip sync is performed at a later time.\n\t\tfirstHeight = channelRange.Height\n\t\tchunkSize := numChannels\n\t\texceedsChunkSize := numChannels > g.cfg.chunkSize\n\t\tif exceedsChunkSize {\n\t\t\trand.Shuffle(len(channels), func(i, j int) {\n\t\t\t\tchannels[i], channels[j] = channels[j], channels[i]\n\t\t\t})\n\t\t\tchunkSize = g.cfg.chunkSize\n\t\t}\n\t\tchannelChunk = channels[:chunkSize]\n\n\t\t// Sort the chunk once again if we had to shuffle it.\n\t\tif exceedsChunkSize {\n\t\t\tsort.Slice(channelChunk, func(i, j int) bool {\n\t\t\t\treturn channelChunk[i].ToUint64() <\n\t\t\t\t\tchannelChunk[j].ToUint64()\n\t\t\t})\n\t\t}\n\t}\n\n\t// Send the remaining chunk as the final reply.\n\tlog.Infof(\"GossipSyncer(%x): sending final chan range chunk, size=%v\",\n\t\tg.cfg.peerPub[:], len(channelChunk))\n\treturn sendReplyForChunk(\n\t\tchannelChunk, firstHeight, query.LastBlockHeight(), true,\n\t)\n}\n\n// replyShortChanIDs will be dispatched in response to a query by the remote\n// node for information concerning a set of short channel ID's. Our response\n// will be sent in a streaming chunked manner to ensure that we remain below\n// the current transport level message size.",
      "length": 4545,
      "tokens": 617,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) replyShortChanIDs(query *lnwire.QueryShortChanIDs) error {",
      "content": "func (g *GossipSyncer) replyShortChanIDs(query *lnwire.QueryShortChanIDs) error {\n\t// Before responding, we'll check to ensure that the remote peer is\n\t// querying for the same chain that we're on. If not, we'll send back a\n\t// response with a complete value of zero to indicate we're on a\n\t// different chain.\n\tif g.cfg.chainHash != query.ChainHash {\n\t\tlog.Warnf(\"Remote peer requested QueryShortChanIDs for \"+\n\t\t\t\"chain=%v, we're on chain=%v\", query.ChainHash,\n\t\t\tg.cfg.chainHash)\n\n\t\treturn g.cfg.sendToPeerSync(&lnwire.ReplyShortChanIDsEnd{\n\t\t\tChainHash: query.ChainHash,\n\t\t\tComplete:  0,\n\t\t})\n\t}\n\n\tif len(query.ShortChanIDs) == 0 {\n\t\tlog.Infof(\"GossipSyncer(%x): ignoring query for blank short chan ID's\",\n\t\t\tg.cfg.peerPub[:])\n\t\treturn nil\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): fetching chan anns for %v chans\",\n\t\tg.cfg.peerPub[:], len(query.ShortChanIDs))\n\n\t// Now that we know we're on the same chain, we'll query the channel\n\t// time series for the set of messages that we know of which satisfies\n\t// the requirement of being a chan ann, chan update, or a node ann\n\t// related to the set of queried channels.\n\treplyMsgs, err := g.cfg.channelSeries.FetchChanAnns(\n\t\tquery.ChainHash, query.ShortChanIDs,\n\t)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to fetch chan anns for %v..., %v\",\n\t\t\tquery.ShortChanIDs[0].ToUint64(), err)\n\t}\n\n\t// Reply with any messages related to those channel ID's, we'll write\n\t// each one individually and synchronously to throttle the sends and\n\t// perform buffering of responses in the syncer as opposed to the peer.\n\tfor _, msg := range replyMsgs {\n\t\terr := g.cfg.sendToPeerSync(msg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Regardless of whether we had any messages to reply with, send over\n\t// the sentinel message to signal that the stream has terminated.\n\treturn g.cfg.sendToPeerSync(&lnwire.ReplyShortChanIDsEnd{\n\t\tChainHash: query.ChainHash,\n\t\tComplete:  1,\n\t})\n}\n\n// ApplyGossipFilter applies a gossiper filter sent by the remote node to the\n// state machine. Once applied, we'll ensure that we don't forward any messages\n// to the peer that aren't within the time range of the filter.",
      "length": 1989,
      "tokens": 294,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) ApplyGossipFilter(filter *lnwire.GossipTimestampRange) error {",
      "content": "func (g *GossipSyncer) ApplyGossipFilter(filter *lnwire.GossipTimestampRange) error {\n\tg.Lock()\n\n\tg.remoteUpdateHorizon = filter\n\n\tstartTime := time.Unix(int64(g.remoteUpdateHorizon.FirstTimestamp), 0)\n\tendTime := startTime.Add(\n\t\ttime.Duration(g.remoteUpdateHorizon.TimestampRange) * time.Second,\n\t)\n\n\tg.Unlock()\n\n\t// If requested, don't reply with historical gossip data when the remote\n\t// peer sets their gossip timestamp range.\n\tif g.cfg.ignoreHistoricalFilters {\n\t\treturn nil\n\t}\n\n\t// Now that the remote peer has applied their filter, we'll query the\n\t// database for all the messages that are beyond this filter.\n\tnewUpdatestoSend, err := g.cfg.channelSeries.UpdatesInHorizon(\n\t\tg.cfg.chainHash, startTime, endTime,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"GossipSyncer(%x): applying new update horizon: start=%v, \"+\n\t\t\"end=%v, backlog_size=%v\", g.cfg.peerPub[:], startTime, endTime,\n\t\tlen(newUpdatestoSend))\n\n\t// If we don't have any to send, then we can return early.\n\tif len(newUpdatestoSend) == 0 {\n\t\treturn nil\n\t}\n\n\t// We'll conclude by launching a goroutine to send out any updates.\n\tg.wg.Add(1)\n\tgo func() {\n\t\tdefer g.wg.Done()\n\n\t\tfor _, msg := range newUpdatestoSend {\n\t\t\terr := g.cfg.sendToPeerSync(msg)\n\t\t\tswitch {\n\t\t\tcase err == ErrGossipSyncerExiting:\n\t\t\t\treturn\n\n\t\t\tcase err == lnpeer.ErrPeerExiting:\n\t\t\t\treturn\n\n\t\t\tcase err != nil:\n\t\t\t\tlog.Errorf(\"Unable to send message for \"+\n\t\t\t\t\t\"peer catch up: %v\", err)\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn nil\n}\n\n// FilterGossipMsgs takes a set of gossip messages, and only send it to a peer\n// iff the message is within the bounds of their set gossip filter. If the peer\n// doesn't have a gossip filter set, then no messages will be forwarded.",
      "length": 1552,
      "tokens": 220,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) FilterGossipMsgs(msgs ...msgWithSenders) {",
      "content": "func (g *GossipSyncer) FilterGossipMsgs(msgs ...msgWithSenders) {\n\t// If the peer doesn't have an update horizon set, then we won't send\n\t// it any new update messages.\n\tif g.remoteUpdateHorizon == nil {\n\t\treturn\n\t}\n\n\t// If we've been signaled to exit, or are exiting, then we'll stop\n\t// short.\n\tselect {\n\tcase <-g.quit:\n\t\treturn\n\tdefault:\n\t}\n\n\t// TODO(roasbeef): need to ensure that peer still online...send msg to\n\t// gossiper on peer termination to signal peer disconnect?\n\n\tvar err error\n\n\t// Before we filter out the messages, we'll construct an index over the\n\t// set of channel announcements and channel updates. This will allow us\n\t// to quickly check if we should forward a chan ann, based on the known\n\t// channel updates for a channel.\n\tchanUpdateIndex := make(map[lnwire.ShortChannelID][]*lnwire.ChannelUpdate)\n\tfor _, msg := range msgs {\n\t\tchanUpdate, ok := msg.msg.(*lnwire.ChannelUpdate)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tchanUpdateIndex[chanUpdate.ShortChannelID] = append(\n\t\t\tchanUpdateIndex[chanUpdate.ShortChannelID], chanUpdate,\n\t\t)\n\t}\n\n\t// We'll construct a helper function that we'll us below to determine\n\t// if a given messages passes the gossip msg filter.\n\tg.Lock()\n\tstartTime := time.Unix(int64(g.remoteUpdateHorizon.FirstTimestamp), 0)\n\tendTime := startTime.Add(\n\t\ttime.Duration(g.remoteUpdateHorizon.TimestampRange) * time.Second,\n\t)\n\tg.Unlock()\n\n\tpassesFilter := func(timeStamp uint32) bool {\n\t\tt := time.Unix(int64(timeStamp), 0)\n\t\treturn t.Equal(startTime) ||\n\t\t\t(t.After(startTime) && t.Before(endTime))\n\t}\n\n\tmsgsToSend := make([]lnwire.Message, 0, len(msgs))\n\tfor _, msg := range msgs {\n\t\t// If the target peer is the peer that sent us this message,\n\t\t// then we'll exit early as we don't need to filter this\n\t\t// message.\n\t\tif _, ok := msg.senders[g.cfg.peerPub]; ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch msg := msg.msg.(type) {\n\n\t\t// For each channel announcement message, we'll only send this\n\t\t// message if the channel updates for the channel are between\n\t\t// our time range.\n\t\tcase *lnwire.ChannelAnnouncement:\n\t\t\t// First, we'll check if the channel updates are in\n\t\t\t// this message batch.\n\t\t\tchanUpdates, ok := chanUpdateIndex[msg.ShortChannelID]\n\t\t\tif !ok {\n\t\t\t\t// If not, we'll attempt to query the database\n\t\t\t\t// to see if we know of the updates.\n\t\t\t\tchanUpdates, err = g.cfg.channelSeries.FetchChanUpdates(\n\t\t\t\t\tg.cfg.chainHash, msg.ShortChannelID,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Warnf(\"no channel updates found for \"+\n\t\t\t\t\t\t\"short_chan_id=%v\",\n\t\t\t\t\t\tmsg.ShortChannelID)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor _, chanUpdate := range chanUpdates {\n\t\t\t\tif passesFilter(chanUpdate.Timestamp) {\n\t\t\t\t\tmsgsToSend = append(msgsToSend, msg)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(chanUpdates) == 0 {\n\t\t\t\tmsgsToSend = append(msgsToSend, msg)\n\t\t\t}\n\n\t\t// For each channel update, we'll only send if it the timestamp\n\t\t// is between our time range.\n\t\tcase *lnwire.ChannelUpdate:\n\t\t\tif passesFilter(msg.Timestamp) {\n\t\t\t\tmsgsToSend = append(msgsToSend, msg)\n\t\t\t}\n\n\t\t// Similarly, we only send node announcements if the update\n\t\t// timestamp ifs between our set gossip filter time range.\n\t\tcase *lnwire.NodeAnnouncement:\n\t\t\tif passesFilter(msg.Timestamp) {\n\t\t\t\tmsgsToSend = append(msgsToSend, msg)\n\t\t\t}\n\t\t}\n\t}\n\n\tlog.Tracef(\"GossipSyncer(%x): filtered gossip msgs: set=%v, sent=%v\",\n\t\tg.cfg.peerPub[:], len(msgs), len(msgsToSend))\n\n\tif len(msgsToSend) == 0 {\n\t\treturn\n\t}\n\n\tg.cfg.sendToPeer(msgsToSend...)\n}\n\n// ProcessQueryMsg is used by outside callers to pass new channel time series\n// queries to the internal processing goroutine.",
      "length": 3359,
      "tokens": 463,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) ProcessQueryMsg(msg lnwire.Message, peerQuit <-chan struct{}) error {",
      "content": "func (g *GossipSyncer) ProcessQueryMsg(msg lnwire.Message, peerQuit <-chan struct{}) error {\n\tvar msgChan chan lnwire.Message\n\tswitch msg.(type) {\n\tcase *lnwire.QueryChannelRange, *lnwire.QueryShortChanIDs:\n\t\tmsgChan = g.queryMsgs\n\n\t// Reply messages should only be expected in states where we're waiting\n\t// for a reply.\n\tcase *lnwire.ReplyChannelRange, *lnwire.ReplyShortChanIDsEnd:\n\t\tsyncState := g.syncState()\n\t\tif syncState != waitingQueryRangeReply &&\n\t\t\tsyncState != waitingQueryChanReply {\n\n\t\t\treturn fmt.Errorf(\"received unexpected query reply \"+\n\t\t\t\t\"message %T\", msg)\n\t\t}\n\t\tmsgChan = g.gossipMsgs\n\n\tdefault:\n\t\tmsgChan = g.gossipMsgs\n\t}\n\n\tselect {\n\tcase msgChan <- msg:\n\tcase <-peerQuit:\n\tcase <-g.quit:\n\t}\n\n\treturn nil\n}\n\n// setSyncState sets the gossip syncer's state to the given state.",
      "length": 676,
      "tokens": 87,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) setSyncState(state syncerState) {",
      "content": "func (g *GossipSyncer) setSyncState(state syncerState) {\n\tatomic.StoreUint32(&g.state, uint32(state))\n}\n\n// syncState returns the current syncerState of the target GossipSyncer.",
      "length": 117,
      "tokens": 13,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) syncState() syncerState {",
      "content": "func (g *GossipSyncer) syncState() syncerState {\n\treturn syncerState(atomic.LoadUint32(&g.state))\n}\n\n// ResetSyncedSignal returns a channel that will be closed in order to serve as\n// a signal for when the GossipSyncer has reached its chansSynced state.",
      "length": 200,
      "tokens": 29,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) ResetSyncedSignal() chan struct{} {",
      "content": "func (g *GossipSyncer) ResetSyncedSignal() chan struct{} {\n\tg.Lock()\n\tdefer g.Unlock()\n\n\tsyncedSignal := make(chan struct{})\n\n\tsyncState := syncerState(atomic.LoadUint32(&g.state))\n\tif syncState == chansSynced {\n\t\tclose(syncedSignal)\n\t\treturn syncedSignal\n\t}\n\n\tg.syncedSignal = syncedSignal\n\treturn g.syncedSignal\n}\n\n// ProcessSyncTransition sends a request to the gossip syncer to transition its\n// sync type to a new one.\n//\n// NOTE: This can only be done once the gossip syncer has reached its final\n// chansSynced state.",
      "length": 446,
      "tokens": 63,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) ProcessSyncTransition(newSyncType SyncerType) error {",
      "content": "func (g *GossipSyncer) ProcessSyncTransition(newSyncType SyncerType) error {\n\terrChan := make(chan error, 1)\n\tselect {\n\tcase g.syncTransitionReqs <- &syncTransitionReq{\n\t\tnewSyncType: newSyncType,\n\t\terrChan:     errChan,\n\t}:\n\tcase <-time.After(syncTransitionTimeout):\n\t\treturn ErrSyncTransitionTimeout\n\tcase <-g.quit:\n\t\treturn ErrGossipSyncerExiting\n\t}\n\n\tselect {\n\tcase err := <-errChan:\n\t\treturn err\n\tcase <-g.quit:\n\t\treturn ErrGossipSyncerExiting\n\t}\n}\n\n// handleSyncTransition handles a new sync type transition request.\n//\n// NOTE: The gossip syncer might have another sync state as a result of this\n// transition.",
      "length": 517,
      "tokens": 66,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) handleSyncTransition(req *syncTransitionReq) error {",
      "content": "func (g *GossipSyncer) handleSyncTransition(req *syncTransitionReq) error {\n\t// Return early from any NOP sync transitions.\n\tsyncType := g.SyncType()\n\tif syncType == req.newSyncType {\n\t\treturn nil\n\t}\n\n\tlog.Debugf(\"GossipSyncer(%x): transitioning from %v to %v\",\n\t\tg.cfg.peerPub, syncType, req.newSyncType)\n\n\tvar (\n\t\tfirstTimestamp time.Time\n\t\ttimestampRange uint32\n\t)\n\n\tswitch req.newSyncType {\n\t// If an active sync has been requested, then we should resume receiving\n\t// new graph updates from the remote peer.\n\tcase ActiveSync, PinnedSync:\n\t\tfirstTimestamp = time.Now()\n\t\ttimestampRange = math.MaxUint32\n\n\t// If a PassiveSync transition has been requested, then we should no\n\t// longer receive any new updates from the remote peer. We can do this\n\t// by setting our update horizon to a range in the past ensuring no\n\t// graph updates match the timestamp range.\n\tcase PassiveSync:\n\t\tfirstTimestamp = zeroTimestamp\n\t\ttimestampRange = 0\n\n\tdefault:\n\t\treturn fmt.Errorf(\"unhandled sync transition %v\",\n\t\t\treq.newSyncType)\n\t}\n\n\terr := g.sendGossipTimestampRange(firstTimestamp, timestampRange)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to send local update horizon: %v\", err)\n\t}\n\n\tg.setSyncType(req.newSyncType)\n\n\treturn nil\n}\n\n// setSyncType sets the gossip syncer's sync type to the given type.",
      "length": 1176,
      "tokens": 166,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) setSyncType(syncType SyncerType) {",
      "content": "func (g *GossipSyncer) setSyncType(syncType SyncerType) {\n\tatomic.StoreUint32(&g.syncType, uint32(syncType))\n}\n\n// SyncType returns the current SyncerType of the target GossipSyncer.",
      "length": 121,
      "tokens": 13,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) SyncType() SyncerType {",
      "content": "func (g *GossipSyncer) SyncType() SyncerType {\n\treturn SyncerType(atomic.LoadUint32(&g.syncType))\n}\n\n// historicalSync sends a request to the gossip syncer to perofmr a historical\n// sync.\n//\n// NOTE: This can only be done once the gossip syncer has reached its final\n// chansSynced state.",
      "length": 235,
      "tokens": 37,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) historicalSync() error {",
      "content": "func (g *GossipSyncer) historicalSync() error {\n\tdone := make(chan struct{})\n\n\tselect {\n\tcase g.historicalSyncReqs <- &historicalSyncReq{\n\t\tdoneChan: done,\n\t}:\n\tcase <-time.After(syncTransitionTimeout):\n\t\treturn ErrSyncTransitionTimeout\n\tcase <-g.quit:\n\t\treturn ErrGossiperShuttingDown\n\t}\n\n\tselect {\n\tcase <-done:\n\t\treturn nil\n\tcase <-g.quit:\n\t\treturn ErrGossiperShuttingDown\n\t}\n}\n\n// handleHistoricalSync handles a request to the gossip syncer to perform a\n// historical sync.",
      "length": 408,
      "tokens": 49,
      "embedding": []
    },
    {
      "slug": "func (g *GossipSyncer) handleHistoricalSync(req *historicalSyncReq) {",
      "content": "func (g *GossipSyncer) handleHistoricalSync(req *historicalSyncReq) {\n\t// We'll go back to our initial syncingChans state in order to request\n\t// the remote peer to give us all of the channel IDs they know of\n\t// starting from the genesis block.\n\tg.genHistoricalChanRangeQuery = true\n\tg.setSyncState(syncingChans)\n\tclose(req.doneChan)\n}\n",
      "length": 260,
      "tokens": 40,
      "embedding": []
    }
  ]
}