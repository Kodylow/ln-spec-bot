{
  "filepath": "../implementations/go/lnd/channeldb/migration_01_to_11/graph.go",
  "package": "migration_01_to_11",
  "sections": [
    {
      "slug": "type ChannelGraph struct {",
      "content": "type ChannelGraph struct {\n\tdb *DB\n}\n\n// newChannelGraph allocates a new ChannelGraph backed by a DB instance. The\n// returned instance has its own unique reject cache and channel cache.",
      "length": 155,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func newChannelGraph(db *DB, rejectCacheSize, chanCacheSize int) *ChannelGraph {",
      "content": "func newChannelGraph(db *DB, rejectCacheSize, chanCacheSize int) *ChannelGraph {\n\treturn &ChannelGraph{\n\t\tdb: db,\n\t}\n}\n\n// SourceNode returns the source node of the graph. The source node is treated\n// as the center node within a star-graph. This method may be used to kick off\n// a path finding algorithm in order to explore the reachability of another\n// node based off the source node.",
      "length": 299,
      "tokens": 56,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) SourceNode() (*LightningNode, error) {",
      "content": "func (c *ChannelGraph) SourceNode() (*LightningNode, error) {\n\tvar source *LightningNode\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\tnode, err := c.sourceNode(nodes)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsource = node\n\n\t\treturn nil\n\t}, func() {\n\t\tsource = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn source, nil\n}\n\n// sourceNode uses an existing database transaction and returns the source node\n// of the graph. The source node is treated as the center node within a\n// star-graph. This method may be used to kick off a path finding algorithm in\n// order to explore the reachability of another node based off the source node.",
      "length": 738,
      "tokens": 130,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) sourceNode(nodes kvdb.RBucket) (*LightningNode, error) {",
      "content": "func (c *ChannelGraph) sourceNode(nodes kvdb.RBucket) (*LightningNode, error) {\n\tselfPub := nodes.Get(sourceKey)\n\tif selfPub == nil {\n\t\treturn nil, ErrSourceNodeNotSet\n\t}\n\n\t// With the pubKey of the source node retrieved, we're able to\n\t// fetch the full node information.\n\tnode, err := fetchLightningNode(nodes, selfPub)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnode.db = c.db\n\n\treturn &node, nil\n}\n\n// SetSourceNode sets the source node within the graph database. The source\n// node is to be used as the center of a star-graph within path finding\n// algorithms.",
      "length": 463,
      "tokens": 80,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) SetSourceNode(node *LightningNode) error {",
      "content": "func (c *ChannelGraph) SetSourceNode(node *LightningNode) error {\n\tnodePubBytes := node.PubKeyBytes[:]\n\n\treturn kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Next we create the mapping from source to the targeted\n\t\t// public key.\n\t\tif err := nodes.Put(sourceKey, nodePubBytes); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Finally, we commit the information of the lightning node\n\t\t// itself.\n\t\treturn addLightningNode(tx, node)\n\t}, func() {})\n}\n",
      "length": 540,
      "tokens": 82,
      "embedding": []
    },
    {
      "slug": "func addLightningNode(tx kvdb.RwTx, node *LightningNode) error {",
      "content": "func addLightningNode(tx kvdb.RwTx, node *LightningNode) error {\n\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\taliases, err := nodes.CreateBucketIfNotExists(aliasIndexBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tupdateIndex, err := nodes.CreateBucketIfNotExists(\n\t\tnodeUpdateIndexBucket,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn putLightningNode(nodes, aliases, updateIndex, node)\n}\n\n// updateEdgePolicy attempts to update an edge's policy within the relevant\n// buckets using an existing database transaction. The returned boolean will be\n// true if the updated policy belongs to node1, and false if the policy belonged\n// to node2.",
      "length": 587,
      "tokens": 85,
      "embedding": []
    },
    {
      "slug": "func updateEdgePolicy(tx kvdb.RwTx, edge *ChannelEdgePolicy) (bool, error) {",
      "content": "func updateEdgePolicy(tx kvdb.RwTx, edge *ChannelEdgePolicy) (bool, error) {\n\tedges, err := tx.CreateTopLevelBucket(edgeBucket)\n\tif err != nil {\n\t\treturn false, ErrEdgeNotFound\n\n\t}\n\tedgeIndex := edges.NestedReadWriteBucket(edgeIndexBucket)\n\tif edgeIndex == nil {\n\t\treturn false, ErrEdgeNotFound\n\t}\n\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t// Create the channelID key be converting the channel ID\n\t// integer into a byte slice.\n\tvar chanID [8]byte\n\tbyteOrder.PutUint64(chanID[:], edge.ChannelID)\n\n\t// With the channel ID, we then fetch the value storing the two\n\t// nodes which connect this channel edge.\n\tnodeInfo := edgeIndex.Get(chanID[:])\n\tif nodeInfo == nil {\n\t\treturn false, ErrEdgeNotFound\n\t}\n\n\t// Depending on the flags value passed above, either the first\n\t// or second edge policy is being updated.\n\tvar fromNode, toNode []byte\n\tvar isUpdate1 bool\n\tif edge.ChannelFlags&lnwire.ChanUpdateDirection == 0 {\n\t\tfromNode = nodeInfo[:33]\n\t\ttoNode = nodeInfo[33:66]\n\t\tisUpdate1 = true\n\t} else {\n\t\tfromNode = nodeInfo[33:66]\n\t\ttoNode = nodeInfo[:33]\n\t\tisUpdate1 = false\n\t}\n\n\t// Finally, with the direction of the edge being updated\n\t// identified, we update the on-disk edge representation.\n\terr = putChanEdgePolicy(edges, nodes, edge, fromNode, toNode)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn isUpdate1, nil\n}\n\n// LightningNode represents an individual vertex/node within the channel graph.\n// A node is connected to other nodes by one or more channel edges emanating\n// from it. As the graph is directed, a node will also have an incoming edge\n// attached to it for each outgoing edge.",
      "length": 1518,
      "tokens": 231,
      "embedding": []
    },
    {
      "slug": "type LightningNode struct {",
      "content": "type LightningNode struct {\n\t// PubKeyBytes is the raw bytes of the public key of the target node.\n\tPubKeyBytes [33]byte\n\tpubKey      *btcec.PublicKey\n\n\t// HaveNodeAnnouncement indicates whether we received a node\n\t// announcement for this particular node. If true, the remaining fields\n\t// will be set, if false only the PubKey is known for this node.\n\tHaveNodeAnnouncement bool\n\n\t// LastUpdate is the last time the vertex information for this node has\n\t// been updated.\n\tLastUpdate time.Time\n\n\t// Address is the TCP address this node is reachable over.\n\tAddresses []net.Addr\n\n\t// Color is the selected color for the node.\n\tColor color.RGBA\n\n\t// Alias is a nick-name for the node. The alias can be used to confirm\n\t// a node's identity or to serve as a short ID for an address book.\n\tAlias string\n\n\t// AuthSigBytes is the raw signature under the advertised public key\n\t// which serves to authenticate the attributes announced by this node.\n\tAuthSigBytes []byte\n\n\t// Features is the list of protocol features supported by this node.\n\tFeatures *lnwire.FeatureVector\n\n\t// ExtraOpaqueData is the set of data that was appended to this\n\t// message, some of which we may not actually know how to iterate or\n\t// parse. By holding onto this data, we ensure that we're able to\n\t// properly validate the set of signatures that cover these new fields,\n\t// and ensure we're able to make upgrades to the network in a forwards\n\t// compatible manner.\n\tExtraOpaqueData []byte\n\n\tdb *DB\n\n\t// TODO(roasbeef): discovery will need storage to keep it's last IP\n\t// address and re-announce if interface changes?\n\n\t// TODO(roasbeef): add update method and fetch?\n}\n\n// PubKey is the node's long-term identity public key. This key will be used to\n// authenticated any advertisements/updates sent by the node.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the pubkey if absolutely necessary.",
      "length": 1846,
      "tokens": 311,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) PubKey() (*btcec.PublicKey, error) {",
      "content": "func (l *LightningNode) PubKey() (*btcec.PublicKey, error) {\n\tif l.pubKey != nil {\n\t\treturn l.pubKey, nil\n\t}\n\n\tkey, err := btcec.ParsePubKey(l.PubKeyBytes[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tl.pubKey = key\n\n\treturn key, nil\n}\n\n// ChannelEdgeInfo represents a fully authenticated channel along with all its\n// unique attributes. Once an authenticated channel announcement has been\n// processed on the network, then an instance of ChannelEdgeInfo encapsulating\n// the channels attributes is stored. The other portions relevant to routing\n// policy of a channel are stored within a ChannelEdgePolicy for each direction\n// of the channel.",
      "length": 562,
      "tokens": 90,
      "embedding": []
    },
    {
      "slug": "type ChannelEdgeInfo struct {",
      "content": "type ChannelEdgeInfo struct {\n\t// ChannelID is the unique channel ID for the channel. The first 3\n\t// bytes are the block height, the next 3 the index within the block,\n\t// and the last 2 bytes are the output index for the channel.\n\tChannelID uint64\n\n\t// ChainHash is the hash that uniquely identifies the chain that this\n\t// channel was opened within.\n\t//\n\t// TODO(roasbeef): need to modify db keying for multi-chain\n\t//  * must add chain hash to prefix as well\n\tChainHash chainhash.Hash\n\n\t// NodeKey1Bytes is the raw public key of the first node.\n\tNodeKey1Bytes [33]byte\n\n\t// NodeKey2Bytes is the raw public key of the first node.\n\tNodeKey2Bytes [33]byte\n\n\t// BitcoinKey1Bytes is the raw public key of the first node.\n\tBitcoinKey1Bytes [33]byte\n\n\t// BitcoinKey2Bytes is the raw public key of the first node.\n\tBitcoinKey2Bytes [33]byte\n\n\t// Features is an opaque byte slice that encodes the set of channel\n\t// specific features that this channel edge supports.\n\tFeatures []byte\n\n\t// AuthProof is the authentication proof for this channel. This proof\n\t// contains a set of signatures binding four identities, which attests\n\t// to the legitimacy of the advertised channel.\n\tAuthProof *ChannelAuthProof\n\n\t// ChannelPoint is the funding outpoint of the channel. This can be\n\t// used to uniquely identify the channel within the channel graph.\n\tChannelPoint wire.OutPoint\n\n\t// Capacity is the total capacity of the channel, this is determined by\n\t// the value output in the outpoint that created this channel.\n\tCapacity btcutil.Amount\n\n\t// ExtraOpaqueData is the set of data that was appended to this\n\t// message, some of which we may not actually know how to iterate or\n\t// parse. By holding onto this data, we ensure that we're able to\n\t// properly validate the set of signatures that cover these new fields,\n\t// and ensure we're able to make upgrades to the network in a forwards\n\t// compatible manner.\n\tExtraOpaqueData []byte\n}\n\n// ChannelAuthProof is the authentication proof (the signature portion) for a\n// channel. Using the four signatures contained in the struct, and some\n// auxiliary knowledge (the funding script, node identities, and outpoint) nodes\n// on the network are able to validate the authenticity and existence of a\n// channel. Each of these signatures signs the following digest: chanID ||\n// nodeID1 || nodeID2 || bitcoinKey1|| bitcoinKey2 || 2-byte-feature-len ||\n// features.",
      "length": 2311,
      "tokens": 382,
      "embedding": []
    },
    {
      "slug": "type ChannelAuthProof struct {",
      "content": "type ChannelAuthProof struct {\n\t// NodeSig1Bytes are the raw bytes of the first node signature encoded\n\t// in DER format.\n\tNodeSig1Bytes []byte\n\n\t// NodeSig2Bytes are the raw bytes of the second node signature\n\t// encoded in DER format.\n\tNodeSig2Bytes []byte\n\n\t// BitcoinSig1Bytes are the raw bytes of the first bitcoin signature\n\t// encoded in DER format.\n\tBitcoinSig1Bytes []byte\n\n\t// BitcoinSig2Bytes are the raw bytes of the second bitcoin signature\n\t// encoded in DER format.\n\tBitcoinSig2Bytes []byte\n}\n\n// IsEmpty check is the authentication proof is empty Proof is empty if at\n// least one of the signatures are equal to nil.",
      "length": 583,
      "tokens": 97,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelAuthProof) IsEmpty() bool {",
      "content": "func (c *ChannelAuthProof) IsEmpty() bool {\n\treturn len(c.NodeSig1Bytes) == 0 ||\n\t\tlen(c.NodeSig2Bytes) == 0 ||\n\t\tlen(c.BitcoinSig1Bytes) == 0 ||\n\t\tlen(c.BitcoinSig2Bytes) == 0\n}\n\n// ChannelEdgePolicy represents a *directed* edge within the channel graph. For\n// each channel in the database, there are two distinct edges: one for each\n// possible direction of travel along the channel. The edges themselves hold\n// information concerning fees, and minimum time-lock information which is\n// utilized during path finding.",
      "length": 466,
      "tokens": 69,
      "embedding": []
    },
    {
      "slug": "type ChannelEdgePolicy struct {",
      "content": "type ChannelEdgePolicy struct {\n\t// SigBytes is the raw bytes of the signature of the channel edge\n\t// policy. We'll only parse these if the caller needs to access the\n\t// signature for validation purposes. Do not set SigBytes directly, but\n\t// use SetSigBytes instead to make sure that the cache is invalidated.\n\tSigBytes []byte\n\n\t// ChannelID is the unique channel ID for the channel. The first 3\n\t// bytes are the block height, the next 3 the index within the block,\n\t// and the last 2 bytes are the output index for the channel.\n\tChannelID uint64\n\n\t// LastUpdate is the last time an authenticated edge for this channel\n\t// was received.\n\tLastUpdate time.Time\n\n\t// MessageFlags is a bitfield which indicates the presence of optional\n\t// fields (like max_htlc) in the policy.\n\tMessageFlags lnwire.ChanUpdateMsgFlags\n\n\t// ChannelFlags is a bitfield which signals the capabilities of the\n\t// channel as well as the directed edge this update applies to.\n\tChannelFlags lnwire.ChanUpdateChanFlags\n\n\t// TimeLockDelta is the number of blocks this node will subtract from\n\t// the expiry of an incoming HTLC. This value expresses the time buffer\n\t// the node would like to HTLC exchanges.\n\tTimeLockDelta uint16\n\n\t// MinHTLC is the smallest value HTLC this node will accept, expressed\n\t// in millisatoshi.\n\tMinHTLC lnwire.MilliSatoshi\n\n\t// MaxHTLC is the largest value HTLC this node will accept, expressed\n\t// in millisatoshi.\n\tMaxHTLC lnwire.MilliSatoshi\n\n\t// FeeBaseMSat is the base HTLC fee that will be charged for forwarding\n\t// ANY HTLC, expressed in mSAT's.\n\tFeeBaseMSat lnwire.MilliSatoshi\n\n\t// FeeProportionalMillionths is the rate that the node will charge for\n\t// HTLCs for each millionth of a satoshi forwarded.\n\tFeeProportionalMillionths lnwire.MilliSatoshi\n\n\t// Node is the LightningNode that this directed edge leads to. Using\n\t// this pointer the channel graph can further be traversed.\n\tNode *LightningNode\n\n\t// ExtraOpaqueData is the set of data that was appended to this\n\t// message, some of which we may not actually know how to iterate or\n\t// parse. By holding onto this data, we ensure that we're able to\n\t// properly validate the set of signatures that cover these new fields,\n\t// and ensure we're able to make upgrades to the network in a forwards\n\t// compatible manner.\n\tExtraOpaqueData []byte\n}\n\n// IsDisabled determines whether the edge has the disabled bit set.",
      "length": 2293,
      "tokens": 373,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgePolicy) IsDisabled() bool {",
      "content": "func (c *ChannelEdgePolicy) IsDisabled() bool {\n\treturn c.ChannelFlags&lnwire.ChanUpdateDisabled ==\n\t\tlnwire.ChanUpdateDisabled\n}\n",
      "length": 79,
      "tokens": 5,
      "embedding": []
    },
    {
      "slug": "func putLightningNode(nodeBucket kvdb.RwBucket, aliasBucket kvdb.RwBucket,",
      "content": "func putLightningNode(nodeBucket kvdb.RwBucket, aliasBucket kvdb.RwBucket,\n\tupdateIndex kvdb.RwBucket, node *LightningNode) error {\n\n\tvar (\n\t\tscratch [16]byte\n\t\tb       bytes.Buffer\n\t)\n\n\tpub, err := node.PubKey()\n\tif err != nil {\n\t\treturn err\n\t}\n\tnodePub := pub.SerializeCompressed()\n\n\t// If the node has the update time set, write it, else write 0.\n\tupdateUnix := uint64(0)\n\tif node.LastUpdate.Unix() > 0 {\n\t\tupdateUnix = uint64(node.LastUpdate.Unix())\n\t}\n\n\tbyteOrder.PutUint64(scratch[:8], updateUnix)\n\tif _, err := b.Write(scratch[:8]); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := b.Write(nodePub); err != nil {\n\t\treturn err\n\t}\n\n\t// If we got a node announcement for this node, we will have the rest\n\t// of the data available. If not we don't have more data to write.\n\tif !node.HaveNodeAnnouncement {\n\t\t// Write HaveNodeAnnouncement=0.\n\t\tbyteOrder.PutUint16(scratch[:2], 0)\n\t\tif _, err := b.Write(scratch[:2]); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn nodeBucket.Put(nodePub, b.Bytes())\n\t}\n\n\t// Write HaveNodeAnnouncement=1.\n\tbyteOrder.PutUint16(scratch[:2], 1)\n\tif _, err := b.Write(scratch[:2]); err != nil {\n\t\treturn err\n\t}\n\n\tif err := binary.Write(&b, byteOrder, node.Color.R); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(&b, byteOrder, node.Color.G); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(&b, byteOrder, node.Color.B); err != nil {\n\t\treturn err\n\t}\n\n\tif err := wire.WriteVarString(&b, 0, node.Alias); err != nil {\n\t\treturn err\n\t}\n\n\tif err := node.Features.Encode(&b); err != nil {\n\t\treturn err\n\t}\n\n\tnumAddresses := uint16(len(node.Addresses))\n\tbyteOrder.PutUint16(scratch[:2], numAddresses)\n\tif _, err := b.Write(scratch[:2]); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, address := range node.Addresses {\n\t\tif err := serializeAddr(&b, address); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tsigLen := len(node.AuthSigBytes)\n\tif sigLen > 80 {\n\t\treturn fmt.Errorf(\"max sig len allowed is 80, had %v\",\n\t\t\tsigLen)\n\t}\n\n\terr = wire.WriteVarBytes(&b, 0, node.AuthSigBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(node.ExtraOpaqueData) > MaxAllowedExtraOpaqueBytes {\n\t\treturn ErrTooManyExtraOpaqueBytes(len(node.ExtraOpaqueData))\n\t}\n\terr = wire.WriteVarBytes(&b, 0, node.ExtraOpaqueData)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := aliasBucket.Put(nodePub, []byte(node.Alias)); err != nil {\n\t\treturn err\n\t}\n\n\t// With the alias bucket updated, we'll now update the index that\n\t// tracks the time series of node updates.\n\tvar indexKey [8 + 33]byte\n\tbyteOrder.PutUint64(indexKey[:8], updateUnix)\n\tcopy(indexKey[8:], nodePub)\n\n\t// If there was already an old index entry for this node, then we'll\n\t// delete the old one before we write the new entry.\n\tif nodeBytes := nodeBucket.Get(nodePub); nodeBytes != nil {\n\t\t// Extract out the old update time to we can reconstruct the\n\t\t// prior index key to delete it from the index.\n\t\toldUpdateTime := nodeBytes[:8]\n\n\t\tvar oldIndexKey [8 + 33]byte\n\t\tcopy(oldIndexKey[:8], oldUpdateTime)\n\t\tcopy(oldIndexKey[8:], nodePub)\n\n\t\tif err := updateIndex.Delete(oldIndexKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := updateIndex.Put(indexKey[:], nil); err != nil {\n\t\treturn err\n\t}\n\n\treturn nodeBucket.Put(nodePub, b.Bytes())\n}\n",
      "length": 2971,
      "tokens": 439,
      "embedding": []
    },
    {
      "slug": "func fetchLightningNode(nodeBucket kvdb.RBucket,",
      "content": "func fetchLightningNode(nodeBucket kvdb.RBucket,\n\tnodePub []byte) (LightningNode, error) {\n\n\tnodeBytes := nodeBucket.Get(nodePub)\n\tif nodeBytes == nil {\n\t\treturn LightningNode{}, ErrGraphNodeNotFound\n\t}\n\n\tnodeReader := bytes.NewReader(nodeBytes)\n\treturn deserializeLightningNode(nodeReader)\n}\n",
      "length": 234,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func deserializeLightningNode(r io.Reader) (LightningNode, error) {",
      "content": "func deserializeLightningNode(r io.Reader) (LightningNode, error) {\n\tvar (\n\t\tnode    LightningNode\n\t\tscratch [8]byte\n\t\terr     error\n\t)\n\n\tif _, err := r.Read(scratch[:]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tunix := int64(byteOrder.Uint64(scratch[:]))\n\tnode.LastUpdate = time.Unix(unix, 0)\n\n\tif _, err := io.ReadFull(r, node.PubKeyBytes[:]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tif _, err := r.Read(scratch[:2]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\thasNodeAnn := byteOrder.Uint16(scratch[:2])\n\tif hasNodeAnn == 1 {\n\t\tnode.HaveNodeAnnouncement = true\n\t} else {\n\t\tnode.HaveNodeAnnouncement = false\n\t}\n\n\t// The rest of the data is optional, and will only be there if we got a node\n\t// announcement for this node.\n\tif !node.HaveNodeAnnouncement {\n\t\treturn node, nil\n\t}\n\n\t// We did get a node announcement for this node, so we'll have the rest\n\t// of the data available.\n\tif err := binary.Read(r, byteOrder, &node.Color.R); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &node.Color.G); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &node.Color.B); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tnode.Alias, err = wire.ReadVarString(r, 0)\n\tif err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tfv := lnwire.NewFeatureVector(nil, nil)\n\terr = fv.Decode(r)\n\tif err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tnode.Features = fv\n\n\tif _, err := r.Read(scratch[:2]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tnumAddresses := int(byteOrder.Uint16(scratch[:2]))\n\n\tvar addresses []net.Addr\n\tfor i := 0; i < numAddresses; i++ {\n\t\taddress, err := deserializeAddr(r)\n\t\tif err != nil {\n\t\t\treturn LightningNode{}, err\n\t\t}\n\t\taddresses = append(addresses, address)\n\t}\n\tnode.Addresses = addresses\n\n\tnode.AuthSigBytes, err = wire.ReadVarBytes(r, 0, 80, \"sig\")\n\tif err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\t// We'll try and see if there are any opaque bytes left, if not, then\n\t// we'll ignore the EOF error and return the node as is.\n\tnode.ExtraOpaqueData, err = wire.ReadVarBytes(\n\t\tr, 0, MaxAllowedExtraOpaqueBytes, \"blob\",\n\t)\n\tswitch {\n\tcase err == io.ErrUnexpectedEOF:\n\tcase err == io.EOF:\n\tcase err != nil:\n\t\treturn LightningNode{}, err\n\t}\n\n\treturn node, nil\n}\n",
      "length": 2098,
      "tokens": 322,
      "embedding": []
    },
    {
      "slug": "func deserializeChanEdgeInfo(r io.Reader) (ChannelEdgeInfo, error) {",
      "content": "func deserializeChanEdgeInfo(r io.Reader) (ChannelEdgeInfo, error) {\n\tvar (\n\t\terr      error\n\t\tedgeInfo ChannelEdgeInfo\n\t)\n\n\tif _, err := io.ReadFull(r, edgeInfo.NodeKey1Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif _, err := io.ReadFull(r, edgeInfo.NodeKey2Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif _, err := io.ReadFull(r, edgeInfo.BitcoinKey1Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif _, err := io.ReadFull(r, edgeInfo.BitcoinKey2Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tedgeInfo.Features, err = wire.ReadVarBytes(r, 0, 900, \"features\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tproof := &ChannelAuthProof{}\n\n\tproof.NodeSig1Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tproof.NodeSig2Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tproof.BitcoinSig1Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tproof.BitcoinSig2Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tif !proof.IsEmpty() {\n\t\tedgeInfo.AuthProof = proof\n\t}\n\n\tedgeInfo.ChannelPoint = wire.OutPoint{}\n\tif err := ReadOutpoint(r, &edgeInfo.ChannelPoint); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edgeInfo.Capacity); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edgeInfo.ChannelID); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tif _, err := io.ReadFull(r, edgeInfo.ChainHash[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\t// We'll try and see if there are any opaque bytes left, if not, then\n\t// we'll ignore the EOF error and return the edge as is.\n\tedgeInfo.ExtraOpaqueData, err = wire.ReadVarBytes(\n\t\tr, 0, MaxAllowedExtraOpaqueBytes, \"blob\",\n\t)\n\tswitch {\n\tcase err == io.ErrUnexpectedEOF:\n\tcase err == io.EOF:\n\tcase err != nil:\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\treturn edgeInfo, nil\n}\n",
      "length": 1913,
      "tokens": 269,
      "embedding": []
    },
    {
      "slug": "func putChanEdgePolicy(edges, nodes kvdb.RwBucket, edge *ChannelEdgePolicy,",
      "content": "func putChanEdgePolicy(edges, nodes kvdb.RwBucket, edge *ChannelEdgePolicy,\n\tfrom, to []byte) error {\n\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[:], from)\n\tbyteOrder.PutUint64(edgeKey[33:], edge.ChannelID)\n\n\tvar b bytes.Buffer\n\tif err := serializeChanEdgePolicy(&b, edge, to); err != nil {\n\t\treturn err\n\t}\n\n\t// Before we write out the new edge, we'll create a new entry in the\n\t// update index in order to keep it fresh.\n\tupdateUnix := uint64(edge.LastUpdate.Unix())\n\tvar indexKey [8 + 8]byte\n\tbyteOrder.PutUint64(indexKey[:8], updateUnix)\n\tbyteOrder.PutUint64(indexKey[8:], edge.ChannelID)\n\n\tupdateIndex, err := edges.CreateBucketIfNotExists(edgeUpdateIndexBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If there was already an entry for this edge, then we'll need to\n\t// delete the old one to ensure we don't leave around any after-images.\n\t// An unknown policy value does not have a update time recorded, so\n\t// it also does not need to be removed.\n\tif edgeBytes := edges.Get(edgeKey[:]); edgeBytes != nil &&\n\t\t!bytes.Equal(edgeBytes[:], unknownPolicy) {\n\n\t\t// In order to delete the old entry, we'll need to obtain the\n\t\t// *prior* update time in order to delete it. To do this, we'll\n\t\t// need to deserialize the existing policy within the database\n\t\t// (now outdated by the new one), and delete its corresponding\n\t\t// entry within the update index. We'll ignore any\n\t\t// ErrEdgePolicyOptionalFieldNotFound error, as we only need\n\t\t// the channel ID and update time to delete the entry.\n\t\t// TODO(halseth): get rid of these invalid policies in a\n\t\t// migration.\n\t\toldEdgePolicy, err := deserializeChanEdgePolicy(\n\t\t\tbytes.NewReader(edgeBytes), nodes,\n\t\t)\n\t\tif err != nil && err != ErrEdgePolicyOptionalFieldNotFound {\n\t\t\treturn err\n\t\t}\n\n\t\toldUpdateTime := uint64(oldEdgePolicy.LastUpdate.Unix())\n\n\t\tvar oldIndexKey [8 + 8]byte\n\t\tbyteOrder.PutUint64(oldIndexKey[:8], oldUpdateTime)\n\t\tbyteOrder.PutUint64(oldIndexKey[8:], edge.ChannelID)\n\n\t\tif err := updateIndex.Delete(oldIndexKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := updateIndex.Put(indexKey[:], nil); err != nil {\n\t\treturn err\n\t}\n\n\tupdateEdgePolicyDisabledIndex(\n\t\tedges, edge.ChannelID,\n\t\tedge.ChannelFlags&lnwire.ChanUpdateDirection > 0,\n\t\tedge.IsDisabled(),\n\t)\n\n\treturn edges.Put(edgeKey[:], b.Bytes()[:])\n}\n\n// updateEdgePolicyDisabledIndex is used to update the disabledEdgePolicyIndex\n// bucket by either add a new disabled ChannelEdgePolicy or remove an existing\n// one.\n// The direction represents the direction of the edge and disabled is used for\n// deciding whether to remove or add an entry to the bucket.\n// In general a channel is disabled if two entries for the same chanID exist\n// in this bucket.\n// Maintaining the bucket this way allows a fast retrieval of disabled\n// channels, for example when prune is needed.",
      "length": 2644,
      "tokens": 379,
      "embedding": []
    },
    {
      "slug": "func updateEdgePolicyDisabledIndex(edges kvdb.RwBucket, chanID uint64,",
      "content": "func updateEdgePolicyDisabledIndex(edges kvdb.RwBucket, chanID uint64,\n\tdirection bool, disabled bool) error {\n\n\tvar disabledEdgeKey [8 + 1]byte\n\tbyteOrder.PutUint64(disabledEdgeKey[0:], chanID)\n\tif direction {\n\t\tdisabledEdgeKey[8] = 1\n\t}\n\n\tdisabledEdgePolicyIndex, err := edges.CreateBucketIfNotExists(\n\t\tdisabledEdgePolicyBucket,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif disabled {\n\t\treturn disabledEdgePolicyIndex.Put(disabledEdgeKey[:], []byte{})\n\t}\n\n\treturn disabledEdgePolicyIndex.Delete(disabledEdgeKey[:])\n}\n\n// putChanEdgePolicyUnknown marks the edge policy as unknown\n// in the edges bucket.",
      "length": 507,
      "tokens": 57,
      "embedding": []
    },
    {
      "slug": "func putChanEdgePolicyUnknown(edges kvdb.RwBucket, channelID uint64,",
      "content": "func putChanEdgePolicyUnknown(edges kvdb.RwBucket, channelID uint64,\n\tfrom []byte) error {\n\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[:], from)\n\tbyteOrder.PutUint64(edgeKey[33:], channelID)\n\n\tif edges.Get(edgeKey[:]) != nil {\n\t\treturn fmt.Errorf(\"Cannot write unknown policy for channel %v \"+\n\t\t\t\" when there is already a policy present\", channelID)\n\t}\n\n\treturn edges.Put(edgeKey[:], unknownPolicy)\n}\n",
      "length": 317,
      "tokens": 41,
      "embedding": []
    },
    {
      "slug": "func fetchChanEdgePolicy(edges kvdb.RBucket, chanID []byte,",
      "content": "func fetchChanEdgePolicy(edges kvdb.RBucket, chanID []byte,\n\tnodePub []byte, nodes kvdb.RBucket) (*ChannelEdgePolicy, error) {\n\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[:], nodePub)\n\tcopy(edgeKey[33:], chanID[:])\n\n\tedgeBytes := edges.Get(edgeKey[:])\n\tif edgeBytes == nil {\n\t\treturn nil, ErrEdgeNotFound\n\t}\n\n\t// No need to deserialize unknown policy.\n\tif bytes.Equal(edgeBytes[:], unknownPolicy) {\n\t\treturn nil, nil\n\t}\n\n\tedgeReader := bytes.NewReader(edgeBytes)\n\n\tep, err := deserializeChanEdgePolicy(edgeReader, nodes)\n\tswitch {\n\t// If the db policy was missing an expected optional field, we return\n\t// nil as if the policy was unknown.\n\tcase err == ErrEdgePolicyOptionalFieldNotFound:\n\t\treturn nil, nil\n\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\treturn ep, nil\n}\n",
      "length": 672,
      "tokens": 93,
      "embedding": []
    },
    {
      "slug": "func serializeChanEdgePolicy(w io.Writer, edge *ChannelEdgePolicy,",
      "content": "func serializeChanEdgePolicy(w io.Writer, edge *ChannelEdgePolicy,\n\tto []byte) error {\n\n\terr := wire.WriteVarBytes(w, 0, edge.SigBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := binary.Write(w, byteOrder, edge.ChannelID); err != nil {\n\t\treturn err\n\t}\n\n\tvar scratch [8]byte\n\tupdateUnix := uint64(edge.LastUpdate.Unix())\n\tbyteOrder.PutUint64(scratch[:], updateUnix)\n\tif _, err := w.Write(scratch[:]); err != nil {\n\t\treturn err\n\t}\n\n\tif err := binary.Write(w, byteOrder, edge.MessageFlags); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, edge.ChannelFlags); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, edge.TimeLockDelta); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, uint64(edge.MinHTLC)); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, uint64(edge.FeeBaseMSat)); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, uint64(edge.FeeProportionalMillionths)); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := w.Write(to); err != nil {\n\t\treturn err\n\t}\n\n\t// If the max_htlc field is present, we write it. To be compatible with\n\t// older versions that wasn't aware of this field, we write it as part\n\t// of the opaque data.\n\t// TODO(halseth): clean up when moving to TLV.\n\tvar opaqueBuf bytes.Buffer\n\tif edge.MessageFlags.HasMaxHtlc() {\n\t\terr := binary.Write(&opaqueBuf, byteOrder, uint64(edge.MaxHTLC))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif len(edge.ExtraOpaqueData) > MaxAllowedExtraOpaqueBytes {\n\t\treturn ErrTooManyExtraOpaqueBytes(len(edge.ExtraOpaqueData))\n\t}\n\tif _, err := opaqueBuf.Write(edge.ExtraOpaqueData); err != nil {\n\t\treturn err\n\t}\n\n\tif err := wire.WriteVarBytes(w, 0, opaqueBuf.Bytes()); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
      "length": 1610,
      "tokens": 237,
      "embedding": []
    },
    {
      "slug": "func deserializeChanEdgePolicy(r io.Reader,",
      "content": "func deserializeChanEdgePolicy(r io.Reader,\n\tnodes kvdb.RBucket) (*ChannelEdgePolicy, error) {\n\n\tedge := &ChannelEdgePolicy{}\n\n\tvar err error\n\tedge.SigBytes, err = wire.ReadVarBytes(r, 0, 80, \"sig\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := binary.Read(r, byteOrder, &edge.ChannelID); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar scratch [8]byte\n\tif _, err := r.Read(scratch[:]); err != nil {\n\t\treturn nil, err\n\t}\n\tunix := int64(byteOrder.Uint64(scratch[:]))\n\tedge.LastUpdate = time.Unix(unix, 0)\n\n\tif err := binary.Read(r, byteOrder, &edge.MessageFlags); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edge.ChannelFlags); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edge.TimeLockDelta); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar n uint64\n\tif err := binary.Read(r, byteOrder, &n); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.MinHTLC = lnwire.MilliSatoshi(n)\n\n\tif err := binary.Read(r, byteOrder, &n); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.FeeBaseMSat = lnwire.MilliSatoshi(n)\n\n\tif err := binary.Read(r, byteOrder, &n); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.FeeProportionalMillionths = lnwire.MilliSatoshi(n)\n\n\tvar pub [33]byte\n\tif _, err := r.Read(pub[:]); err != nil {\n\t\treturn nil, err\n\t}\n\n\tnode, err := fetchLightningNode(nodes, pub[:])\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to fetch node: %x, %v\",\n\t\t\tpub[:], err)\n\t}\n\tedge.Node = &node\n\n\t// We'll try and see if there are any opaque bytes left, if not, then\n\t// we'll ignore the EOF error and return the edge as is.\n\tedge.ExtraOpaqueData, err = wire.ReadVarBytes(\n\t\tr, 0, MaxAllowedExtraOpaqueBytes, \"blob\",\n\t)\n\tswitch {\n\tcase err == io.ErrUnexpectedEOF:\n\tcase err == io.EOF:\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\t// See if optional fields are present.\n\tif edge.MessageFlags.HasMaxHtlc() {\n\t\t// The max_htlc field should be at the beginning of the opaque\n\t\t// bytes.\n\t\topq := edge.ExtraOpaqueData\n\n\t\t// If the max_htlc field is not present, it might be old data\n\t\t// stored before this field was validated. We'll return the\n\t\t// edge along with an error.\n\t\tif len(opq) < 8 {\n\t\t\treturn edge, ErrEdgePolicyOptionalFieldNotFound\n\t\t}\n\n\t\tmaxHtlc := byteOrder.Uint64(opq[:8])\n\t\tedge.MaxHTLC = lnwire.MilliSatoshi(maxHtlc)\n\n\t\t// Exclude the parsed field from the rest of the opaque data.\n\t\tedge.ExtraOpaqueData = opq[8:]\n\t}\n\n\treturn edge, nil\n}\n",
      "length": 2224,
      "tokens": 345,
      "embedding": []
    }
  ]
}