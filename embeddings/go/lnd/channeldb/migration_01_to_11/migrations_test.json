{
  "filepath": "../implementations/go/lnd/channeldb/migration_01_to_11/migrations_test.go",
  "package": "migration_01_to_11",
  "sections": [
    {
      "slug": "func TestPaymentStatusesMigration(t *testing.T) {",
      "content": "func TestPaymentStatusesMigration(t *testing.T) {\n\tt.Parallel()\n\n\tfakePayment := makeFakePayment()\n\tpaymentHash := sha256.Sum256(fakePayment.PaymentPreimage[:])\n\n\t// Add fake payment to test database, verifying that it was created,\n\t// that we have only one payment, and its status is not \"Completed\".\n\tbeforeMigrationFunc := func(d *DB) {\n\t\tif err := d.addPayment(fakePayment); err != nil {\n\t\t\tt.Fatalf(\"unable to add payment: %v\", err)\n\t\t}\n\n\t\tpayments, err := d.fetchAllPayments()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch payments: %v\", err)\n\t\t}\n\n\t\tif len(payments) != 1 {\n\t\t\tt.Fatalf(\"wrong qty of paymets: expected 1, got %v\",\n\t\t\t\tlen(payments))\n\t\t}\n\n\t\tpaymentStatus, err := d.fetchPaymentStatus(paymentHash)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch payment status: %v\", err)\n\t\t}\n\n\t\t// We should receive default status if we have any in database.\n\t\tif paymentStatus != StatusUnknown {\n\t\t\tt.Fatalf(\"wrong payment status: expected %v, got %v\",\n\t\t\t\tStatusUnknown.String(), paymentStatus.String())\n\t\t}\n\n\t\t// Lastly, we'll add a locally-sourced circuit and\n\t\t// non-locally-sourced circuit to the circuit map. The\n\t\t// locally-sourced payment should end up with an InFlight\n\t\t// status, while the other should remain unchanged, which\n\t\t// defaults to Grounded.\n\t\terr = kvdb.Update(d, func(tx kvdb.RwTx) error {\n\t\t\tcircuits, err := tx.CreateTopLevelBucket(\n\t\t\t\t[]byte(\"circuit-adds\"),\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tgroundedKey := make([]byte, 16)\n\t\t\tbinary.BigEndian.PutUint64(groundedKey[:8], 1)\n\t\t\tbinary.BigEndian.PutUint64(groundedKey[8:], 1)\n\n\t\t\t// Generated using TestHalfCircuitSerialization with nil\n\t\t\t// ErrorEncrypter, which is the case for locally-sourced\n\t\t\t// payments. No payment status should end up being set\n\t\t\t// for this circuit, since the short channel id of the\n\t\t\t// key is non-zero (e.g., a forwarded circuit). This\n\t\t\t// will default it to Grounded.\n\t\t\tgroundedCircuit := []byte{\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x01,\n\t\t\t\t// start payment hash\n\t\t\t\t0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t// end payment hash\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x0f,\n\t\t\t\t0x42, 0x40, 0x00,\n\t\t\t}\n\n\t\t\terr = circuits.Put(groundedKey, groundedCircuit)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tinFlightKey := make([]byte, 16)\n\t\t\tbinary.BigEndian.PutUint64(inFlightKey[:8], 0)\n\t\t\tbinary.BigEndian.PutUint64(inFlightKey[8:], 1)\n\n\t\t\t// Generated using TestHalfCircuitSerialization with nil\n\t\t\t// ErrorEncrypter, which is not the case for forwarded\n\t\t\t// payments, but should have no impact on the\n\t\t\t// correctness of the test. The payment status for this\n\t\t\t// circuit should be set to InFlight, since the short\n\t\t\t// channel id in the key is 0 (sourceHop).\n\t\t\tinFlightCircuit := []byte{\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x01,\n\t\t\t\t// start payment hash\n\t\t\t\t0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t// end payment hash\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x0f,\n\t\t\t\t0x42, 0x40, 0x00,\n\t\t\t}\n\n\t\t\treturn circuits.Put(inFlightKey, inFlightCircuit)\n\t\t}, func() {})\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to add circuit map entry: %v\", err)\n\t\t}\n\t}\n\n\t// Verify that the created payment status is \"Completed\" for our one\n\t// fake payment.\n\tafterMigrationFunc := func(d *DB) {\n\t\t// Check that our completed payments were migrated.\n\t\tpaymentStatus, err := d.fetchPaymentStatus(paymentHash)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch payment status: %v\", err)\n\t\t}\n\n\t\tif paymentStatus != StatusSucceeded {\n\t\t\tt.Fatalf(\"wrong payment status: expected %v, got %v\",\n\t\t\t\tStatusSucceeded.String(), paymentStatus.String())\n\t\t}\n\n\t\tinFlightHash := [32]byte{\n\t\t\t0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t}\n\n\t\t// Check that the locally sourced payment was transitioned to\n\t\t// InFlight.\n\t\tpaymentStatus, err = d.fetchPaymentStatus(inFlightHash)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch payment status: %v\", err)\n\t\t}\n\n\t\tif paymentStatus != StatusInFlight {\n\t\t\tt.Fatalf(\"wrong payment status: expected %v, got %v\",\n\t\t\t\tStatusInFlight.String(), paymentStatus.String())\n\t\t}\n\n\t\tgroundedHash := [32]byte{\n\t\t\t0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t\t}\n\n\t\t// Check that non-locally sourced payments remain in the default\n\t\t// Grounded state.\n\t\tpaymentStatus, err = d.fetchPaymentStatus(groundedHash)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch payment status: %v\", err)\n\t\t}\n\n\t\tif paymentStatus != StatusUnknown {\n\t\t\tt.Fatalf(\"wrong payment status: expected %v, got %v\",\n\t\t\t\tStatusUnknown.String(), paymentStatus.String())\n\t\t}\n\t}\n\n\tapplyMigration(t,\n\t\tbeforeMigrationFunc,\n\t\tafterMigrationFunc,\n\t\tPaymentStatusesMigration,\n\t\tfalse)\n}\n\n// TestMigrateOptionalChannelCloseSummaryFields properly converts a\n// ChannelCloseSummary to the v7 format, where optional fields have their\n// presence indicated with boolean markers.",
      "length": 5531,
      "tokens": 762,
      "embedding": []
    },
    {
      "slug": "func TestMigrateOptionalChannelCloseSummaryFields(t *testing.T) {",
      "content": "func TestMigrateOptionalChannelCloseSummaryFields(t *testing.T) {\n\tt.Parallel()\n\n\tchanState, err := createTestChannelState(nil)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to create channel state: %v\", err)\n\t}\n\n\tvar chanPointBuf bytes.Buffer\n\terr = WriteOutpoint(&chanPointBuf, &chanState.FundingOutpoint)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to write outpoint: %v\", err)\n\t}\n\n\tchanID := chanPointBuf.Bytes()\n\n\ttestCases := []struct {\n\t\tcloseSummary     *ChannelCloseSummary\n\t\toldSerialization func(c *ChannelCloseSummary) []byte\n\t}{\n\t\t{\n\t\t\t// A close summary where none of the new fields are\n\t\t\t// set.\n\t\t\tcloseSummary: &ChannelCloseSummary{\n\t\t\t\tChanPoint:      chanState.FundingOutpoint,\n\t\t\t\tShortChanID:    chanState.ShortChanID(),\n\t\t\t\tChainHash:      chanState.ChainHash,\n\t\t\t\tClosingTXID:    testTx.TxHash(),\n\t\t\t\tCloseHeight:    100,\n\t\t\t\tRemotePub:      chanState.IdentityPub,\n\t\t\t\tCapacity:       chanState.Capacity,\n\t\t\t\tSettledBalance: btcutil.Amount(50000),\n\t\t\t\tCloseType:      RemoteForceClose,\n\t\t\t\tIsPending:      true,\n\n\t\t\t\t// The last fields will be unset.\n\t\t\t\tRemoteCurrentRevocation: nil,\n\t\t\t\tLocalChanConfig:         ChannelConfig{},\n\t\t\t\tRemoteNextRevocation:    nil,\n\t\t\t},\n\n\t\t\t// In the old format the last field written is the\n\t\t\t// IsPendingField. It should be converted by adding an\n\t\t\t// extra boolean marker at the end to indicate that the\n\t\t\t// remaining fields are not there.\n\t\t\toldSerialization: func(cs *ChannelCloseSummary) []byte {\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\terr := WriteElements(&buf, cs.ChanPoint,\n\t\t\t\t\tcs.ShortChanID, cs.ChainHash,\n\t\t\t\t\tcs.ClosingTXID, cs.CloseHeight,\n\t\t\t\t\tcs.RemotePub, cs.Capacity,\n\t\t\t\t\tcs.SettledBalance, cs.TimeLockedBalance,\n\t\t\t\t\tcs.CloseType, cs.IsPending,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\t// For the old format, these are all the fields\n\t\t\t\t// that are written.\n\t\t\t\treturn buf.Bytes()\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t// A close summary where the new fields are present,\n\t\t\t// but the optional RemoteNextRevocation field is not\n\t\t\t// set.\n\t\t\tcloseSummary: &ChannelCloseSummary{\n\t\t\t\tChanPoint:               chanState.FundingOutpoint,\n\t\t\t\tShortChanID:             chanState.ShortChanID(),\n\t\t\t\tChainHash:               chanState.ChainHash,\n\t\t\t\tClosingTXID:             testTx.TxHash(),\n\t\t\t\tCloseHeight:             100,\n\t\t\t\tRemotePub:               chanState.IdentityPub,\n\t\t\t\tCapacity:                chanState.Capacity,\n\t\t\t\tSettledBalance:          btcutil.Amount(50000),\n\t\t\t\tCloseType:               RemoteForceClose,\n\t\t\t\tIsPending:               true,\n\t\t\t\tRemoteCurrentRevocation: chanState.RemoteCurrentRevocation,\n\t\t\t\tLocalChanConfig:         chanState.LocalChanCfg,\n\n\t\t\t\t// RemoteNextRevocation is optional, and here\n\t\t\t\t// it is not set.\n\t\t\t\tRemoteNextRevocation: nil,\n\t\t\t},\n\n\t\t\t// In the old format the last field written is the\n\t\t\t// LocalChanConfig. This indicates that the optional\n\t\t\t// RemoteNextRevocation field is not present. It should\n\t\t\t// be converted by adding boolean markers for all these\n\t\t\t// fields.\n\t\t\toldSerialization: func(cs *ChannelCloseSummary) []byte {\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\terr := WriteElements(&buf, cs.ChanPoint,\n\t\t\t\t\tcs.ShortChanID, cs.ChainHash,\n\t\t\t\t\tcs.ClosingTXID, cs.CloseHeight,\n\t\t\t\t\tcs.RemotePub, cs.Capacity,\n\t\t\t\t\tcs.SettledBalance, cs.TimeLockedBalance,\n\t\t\t\t\tcs.CloseType, cs.IsPending,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\terr = WriteElements(&buf, cs.RemoteCurrentRevocation)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\terr = WriteChanConfig(&buf, &cs.LocalChanConfig)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\t// RemoteNextRevocation is not written.\n\t\t\t\treturn buf.Bytes()\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t// A close summary where all fields are present.\n\t\t\tcloseSummary: &ChannelCloseSummary{\n\t\t\t\tChanPoint:               chanState.FundingOutpoint,\n\t\t\t\tShortChanID:             chanState.ShortChanID(),\n\t\t\t\tChainHash:               chanState.ChainHash,\n\t\t\t\tClosingTXID:             testTx.TxHash(),\n\t\t\t\tCloseHeight:             100,\n\t\t\t\tRemotePub:               chanState.IdentityPub,\n\t\t\t\tCapacity:                chanState.Capacity,\n\t\t\t\tSettledBalance:          btcutil.Amount(50000),\n\t\t\t\tCloseType:               RemoteForceClose,\n\t\t\t\tIsPending:               true,\n\t\t\t\tRemoteCurrentRevocation: chanState.RemoteCurrentRevocation,\n\t\t\t\tLocalChanConfig:         chanState.LocalChanCfg,\n\n\t\t\t\t// RemoteNextRevocation is optional, and in\n\t\t\t\t// this case we set it.\n\t\t\t\tRemoteNextRevocation: chanState.RemoteNextRevocation,\n\t\t\t},\n\n\t\t\t// In the old format all the fields are written. It\n\t\t\t// should be converted by adding boolean markers for\n\t\t\t// all these fields.\n\t\t\toldSerialization: func(cs *ChannelCloseSummary) []byte {\n\t\t\t\tvar buf bytes.Buffer\n\t\t\t\terr := WriteElements(&buf, cs.ChanPoint,\n\t\t\t\t\tcs.ShortChanID, cs.ChainHash,\n\t\t\t\t\tcs.ClosingTXID, cs.CloseHeight,\n\t\t\t\t\tcs.RemotePub, cs.Capacity,\n\t\t\t\t\tcs.SettledBalance, cs.TimeLockedBalance,\n\t\t\t\t\tcs.CloseType, cs.IsPending,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\terr = WriteElements(&buf, cs.RemoteCurrentRevocation)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\terr = WriteChanConfig(&buf, &cs.LocalChanConfig)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\terr = WriteElements(&buf, cs.RemoteNextRevocation)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\treturn buf.Bytes()\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range testCases {\n\n\t\t// Before the migration we must add the old format to the DB.\n\t\tbeforeMigrationFunc := func(d *DB) {\n\n\t\t\t// Get the old serialization format for this test's\n\t\t\t// close summary, and it to the closed channel bucket.\n\t\t\told := test.oldSerialization(test.closeSummary)\n\t\t\terr = kvdb.Update(d, func(tx kvdb.RwTx) error {\n\t\t\t\tclosedChanBucket, err := tx.CreateTopLevelBucket(\n\t\t\t\t\tclosedChannelBucket,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\treturn closedChanBucket.Put(chanID, old)\n\t\t\t}, func() {})\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to add old serialization: %v\",\n\t\t\t\t\terr)\n\t\t\t}\n\t\t}\n\n\t\t// After the migration it should be found in the new format.\n\t\tafterMigrationFunc := func(d *DB) {\n\t\t\t// We generate the new serialized version, to check\n\t\t\t// against what is found in the DB.\n\t\t\tvar b bytes.Buffer\n\t\t\terr = serializeChannelCloseSummary(&b, test.closeSummary)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to serialize: %v\", err)\n\t\t\t}\n\t\t\tnewSerialization := b.Bytes()\n\n\t\t\tvar dbSummary []byte\n\t\t\terr = kvdb.View(d, func(tx kvdb.RTx) error {\n\t\t\t\tclosedChanBucket := tx.ReadBucket(closedChannelBucket)\n\t\t\t\tif closedChanBucket == nil {\n\t\t\t\t\treturn errors.New(\"unable to find bucket\")\n\t\t\t\t}\n\n\t\t\t\t// Get the serialized verision from the DB and\n\t\t\t\t// make sure it matches what we expected.\n\t\t\t\tdbSummary = closedChanBucket.Get(chanID)\n\t\t\t\tif !bytes.Equal(dbSummary, newSerialization) {\n\t\t\t\t\treturn fmt.Errorf(\"unexpected new \" +\n\t\t\t\t\t\t\"serialization\")\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}, func() {\n\t\t\t\tdbSummary = nil\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to view DB: %v\", err)\n\t\t\t}\n\n\t\t\t// Finally we fetch the deserialized summary from the\n\t\t\t// DB and check that it is equal to our original one.\n\t\t\tdbChannels, err := d.FetchClosedChannels(false)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to fetch closed channels: %v\",\n\t\t\t\t\terr)\n\t\t\t}\n\n\t\t\tif len(dbChannels) != 1 {\n\t\t\t\tt.Fatalf(\"expected 1 closed channels, found %v\",\n\t\t\t\t\tlen(dbChannels))\n\t\t\t}\n\n\t\t\tdbChan := dbChannels[0]\n\t\t\tif !reflect.DeepEqual(dbChan, test.closeSummary) {\n\t\t\t\tt.Fatalf(\"not equal: %v vs %v\",\n\t\t\t\t\tspew.Sdump(dbChan),\n\t\t\t\t\tspew.Sdump(test.closeSummary))\n\t\t\t}\n\n\t\t}\n\n\t\tapplyMigration(t,\n\t\t\tbeforeMigrationFunc,\n\t\t\tafterMigrationFunc,\n\t\t\tMigrateOptionalChannelCloseSummaryFields,\n\t\t\tfalse)\n\t}\n}\n\n// TestMigrateGossipMessageStoreKeys ensures that the migration to the new\n// gossip message store key format is successful/unsuccessful under various\n// scenarios.",
      "length": 7423,
      "tokens": 803,
      "embedding": []
    },
    {
      "slug": "func TestMigrateGossipMessageStoreKeys(t *testing.T) {",
      "content": "func TestMigrateGossipMessageStoreKeys(t *testing.T) {\n\tt.Parallel()\n\n\t// Construct the message which we'll use to test the migration, along\n\t// with its old and new key formats.\n\tshortChanID := lnwire.ShortChannelID{BlockHeight: 10}\n\tmsg := &lnwire.AnnounceSignatures{ShortChannelID: shortChanID}\n\n\tvar oldMsgKey [33 + 8]byte\n\tcopy(oldMsgKey[:33], pubKey.SerializeCompressed())\n\tbinary.BigEndian.PutUint64(oldMsgKey[33:41], shortChanID.ToUint64())\n\n\tvar newMsgKey [33 + 8 + 2]byte\n\tcopy(newMsgKey[:41], oldMsgKey[:])\n\tbinary.BigEndian.PutUint16(newMsgKey[41:43], uint16(msg.MsgType()))\n\n\t// Before the migration, we'll create the bucket where the messages\n\t// should live and insert them.\n\tbeforeMigration := func(db *DB) {\n\t\tvar b bytes.Buffer\n\t\tif err := msg.Encode(&b, 0); err != nil {\n\t\t\tt.Fatalf(\"unable to serialize message: %v\", err)\n\t\t}\n\n\t\terr := kvdb.Update(db, func(tx kvdb.RwTx) error {\n\t\t\tmessageStore, err := tx.CreateTopLevelBucket(\n\t\t\t\tmessageStoreBucket,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn messageStore.Put(oldMsgKey[:], b.Bytes())\n\t\t}, func() {})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\t// After the migration, we'll make sure that:\n\t//   1. We cannot find the message under its old key.\n\t//   2. We can find the message under its new key.\n\t//   3. The message matches the original.\n\tafterMigration := func(db *DB) {\n\t\tvar rawMsg []byte\n\t\terr := kvdb.View(db, func(tx kvdb.RTx) error {\n\t\t\tmessageStore := tx.ReadBucket(messageStoreBucket)\n\t\t\tif messageStore == nil {\n\t\t\t\treturn errors.New(\"message store bucket not \" +\n\t\t\t\t\t\"found\")\n\t\t\t}\n\t\t\trawMsg = messageStore.Get(oldMsgKey[:])\n\t\t\tif rawMsg != nil {\n\t\t\t\tt.Fatal(\"expected to not find message under \" +\n\t\t\t\t\t\"old key, but did\")\n\t\t\t}\n\t\t\trawMsg = messageStore.Get(newMsgKey[:])\n\t\t\tif rawMsg == nil {\n\t\t\t\treturn fmt.Errorf(\"expected to find message \" +\n\t\t\t\t\t\"under new key, but didn't\")\n\t\t\t}\n\n\t\t\treturn nil\n\t\t}, func() {\n\t\t\trawMsg = nil\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tgotMsg, err := lnwire.ReadMessage(bytes.NewReader(rawMsg), 0)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to deserialize raw message: %v\", err)\n\t\t}\n\t\tif !reflect.DeepEqual(msg, gotMsg) {\n\t\t\tt.Fatalf(\"expected message: %v\\ngot message: %v\",\n\t\t\t\tspew.Sdump(msg), spew.Sdump(gotMsg))\n\t\t}\n\t}\n\n\tapplyMigration(\n\t\tt, beforeMigration, afterMigration,\n\t\tMigrateGossipMessageStoreKeys, false,\n\t)\n}\n\n// TestOutgoingPaymentsMigration checks that OutgoingPayments are migrated to a\n// new bucket structure after the migration.",
      "length": 2340,
      "tokens": 307,
      "embedding": []
    },
    {
      "slug": "func TestOutgoingPaymentsMigration(t *testing.T) {",
      "content": "func TestOutgoingPaymentsMigration(t *testing.T) {\n\tt.Parallel()\n\n\tconst numPayments = 4\n\tvar oldPayments []*outgoingPayment\n\n\t// Add fake payments to test database, verifying that it was created.\n\tbeforeMigrationFunc := func(d *DB) {\n\t\tfor i := 0; i < numPayments; i++ {\n\t\t\tvar p *outgoingPayment\n\t\t\tvar err error\n\n\t\t\t// We fill the database with random payments. For the\n\t\t\t// very last one we'll use a duplicate of the first, to\n\t\t\t// ensure we are able to handle migration from a\n\t\t\t// database that has copies.\n\t\t\tif i < numPayments-1 {\n\t\t\t\tp, err = makeRandomFakePayment()\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to create payment: %v\",\n\t\t\t\t\t\terr)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tp = oldPayments[0]\n\t\t\t}\n\n\t\t\tif err := d.addPayment(p); err != nil {\n\t\t\t\tt.Fatalf(\"unable to add payment: %v\", err)\n\t\t\t}\n\n\t\t\toldPayments = append(oldPayments, p)\n\t\t}\n\n\t\tpayments, err := d.fetchAllPayments()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch payments: %v\", err)\n\t\t}\n\n\t\tif len(payments) != numPayments {\n\t\t\tt.Fatalf(\"wrong qty of paymets: expected %d got %v\",\n\t\t\t\tnumPayments, len(payments))\n\t\t}\n\t}\n\n\t// Verify that all payments were migrated.\n\tafterMigrationFunc := func(d *DB) {\n\t\tsentPayments, err := d.fetchPaymentsMigration9()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch sent payments: %v\", err)\n\t\t}\n\n\t\tif len(sentPayments) != numPayments {\n\t\t\tt.Fatalf(\"expected %d payments, got %d\", numPayments,\n\t\t\t\tlen(sentPayments))\n\t\t}\n\n\t\tgraph := d.ChannelGraph()\n\t\tsourceNode, err := graph.SourceNode()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch source node: %v\", err)\n\t\t}\n\n\t\tfor i, p := range sentPayments {\n\t\t\t// The payment status should be Completed.\n\t\t\tif p.Status != StatusSucceeded {\n\t\t\t\tt.Fatalf(\"expected Completed, got %v\", p.Status)\n\t\t\t}\n\n\t\t\t// Check that the sequence number is preserved. They\n\t\t\t// start counting at 1.\n\t\t\tif p.sequenceNum != uint64(i+1) {\n\t\t\t\tt.Fatalf(\"expected seqnum %d, got %d\", i,\n\t\t\t\t\tp.sequenceNum)\n\t\t\t}\n\n\t\t\t// Order of payments should be be preserved.\n\t\t\told := oldPayments[i]\n\n\t\t\t// Check the individual fields.\n\t\t\tif p.Info.Value != old.Terms.Value {\n\t\t\t\tt.Fatalf(\"value mismatch\")\n\t\t\t}\n\n\t\t\tif p.Info.CreationDate != old.CreationDate {\n\t\t\t\tt.Fatalf(\"date mismatch\")\n\t\t\t}\n\n\t\t\tif !bytes.Equal(p.Info.PaymentRequest, old.PaymentRequest) {\n\t\t\t\tt.Fatalf(\"payreq mismatch\")\n\t\t\t}\n\n\t\t\tif *p.PaymentPreimage != old.PaymentPreimage {\n\t\t\t\tt.Fatalf(\"preimage mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.TotalFees() != old.Fee {\n\t\t\t\tt.Fatalf(\"Fee mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.TotalAmount != old.Fee+old.Terms.Value {\n\t\t\t\tt.Fatalf(\"Total amount mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.TotalTimeLock != old.TimeLockLength {\n\t\t\t\tt.Fatalf(\"timelock mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.SourcePubKey != sourceNode.PubKeyBytes {\n\t\t\t\tt.Fatalf(\"source mismatch: %x vs %x\",\n\t\t\t\t\tp.Attempt.Route.SourcePubKey[:],\n\t\t\t\t\tsourceNode.PubKeyBytes[:])\n\t\t\t}\n\n\t\t\tfor i, hop := range old.Path {\n\t\t\t\tif hop != p.Attempt.Route.Hops[i].PubKeyBytes {\n\t\t\t\t\tt.Fatalf(\"path mismatch\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Finally, check that the payment sequence number is updated\n\t\t// to reflect the migrated payments.\n\t\terr = kvdb.Update(d, func(tx kvdb.RwTx) error {\n\t\t\tpayments := tx.ReadWriteBucket(paymentsRootBucket)\n\t\t\tif payments == nil {\n\t\t\t\treturn fmt.Errorf(\"payments bucket not found\")\n\t\t\t}\n\n\t\t\tseq := payments.Sequence()\n\t\t\tif seq != numPayments {\n\t\t\t\treturn fmt.Errorf(\"expected sequence to be \"+\n\t\t\t\t\t\"%d, got %d\", numPayments, seq)\n\t\t\t}\n\n\t\t\treturn nil\n\t\t}, func() {})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\tapplyMigration(t,\n\t\tbeforeMigrationFunc,\n\t\tafterMigrationFunc,\n\t\tMigrateOutgoingPayments,\n\t\tfalse)\n}\n",
      "length": 3413,
      "tokens": 450,
      "embedding": []
    },
    {
      "slug": "func makeRandPaymentCreationInfo() (*PaymentCreationInfo, error) {",
      "content": "func makeRandPaymentCreationInfo() (*PaymentCreationInfo, error) {\n\tvar payHash lntypes.Hash\n\tif _, err := rand.Read(payHash[:]); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &PaymentCreationInfo{\n\t\tPaymentHash:    payHash,\n\t\tValue:          lnwire.MilliSatoshi(rand.Int63()),\n\t\tCreationDate:   time.Now(),\n\t\tPaymentRequest: []byte(\"test\"),\n\t}, nil\n}\n\n// TestPaymentRouteSerialization tests that we're able to properly migrate\n// existing payments on disk that contain the traversed routes to the new\n// routing format which supports the TLV payloads. We also test that the\n// migration is able to handle duplicate payment attempts.",
      "length": 547,
      "tokens": 73,
      "embedding": []
    },
    {
      "slug": "func TestPaymentRouteSerialization(t *testing.T) {",
      "content": "func TestPaymentRouteSerialization(t *testing.T) {\n\tt.Parallel()\n\n\tlegacyHop1 := &Hop{\n\t\tPubKeyBytes:      NewVertex(pub),\n\t\tChannelID:        12345,\n\t\tOutgoingTimeLock: 111,\n\t\tLegacyPayload:    true,\n\t\tAmtToForward:     555,\n\t}\n\tlegacyHop2 := &Hop{\n\t\tPubKeyBytes:      NewVertex(pub),\n\t\tChannelID:        12345,\n\t\tOutgoingTimeLock: 111,\n\t\tLegacyPayload:    true,\n\t\tAmtToForward:     555,\n\t}\n\tlegacyRoute := Route{\n\t\tTotalTimeLock: 123,\n\t\tTotalAmount:   1234567,\n\t\tSourcePubKey:  NewVertex(pub),\n\t\tHops:          []*Hop{legacyHop1, legacyHop2},\n\t}\n\n\tconst numPayments = 4\n\tvar oldPayments []*Payment\n\n\tsharedPayAttempt := PaymentAttemptInfo{\n\t\tPaymentID:  1,\n\t\tSessionKey: priv,\n\t\tRoute:      legacyRoute,\n\t}\n\n\t// We'll first add a series of fake payments, using the existing legacy\n\t// serialization format.\n\tbeforeMigrationFunc := func(d *DB) {\n\t\terr := kvdb.Update(d, func(tx kvdb.RwTx) error {\n\t\t\tpaymentsBucket, err := tx.CreateTopLevelBucket(\n\t\t\t\tpaymentsRootBucket,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to create new payments \"+\n\t\t\t\t\t\"bucket: %v\", err)\n\t\t\t}\n\n\t\t\tfor i := 0; i < numPayments; i++ {\n\t\t\t\tvar seqNum [8]byte\n\t\t\t\tbyteOrder.PutUint64(seqNum[:], uint64(i))\n\n\t\t\t\t// All payments will be randomly generated,\n\t\t\t\t// other than the final payment. We'll force\n\t\t\t\t// the final payment to re-use an existing\n\t\t\t\t// payment hash so we can insert it into the\n\t\t\t\t// duplicate payment hash bucket.\n\t\t\t\tvar payInfo *PaymentCreationInfo\n\t\t\t\tif i < numPayments-1 {\n\t\t\t\t\tpayInfo, err = makeRandPaymentCreationInfo()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tt.Fatalf(\"unable to create \"+\n\t\t\t\t\t\t\t\"payment: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tpayInfo = oldPayments[0].Info\n\t\t\t\t}\n\n\t\t\t\t// Next, legacy encoded when needed, we'll\n\t\t\t\t// serialize the info and the attempt.\n\t\t\t\tvar payInfoBytes bytes.Buffer\n\t\t\t\terr = serializePaymentCreationInfo(\n\t\t\t\t\t&payInfoBytes, payInfo,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to encode pay \"+\n\t\t\t\t\t\t\"info: %v\", err)\n\t\t\t\t}\n\t\t\t\tvar payAttemptBytes bytes.Buffer\n\t\t\t\terr = serializePaymentAttemptInfoLegacy(\n\t\t\t\t\t&payAttemptBytes, &sharedPayAttempt,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to encode payment attempt: \"+\n\t\t\t\t\t\t\"%v\", err)\n\t\t\t\t}\n\n\t\t\t\t// Before we write to disk, we'll need to fetch\n\t\t\t\t// the proper bucket. If this is the duplicate\n\t\t\t\t// payment, then we'll grab the dup bucket,\n\t\t\t\t// otherwise, we'll use the top level bucket.\n\t\t\t\tvar payHashBucket kvdb.RwBucket\n\t\t\t\tif i < numPayments-1 {\n\t\t\t\t\tpayHashBucket, err = paymentsBucket.CreateBucket(\n\t\t\t\t\t\tpayInfo.PaymentHash[:],\n\t\t\t\t\t)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tt.Fatalf(\"unable to create payments bucket: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tpayHashBucket = paymentsBucket.NestedReadWriteBucket(\n\t\t\t\t\t\tpayInfo.PaymentHash[:],\n\t\t\t\t\t)\n\t\t\t\t\tdupPayBucket, err := payHashBucket.CreateBucket(\n\t\t\t\t\t\tpaymentDuplicateBucket,\n\t\t\t\t\t)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tt.Fatalf(\"unable to create \"+\n\t\t\t\t\t\t\t\"dup hash bucket: %v\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\tpayHashBucket, err = dupPayBucket.CreateBucket(\n\t\t\t\t\t\tseqNum[:],\n\t\t\t\t\t)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tt.Fatalf(\"unable to make dup \"+\n\t\t\t\t\t\t\t\"bucket: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\terr = payHashBucket.Put(paymentSequenceKey, seqNum[:])\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to write seqno: %v\", err)\n\t\t\t\t}\n\n\t\t\t\terr = payHashBucket.Put(\n\t\t\t\t\tpaymentCreationInfoKey, payInfoBytes.Bytes(),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to write creation \"+\n\t\t\t\t\t\t\"info: %v\", err)\n\t\t\t\t}\n\n\t\t\t\terr = payHashBucket.Put(\n\t\t\t\t\tpaymentAttemptInfoKey, payAttemptBytes.Bytes(),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to write attempt \"+\n\t\t\t\t\t\t\"info: %v\", err)\n\t\t\t\t}\n\n\t\t\t\toldPayments = append(oldPayments, &Payment{\n\t\t\t\t\tInfo:    payInfo,\n\t\t\t\t\tAttempt: &sharedPayAttempt,\n\t\t\t\t})\n\t\t\t}\n\n\t\t\treturn nil\n\t\t}, func() {\n\t\t\toldPayments = nil\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to create test payments: %v\", err)\n\t\t}\n\t}\n\n\tafterMigrationFunc := func(d *DB) {\n\t\tnewPayments, err := d.FetchPayments()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to fetch new payments: %v\", err)\n\t\t}\n\n\t\tif len(newPayments) != numPayments {\n\t\t\tt.Fatalf(\"expected %d payments, got %d\", numPayments,\n\t\t\t\tlen(newPayments))\n\t\t}\n\n\t\tfor i, p := range newPayments {\n\t\t\t// Order of payments should be be preserved.\n\t\t\told := oldPayments[i]\n\n\t\t\tif p.Attempt.PaymentID != old.Attempt.PaymentID {\n\t\t\t\tt.Fatalf(\"wrong pay ID: expected %v, got %v\",\n\t\t\t\t\tp.Attempt.PaymentID,\n\t\t\t\t\told.Attempt.PaymentID)\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.TotalFees() != old.Attempt.Route.TotalFees() {\n\t\t\t\tt.Fatalf(\"Fee mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.TotalAmount != old.Attempt.Route.TotalAmount {\n\t\t\t\tt.Fatalf(\"Total amount mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.TotalTimeLock != old.Attempt.Route.TotalTimeLock {\n\t\t\t\tt.Fatalf(\"timelock mismatch\")\n\t\t\t}\n\n\t\t\tif p.Attempt.Route.SourcePubKey != old.Attempt.Route.SourcePubKey {\n\t\t\t\tt.Fatalf(\"source mismatch: %x vs %x\",\n\t\t\t\t\tp.Attempt.Route.SourcePubKey[:],\n\t\t\t\t\told.Attempt.Route.SourcePubKey[:])\n\t\t\t}\n\n\t\t\tfor i, hop := range p.Attempt.Route.Hops {\n\t\t\t\tif !reflect.DeepEqual(hop, legacyRoute.Hops[i]) {\n\t\t\t\t\tt.Fatalf(\"hop mismatch\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tapplyMigration(t,\n\t\tbeforeMigrationFunc,\n\t\tafterMigrationFunc,\n\t\tMigrateRouteSerialization,\n\t\tfalse)\n}\n\n// TestNotCoveredMigrations only references migrations that are not referenced\n// anywhere else in this package. This prevents false positives when linting\n// with unused.",
      "length": 5091,
      "tokens": 606,
      "embedding": []
    },
    {
      "slug": "func TestNotCoveredMigrations(t *testing.T) {",
      "content": "func TestNotCoveredMigrations(t *testing.T) {\n\t_ = MigrateNodeAndEdgeUpdateIndex\n\t_ = MigrateInvoiceTimeSeries\n\t_ = MigrateInvoiceTimeSeriesOutgoingPayments\n\t_ = MigrateEdgePolicies\n\t_ = MigratePruneEdgeUpdateIndex\n}\n",
      "length": 165,
      "tokens": 16,
      "embedding": []
    }
  ]
}