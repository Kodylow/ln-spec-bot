{
  "filepath": "../implementations/go/lnd/channeldb/graph_test.go",
  "package": "channeldb",
  "sections": [
    {
      "slug": "func MakeTestGraph(t testing.TB, modifiers ...OptionModifier) (*ChannelGraph, error) {",
      "content": "func MakeTestGraph(t testing.TB, modifiers ...OptionModifier) (*ChannelGraph, error) {\n\topts := DefaultOptions()\n\tfor _, modifier := range modifiers {\n\t\tmodifier(&opts)\n\t}\n\n\t// Next, create channelgraph for the first time.\n\tbackend, backendCleanup, err := kvdb.GetTestBackend(t.TempDir(), \"cgr\")\n\tif err != nil {\n\t\tbackendCleanup()\n\t\treturn nil, err\n\t}\n\n\tgraph, err := NewChannelGraph(\n\t\tbackend, opts.RejectCacheSize, opts.ChannelCacheSize,\n\t\topts.BatchCommitInterval, opts.PreAllocCacheNumNodes,\n\t\ttrue, false,\n\t)\n\tif err != nil {\n\t\tbackendCleanup()\n\t\treturn nil, err\n\t}\n\n\tt.Cleanup(func() {\n\t\t_ = backend.Close()\n\t\tbackendCleanup()\n\t})\n\n\treturn graph, nil\n}\n",
      "length": 545,
      "tokens": 69,
      "embedding": []
    },
    {
      "slug": "func createLightningNode(db kvdb.Backend, priv *btcec.PrivateKey) (*LightningNode, error) {",
      "content": "func createLightningNode(db kvdb.Backend, priv *btcec.PrivateKey) (*LightningNode, error) {\n\tupdateTime := prand.Int63()\n\n\tpub := priv.PubKey().SerializeCompressed()\n\tn := &LightningNode{\n\t\tHaveNodeAnnouncement: true,\n\t\tAuthSigBytes:         testSig.Serialize(),\n\t\tLastUpdate:           time.Unix(updateTime, 0),\n\t\tColor:                color.RGBA{1, 2, 3, 0},\n\t\tAlias:                \"kek\" + string(pub[:]),\n\t\tFeatures:             testFeatures,\n\t\tAddresses:            testAddrs,\n\t\tdb:                   db,\n\t}\n\tcopy(n.PubKeyBytes[:], priv.PubKey().SerializeCompressed())\n\n\treturn n, nil\n}\n",
      "length": 483,
      "tokens": 38,
      "embedding": []
    },
    {
      "slug": "func createTestVertex(db kvdb.Backend) (*LightningNode, error) {",
      "content": "func createTestVertex(db kvdb.Backend) (*LightningNode, error) {\n\tpriv, err := btcec.NewPrivateKey()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn createLightningNode(db, priv)\n}\n",
      "length": 108,
      "tokens": 17,
      "embedding": []
    },
    {
      "slug": "func TestNodeInsertionAndDeletion(t *testing.T) {",
      "content": "func TestNodeInsertionAndDeletion(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test basic insertion/deletion for vertexes from the\n\t// graph, so we'll create a test vertex to start with.\n\tnode := &LightningNode{\n\t\tHaveNodeAnnouncement: true,\n\t\tAuthSigBytes:         testSig.Serialize(),\n\t\tLastUpdate:           time.Unix(1232342, 0),\n\t\tColor:                color.RGBA{1, 2, 3, 0},\n\t\tAlias:                \"kek\",\n\t\tFeatures:             testFeatures,\n\t\tAddresses:            testAddrs,\n\t\tExtraOpaqueData:      []byte(\"extra new data\"),\n\t\tPubKeyBytes:          testPub,\n\t\tdb:                   graph.db,\n\t}\n\n\t// First, insert the node into the graph DB. This should succeed\n\t// without any errors.\n\tif err := graph.AddLightningNode(node); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tassertNodeInCache(t, graph, node, testFeatures)\n\n\t// Next, fetch the node from the database to ensure everything was\n\t// serialized properly.\n\tdbNode, err := graph.FetchLightningNode(testPub)\n\trequire.NoError(t, err, \"unable to locate node\")\n\n\tif _, exists, err := graph.HasLightningNode(dbNode.PubKeyBytes); err != nil {\n\t\tt.Fatalf(\"unable to query for node: %v\", err)\n\t} else if !exists {\n\t\tt.Fatalf(\"node should be found but wasn't\")\n\t}\n\n\t// The two nodes should match exactly!\n\tif err := compareNodes(node, dbNode); err != nil {\n\t\tt.Fatalf(\"nodes don't match: %v\", err)\n\t}\n\n\t// Next, delete the node from the graph, this should purge all data\n\t// related to the node.\n\tif err := graph.DeleteLightningNode(testPub); err != nil {\n\t\tt.Fatalf(\"unable to delete node; %v\", err)\n\t}\n\tassertNodeNotInCache(t, graph, testPub)\n\n\t// Finally, attempt to fetch the node again. This should fail as the\n\t// node should have been deleted from the database.\n\t_, err = graph.FetchLightningNode(testPub)\n\tif err != ErrGraphNodeNotFound {\n\t\tt.Fatalf(\"fetch after delete should fail!\")\n\t}\n}\n\n// TestPartialNode checks that we can add and retrieve a LightningNode where\n// where only the pubkey is known to the database.",
      "length": 1983,
      "tokens": 271,
      "embedding": []
    },
    {
      "slug": "func TestPartialNode(t *testing.T) {",
      "content": "func TestPartialNode(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We want to be able to insert nodes into the graph that only has the\n\t// PubKey set.\n\tnode := &LightningNode{\n\t\tHaveNodeAnnouncement: false,\n\t\tPubKeyBytes:          testPub,\n\t}\n\n\tif err := graph.AddLightningNode(node); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tassertNodeInCache(t, graph, node, nil)\n\n\t// Next, fetch the node from the database to ensure everything was\n\t// serialized properly.\n\tdbNode, err := graph.FetchLightningNode(testPub)\n\trequire.NoError(t, err, \"unable to locate node\")\n\n\tif _, exists, err := graph.HasLightningNode(dbNode.PubKeyBytes); err != nil {\n\t\tt.Fatalf(\"unable to query for node: %v\", err)\n\t} else if !exists {\n\t\tt.Fatalf(\"node should be found but wasn't\")\n\t}\n\n\t// The two nodes should match exactly! (with default values for\n\t// LastUpdate and db set to satisfy compareNodes())\n\tnode = &LightningNode{\n\t\tHaveNodeAnnouncement: false,\n\t\tLastUpdate:           time.Unix(0, 0),\n\t\tPubKeyBytes:          testPub,\n\t\tdb:                   graph.db,\n\t}\n\n\tif err := compareNodes(node, dbNode); err != nil {\n\t\tt.Fatalf(\"nodes don't match: %v\", err)\n\t}\n\n\t// Next, delete the node from the graph, this should purge all data\n\t// related to the node.\n\tif err := graph.DeleteLightningNode(testPub); err != nil {\n\t\tt.Fatalf(\"unable to delete node: %v\", err)\n\t}\n\tassertNodeNotInCache(t, graph, testPub)\n\n\t// Finally, attempt to fetch the node again. This should fail as the\n\t// node should have been deleted from the database.\n\t_, err = graph.FetchLightningNode(testPub)\n\tif err != ErrGraphNodeNotFound {\n\t\tt.Fatalf(\"fetch after delete should fail!\")\n\t}\n}\n",
      "length": 1641,
      "tokens": 233,
      "embedding": []
    },
    {
      "slug": "func TestAliasLookup(t *testing.T) {",
      "content": "func TestAliasLookup(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test the alias index within the database, so first\n\t// create a new test node.\n\ttestNode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\t// Add the node to the graph's database, this should also insert an\n\t// entry into the alias index for this node.\n\tif err := graph.AddLightningNode(testNode); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// Next, attempt to lookup the alias. The alias should exactly match\n\t// the one which the test node was assigned.\n\tnodePub, err := testNode.PubKey()\n\trequire.NoError(t, err, \"unable to generate pubkey\")\n\tdbAlias, err := graph.LookupAlias(nodePub)\n\trequire.NoError(t, err, \"unable to find alias\")\n\tif dbAlias != testNode.Alias {\n\t\tt.Fatalf(\"aliases don't match, expected %v got %v\",\n\t\t\ttestNode.Alias, dbAlias)\n\t}\n\n\t// Ensure that looking up a non-existent alias results in an error.\n\tnode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tnodePub, err = node.PubKey()\n\trequire.NoError(t, err, \"unable to generate pubkey\")\n\t_, err = graph.LookupAlias(nodePub)\n\tif err != ErrNodeAliasNotFound {\n\t\tt.Fatalf(\"alias lookup should fail for non-existent pubkey\")\n\t}\n}\n",
      "length": 1288,
      "tokens": 186,
      "embedding": []
    },
    {
      "slug": "func TestSourceNode(t *testing.T) {",
      "content": "func TestSourceNode(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test the setting/getting of the source node, so we\n\t// first create a fake node to use within the test.\n\ttestNode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\t// Attempt to fetch the source node, this should return an error as the\n\t// source node hasn't yet been set.\n\tif _, err := graph.SourceNode(); err != ErrSourceNodeNotSet {\n\t\tt.Fatalf(\"source node shouldn't be set in new graph\")\n\t}\n\n\t// Set the source the source node, this should insert the node into the\n\t// database in a special way indicating it's the source node.\n\tif err := graph.SetSourceNode(testNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\t// Retrieve the source node from the database, it should exactly match\n\t// the one we set above.\n\tsourceNode, err := graph.SourceNode()\n\trequire.NoError(t, err, \"unable to fetch source node\")\n\tif err := compareNodes(testNode, sourceNode); err != nil {\n\t\tt.Fatalf(\"nodes don't match: %v\", err)\n\t}\n}\n",
      "length": 1073,
      "tokens": 172,
      "embedding": []
    },
    {
      "slug": "func TestEdgeInsertionDeletion(t *testing.T) {",
      "content": "func TestEdgeInsertionDeletion(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test the insertion/deletion of edges, so we create two\n\t// vertexes to connect.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\t// In addition to the fake vertexes we create some fake channel\n\t// identifiers.\n\tchanID := uint64(prand.Int63())\n\toutpoint := wire.OutPoint{\n\t\tHash:  rev,\n\t\tIndex: 9,\n\t}\n\n\t// Add the new edge to the database, this should proceed without any\n\t// errors.\n\tnode1Pub, err := node1.PubKey()\n\trequire.NoError(t, err, \"unable to generate node key\")\n\tnode2Pub, err := node2.PubKey()\n\trequire.NoError(t, err, \"unable to generate node key\")\n\tedgeInfo := ChannelEdgeInfo{\n\t\tChannelID: chanID,\n\t\tChainHash: key,\n\t\tAuthProof: &ChannelAuthProof{\n\t\t\tNodeSig1Bytes:    testSig.Serialize(),\n\t\t\tNodeSig2Bytes:    testSig.Serialize(),\n\t\t\tBitcoinSig1Bytes: testSig.Serialize(),\n\t\t\tBitcoinSig2Bytes: testSig.Serialize(),\n\t\t},\n\t\tChannelPoint: outpoint,\n\t\tCapacity:     9000,\n\t}\n\tcopy(edgeInfo.NodeKey1Bytes[:], node1Pub.SerializeCompressed())\n\tcopy(edgeInfo.NodeKey2Bytes[:], node2Pub.SerializeCompressed())\n\tcopy(edgeInfo.BitcoinKey1Bytes[:], node1Pub.SerializeCompressed())\n\tcopy(edgeInfo.BitcoinKey2Bytes[:], node2Pub.SerializeCompressed())\n\n\tif err := graph.AddChannelEdge(&edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\tassertEdgeWithNoPoliciesInCache(t, graph, &edgeInfo)\n\n\t// Ensure that both policies are returned as unknown (nil).\n\t_, e1, e2, err := graph.FetchChannelEdgesByID(chanID)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to fetch channel edge\")\n\t}\n\tif e1 != nil || e2 != nil {\n\t\tt.Fatalf(\"channel edges not unknown\")\n\t}\n\n\t// Next, attempt to delete the edge from the database, again this\n\t// should proceed without any issues.\n\tif err := graph.DeleteChannelEdges(false, true, chanID); err != nil {\n\t\tt.Fatalf(\"unable to delete edge: %v\", err)\n\t}\n\tassertNoEdge(t, graph, chanID)\n\n\t// Ensure that any query attempts to lookup the delete channel edge are\n\t// properly deleted.\n\tif _, _, _, err := graph.FetchChannelEdgesByOutpoint(&outpoint); err == nil {\n\t\tt.Fatalf(\"channel edge not deleted\")\n\t}\n\tif _, _, _, err := graph.FetchChannelEdgesByID(chanID); err == nil {\n\t\tt.Fatalf(\"channel edge not deleted\")\n\t}\n\tisZombie, _, _ := graph.IsZombieEdge(chanID)\n\tif !isZombie {\n\t\tt.Fatal(\"channel edge not marked as zombie\")\n\t}\n\n\t// Finally, attempt to delete a (now) non-existent edge within the\n\t// database, this should result in an error.\n\terr = graph.DeleteChannelEdges(false, true, chanID)\n\tif err != ErrEdgeNotFound {\n\t\tt.Fatalf(\"deleting a non-existent edge should fail!\")\n\t}\n}\n",
      "length": 2714,
      "tokens": 342,
      "embedding": []
    },
    {
      "slug": "func createEdge(height, txIndex uint32, txPosition uint16, outPointIndex uint32,",
      "content": "func createEdge(height, txIndex uint32, txPosition uint16, outPointIndex uint32,\n\tnode1, node2 *LightningNode) (ChannelEdgeInfo, lnwire.ShortChannelID) {\n\n\tshortChanID := lnwire.ShortChannelID{\n\t\tBlockHeight: height,\n\t\tTxIndex:     txIndex,\n\t\tTxPosition:  txPosition,\n\t}\n\toutpoint := wire.OutPoint{\n\t\tHash:  rev,\n\t\tIndex: outPointIndex,\n\t}\n\n\tnode1Pub, _ := node1.PubKey()\n\tnode2Pub, _ := node2.PubKey()\n\tedgeInfo := ChannelEdgeInfo{\n\t\tChannelID: shortChanID.ToUint64(),\n\t\tChainHash: key,\n\t\tAuthProof: &ChannelAuthProof{\n\t\t\tNodeSig1Bytes:    testSig.Serialize(),\n\t\t\tNodeSig2Bytes:    testSig.Serialize(),\n\t\t\tBitcoinSig1Bytes: testSig.Serialize(),\n\t\t\tBitcoinSig2Bytes: testSig.Serialize(),\n\t\t},\n\t\tChannelPoint: outpoint,\n\t\tCapacity:     9000,\n\t}\n\n\tcopy(edgeInfo.NodeKey1Bytes[:], node1Pub.SerializeCompressed())\n\tcopy(edgeInfo.NodeKey2Bytes[:], node2Pub.SerializeCompressed())\n\tcopy(edgeInfo.BitcoinKey1Bytes[:], node1Pub.SerializeCompressed())\n\tcopy(edgeInfo.BitcoinKey2Bytes[:], node2Pub.SerializeCompressed())\n\n\treturn edgeInfo, shortChanID\n}\n\n// TestDisconnectBlockAtHeight checks that the pruned state of the channel\n// database is what we expect after calling DisconnectBlockAtHeight.",
      "length": 1071,
      "tokens": 86,
      "embedding": []
    },
    {
      "slug": "func TestDisconnectBlockAtHeight(t *testing.T) {",
      "content": "func TestDisconnectBlockAtHeight(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\tsourceNode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create source node\")\n\tif err := graph.SetSourceNode(sourceNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\t// We'd like to test the insertion/deletion of edges, so we create two\n\t// vertexes to connect.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\t// In addition to the fake vertexes we create some fake channel\n\t// identifiers.\n\tvar spendOutputs []*wire.OutPoint\n\tvar blockHash chainhash.Hash\n\tcopy(blockHash[:], bytes.Repeat([]byte{1}, 32))\n\n\t// Prune the graph a few times to make sure we have entries in the\n\t// prune log.\n\t_, err = graph.PruneGraph(spendOutputs, &blockHash, 155)\n\trequire.NoError(t, err, \"unable to prune graph\")\n\tvar blockHash2 chainhash.Hash\n\tcopy(blockHash2[:], bytes.Repeat([]byte{2}, 32))\n\n\t_, err = graph.PruneGraph(spendOutputs, &blockHash2, 156)\n\trequire.NoError(t, err, \"unable to prune graph\")\n\n\t// We'll create 3 almost identical edges, so first create a helper\n\t// method containing all logic for doing so.\n\n\t// Create an edge which has its block height at 156.\n\theight := uint32(156)\n\tedgeInfo, _ := createEdge(height, 0, 0, 0, node1, node2)\n\n\t// Create an edge with block height 157. We give it\n\t// maximum values for tx index and position, to make\n\t// sure our database range scan get edges from the\n\t// entire range.\n\tedgeInfo2, _ := createEdge(\n\t\theight+1, math.MaxUint32&0x00ffffff, math.MaxUint16, 1,\n\t\tnode1, node2,\n\t)\n\n\t// Create a third edge, this with a block height of 155.\n\tedgeInfo3, _ := createEdge(height-1, 0, 0, 2, node1, node2)\n\n\t// Now add all these new edges to the database.\n\tif err := graph.AddChannelEdge(&edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\tif err := graph.AddChannelEdge(&edgeInfo2); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\tif err := graph.AddChannelEdge(&edgeInfo3); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\tassertEdgeWithNoPoliciesInCache(t, graph, &edgeInfo)\n\tassertEdgeWithNoPoliciesInCache(t, graph, &edgeInfo2)\n\tassertEdgeWithNoPoliciesInCache(t, graph, &edgeInfo3)\n\n\t// Call DisconnectBlockAtHeight, which should prune every channel\n\t// that has a funding height of 'height' or greater.\n\tremoved, err := graph.DisconnectBlockAtHeight(uint32(height))\n\tif err != nil {\n\t\tt.Fatalf(\"unable to prune %v\", err)\n\t}\n\tassertNoEdge(t, graph, edgeInfo.ChannelID)\n\tassertNoEdge(t, graph, edgeInfo2.ChannelID)\n\tassertEdgeWithNoPoliciesInCache(t, graph, &edgeInfo3)\n\n\t// The two edges should have been removed.\n\tif len(removed) != 2 {\n\t\tt.Fatalf(\"expected two edges to be removed from graph, \"+\n\t\t\t\"only %d were\", len(removed))\n\t}\n\tif removed[0].ChannelID != edgeInfo.ChannelID {\n\t\tt.Fatalf(\"expected edge to be removed from graph\")\n\t}\n\tif removed[1].ChannelID != edgeInfo2.ChannelID {\n\t\tt.Fatalf(\"expected edge to be removed from graph\")\n\t}\n\n\t// The two first edges should be removed from the db.\n\t_, _, has, isZombie, err := graph.HasChannelEdge(edgeInfo.ChannelID)\n\trequire.NoError(t, err, \"unable to query for edge\")\n\tif has {\n\t\tt.Fatalf(\"edge1 was not pruned from the graph\")\n\t}\n\tif isZombie {\n\t\tt.Fatal(\"reorged edge1 should not be marked as zombie\")\n\t}\n\t_, _, has, isZombie, err = graph.HasChannelEdge(edgeInfo2.ChannelID)\n\trequire.NoError(t, err, \"unable to query for edge\")\n\tif has {\n\t\tt.Fatalf(\"edge2 was not pruned from the graph\")\n\t}\n\tif isZombie {\n\t\tt.Fatal(\"reorged edge2 should not be marked as zombie\")\n\t}\n\n\t// Edge 3 should not be removed.\n\t_, _, has, isZombie, err = graph.HasChannelEdge(edgeInfo3.ChannelID)\n\trequire.NoError(t, err, \"unable to query for edge\")\n\tif !has {\n\t\tt.Fatalf(\"edge3 was pruned from the graph\")\n\t}\n\tif isZombie {\n\t\tt.Fatal(\"edge3 was marked as zombie\")\n\t}\n\n\t// PruneTip should be set to the blockHash we specified for the block\n\t// at height 155.\n\thash, h, err := graph.PruneTip()\n\trequire.NoError(t, err, \"unable to get prune tip\")\n\tif !blockHash.IsEqual(hash) {\n\t\tt.Fatalf(\"expected best block to be %x, was %x\", blockHash, hash)\n\t}\n\tif h != height-1 {\n\t\tt.Fatalf(\"expected best block height to be %d, was %d\", height-1, h)\n\t}\n}\n",
      "length": 4266,
      "tokens": 606,
      "embedding": []
    },
    {
      "slug": "func assertEdgeInfoEqual(t *testing.T, e1 *ChannelEdgeInfo,",
      "content": "func assertEdgeInfoEqual(t *testing.T, e1 *ChannelEdgeInfo,\n\te2 *ChannelEdgeInfo) {\n\n\tif e1.ChannelID != e2.ChannelID {\n\t\tt.Fatalf(\"chan id's don't match: %v vs %v\", e1.ChannelID,\n\t\t\te2.ChannelID)\n\t}\n\n\tif e1.ChainHash != e2.ChainHash {\n\t\tt.Fatalf(\"chain hashes don't match: %v vs %v\", e1.ChainHash,\n\t\t\te2.ChainHash)\n\t}\n\n\tif !bytes.Equal(e1.NodeKey1Bytes[:], e2.NodeKey1Bytes[:]) {\n\t\tt.Fatalf(\"nodekey1 doesn't match\")\n\t}\n\tif !bytes.Equal(e1.NodeKey2Bytes[:], e2.NodeKey2Bytes[:]) {\n\t\tt.Fatalf(\"nodekey2 doesn't match\")\n\t}\n\tif !bytes.Equal(e1.BitcoinKey1Bytes[:], e2.BitcoinKey1Bytes[:]) {\n\t\tt.Fatalf(\"bitcoinkey1 doesn't match\")\n\t}\n\tif !bytes.Equal(e1.BitcoinKey2Bytes[:], e2.BitcoinKey2Bytes[:]) {\n\t\tt.Fatalf(\"bitcoinkey2 doesn't match\")\n\t}\n\n\tif !bytes.Equal(e1.Features, e2.Features) {\n\t\tt.Fatalf(\"features doesn't match: %x vs %x\", e1.Features,\n\t\t\te2.Features)\n\t}\n\n\tif !bytes.Equal(e1.AuthProof.NodeSig1Bytes, e2.AuthProof.NodeSig1Bytes) {\n\t\tt.Fatalf(\"nodesig1 doesn't match: %v vs %v\",\n\t\t\tspew.Sdump(e1.AuthProof.NodeSig1Bytes),\n\t\t\tspew.Sdump(e2.AuthProof.NodeSig1Bytes))\n\t}\n\tif !bytes.Equal(e1.AuthProof.NodeSig2Bytes, e2.AuthProof.NodeSig2Bytes) {\n\t\tt.Fatalf(\"nodesig2 doesn't match\")\n\t}\n\tif !bytes.Equal(e1.AuthProof.BitcoinSig1Bytes, e2.AuthProof.BitcoinSig1Bytes) {\n\t\tt.Fatalf(\"bitcoinsig1 doesn't match\")\n\t}\n\tif !bytes.Equal(e1.AuthProof.BitcoinSig2Bytes, e2.AuthProof.BitcoinSig2Bytes) {\n\t\tt.Fatalf(\"bitcoinsig2 doesn't match\")\n\t}\n\n\tif e1.ChannelPoint != e2.ChannelPoint {\n\t\tt.Fatalf(\"channel point match: %v vs %v\", e1.ChannelPoint,\n\t\t\te2.ChannelPoint)\n\t}\n\n\tif e1.Capacity != e2.Capacity {\n\t\tt.Fatalf(\"capacity doesn't match: %v vs %v\", e1.Capacity,\n\t\t\te2.Capacity)\n\t}\n\n\tif !bytes.Equal(e1.ExtraOpaqueData, e2.ExtraOpaqueData) {\n\t\tt.Fatalf(\"extra data doesn't match: %v vs %v\",\n\t\t\te2.ExtraOpaqueData, e2.ExtraOpaqueData)\n\t}\n}\n",
      "length": 1718,
      "tokens": 158,
      "embedding": []
    },
    {
      "slug": "func createChannelEdge(db kvdb.Backend, node1, node2 *LightningNode) (*ChannelEdgeInfo,",
      "content": "func createChannelEdge(db kvdb.Backend, node1, node2 *LightningNode) (*ChannelEdgeInfo,\n\t*ChannelEdgePolicy, *ChannelEdgePolicy) {\n\n\tvar (\n\t\tfirstNode  *LightningNode\n\t\tsecondNode *LightningNode\n\t)\n\tif bytes.Compare(node1.PubKeyBytes[:], node2.PubKeyBytes[:]) == -1 {\n\t\tfirstNode = node1\n\t\tsecondNode = node2\n\t} else {\n\t\tfirstNode = node2\n\t\tsecondNode = node1\n\t}\n\n\t// In addition to the fake vertexes we create some fake channel\n\t// identifiers.\n\tchanID := uint64(prand.Int63())\n\toutpoint := wire.OutPoint{\n\t\tHash:  rev,\n\t\tIndex: 9,\n\t}\n\n\t// Add the new edge to the database, this should proceed without any\n\t// errors.\n\tedgeInfo := &ChannelEdgeInfo{\n\t\tChannelID: chanID,\n\t\tChainHash: key,\n\t\tAuthProof: &ChannelAuthProof{\n\t\t\tNodeSig1Bytes:    testSig.Serialize(),\n\t\t\tNodeSig2Bytes:    testSig.Serialize(),\n\t\t\tBitcoinSig1Bytes: testSig.Serialize(),\n\t\t\tBitcoinSig2Bytes: testSig.Serialize(),\n\t\t},\n\t\tChannelPoint:    outpoint,\n\t\tCapacity:        1000,\n\t\tExtraOpaqueData: []byte(\"new unknown feature\"),\n\t}\n\tcopy(edgeInfo.NodeKey1Bytes[:], firstNode.PubKeyBytes[:])\n\tcopy(edgeInfo.NodeKey2Bytes[:], secondNode.PubKeyBytes[:])\n\tcopy(edgeInfo.BitcoinKey1Bytes[:], firstNode.PubKeyBytes[:])\n\tcopy(edgeInfo.BitcoinKey2Bytes[:], secondNode.PubKeyBytes[:])\n\n\tedge1 := &ChannelEdgePolicy{\n\t\tSigBytes:                  testSig.Serialize(),\n\t\tChannelID:                 chanID,\n\t\tLastUpdate:                time.Unix(433453, 0),\n\t\tMessageFlags:              1,\n\t\tChannelFlags:              0,\n\t\tTimeLockDelta:             99,\n\t\tMinHTLC:                   2342135,\n\t\tMaxHTLC:                   13928598,\n\t\tFeeBaseMSat:               4352345,\n\t\tFeeProportionalMillionths: 3452352,\n\t\tNode:                      secondNode,\n\t\tExtraOpaqueData:           []byte(\"new unknown feature2\"),\n\t\tdb:                        db,\n\t}\n\tedge2 := &ChannelEdgePolicy{\n\t\tSigBytes:                  testSig.Serialize(),\n\t\tChannelID:                 chanID,\n\t\tLastUpdate:                time.Unix(124234, 0),\n\t\tMessageFlags:              1,\n\t\tChannelFlags:              1,\n\t\tTimeLockDelta:             99,\n\t\tMinHTLC:                   2342135,\n\t\tMaxHTLC:                   13928598,\n\t\tFeeBaseMSat:               4352345,\n\t\tFeeProportionalMillionths: 90392423,\n\t\tNode:                      firstNode,\n\t\tExtraOpaqueData:           []byte(\"new unknown feature1\"),\n\t\tdb:                        db,\n\t}\n\n\treturn edgeInfo, edge1, edge2\n}\n",
      "length": 2229,
      "tokens": 178,
      "embedding": []
    },
    {
      "slug": "func TestEdgeInfoUpdates(t *testing.T) {",
      "content": "func TestEdgeInfoUpdates(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test the update of edges inserted into the database, so\n\t// we create two vertexes to connect.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tassertNodeInCache(t, graph, node1, testFeatures)\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tassertNodeInCache(t, graph, node2, testFeatures)\n\n\t// Create an edge and add it to the db.\n\tedgeInfo, edge1, edge2 := createChannelEdge(graph.db, node1, node2)\n\n\t// Make sure inserting the policy at this point, before the edge info\n\t// is added, will fail.\n\tif err := graph.UpdateEdgePolicy(edge1); err != ErrEdgeNotFound {\n\t\tt.Fatalf(\"expected ErrEdgeNotFound, got: %v\", err)\n\t}\n\trequire.Len(t, graph.graphCache.nodeChannels, 0)\n\n\t// Add the edge info.\n\tif err := graph.AddChannelEdge(edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\tassertEdgeWithNoPoliciesInCache(t, graph, edgeInfo)\n\n\tchanID := edgeInfo.ChannelID\n\toutpoint := edgeInfo.ChannelPoint\n\n\t// Next, insert both edge policies into the database, they should both\n\t// be inserted without any issues.\n\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\tassertEdgeWithPolicyInCache(t, graph, edgeInfo, edge1, true)\n\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\tassertEdgeWithPolicyInCache(t, graph, edgeInfo, edge2, false)\n\n\t// Check for existence of the edge within the database, it should be\n\t// found.\n\t_, _, found, isZombie, err := graph.HasChannelEdge(chanID)\n\trequire.NoError(t, err, \"unable to query for edge\")\n\tif !found {\n\t\tt.Fatalf(\"graph should have of inserted edge\")\n\t}\n\tif isZombie {\n\t\tt.Fatal(\"live edge should not be marked as zombie\")\n\t}\n\n\t// We should also be able to retrieve the channelID only knowing the\n\t// channel point of the channel.\n\tdbChanID, err := graph.ChannelID(&outpoint)\n\trequire.NoError(t, err, \"unable to retrieve channel ID\")\n\tif dbChanID != chanID {\n\t\tt.Fatalf(\"chan ID's mismatch, expected %v got %v\", dbChanID,\n\t\t\tchanID)\n\t}\n\n\t// With the edges inserted, perform some queries to ensure that they've\n\t// been inserted properly.\n\tdbEdgeInfo, dbEdge1, dbEdge2, err := graph.FetchChannelEdgesByID(chanID)\n\trequire.NoError(t, err, \"unable to fetch channel by ID\")\n\tif err := compareEdgePolicies(dbEdge1, edge1); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tif err := compareEdgePolicies(dbEdge2, edge2); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tassertEdgeInfoEqual(t, dbEdgeInfo, edgeInfo)\n\n\t// Next, attempt to query the channel edges according to the outpoint\n\t// of the channel.\n\tdbEdgeInfo, dbEdge1, dbEdge2, err = graph.FetchChannelEdgesByOutpoint(&outpoint)\n\trequire.NoError(t, err, \"unable to fetch channel by ID\")\n\tif err := compareEdgePolicies(dbEdge1, edge1); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tif err := compareEdgePolicies(dbEdge2, edge2); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tassertEdgeInfoEqual(t, dbEdgeInfo, edgeInfo)\n}\n",
      "length": 3319,
      "tokens": 456,
      "embedding": []
    },
    {
      "slug": "func assertNodeInCache(t *testing.T, g *ChannelGraph, n *LightningNode,",
      "content": "func assertNodeInCache(t *testing.T, g *ChannelGraph, n *LightningNode,\n\texpectedFeatures *lnwire.FeatureVector) {\n\n\t// Let's check the internal view first.\n\trequire.Equal(\n\t\tt, expectedFeatures, g.graphCache.nodeFeatures[n.PubKeyBytes],\n\t)\n\n\t// The external view should reflect this as well. Except when we expect\n\t// the features to be nil internally, we return an empty feature vector\n\t// on the public interface instead.\n\tif expectedFeatures == nil {\n\t\texpectedFeatures = lnwire.EmptyFeatureVector()\n\t}\n\tfeatures := g.graphCache.GetFeatures(n.PubKeyBytes)\n\trequire.Equal(t, expectedFeatures, features)\n}\n",
      "length": 520,
      "tokens": 63,
      "embedding": []
    },
    {
      "slug": "func assertNodeNotInCache(t *testing.T, g *ChannelGraph, n route.Vertex) {",
      "content": "func assertNodeNotInCache(t *testing.T, g *ChannelGraph, n route.Vertex) {\n\t_, ok := g.graphCache.nodeFeatures[n]\n\trequire.False(t, ok)\n\n\t_, ok = g.graphCache.nodeChannels[n]\n\trequire.False(t, ok)\n\n\t// We should get the default features for this node.\n\tfeatures := g.graphCache.GetFeatures(n)\n\trequire.Equal(t, lnwire.EmptyFeatureVector(), features)\n}\n",
      "length": 267,
      "tokens": 29,
      "embedding": []
    },
    {
      "slug": "func assertEdgeWithNoPoliciesInCache(t *testing.T, g *ChannelGraph,",
      "content": "func assertEdgeWithNoPoliciesInCache(t *testing.T, g *ChannelGraph,\n\te *ChannelEdgeInfo) {\n\n\t// Let's check the internal view first.\n\trequire.NotEmpty(t, g.graphCache.nodeChannels[e.NodeKey1Bytes])\n\trequire.NotEmpty(t, g.graphCache.nodeChannels[e.NodeKey2Bytes])\n\n\texpectedNode1Channel := &DirectedChannel{\n\t\tChannelID:    e.ChannelID,\n\t\tIsNode1:      true,\n\t\tOtherNode:    e.NodeKey2Bytes,\n\t\tCapacity:     e.Capacity,\n\t\tOutPolicySet: false,\n\t\tInPolicy:     nil,\n\t}\n\trequire.Contains(\n\t\tt, g.graphCache.nodeChannels[e.NodeKey1Bytes], e.ChannelID,\n\t)\n\trequire.Equal(\n\t\tt, expectedNode1Channel,\n\t\tg.graphCache.nodeChannels[e.NodeKey1Bytes][e.ChannelID],\n\t)\n\n\texpectedNode2Channel := &DirectedChannel{\n\t\tChannelID:    e.ChannelID,\n\t\tIsNode1:      false,\n\t\tOtherNode:    e.NodeKey1Bytes,\n\t\tCapacity:     e.Capacity,\n\t\tOutPolicySet: false,\n\t\tInPolicy:     nil,\n\t}\n\trequire.Contains(\n\t\tt, g.graphCache.nodeChannels[e.NodeKey2Bytes], e.ChannelID,\n\t)\n\trequire.Equal(\n\t\tt, expectedNode2Channel,\n\t\tg.graphCache.nodeChannels[e.NodeKey2Bytes][e.ChannelID],\n\t)\n\n\t// The external view should reflect this as well.\n\tvar foundChannel *DirectedChannel\n\terr := g.graphCache.ForEachChannel(\n\t\te.NodeKey1Bytes, func(c *DirectedChannel) error {\n\t\t\tif c.ChannelID == e.ChannelID {\n\t\t\t\tfoundChannel = c\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, foundChannel)\n\trequire.Equal(t, expectedNode1Channel, foundChannel)\n\n\terr = g.graphCache.ForEachChannel(\n\t\te.NodeKey2Bytes, func(c *DirectedChannel) error {\n\t\t\tif c.ChannelID == e.ChannelID {\n\t\t\t\tfoundChannel = c\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t)\n\trequire.NoError(t, err)\n\trequire.NotNil(t, foundChannel)\n\trequire.Equal(t, expectedNode2Channel, foundChannel)\n}\n",
      "length": 1573,
      "tokens": 135,
      "embedding": []
    },
    {
      "slug": "func assertNoEdge(t *testing.T, g *ChannelGraph, chanID uint64) {",
      "content": "func assertNoEdge(t *testing.T, g *ChannelGraph, chanID uint64) {\n\t// Make sure no channel in the cache has the given channel ID. If there\n\t// are no channels at all, that is fine as well.\n\tfor _, channels := range g.graphCache.nodeChannels {\n\t\tfor _, channel := range channels {\n\t\t\trequire.NotEqual(t, channel.ChannelID, chanID)\n\t\t}\n\t}\n}\n",
      "length": 265,
      "tokens": 46,
      "embedding": []
    },
    {
      "slug": "func assertEdgeWithPolicyInCache(t *testing.T, g *ChannelGraph,",
      "content": "func assertEdgeWithPolicyInCache(t *testing.T, g *ChannelGraph,\n\te *ChannelEdgeInfo, p *ChannelEdgePolicy, policy1 bool) {\n\n\t// Check the internal state first.\n\tc1, ok := g.graphCache.nodeChannels[e.NodeKey1Bytes][e.ChannelID]\n\trequire.True(t, ok)\n\n\tif policy1 {\n\t\trequire.True(t, c1.OutPolicySet)\n\t} else {\n\t\trequire.NotNil(t, c1.InPolicy)\n\t\trequire.Equal(\n\t\t\tt, p.FeeProportionalMillionths,\n\t\t\tc1.InPolicy.FeeProportionalMillionths,\n\t\t)\n\t}\n\n\tc2, ok := g.graphCache.nodeChannels[e.NodeKey2Bytes][e.ChannelID]\n\trequire.True(t, ok)\n\n\tif policy1 {\n\t\trequire.NotNil(t, c2.InPolicy)\n\t\trequire.Equal(\n\t\t\tt, p.FeeProportionalMillionths,\n\t\t\tc2.InPolicy.FeeProportionalMillionths,\n\t\t)\n\t} else {\n\t\trequire.True(t, c2.OutPolicySet)\n\t}\n\n\t// Now for both nodes make sure that the external view is also correct.\n\tvar (\n\t\tc1Ext *DirectedChannel\n\t\tc2Ext *DirectedChannel\n\t)\n\trequire.NoError(t, g.graphCache.ForEachChannel(\n\t\te.NodeKey1Bytes, func(c *DirectedChannel) error {\n\t\t\tc1Ext = c\n\n\t\t\treturn nil\n\t\t},\n\t))\n\trequire.NoError(t, g.graphCache.ForEachChannel(\n\t\te.NodeKey2Bytes, func(c *DirectedChannel) error {\n\t\t\tc2Ext = c\n\n\t\t\treturn nil\n\t\t},\n\t))\n\n\t// Only compare the fields that are actually copied, then compare the\n\t// values of the functions separately.\n\trequire.Equal(t, c1, c1Ext.DeepCopy())\n\trequire.Equal(t, c2, c2Ext.DeepCopy())\n\tif policy1 {\n\t\trequire.Equal(\n\t\t\tt, p.FeeProportionalMillionths,\n\t\t\tc2Ext.InPolicy.FeeProportionalMillionths,\n\t\t)\n\t\trequire.Equal(\n\t\t\tt, route.Vertex(e.NodeKey2Bytes),\n\t\t\tc2Ext.InPolicy.ToNodePubKey(),\n\t\t)\n\t\trequire.Equal(t, testFeatures, c2Ext.InPolicy.ToNodeFeatures)\n\t} else {\n\t\trequire.Equal(\n\t\t\tt, p.FeeProportionalMillionths,\n\t\t\tc1Ext.InPolicy.FeeProportionalMillionths,\n\t\t)\n\t\trequire.Equal(\n\t\t\tt, route.Vertex(e.NodeKey1Bytes),\n\t\t\tc1Ext.InPolicy.ToNodePubKey(),\n\t\t)\n\t\trequire.Equal(t, testFeatures, c1Ext.InPolicy.ToNodeFeatures)\n\t}\n}\n",
      "length": 1731,
      "tokens": 164,
      "embedding": []
    },
    {
      "slug": "func randEdgePolicy(chanID uint64, db kvdb.Backend) *ChannelEdgePolicy {",
      "content": "func randEdgePolicy(chanID uint64, db kvdb.Backend) *ChannelEdgePolicy {\n\tupdate := prand.Int63()\n\n\treturn newEdgePolicy(chanID, db, update)\n}\n",
      "length": 66,
      "tokens": 8,
      "embedding": []
    },
    {
      "slug": "func newEdgePolicy(chanID uint64, db kvdb.Backend,",
      "content": "func newEdgePolicy(chanID uint64, db kvdb.Backend,\n\tupdateTime int64) *ChannelEdgePolicy {\n\n\treturn &ChannelEdgePolicy{\n\t\tChannelID:                 chanID,\n\t\tLastUpdate:                time.Unix(updateTime, 0),\n\t\tMessageFlags:              1,\n\t\tChannelFlags:              0,\n\t\tTimeLockDelta:             uint16(prand.Int63()),\n\t\tMinHTLC:                   lnwire.MilliSatoshi(prand.Int63()),\n\t\tMaxHTLC:                   lnwire.MilliSatoshi(prand.Int63()),\n\t\tFeeBaseMSat:               lnwire.MilliSatoshi(prand.Int63()),\n\t\tFeeProportionalMillionths: lnwire.MilliSatoshi(prand.Int63()),\n\t\tdb:                        db,\n\t}\n}\n",
      "length": 560,
      "tokens": 29,
      "embedding": []
    },
    {
      "slug": "func TestGraphTraversal(t *testing.T) {",
      "content": "func TestGraphTraversal(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test some of the graph traversal capabilities within\n\t// the DB, so we'll create a series of fake nodes to insert into the\n\t// graph. And we'll create 5 channels between each node pair.\n\tconst numNodes = 20\n\tconst numChannels = 5\n\tchanIndex, nodeList := fillTestGraph(t, graph, numNodes, numChannels)\n\n\t// Make an index of the node list for easy look up below.\n\tnodeIndex := make(map[route.Vertex]struct{})\n\tfor _, node := range nodeList {\n\t\tnodeIndex[node.PubKeyBytes] = struct{}{}\n\t}\n\n\t// If we turn the channel graph cache _off_, then iterate through the\n\t// set of channels (to force the fall back), we should find all the\n\t// channel as well as the nodes included.\n\tgraph.graphCache = nil\n\terr = graph.ForEachNodeCached(func(node route.Vertex,\n\t\tchans map[uint64]*DirectedChannel) error {\n\n\t\tif _, ok := nodeIndex[node]; !ok {\n\t\t\treturn fmt.Errorf(\"node %x not found in graph\", node)\n\t\t}\n\n\t\tfor chanID := range chans {\n\t\t\tif _, ok := chanIndex[chanID]; !ok {\n\t\t\t\treturn fmt.Errorf(\"chan %v not found in \"+\n\t\t\t\t\t\"graph\", chanID)\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\trequire.NoError(t, err)\n\n\t// Iterate through all the known channels within the graph DB, once\n\t// again if the map is empty that indicates that all edges have\n\t// properly been reached.\n\terr = graph.ForEachChannel(func(ei *ChannelEdgeInfo, _ *ChannelEdgePolicy,\n\t\t_ *ChannelEdgePolicy) error {\n\n\t\tdelete(chanIndex, ei.ChannelID)\n\t\treturn nil\n\t})\n\trequire.NoError(t, err)\n\trequire.Len(t, chanIndex, 0)\n\n\t// Finally, we want to test the ability to iterate over all the\n\t// outgoing channels for a particular node.\n\tnumNodeChans := 0\n\tfirstNode, secondNode := nodeList[0], nodeList[1]\n\terr = firstNode.ForEachChannel(nil, func(_ kvdb.RTx, _ *ChannelEdgeInfo,\n\t\toutEdge, inEdge *ChannelEdgePolicy) error {\n\n\t\t// All channels between first and second node should have fully\n\t\t// (both sides) specified policies.\n\t\tif inEdge == nil || outEdge == nil {\n\t\t\treturn fmt.Errorf(\"channel policy not present\")\n\t\t}\n\n\t\t// Each should indicate that it's outgoing (pointed\n\t\t// towards the second node).\n\t\tif !bytes.Equal(outEdge.Node.PubKeyBytes[:], secondNode.PubKeyBytes[:]) {\n\t\t\treturn fmt.Errorf(\"wrong outgoing edge\")\n\t\t}\n\n\t\t// The incoming edge should also indicate that it's pointing to\n\t\t// the origin node.\n\t\tif !bytes.Equal(inEdge.Node.PubKeyBytes[:], firstNode.PubKeyBytes[:]) {\n\t\t\treturn fmt.Errorf(\"wrong outgoing edge\")\n\t\t}\n\n\t\tnumNodeChans++\n\t\treturn nil\n\t})\n\trequire.NoError(t, err)\n\trequire.Equal(t, numChannels, numNodeChans)\n}\n\n// TestGraphTraversalCacheable tests that the memory optimized node traversal is\n// working correctly.",
      "length": 2630,
      "tokens": 372,
      "embedding": []
    },
    {
      "slug": "func TestGraphTraversalCacheable(t *testing.T) {",
      "content": "func TestGraphTraversalCacheable(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test some of the graph traversal capabilities within\n\t// the DB, so we'll create a series of fake nodes to insert into the\n\t// graph. And we'll create 5 channels between the first two nodes.\n\tconst numNodes = 20\n\tconst numChannels = 5\n\tchanIndex, _ := fillTestGraph(t, graph, numNodes, numChannels)\n\n\t// Create a map of all nodes with the iteration we know works (because\n\t// it is tested in another test).\n\tnodeMap := make(map[route.Vertex]struct{})\n\terr = graph.ForEachNode(func(tx kvdb.RTx, n *LightningNode) error {\n\t\tnodeMap[n.PubKeyBytes] = struct{}{}\n\n\t\treturn nil\n\t})\n\trequire.NoError(t, err)\n\trequire.Len(t, nodeMap, numNodes)\n\n\t// Iterate through all the known channels within the graph DB by\n\t// iterating over each node, once again if the map is empty that\n\t// indicates that all edges have properly been reached.\n\tvar nodes []GraphCacheNode\n\terr = graph.ForEachNodeCacheable(\n\t\tfunc(tx kvdb.RTx, node GraphCacheNode) error {\n\t\t\tdelete(nodeMap, node.PubKey())\n\n\t\t\tnodes = append(nodes, node)\n\n\t\t\treturn nil\n\t\t},\n\t)\n\trequire.NoError(t, err)\n\trequire.Len(t, nodeMap, 0)\n\n\terr = graph.db.View(func(tx kvdb.RTx) error {\n\t\tfor _, node := range nodes {\n\t\t\terr := node.ForEachChannel(\n\t\t\t\ttx, func(tx kvdb.RTx, info *ChannelEdgeInfo,\n\t\t\t\t\tpolicy *ChannelEdgePolicy,\n\t\t\t\t\tpolicy2 *ChannelEdgePolicy) error {\n\n\t\t\t\t\tdelete(chanIndex, info.ChannelID)\n\t\t\t\t\treturn nil\n\t\t\t\t},\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n\n\trequire.NoError(t, err)\n\trequire.Len(t, chanIndex, 0)\n}\n",
      "length": 1571,
      "tokens": 223,
      "embedding": []
    },
    {
      "slug": "func TestGraphCacheTraversal(t *testing.T) {",
      "content": "func TestGraphCacheTraversal(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err)\n\n\t// We'd like to test some of the graph traversal capabilities within\n\t// the DB, so we'll create a series of fake nodes to insert into the\n\t// graph. And we'll create 5 channels between each node pair.\n\tconst numNodes = 20\n\tconst numChannels = 5\n\tchanIndex, nodeList := fillTestGraph(t, graph, numNodes, numChannels)\n\n\t// Iterate through all the known channels within the graph DB, once\n\t// again if the map is empty that indicates that all edges have\n\t// properly been reached.\n\tnumNodeChans := 0\n\tfor _, node := range nodeList {\n\t\tnode := node\n\n\t\terr = graph.graphCache.ForEachChannel(\n\t\t\tnode.PubKeyBytes, func(d *DirectedChannel) error {\n\t\t\t\tdelete(chanIndex, d.ChannelID)\n\n\t\t\t\tif !d.OutPolicySet || d.InPolicy == nil {\n\t\t\t\t\treturn fmt.Errorf(\"channel policy not \" +\n\t\t\t\t\t\t\"present\")\n\t\t\t\t}\n\n\t\t\t\t// The incoming edge should also indicate that\n\t\t\t\t// it's pointing to the origin node.\n\t\t\t\tinPolicyNodeKey := d.InPolicy.ToNodePubKey()\n\t\t\t\tif !bytes.Equal(\n\t\t\t\t\tinPolicyNodeKey[:], node.PubKeyBytes[:],\n\t\t\t\t) {\n\n\t\t\t\t\treturn fmt.Errorf(\"wrong outgoing edge\")\n\t\t\t\t}\n\n\t\t\t\tnumNodeChans++\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t)\n\t\trequire.NoError(t, err)\n\t}\n\trequire.Len(t, chanIndex, 0)\n\n\t// We count the channels for both nodes, so there should be double the\n\t// amount now. Except for the very last node, that doesn't have any\n\t// channels to make the loop easier in fillTestGraph().\n\trequire.Equal(t, numChannels*2*(numNodes-1), numNodeChans)\n}\n",
      "length": 1452,
      "tokens": 207,
      "embedding": []
    },
    {
      "slug": "func fillTestGraph(t require.TestingT, graph *ChannelGraph, numNodes,",
      "content": "func fillTestGraph(t require.TestingT, graph *ChannelGraph, numNodes,\n\tnumChannels int) (map[uint64]struct{}, []*LightningNode) {\n\n\tnodes := make([]*LightningNode, numNodes)\n\tnodeIndex := map[string]struct{}{}\n\tfor i := 0; i < numNodes; i++ {\n\t\tnode, err := createTestVertex(graph.db)\n\t\trequire.NoError(t, err)\n\n\t\tnodes[i] = node\n\t\tnodeIndex[node.Alias] = struct{}{}\n\t}\n\n\t// Add each of the nodes into the graph, they should be inserted\n\t// without error.\n\tfor _, node := range nodes {\n\t\trequire.NoError(t, graph.AddLightningNode(node))\n\t}\n\n\t// Iterate over each node as returned by the graph, if all nodes are\n\t// reached, then the map created above should be empty.\n\terr := graph.ForEachNode(func(_ kvdb.RTx, node *LightningNode) error {\n\t\tdelete(nodeIndex, node.Alias)\n\t\treturn nil\n\t})\n\trequire.NoError(t, err)\n\trequire.Len(t, nodeIndex, 0)\n\n\t// Create a number of channels between each of the node pairs generated\n\t// above. This will result in numChannels*(numNodes-1) channels.\n\tchanIndex := map[uint64]struct{}{}\n\tfor n := 0; n < numNodes-1; n++ {\n\t\tnode1 := nodes[n]\n\t\tnode2 := nodes[n+1]\n\t\tif bytes.Compare(node1.PubKeyBytes[:], node2.PubKeyBytes[:]) == -1 {\n\t\t\tnode1, node2 = node2, node1\n\t\t}\n\n\t\tfor i := 0; i < numChannels; i++ {\n\t\t\ttxHash := sha256.Sum256([]byte{byte(i)})\n\t\t\tchanID := uint64((n << 8) + i + 1)\n\t\t\top := wire.OutPoint{\n\t\t\t\tHash:  txHash,\n\t\t\t\tIndex: 0,\n\t\t\t}\n\n\t\t\tedgeInfo := ChannelEdgeInfo{\n\t\t\t\tChannelID: chanID,\n\t\t\t\tChainHash: key,\n\t\t\t\tAuthProof: &ChannelAuthProof{\n\t\t\t\t\tNodeSig1Bytes:    testSig.Serialize(),\n\t\t\t\t\tNodeSig2Bytes:    testSig.Serialize(),\n\t\t\t\t\tBitcoinSig1Bytes: testSig.Serialize(),\n\t\t\t\t\tBitcoinSig2Bytes: testSig.Serialize(),\n\t\t\t\t},\n\t\t\t\tChannelPoint: op,\n\t\t\t\tCapacity:     1000,\n\t\t\t}\n\t\t\tcopy(edgeInfo.NodeKey1Bytes[:], node1.PubKeyBytes[:])\n\t\t\tcopy(edgeInfo.NodeKey2Bytes[:], node2.PubKeyBytes[:])\n\t\t\tcopy(edgeInfo.BitcoinKey1Bytes[:], node1.PubKeyBytes[:])\n\t\t\tcopy(edgeInfo.BitcoinKey2Bytes[:], node2.PubKeyBytes[:])\n\t\t\terr := graph.AddChannelEdge(&edgeInfo)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// Create and add an edge with random data that points\n\t\t\t// from node1 -> node2.\n\t\t\tedge := randEdgePolicy(chanID, graph.db)\n\t\t\tedge.ChannelFlags = 0\n\t\t\tedge.Node = node2\n\t\t\tedge.SigBytes = testSig.Serialize()\n\t\t\trequire.NoError(t, graph.UpdateEdgePolicy(edge))\n\n\t\t\t// Create another random edge that points from\n\t\t\t// node2 -> node1 this time.\n\t\t\tedge = randEdgePolicy(chanID, graph.db)\n\t\t\tedge.ChannelFlags = 1\n\t\t\tedge.Node = node1\n\t\t\tedge.SigBytes = testSig.Serialize()\n\t\t\trequire.NoError(t, graph.UpdateEdgePolicy(edge))\n\n\t\t\tchanIndex[chanID] = struct{}{}\n\t\t}\n\t}\n\n\treturn chanIndex, nodes\n}\n",
      "length": 2476,
      "tokens": 287,
      "embedding": []
    },
    {
      "slug": "func assertPruneTip(t *testing.T, graph *ChannelGraph, blockHash *chainhash.Hash,",
      "content": "func assertPruneTip(t *testing.T, graph *ChannelGraph, blockHash *chainhash.Hash,\n\tblockHeight uint32) {\n\n\tpruneHash, pruneHeight, err := graph.PruneTip()\n\tif err != nil {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: unable to fetch prune tip: %v\", line, err)\n\t}\n\tif !bytes.Equal(blockHash[:], pruneHash[:]) {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line: %v, prune tips don't match, expected %x got %x\",\n\t\t\tline, blockHash, pruneHash)\n\t}\n\tif pruneHeight != blockHeight {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: prune heights don't match, expected %v \"+\n\t\t\t\"got %v\", line, blockHeight, pruneHeight)\n\t}\n}\n",
      "length": 544,
      "tokens": 81,
      "embedding": []
    },
    {
      "slug": "func assertNumChans(t *testing.T, graph *ChannelGraph, n int) {",
      "content": "func assertNumChans(t *testing.T, graph *ChannelGraph, n int) {\n\tnumChans := 0\n\tif err := graph.ForEachChannel(func(*ChannelEdgeInfo, *ChannelEdgePolicy,\n\t\t*ChannelEdgePolicy) error {\n\n\t\tnumChans++\n\t\treturn nil\n\t}); err != nil {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: unable to scan channels: %v\", line, err)\n\t}\n\tif numChans != n {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: expected %v chans instead have %v\", line,\n\t\t\tn, numChans)\n\t}\n}\n",
      "length": 392,
      "tokens": 59,
      "embedding": []
    },
    {
      "slug": "func assertNumNodes(t *testing.T, graph *ChannelGraph, n int) {",
      "content": "func assertNumNodes(t *testing.T, graph *ChannelGraph, n int) {\n\tnumNodes := 0\n\terr := graph.ForEachNode(func(_ kvdb.RTx, _ *LightningNode) error {\n\t\tnumNodes++\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: unable to scan nodes: %v\", line, err)\n\t}\n\n\tif numNodes != n {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: expected %v nodes, got %v\", line, n, numNodes)\n\t}\n}\n",
      "length": 346,
      "tokens": 59,
      "embedding": []
    },
    {
      "slug": "func assertChanViewEqual(t *testing.T, a []EdgePoint, b []EdgePoint) {",
      "content": "func assertChanViewEqual(t *testing.T, a []EdgePoint, b []EdgePoint) {\n\tif len(a) != len(b) {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: chan views don't match\", line)\n\t}\n\n\tchanViewSet := make(map[wire.OutPoint]struct{})\n\tfor _, op := range a {\n\t\tchanViewSet[op.OutPoint] = struct{}{}\n\t}\n\n\tfor _, op := range b {\n\t\tif _, ok := chanViewSet[op.OutPoint]; !ok {\n\t\t\t_, _, line, _ := runtime.Caller(1)\n\t\t\tt.Fatalf(\"line %v: chanPoint(%v) not found in first \"+\n\t\t\t\t\"view\", line, op)\n\t\t}\n\t}\n}\n",
      "length": 412,
      "tokens": 67,
      "embedding": []
    },
    {
      "slug": "func assertChanViewEqualChanPoints(t *testing.T, a []EdgePoint, b []*wire.OutPoint) {",
      "content": "func assertChanViewEqualChanPoints(t *testing.T, a []EdgePoint, b []*wire.OutPoint) {\n\tif len(a) != len(b) {\n\t\t_, _, line, _ := runtime.Caller(1)\n\t\tt.Fatalf(\"line %v: chan views don't match\", line)\n\t}\n\n\tchanViewSet := make(map[wire.OutPoint]struct{})\n\tfor _, op := range a {\n\t\tchanViewSet[op.OutPoint] = struct{}{}\n\t}\n\n\tfor _, op := range b {\n\t\tif _, ok := chanViewSet[*op]; !ok {\n\t\t\t_, _, line, _ := runtime.Caller(1)\n\t\t\tt.Fatalf(\"line %v: chanPoint(%v) not found in first \"+\n\t\t\t\t\"view\", line, op)\n\t\t}\n\t}\n}\n",
      "length": 404,
      "tokens": 67,
      "embedding": []
    },
    {
      "slug": "func TestGraphPruning(t *testing.T) {",
      "content": "func TestGraphPruning(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\tsourceNode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create source node\")\n\tif err := graph.SetSourceNode(sourceNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\t// As initial set up for the test, we'll create a graph with 5 vertexes\n\t// and enough edges to create a fully connected graph. The graph will\n\t// be rather simple, representing a straight line.\n\tconst numNodes = 5\n\tgraphNodes := make([]*LightningNode, numNodes)\n\tfor i := 0; i < numNodes; i++ {\n\t\tnode, err := createTestVertex(graph.db)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to create node: %v\", err)\n\t\t}\n\n\t\tif err := graph.AddLightningNode(node); err != nil {\n\t\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t\t}\n\n\t\tgraphNodes[i] = node\n\t}\n\n\t// With the vertexes created, we'll next create a series of channels\n\t// between them.\n\tchannelPoints := make([]*wire.OutPoint, 0, numNodes-1)\n\tedgePoints := make([]EdgePoint, 0, numNodes-1)\n\tfor i := 0; i < numNodes-1; i++ {\n\t\ttxHash := sha256.Sum256([]byte{byte(i)})\n\t\tchanID := uint64(i + 1)\n\t\top := wire.OutPoint{\n\t\t\tHash:  txHash,\n\t\t\tIndex: 0,\n\t\t}\n\n\t\tchannelPoints = append(channelPoints, &op)\n\n\t\tedgeInfo := ChannelEdgeInfo{\n\t\t\tChannelID: chanID,\n\t\t\tChainHash: key,\n\t\t\tAuthProof: &ChannelAuthProof{\n\t\t\t\tNodeSig1Bytes:    testSig.Serialize(),\n\t\t\t\tNodeSig2Bytes:    testSig.Serialize(),\n\t\t\t\tBitcoinSig1Bytes: testSig.Serialize(),\n\t\t\t\tBitcoinSig2Bytes: testSig.Serialize(),\n\t\t\t},\n\t\t\tChannelPoint: op,\n\t\t\tCapacity:     1000,\n\t\t}\n\t\tcopy(edgeInfo.NodeKey1Bytes[:], graphNodes[i].PubKeyBytes[:])\n\t\tcopy(edgeInfo.NodeKey2Bytes[:], graphNodes[i+1].PubKeyBytes[:])\n\t\tcopy(edgeInfo.BitcoinKey1Bytes[:], graphNodes[i].PubKeyBytes[:])\n\t\tcopy(edgeInfo.BitcoinKey2Bytes[:], graphNodes[i+1].PubKeyBytes[:])\n\t\tif err := graph.AddChannelEdge(&edgeInfo); err != nil {\n\t\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t\t}\n\n\t\tpkScript, err := genMultiSigP2WSH(\n\t\t\tedgeInfo.BitcoinKey1Bytes[:], edgeInfo.BitcoinKey2Bytes[:],\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to gen multi-sig p2wsh: %v\", err)\n\t\t}\n\t\tedgePoints = append(edgePoints, EdgePoint{\n\t\t\tFundingPkScript: pkScript,\n\t\t\tOutPoint:        op,\n\t\t})\n\n\t\t// Create and add an edge with random data that points from\n\t\t// node_i -> node_i+1\n\t\tedge := randEdgePolicy(chanID, graph.db)\n\t\tedge.ChannelFlags = 0\n\t\tedge.Node = graphNodes[i]\n\t\tedge.SigBytes = testSig.Serialize()\n\t\tif err := graph.UpdateEdgePolicy(edge); err != nil {\n\t\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t\t}\n\n\t\t// Create another random edge that points from node_i+1 ->\n\t\t// node_i this time.\n\t\tedge = randEdgePolicy(chanID, graph.db)\n\t\tedge.ChannelFlags = 1\n\t\tedge.Node = graphNodes[i]\n\t\tedge.SigBytes = testSig.Serialize()\n\t\tif err := graph.UpdateEdgePolicy(edge); err != nil {\n\t\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t\t}\n\t}\n\n\t// With all the channel points added, we'll consult the graph to ensure\n\t// it has the same channel view as the one we just constructed.\n\tchannelView, err := graph.ChannelView()\n\trequire.NoError(t, err, \"unable to get graph channel view\")\n\tassertChanViewEqual(t, channelView, edgePoints)\n\n\t// Now with our test graph created, we can test the pruning\n\t// capabilities of the channel graph.\n\n\t// First we create a mock block that ends up closing the first two\n\t// channels.\n\tvar blockHash chainhash.Hash\n\tcopy(blockHash[:], bytes.Repeat([]byte{1}, 32))\n\tblockHeight := uint32(1)\n\tblock := channelPoints[:2]\n\tprunedChans, err := graph.PruneGraph(block, &blockHash, blockHeight)\n\trequire.NoError(t, err, \"unable to prune graph\")\n\tif len(prunedChans) != 2 {\n\t\tt.Fatalf(\"incorrect number of channels pruned: \"+\n\t\t\t\"expected %v, got %v\", 2, prunedChans)\n\t}\n\n\t// Now ensure that the prune tip has been updated.\n\tassertPruneTip(t, graph, &blockHash, blockHeight)\n\n\t// Count up the number of channels known within the graph, only 2\n\t// should be remaining.\n\tassertNumChans(t, graph, 2)\n\n\t// Those channels should also be missing from the channel view.\n\tchannelView, err = graph.ChannelView()\n\trequire.NoError(t, err, \"unable to get graph channel view\")\n\tassertChanViewEqualChanPoints(t, channelView, channelPoints[2:])\n\n\t// Next we'll create a block that doesn't close any channels within the\n\t// graph to test the negative error case.\n\tfakeHash := sha256.Sum256([]byte(\"test prune\"))\n\tnonChannel := &wire.OutPoint{\n\t\tHash:  fakeHash,\n\t\tIndex: 9,\n\t}\n\tblockHash = sha256.Sum256(blockHash[:])\n\tblockHeight = 2\n\tprunedChans, err = graph.PruneGraph(\n\t\t[]*wire.OutPoint{nonChannel}, &blockHash, blockHeight,\n\t)\n\trequire.NoError(t, err, \"unable to prune graph\")\n\n\t// No channels should have been detected as pruned.\n\tif len(prunedChans) != 0 {\n\t\tt.Fatalf(\"channels were pruned but shouldn't have been\")\n\t}\n\n\t// Once again, the prune tip should have been updated. We should still\n\t// see both channels and their participants, along with the source node.\n\tassertPruneTip(t, graph, &blockHash, blockHeight)\n\tassertNumChans(t, graph, 2)\n\tassertNumNodes(t, graph, 4)\n\n\t// Finally, create a block that prunes the remainder of the channels\n\t// from the graph.\n\tblockHash = sha256.Sum256(blockHash[:])\n\tblockHeight = 3\n\tprunedChans, err = graph.PruneGraph(\n\t\tchannelPoints[2:], &blockHash, blockHeight,\n\t)\n\trequire.NoError(t, err, \"unable to prune graph\")\n\n\t// The remainder of the channels should have been pruned from the\n\t// graph.\n\tif len(prunedChans) != 2 {\n\t\tt.Fatalf(\"incorrect number of channels pruned: \"+\n\t\t\t\"expected %v, got %v\", 2, len(prunedChans))\n\t}\n\n\t// The prune tip should be updated, no channels should be found, and\n\t// only the source node should remain within the current graph.\n\tassertPruneTip(t, graph, &blockHash, blockHeight)\n\tassertNumChans(t, graph, 0)\n\tassertNumNodes(t, graph, 1)\n\n\t// Finally, the channel view at this point in the graph should now be\n\t// completely empty.  Those channels should also be missing from the\n\t// channel view.\n\tchannelView, err = graph.ChannelView()\n\trequire.NoError(t, err, \"unable to get graph channel view\")\n\tif len(channelView) != 0 {\n\t\tt.Fatalf(\"channel view should be empty, instead have: %v\",\n\t\t\tchannelView)\n\t}\n}\n\n// TestHighestChanID tests that we're able to properly retrieve the highest\n// known channel ID in the database.",
      "length": 6079,
      "tokens": 806,
      "embedding": []
    },
    {
      "slug": "func TestHighestChanID(t *testing.T) {",
      "content": "func TestHighestChanID(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// If we don't yet have any channels in the database, then we should\n\t// get a channel ID of zero if we ask for the highest channel ID.\n\tbestID, err := graph.HighestChanID()\n\trequire.NoError(t, err, \"unable to get highest ID\")\n\tif bestID != 0 {\n\t\tt.Fatalf(\"best ID w/ no chan should be zero, is instead: %v\",\n\t\t\tbestID)\n\t}\n\n\t// Next, we'll insert two channels into the database, with each channel\n\t// connecting the same two nodes.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\t// The first channel with be at height 10, while the other will be at\n\t// height 100.\n\tedge1, _ := createEdge(10, 0, 0, 0, node1, node2)\n\tedge2, chanID2 := createEdge(100, 0, 0, 0, node1, node2)\n\n\tif err := graph.AddChannelEdge(&edge1); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\tif err := graph.AddChannelEdge(&edge2); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\t// Now that the edges has been inserted, we'll query for the highest\n\t// known channel ID in the database.\n\tbestID, err = graph.HighestChanID()\n\trequire.NoError(t, err, \"unable to get highest ID\")\n\n\tif bestID != chanID2.ToUint64() {\n\t\tt.Fatalf(\"expected %v got %v for best chan ID: \",\n\t\t\tchanID2.ToUint64(), bestID)\n\t}\n\n\t// If we add another edge, then the current best chan ID should be\n\t// updated as well.\n\tedge3, chanID3 := createEdge(1000, 0, 0, 0, node1, node2)\n\tif err := graph.AddChannelEdge(&edge3); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\tbestID, err = graph.HighestChanID()\n\trequire.NoError(t, err, \"unable to get highest ID\")\n\n\tif bestID != chanID3.ToUint64() {\n\t\tt.Fatalf(\"expected %v got %v for best chan ID: \",\n\t\t\tchanID3.ToUint64(), bestID)\n\t}\n}\n\n// TestChanUpdatesInHorizon tests the we're able to properly retrieve all known\n// channel updates within a specific time horizon. It also tests that upon\n// insertion of a new edge, the edge update index is updated properly.",
      "length": 2110,
      "tokens": 335,
      "embedding": []
    },
    {
      "slug": "func TestChanUpdatesInHorizon(t *testing.T) {",
      "content": "func TestChanUpdatesInHorizon(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// If we issue an arbitrary query before any channel updates are\n\t// inserted in the database, we should get zero results.\n\tchanUpdates, err := graph.ChanUpdatesInHorizon(\n\t\ttime.Unix(999, 0), time.Unix(9999, 0),\n\t)\n\trequire.NoError(t, err, \"unable to updates for updates\")\n\tif len(chanUpdates) != 0 {\n\t\tt.Fatalf(\"expected 0 chan updates, instead got %v\",\n\t\t\tlen(chanUpdates))\n\t}\n\n\t// We'll start by creating two nodes which will seed our test graph.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// We'll now create 10 channels between the two nodes, with update\n\t// times 10 seconds after each other.\n\tconst numChans = 10\n\tstartTime := time.Unix(1234, 0)\n\tendTime := startTime\n\tedges := make([]ChannelEdge, 0, numChans)\n\tfor i := 0; i < numChans; i++ {\n\t\tchannel, chanID := createEdge(\n\t\t\tuint32(i*10), 0, 0, 0, node1, node2,\n\t\t)\n\n\t\tif err := graph.AddChannelEdge(&channel); err != nil {\n\t\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t\t}\n\n\t\tedge1UpdateTime := endTime\n\t\tedge2UpdateTime := edge1UpdateTime.Add(time.Second)\n\t\tendTime = endTime.Add(time.Second * 10)\n\n\t\tedge1 := newEdgePolicy(\n\t\t\tchanID.ToUint64(), graph.db, edge1UpdateTime.Unix(),\n\t\t)\n\t\tedge1.ChannelFlags = 0\n\t\tedge1.Node = node2\n\t\tedge1.SigBytes = testSig.Serialize()\n\t\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t\t}\n\n\t\tedge2 := newEdgePolicy(\n\t\t\tchanID.ToUint64(), graph.db, edge2UpdateTime.Unix(),\n\t\t)\n\t\tedge2.ChannelFlags = 1\n\t\tedge2.Node = node1\n\t\tedge2.SigBytes = testSig.Serialize()\n\t\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t\t}\n\n\t\tedges = append(edges, ChannelEdge{\n\t\t\tInfo:    &channel,\n\t\t\tPolicy1: edge1,\n\t\t\tPolicy2: edge2,\n\t\t})\n\t}\n\n\t// With our channels loaded, we'll now start our series of queries.\n\tqueryCases := []struct {\n\t\tstart time.Time\n\t\tend   time.Time\n\n\t\tresp []ChannelEdge\n\t}{\n\t\t// If we query for a time range that's strictly below our set\n\t\t// of updates, then we'll get an empty result back.\n\t\t{\n\t\t\tstart: time.Unix(100, 0),\n\t\t\tend:   time.Unix(200, 0),\n\t\t},\n\n\t\t// If we query for a time range that's well beyond our set of\n\t\t// updates, we should get an empty set of results back.\n\t\t{\n\t\t\tstart: time.Unix(99999, 0),\n\t\t\tend:   time.Unix(999999, 0),\n\t\t},\n\n\t\t// If we query for the start time, and 10 seconds directly\n\t\t// after it, we should only get a single update, that first\n\t\t// one.\n\t\t{\n\t\t\tstart: time.Unix(1234, 0),\n\t\t\tend:   startTime.Add(time.Second * 10),\n\n\t\t\tresp: []ChannelEdge{edges[0]},\n\t\t},\n\n\t\t// If we add 10 seconds past the first update, and then\n\t\t// subtract 10 from the last update, then we should only get\n\t\t// the 8 edges in the middle.\n\t\t{\n\t\t\tstart: startTime.Add(time.Second * 10),\n\t\t\tend:   endTime.Add(-time.Second * 10),\n\n\t\t\tresp: edges[1:9],\n\t\t},\n\n\t\t// If we use the start and end time as is, we should get the\n\t\t// entire range.\n\t\t{\n\t\t\tstart: startTime,\n\t\t\tend:   endTime,\n\n\t\t\tresp: edges,\n\t\t},\n\t}\n\tfor _, queryCase := range queryCases {\n\t\tresp, err := graph.ChanUpdatesInHorizon(\n\t\t\tqueryCase.start, queryCase.end,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to query for updates: %v\", err)\n\t\t}\n\n\t\tif len(resp) != len(queryCase.resp) {\n\t\t\tt.Fatalf(\"expected %v chans, got %v chans\",\n\t\t\t\tlen(queryCase.resp), len(resp))\n\n\t\t}\n\n\t\tfor i := 0; i < len(resp); i++ {\n\t\t\tchanExp := queryCase.resp[i]\n\t\t\tchanRet := resp[i]\n\n\t\t\tassertEdgeInfoEqual(t, chanExp.Info, chanRet.Info)\n\n\t\t\terr := compareEdgePolicies(chanExp.Policy1, chanRet.Policy1)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tcompareEdgePolicies(chanExp.Policy2, chanRet.Policy2)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// TestNodeUpdatesInHorizon tests that we're able to properly scan and retrieve\n// the most recent node updates within a particular time horizon.",
      "length": 4075,
      "tokens": 583,
      "embedding": []
    },
    {
      "slug": "func TestNodeUpdatesInHorizon(t *testing.T) {",
      "content": "func TestNodeUpdatesInHorizon(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\tstartTime := time.Unix(1234, 0)\n\tendTime := startTime\n\n\t// If we issue an arbitrary query before we insert any nodes into the\n\t// database, then we shouldn't get any results back.\n\tnodeUpdates, err := graph.NodeUpdatesInHorizon(\n\t\ttime.Unix(999, 0), time.Unix(9999, 0),\n\t)\n\trequire.NoError(t, err, \"unable to query for node updates\")\n\tif len(nodeUpdates) != 0 {\n\t\tt.Fatalf(\"expected 0 node updates, instead got %v\",\n\t\t\tlen(nodeUpdates))\n\t}\n\n\t// We'll create 10 node announcements, each with an update timestamp 10\n\t// seconds after the other.\n\tconst numNodes = 10\n\tnodeAnns := make([]LightningNode, 0, numNodes)\n\tfor i := 0; i < numNodes; i++ {\n\t\tnodeAnn, err := createTestVertex(graph.db)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to create test vertex: %v\", err)\n\t\t}\n\n\t\t// The node ann will use the current end time as its last\n\t\t// update them, then we'll add 10 seconds in order to create\n\t\t// the proper update time for the next node announcement.\n\t\tupdateTime := endTime\n\t\tendTime = updateTime.Add(time.Second * 10)\n\n\t\tnodeAnn.LastUpdate = updateTime\n\n\t\tnodeAnns = append(nodeAnns, *nodeAnn)\n\n\t\tif err := graph.AddLightningNode(nodeAnn); err != nil {\n\t\t\tt.Fatalf(\"unable to add lightning node: %v\", err)\n\t\t}\n\t}\n\n\tqueryCases := []struct {\n\t\tstart time.Time\n\t\tend   time.Time\n\n\t\tresp []LightningNode\n\t}{\n\t\t// If we query for a time range that's strictly below our set\n\t\t// of updates, then we'll get an empty result back.\n\t\t{\n\t\t\tstart: time.Unix(100, 0),\n\t\t\tend:   time.Unix(200, 0),\n\t\t},\n\n\t\t// If we query for a time range that's well beyond our set of\n\t\t// updates, we should get an empty set of results back.\n\t\t{\n\t\t\tstart: time.Unix(99999, 0),\n\t\t\tend:   time.Unix(999999, 0),\n\t\t},\n\n\t\t// If we skip he first time epoch with out start time, then we\n\t\t// should get back every now but the first.\n\t\t{\n\t\t\tstart: startTime.Add(time.Second * 10),\n\t\t\tend:   endTime,\n\n\t\t\tresp: nodeAnns[1:],\n\t\t},\n\n\t\t// If we query for the range as is, we should get all 10\n\t\t// announcements back.\n\t\t{\n\t\t\tstart: startTime,\n\t\t\tend:   endTime,\n\n\t\t\tresp: nodeAnns,\n\t\t},\n\n\t\t// If we reduce the ending time by 10 seconds, then we should\n\t\t// get all but the last node we inserted.\n\t\t{\n\t\t\tstart: startTime,\n\t\t\tend:   endTime.Add(-time.Second * 10),\n\n\t\t\tresp: nodeAnns[:9],\n\t\t},\n\t}\n\tfor _, queryCase := range queryCases {\n\t\tresp, err := graph.NodeUpdatesInHorizon(queryCase.start, queryCase.end)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to query for nodes: %v\", err)\n\t\t}\n\n\t\tif len(resp) != len(queryCase.resp) {\n\t\t\tt.Fatalf(\"expected %v nodes, got %v nodes\",\n\t\t\t\tlen(queryCase.resp), len(resp))\n\n\t\t}\n\n\t\tfor i := 0; i < len(resp); i++ {\n\t\t\terr := compareNodes(&queryCase.resp[i], &resp[i])\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// TestFilterKnownChanIDs tests that we're able to properly perform the set\n// differences of an incoming set of channel ID's, and those that we already\n// know of on disk.",
      "length": 2872,
      "tokens": 450,
      "embedding": []
    },
    {
      "slug": "func TestFilterKnownChanIDs(t *testing.T) {",
      "content": "func TestFilterKnownChanIDs(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// If we try to filter out a set of channel ID's before we even know of\n\t// any channels, then we should get the entire set back.\n\tpreChanIDs := []uint64{1, 2, 3, 4}\n\tfilteredIDs, err := graph.FilterKnownChanIDs(preChanIDs)\n\trequire.NoError(t, err, \"unable to filter chan IDs\")\n\tif !reflect.DeepEqual(preChanIDs, filteredIDs) {\n\t\tt.Fatalf(\"chan IDs shouldn't have been filtered!\")\n\t}\n\n\t// We'll start by creating two nodes which will seed our test graph.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// Next, we'll add 5 channel ID's to the graph, each of them having a\n\t// block height 10 blocks after the previous.\n\tconst numChans = 5\n\tchanIDs := make([]uint64, 0, numChans)\n\tfor i := 0; i < numChans; i++ {\n\t\tchannel, chanID := createEdge(\n\t\t\tuint32(i*10), 0, 0, 0, node1, node2,\n\t\t)\n\n\t\tif err := graph.AddChannelEdge(&channel); err != nil {\n\t\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t\t}\n\n\t\tchanIDs = append(chanIDs, chanID.ToUint64())\n\t}\n\n\tconst numZombies = 5\n\tzombieIDs := make([]uint64, 0, numZombies)\n\tfor i := 0; i < numZombies; i++ {\n\t\tchannel, chanID := createEdge(\n\t\t\tuint32(i*10+1), 0, 0, 0, node1, node2,\n\t\t)\n\t\tif err := graph.AddChannelEdge(&channel); err != nil {\n\t\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t\t}\n\t\terr := graph.DeleteChannelEdges(false, true, channel.ChannelID)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to mark edge zombie: %v\", err)\n\t\t}\n\n\t\tzombieIDs = append(zombieIDs, chanID.ToUint64())\n\t}\n\n\tqueryCases := []struct {\n\t\tqueryIDs []uint64\n\n\t\tresp []uint64\n\t}{\n\t\t// If we attempt to filter out all chanIDs we know of, the\n\t\t// response should be the empty set.\n\t\t{\n\t\t\tqueryIDs: chanIDs,\n\t\t},\n\t\t// If we attempt to filter out all zombies that we know of, the\n\t\t// response should be the empty set.\n\t\t{\n\t\t\tqueryIDs: zombieIDs,\n\t\t},\n\n\t\t// If we query for a set of ID's that we didn't insert, we\n\t\t// should get the same set back.\n\t\t{\n\t\t\tqueryIDs: []uint64{99, 100},\n\t\t\tresp:     []uint64{99, 100},\n\t\t},\n\n\t\t// If we query for a super-set of our the chan ID's inserted,\n\t\t// we should only get those new chanIDs back.\n\t\t{\n\t\t\tqueryIDs: append(chanIDs, []uint64{99, 101}...),\n\t\t\tresp:     []uint64{99, 101},\n\t\t},\n\t}\n\n\tfor _, queryCase := range queryCases {\n\t\tresp, err := graph.FilterKnownChanIDs(queryCase.queryIDs)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to filter chan IDs: %v\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(resp, queryCase.resp) {\n\t\t\tt.Fatalf(\"expected %v, got %v\", spew.Sdump(queryCase.resp),\n\t\t\t\tspew.Sdump(resp))\n\t\t}\n\t}\n}\n\n// TestFilterChannelRange tests that we're able to properly retrieve the full\n// set of short channel ID's for a given block range.",
      "length": 2961,
      "tokens": 452,
      "embedding": []
    },
    {
      "slug": "func TestFilterChannelRange(t *testing.T) {",
      "content": "func TestFilterChannelRange(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'll first populate our graph with two nodes. All channels created\n\t// below will be made between these two nodes.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// If we try to filter a channel range before we have any channels\n\t// inserted, we should get an empty slice of results.\n\tresp, err := graph.FilterChannelRange(10, 100)\n\trequire.NoError(t, err, \"unable to filter channels\")\n\tif len(resp) != 0 {\n\t\tt.Fatalf(\"expected zero chans, instead got %v\", len(resp))\n\t}\n\n\t// To start, we'll create a set of channels, two mined in a block 10\n\t// blocks after the prior one.\n\tstartHeight := uint32(100)\n\tendHeight := startHeight\n\tconst numChans = 10\n\tchannelRanges := make([]BlockChannelRange, 0, numChans/2)\n\tfor i := 0; i < numChans/2; i++ {\n\t\tchanHeight := endHeight\n\t\tchannel1, chanID1 := createEdge(\n\t\t\tchanHeight, uint32(i+1), 0, 0, node1, node2,\n\t\t)\n\t\tif err := graph.AddChannelEdge(&channel1); err != nil {\n\t\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t\t}\n\n\t\tchannel2, chanID2 := createEdge(\n\t\t\tchanHeight, uint32(i+2), 0, 0, node1, node2,\n\t\t)\n\t\tif err := graph.AddChannelEdge(&channel2); err != nil {\n\t\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t\t}\n\n\t\tchannelRanges = append(channelRanges, BlockChannelRange{\n\t\t\tHeight:   chanHeight,\n\t\t\tChannels: []lnwire.ShortChannelID{chanID1, chanID2},\n\t\t})\n\t\tendHeight += 10\n\t}\n\n\t// With our channels inserted, we'll construct a series of queries that\n\t// we'll execute below in order to exercise the features of the\n\t// FilterKnownChanIDs method.\n\tqueryCases := []struct {\n\t\tstartHeight uint32\n\t\tendHeight   uint32\n\n\t\tresp []BlockChannelRange\n\t}{\n\t\t// If we query for the entire range, then we should get the same\n\t\t// set of short channel IDs back.\n\t\t{\n\t\t\tstartHeight: startHeight,\n\t\t\tendHeight:   endHeight,\n\n\t\t\tresp: channelRanges,\n\t\t},\n\n\t\t// If we query for a range of channels right before our range, we\n\t\t// shouldn't get any results back.\n\t\t{\n\t\t\tstartHeight: 0,\n\t\t\tendHeight:   10,\n\t\t},\n\n\t\t// If we only query for the last height (range wise), we should\n\t\t// only get that last channel.\n\t\t{\n\t\t\tstartHeight: endHeight - 10,\n\t\t\tendHeight:   endHeight - 10,\n\n\t\t\tresp: channelRanges[4:],\n\t\t},\n\n\t\t// If we query for just the first height, we should only get a\n\t\t// single channel back (the first one).\n\t\t{\n\t\t\tstartHeight: startHeight,\n\t\t\tendHeight:   startHeight,\n\n\t\t\tresp: channelRanges[:1],\n\t\t},\n\n\t\t{\n\t\t\tstartHeight: startHeight + 10,\n\t\t\tendHeight:   endHeight - 10,\n\n\t\t\tresp: channelRanges[1:5],\n\t\t},\n\t}\n\tfor i, queryCase := range queryCases {\n\t\tresp, err := graph.FilterChannelRange(\n\t\t\tqueryCase.startHeight, queryCase.endHeight,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to issue range query: %v\", err)\n\t\t}\n\n\t\tif !reflect.DeepEqual(resp, queryCase.resp) {\n\t\t\tt.Fatalf(\"case #%v: expected %v, got %v\", i,\n\t\t\t\tqueryCase.resp, resp)\n\t\t}\n\t}\n}\n\n// TestFetchChanInfos tests that we're able to properly retrieve the full set\n// of ChannelEdge structs for a given set of short channel ID's.",
      "length": 3294,
      "tokens": 482,
      "embedding": []
    },
    {
      "slug": "func TestFetchChanInfos(t *testing.T) {",
      "content": "func TestFetchChanInfos(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'll first populate our graph with two nodes. All channels created\n\t// below will be made between these two nodes.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// We'll make 5 test channels, ensuring we keep track of which channel\n\t// ID corresponds to a particular ChannelEdge.\n\tconst numChans = 5\n\tstartTime := time.Unix(1234, 0)\n\tendTime := startTime\n\tedges := make([]ChannelEdge, 0, numChans)\n\tedgeQuery := make([]uint64, 0, numChans)\n\tfor i := 0; i < numChans; i++ {\n\t\tchannel, chanID := createEdge(\n\t\t\tuint32(i*10), 0, 0, 0, node1, node2,\n\t\t)\n\n\t\tif err := graph.AddChannelEdge(&channel); err != nil {\n\t\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t\t}\n\n\t\tupdateTime := endTime\n\t\tendTime = updateTime.Add(time.Second * 10)\n\n\t\tedge1 := newEdgePolicy(\n\t\t\tchanID.ToUint64(), graph.db, updateTime.Unix(),\n\t\t)\n\t\tedge1.ChannelFlags = 0\n\t\tedge1.Node = node2\n\t\tedge1.SigBytes = testSig.Serialize()\n\t\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t\t}\n\n\t\tedge2 := newEdgePolicy(\n\t\t\tchanID.ToUint64(), graph.db, updateTime.Unix(),\n\t\t)\n\t\tedge2.ChannelFlags = 1\n\t\tedge2.Node = node1\n\t\tedge2.SigBytes = testSig.Serialize()\n\t\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t\t}\n\n\t\tedges = append(edges, ChannelEdge{\n\t\t\tInfo:    &channel,\n\t\t\tPolicy1: edge1,\n\t\t\tPolicy2: edge2,\n\t\t})\n\n\t\tedgeQuery = append(edgeQuery, chanID.ToUint64())\n\t}\n\n\t// Add an additional edge that does not exist. The query should skip\n\t// this channel and return only infos for the edges that exist.\n\tedgeQuery = append(edgeQuery, 500)\n\n\t// Add an another edge to the query that has been marked as a zombie\n\t// edge. The query should also skip this channel.\n\tzombieChan, zombieChanID := createEdge(\n\t\t666, 0, 0, 0, node1, node2,\n\t)\n\tif err := graph.AddChannelEdge(&zombieChan); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\terr = graph.DeleteChannelEdges(false, true, zombieChan.ChannelID)\n\trequire.NoError(t, err, \"unable to delete and mark edge zombie\")\n\tedgeQuery = append(edgeQuery, zombieChanID.ToUint64())\n\n\t// We'll now attempt to query for the range of channel ID's we just\n\t// inserted into the database. We should get the exact same set of\n\t// edges back.\n\tresp, err := graph.FetchChanInfos(edgeQuery)\n\trequire.NoError(t, err, \"unable to fetch chan edges\")\n\tif len(resp) != len(edges) {\n\t\tt.Fatalf(\"expected %v edges, instead got %v\", len(edges),\n\t\t\tlen(resp))\n\t}\n\n\tfor i := 0; i < len(resp); i++ {\n\t\terr := compareEdgePolicies(resp[i].Policy1, edges[i].Policy1)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t\t}\n\t\terr = compareEdgePolicies(resp[i].Policy2, edges[i].Policy2)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t\t}\n\t\tassertEdgeInfoEqual(t, resp[i].Info, edges[i].Info)\n\t}\n}\n\n// TestIncompleteChannelPolicies tests that a channel that only has a policy\n// specified on one end is properly returned in ForEachChannel calls from\n// both sides.",
      "length": 3344,
      "tokens": 471,
      "embedding": []
    },
    {
      "slug": "func TestIncompleteChannelPolicies(t *testing.T) {",
      "content": "func TestIncompleteChannelPolicies(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// Create two nodes.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\tchannel, chanID := createEdge(\n\t\tuint32(0), 0, 0, 0, node1, node2,\n\t)\n\n\tif err := graph.AddChannelEdge(&channel); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\t// Ensure that channel is reported with unknown policies.\n\tcheckPolicies := func(node *LightningNode, expectedIn, expectedOut bool) {\n\t\tcalls := 0\n\t\terr := node.ForEachChannel(nil, func(_ kvdb.RTx, _ *ChannelEdgeInfo,\n\t\t\toutEdge, inEdge *ChannelEdgePolicy) error {\n\n\t\t\tif !expectedOut && outEdge != nil {\n\t\t\t\tt.Fatalf(\"Expected no outgoing policy\")\n\t\t\t}\n\n\t\t\tif expectedOut && outEdge == nil {\n\t\t\t\tt.Fatalf(\"Expected an outgoing policy\")\n\t\t\t}\n\n\t\t\tif !expectedIn && inEdge != nil {\n\t\t\t\tt.Fatalf(\"Expected no incoming policy\")\n\t\t\t}\n\n\t\t\tif expectedIn && inEdge == nil {\n\t\t\t\tt.Fatalf(\"Expected an incoming policy\")\n\t\t\t}\n\n\t\t\tcalls++\n\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to scan channels: %v\", err)\n\t\t}\n\n\t\tif calls != 1 {\n\t\t\tt.Fatalf(\"Expected only one callback call\")\n\t\t}\n\t}\n\n\tcheckPolicies(node2, false, false)\n\n\t// Only create an edge policy for node1 and leave the policy for node2\n\t// unknown.\n\tupdateTime := time.Unix(1234, 0)\n\n\tedgePolicy := newEdgePolicy(\n\t\tchanID.ToUint64(), graph.db, updateTime.Unix(),\n\t)\n\tedgePolicy.ChannelFlags = 0\n\tedgePolicy.Node = node2\n\tedgePolicy.SigBytes = testSig.Serialize()\n\tif err := graph.UpdateEdgePolicy(edgePolicy); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\tcheckPolicies(node1, false, true)\n\tcheckPolicies(node2, true, false)\n\n\t// Create second policy and assert that both policies are reported\n\t// as present.\n\tedgePolicy = newEdgePolicy(\n\t\tchanID.ToUint64(), graph.db, updateTime.Unix(),\n\t)\n\tedgePolicy.ChannelFlags = 1\n\tedgePolicy.Node = node1\n\tedgePolicy.SigBytes = testSig.Serialize()\n\tif err := graph.UpdateEdgePolicy(edgePolicy); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\tcheckPolicies(node1, true, true)\n\tcheckPolicies(node2, true, true)\n}\n\n// TestChannelEdgePruningUpdateIndexDeletion tests that once edges are deleted\n// from the graph, then their entries within the update index are also cleaned\n// up.",
      "length": 2526,
      "tokens": 339,
      "embedding": []
    },
    {
      "slug": "func TestChannelEdgePruningUpdateIndexDeletion(t *testing.T) {",
      "content": "func TestChannelEdgePruningUpdateIndexDeletion(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\tsourceNode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create source node\")\n\tif err := graph.SetSourceNode(sourceNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\t// We'll first populate our graph with two nodes. All channels created\n\t// below will be made between these two nodes.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// With the two nodes created, we'll now create a random channel, as\n\t// well as two edges in the database with distinct update times.\n\tedgeInfo, chanID := createEdge(100, 0, 0, 0, node1, node2)\n\tif err := graph.AddChannelEdge(&edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to add edge: %v\", err)\n\t}\n\n\tedge1 := randEdgePolicy(chanID.ToUint64(), graph.db)\n\tedge1.ChannelFlags = 0\n\tedge1.Node = node1\n\tedge1.SigBytes = testSig.Serialize()\n\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\tedge2 := randEdgePolicy(chanID.ToUint64(), graph.db)\n\tedge2.ChannelFlags = 1\n\tedge2.Node = node2\n\tedge2.SigBytes = testSig.Serialize()\n\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\t// checkIndexTimestamps is a helper function that checks the edge update\n\t// index only includes the given timestamps.\n\tcheckIndexTimestamps := func(timestamps ...uint64) {\n\t\ttimestampSet := make(map[uint64]struct{})\n\t\tfor _, t := range timestamps {\n\t\t\ttimestampSet[t] = struct{}{}\n\t\t}\n\n\t\terr := kvdb.View(graph.db, func(tx kvdb.RTx) error {\n\t\t\tedges := tx.ReadBucket(edgeBucket)\n\t\t\tif edges == nil {\n\t\t\t\treturn ErrGraphNoEdgesFound\n\t\t\t}\n\t\t\tedgeUpdateIndex := edges.NestedReadBucket(\n\t\t\t\tedgeUpdateIndexBucket,\n\t\t\t)\n\t\t\tif edgeUpdateIndex == nil {\n\t\t\t\treturn ErrGraphNoEdgesFound\n\t\t\t}\n\n\t\t\tvar numEntries int\n\t\t\terr := edgeUpdateIndex.ForEach(func(k, v []byte) error {\n\t\t\t\tnumEntries++\n\t\t\t\treturn nil\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\texpectedEntries := len(timestampSet)\n\t\t\tif numEntries != expectedEntries {\n\t\t\t\treturn fmt.Errorf(\"expected %v entries in the \"+\n\t\t\t\t\t\"update index, got %v\", expectedEntries,\n\t\t\t\t\tnumEntries)\n\t\t\t}\n\n\t\t\treturn edgeUpdateIndex.ForEach(func(k, _ []byte) error {\n\t\t\t\tt := byteOrder.Uint64(k[:8])\n\t\t\t\tif _, ok := timestampSet[t]; !ok {\n\t\t\t\t\treturn fmt.Errorf(\"found unexpected \"+\n\t\t\t\t\t\t\"timestamp \"+\"%d\", t)\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t})\n\t\t}, func() {})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\t// With both edges policies added, we'll make sure to check they exist\n\t// within the edge update index.\n\tcheckIndexTimestamps(\n\t\tuint64(edge1.LastUpdate.Unix()),\n\t\tuint64(edge2.LastUpdate.Unix()),\n\t)\n\n\t// Now, we'll update the edge policies to ensure the old timestamps are\n\t// removed from the update index.\n\tedge1.ChannelFlags = 2\n\tedge1.LastUpdate = time.Now()\n\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\tedge2.ChannelFlags = 3\n\tedge2.LastUpdate = edge1.LastUpdate.Add(time.Hour)\n\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\t// With the policies updated, we should now be able to find their\n\t// updated entries within the update index.\n\tcheckIndexTimestamps(\n\t\tuint64(edge1.LastUpdate.Unix()),\n\t\tuint64(edge2.LastUpdate.Unix()),\n\t)\n\n\t// Now we'll prune the graph, removing the edges, and also the update\n\t// index entries from the database all together.\n\tvar blockHash chainhash.Hash\n\tcopy(blockHash[:], bytes.Repeat([]byte{2}, 32))\n\t_, err = graph.PruneGraph(\n\t\t[]*wire.OutPoint{&edgeInfo.ChannelPoint}, &blockHash, 101,\n\t)\n\trequire.NoError(t, err, \"unable to prune graph\")\n\n\t// Finally, we'll check the database state one last time to conclude\n\t// that we should no longer be able to locate _any_ entries within the\n\t// edge update index.\n\tcheckIndexTimestamps()\n}\n\n// TestPruneGraphNodes tests that unconnected vertexes are pruned via the\n// PruneSyncState method.",
      "length": 4200,
      "tokens": 561,
      "embedding": []
    },
    {
      "slug": "func TestPruneGraphNodes(t *testing.T) {",
      "content": "func TestPruneGraphNodes(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'll start off by inserting our source node, to ensure that it's\n\t// the only node left after we prune the graph.\n\tsourceNode, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create source node\")\n\tif err := graph.SetSourceNode(sourceNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\t// With the source node inserted, we'll now add three nodes to the\n\t// channel graph, at the end of the scenario, only two of these nodes\n\t// should still be in the graph.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode3, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node3); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// We'll now add a new edge to the graph, but only actually advertise\n\t// the edge of *one* of the nodes.\n\tedgeInfo, chanID := createEdge(100, 0, 0, 0, node1, node2)\n\tif err := graph.AddChannelEdge(&edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to add edge: %v\", err)\n\t}\n\n\t// We'll now insert an advertised edge, but it'll only be the edge that\n\t// points from the first to the second node.\n\tedge1 := randEdgePolicy(chanID.ToUint64(), graph.db)\n\tedge1.ChannelFlags = 0\n\tedge1.Node = node1\n\tedge1.SigBytes = testSig.Serialize()\n\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\t// We'll now initiate a around of graph pruning.\n\tif err := graph.PruneGraphNodes(); err != nil {\n\t\tt.Fatalf(\"unable to prune graph nodes: %v\", err)\n\t}\n\n\t// At this point, there should be 3 nodes left in the graph still: the\n\t// source node (which can't be pruned), and node 1+2. Nodes 1 and two\n\t// should still be left in the graph as there's half of an advertised\n\t// edge between them.\n\tassertNumNodes(t, graph, 3)\n\n\t// Finally, we'll ensure that node3, the only fully unconnected node as\n\t// properly deleted from the graph and not another node in its place.\n\t_, err = graph.FetchLightningNode(node3.PubKeyBytes)\n\tif err == nil {\n\t\tt.Fatalf(\"node 3 should have been deleted!\")\n\t}\n}\n\n// TestAddChannelEdgeShellNodes tests that when we attempt to add a ChannelEdge\n// to the graph, one or both of the nodes the edge involves aren't found in the\n// database, then shell edges are created for each node if needed.",
      "length": 2677,
      "tokens": 428,
      "embedding": []
    },
    {
      "slug": "func TestAddChannelEdgeShellNodes(t *testing.T) {",
      "content": "func TestAddChannelEdgeShellNodes(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// To start, we'll create two nodes, and only add one of them to the\n\t// channel graph.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\t// We'll now create an edge between the two nodes, as a result, node2\n\t// should be inserted into the database as a shell node.\n\tedgeInfo, _ := createEdge(100, 0, 0, 0, node1, node2)\n\tif err := graph.AddChannelEdge(&edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to add edge: %v\", err)\n\t}\n\n\t// Ensure that node1 was inserted as a full node, while node2 only has\n\t// a shell node present.\n\tnode1, err = graph.FetchLightningNode(node1.PubKeyBytes)\n\trequire.NoError(t, err, \"unable to fetch node1\")\n\tif !node1.HaveNodeAnnouncement {\n\t\tt.Fatalf(\"have shell announcement for node1, shouldn't\")\n\t}\n\n\tnode2, err = graph.FetchLightningNode(node2.PubKeyBytes)\n\trequire.NoError(t, err, \"unable to fetch node2\")\n\tif node2.HaveNodeAnnouncement {\n\t\tt.Fatalf(\"should have shell announcement for node2, but is full\")\n\t}\n}\n\n// TestNodePruningUpdateIndexDeletion tests that once a node has been removed\n// from the channel graph, we also remove the entry from the update index as\n// well.",
      "length": 1418,
      "tokens": 206,
      "embedding": []
    },
    {
      "slug": "func TestNodePruningUpdateIndexDeletion(t *testing.T) {",
      "content": "func TestNodePruningUpdateIndexDeletion(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'll first populate our graph with a single node that will be\n\t// removed shortly.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// We'll confirm that we can retrieve the node using\n\t// NodeUpdatesInHorizon, using a time that's slightly beyond the last\n\t// update time of our test node.\n\tstartTime := time.Unix(9, 0)\n\tendTime := node1.LastUpdate.Add(time.Minute)\n\tnodesInHorizon, err := graph.NodeUpdatesInHorizon(startTime, endTime)\n\trequire.NoError(t, err, \"unable to fetch nodes in horizon\")\n\n\t// We should only have a single node, and that node should exactly\n\t// match the node we just inserted.\n\tif len(nodesInHorizon) != 1 {\n\t\tt.Fatalf(\"should have 1 nodes instead have: %v\",\n\t\t\tlen(nodesInHorizon))\n\t}\n\tif err := compareNodes(node1, &nodesInHorizon[0]); err != nil {\n\t\tt.Fatalf(\"nodes don't match: %v\", err)\n\t}\n\n\t// We'll now delete the node from the graph, this should result in it\n\t// being removed from the update index as well.\n\tif err := graph.DeleteLightningNode(node1.PubKeyBytes); err != nil {\n\t\tt.Fatalf(\"unable to delete node: %v\", err)\n\t}\n\n\t// Now that the node has been deleted, we'll again query the nodes in\n\t// the horizon. This time we should have no nodes at all.\n\tnodesInHorizon, err = graph.NodeUpdatesInHorizon(startTime, endTime)\n\trequire.NoError(t, err, \"unable to fetch nodes in horizon\")\n\n\tif len(nodesInHorizon) != 0 {\n\t\tt.Fatalf(\"should have zero nodes instead have: %v\",\n\t\t\tlen(nodesInHorizon))\n\t}\n}\n\n// TestNodeIsPublic ensures that we properly detect nodes that are seen as\n// public within the network graph.",
      "length": 1760,
      "tokens": 260,
      "embedding": []
    },
    {
      "slug": "func TestNodeIsPublic(t *testing.T) {",
      "content": "func TestNodeIsPublic(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll start off the test by creating a small network of 3\n\t// participants with the following graph:\n\t//\n\t//\tAlice <-> Bob <-> Carol\n\t//\n\t// We'll need to create a separate database and channel graph for each\n\t// participant to replicate real-world scenarios (private edges being in\n\t// some graphs but not others, etc.).\n\taliceGraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\taliceNode, err := createTestVertex(aliceGraph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := aliceGraph.SetSourceNode(aliceNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\tbobGraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\tbobNode, err := createTestVertex(bobGraph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := bobGraph.SetSourceNode(bobNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\tcarolGraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\tcarolNode, err := createTestVertex(carolGraph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := carolGraph.SetSourceNode(carolNode); err != nil {\n\t\tt.Fatalf(\"unable to set source node: %v\", err)\n\t}\n\n\taliceBobEdge, _ := createEdge(10, 0, 0, 0, aliceNode, bobNode)\n\tbobCarolEdge, _ := createEdge(10, 1, 0, 1, bobNode, carolNode)\n\n\t// After creating all of our nodes and edges, we'll add them to each\n\t// participant's graph.\n\tnodes := []*LightningNode{aliceNode, bobNode, carolNode}\n\tedges := []*ChannelEdgeInfo{&aliceBobEdge, &bobCarolEdge}\n\tdbs := []kvdb.Backend{aliceGraph.db, bobGraph.db, carolGraph.db}\n\tgraphs := []*ChannelGraph{aliceGraph, bobGraph, carolGraph}\n\tfor i, graph := range graphs {\n\t\tfor _, node := range nodes {\n\t\t\tnode.db = dbs[i]\n\t\t\tif err := graph.AddLightningNode(node); err != nil {\n\t\t\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t\t\t}\n\t\t}\n\t\tfor _, edge := range edges {\n\t\t\tedge.db = dbs[i]\n\t\t\tif err := graph.AddChannelEdge(edge); err != nil {\n\t\t\t\tt.Fatalf(\"unable to add edge: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// checkNodes is a helper closure that will be used to assert that the\n\t// given nodes are seen as public/private within the given graphs.\n\tcheckNodes := func(nodes []*LightningNode, graphs []*ChannelGraph,\n\t\tpublic bool) {\n\n\t\tt.Helper()\n\n\t\tfor _, node := range nodes {\n\t\t\tfor _, graph := range graphs {\n\t\t\t\tisPublic, err := graph.IsPublicNode(node.PubKeyBytes)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to determine if pivot \"+\n\t\t\t\t\t\t\"is public: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tswitch {\n\t\t\t\tcase isPublic && !public:\n\t\t\t\t\tt.Fatalf(\"expected %x to be private\",\n\t\t\t\t\t\tnode.PubKeyBytes)\n\t\t\t\tcase !isPublic && public:\n\t\t\t\t\tt.Fatalf(\"expected %x to be public\",\n\t\t\t\t\t\tnode.PubKeyBytes)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Due to the way the edges were set up above, we'll make sure each node\n\t// can correctly determine that every other node is public.\n\tcheckNodes(nodes, graphs, true)\n\n\t// Now, we'll remove the edge between Alice and Bob from everyone's\n\t// graph. This will make Alice be seen as a private node as it no longer\n\t// has any advertised edges.\n\tfor _, graph := range graphs {\n\t\terr := graph.DeleteChannelEdges(\n\t\t\tfalse, true, aliceBobEdge.ChannelID,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to remove edge: %v\", err)\n\t\t}\n\t}\n\tcheckNodes(\n\t\t[]*LightningNode{aliceNode},\n\t\t[]*ChannelGraph{bobGraph, carolGraph},\n\t\tfalse,\n\t)\n\n\t// We'll also make the edge between Bob and Carol private. Within Bob's\n\t// and Carol's graph, the edge will exist, but it will not have a proof\n\t// that allows it to be advertised. Within Alice's graph, we'll\n\t// completely remove the edge as it is not possible for her to know of\n\t// it without it being advertised.\n\tfor i, graph := range graphs {\n\t\terr := graph.DeleteChannelEdges(\n\t\t\tfalse, true, bobCarolEdge.ChannelID,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to remove edge: %v\", err)\n\t\t}\n\n\t\tif graph == aliceGraph {\n\t\t\tcontinue\n\t\t}\n\n\t\tbobCarolEdge.AuthProof = nil\n\t\tbobCarolEdge.db = dbs[i]\n\t\tif err := graph.AddChannelEdge(&bobCarolEdge); err != nil {\n\t\t\tt.Fatalf(\"unable to add edge: %v\", err)\n\t\t}\n\t}\n\n\t// With the modifications above, Bob should now be seen as a private\n\t// node from both Alice's and Carol's perspective.\n\tcheckNodes(\n\t\t[]*LightningNode{bobNode},\n\t\t[]*ChannelGraph{aliceGraph, carolGraph},\n\t\tfalse,\n\t)\n}\n\n// TestDisabledChannelIDs ensures that the disabled channels within the\n// disabledEdgePolicyBucket are managed properly and the list returned from\n// DisabledChannelIDs is correct.",
      "length": 4383,
      "tokens": 642,
      "embedding": []
    },
    {
      "slug": "func TestDisabledChannelIDs(t *testing.T) {",
      "content": "func TestDisabledChannelIDs(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// Create first node and add it to the graph.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// Create second node and add it to the graph.\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\t// Adding a new channel edge to the graph.\n\tedgeInfo, edge1, edge2 := createChannelEdge(graph.db, node1, node2)\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\n\tif err := graph.AddChannelEdge(edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\t// Ensure no disabled channels exist in the bucket on start.\n\tdisabledChanIds, err := graph.DisabledChannelIDs()\n\trequire.NoError(t, err, \"unable to get disabled channel ids\")\n\tif len(disabledChanIds) > 0 {\n\t\tt.Fatalf(\"expected empty disabled channels, got %v disabled channels\",\n\t\t\tlen(disabledChanIds))\n\t}\n\n\t// Add one disabled policy and ensure the channel is still not in the\n\t// disabled list.\n\tedge1.ChannelFlags |= lnwire.ChanUpdateDisabled\n\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\tdisabledChanIds, err = graph.DisabledChannelIDs()\n\trequire.NoError(t, err, \"unable to get disabled channel ids\")\n\tif len(disabledChanIds) > 0 {\n\t\tt.Fatalf(\"expected empty disabled channels, got %v disabled channels\",\n\t\t\tlen(disabledChanIds))\n\t}\n\n\t// Add second disabled policy and ensure the channel is now in the\n\t// disabled list.\n\tedge2.ChannelFlags |= lnwire.ChanUpdateDisabled\n\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\tdisabledChanIds, err = graph.DisabledChannelIDs()\n\trequire.NoError(t, err, \"unable to get disabled channel ids\")\n\tif len(disabledChanIds) != 1 || disabledChanIds[0] != edgeInfo.ChannelID {\n\t\tt.Fatalf(\"expected disabled channel with id %v, \"+\n\t\t\t\"got %v\", edgeInfo.ChannelID, disabledChanIds)\n\t}\n\n\t// Delete the channel edge and ensure it is removed from the disabled list.\n\tif err = graph.DeleteChannelEdges(\n\t\tfalse, true, edgeInfo.ChannelID,\n\t); err != nil {\n\t\tt.Fatalf(\"unable to delete channel edge: %v\", err)\n\t}\n\tdisabledChanIds, err = graph.DisabledChannelIDs()\n\trequire.NoError(t, err, \"unable to get disabled channel ids\")\n\tif len(disabledChanIds) > 0 {\n\t\tt.Fatalf(\"expected empty disabled channels, got %v disabled channels\",\n\t\t\tlen(disabledChanIds))\n\t}\n}\n\n// TestEdgePolicyMissingMaxHtcl tests that if we find a ChannelEdgePolicy in\n// the DB that indicates that it should support the htlc_maximum_value_msat\n// field, but it is not part of the opaque data, then we'll handle it as it is\n// unknown. It also checks that we are correctly able to overwrite it when we\n// receive the proper update.",
      "length": 2986,
      "tokens": 419,
      "embedding": []
    },
    {
      "slug": "func TestEdgePolicyMissingMaxHtcl(t *testing.T) {",
      "content": "func TestEdgePolicyMissingMaxHtcl(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\t// We'd like to test the update of edges inserted into the database, so\n\t// we create two vertexes to connect.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\tif err := graph.AddLightningNode(node1); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test node\")\n\n\tedgeInfo, edge1, edge2 := createChannelEdge(graph.db, node1, node2)\n\tif err := graph.AddLightningNode(node2); err != nil {\n\t\tt.Fatalf(\"unable to add node: %v\", err)\n\t}\n\tif err := graph.AddChannelEdge(edgeInfo); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\tchanID := edgeInfo.ChannelID\n\tfrom := edge2.Node.PubKeyBytes[:]\n\tto := edge1.Node.PubKeyBytes[:]\n\n\t// We'll remove the no max_htlc field from the first edge policy, and\n\t// all other opaque data, and serialize it.\n\tedge1.MessageFlags = 0\n\tedge1.ExtraOpaqueData = nil\n\n\tvar b bytes.Buffer\n\terr = serializeChanEdgePolicy(&b, edge1, to)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to serialize policy\")\n\t}\n\n\t// Set the max_htlc field. The extra bytes added to the serialization\n\t// will be the opaque data containing the serialized field.\n\tedge1.MessageFlags = lnwire.ChanUpdateRequiredMaxHtlc\n\tedge1.MaxHTLC = 13928598\n\tvar b2 bytes.Buffer\n\terr = serializeChanEdgePolicy(&b2, edge1, to)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to serialize policy\")\n\t}\n\n\twithMaxHtlc := b2.Bytes()\n\n\t// Remove the opaque data from the serialization.\n\tstripped := withMaxHtlc[:len(b.Bytes())]\n\n\t// Attempting to deserialize these bytes should return an error.\n\tr := bytes.NewReader(stripped)\n\terr = kvdb.View(graph.db, func(tx kvdb.RTx) error {\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\t_, err = deserializeChanEdgePolicy(r, nodes)\n\t\tif err != ErrEdgePolicyOptionalFieldNotFound {\n\t\t\tt.Fatalf(\"expected \"+\n\t\t\t\t\"ErrEdgePolicyOptionalFieldNotFound, got %v\",\n\t\t\t\terr)\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n\trequire.NoError(t, err, \"error reading db\")\n\n\t// Put the stripped bytes in the DB.\n\terr = kvdb.Update(graph.db, func(tx kvdb.RwTx) error {\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\n\t\tedgeIndex := edges.NestedReadWriteBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\n\t\tvar edgeKey [33 + 8]byte\n\t\tcopy(edgeKey[:], from)\n\t\tbyteOrder.PutUint64(edgeKey[33:], edge1.ChannelID)\n\n\t\tvar scratch [8]byte\n\t\tvar indexKey [8 + 8]byte\n\t\tcopy(indexKey[:], scratch[:])\n\t\tbyteOrder.PutUint64(indexKey[8:], edge1.ChannelID)\n\n\t\tupdateIndex, err := edges.CreateBucketIfNotExists(edgeUpdateIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := updateIndex.Put(indexKey[:], nil); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn edges.Put(edgeKey[:], stripped)\n\t}, func() {})\n\trequire.NoError(t, err, \"error writing db\")\n\n\t// And add the second, unmodified edge.\n\tif err := graph.UpdateEdgePolicy(edge2); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\t// Attempt to fetch the edge and policies from the DB. Since the policy\n\t// we added is invalid according to the new format, it should be as we\n\t// are not aware of the policy (indicated by the policy returned being\n\t// nil)\n\tdbEdgeInfo, dbEdge1, dbEdge2, err := graph.FetchChannelEdgesByID(chanID)\n\trequire.NoError(t, err, \"unable to fetch channel by ID\")\n\n\t// The first edge should have a nil-policy returned\n\tif dbEdge1 != nil {\n\t\tt.Fatalf(\"expected db edge to be nil\")\n\t}\n\tif err := compareEdgePolicies(dbEdge2, edge2); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tassertEdgeInfoEqual(t, dbEdgeInfo, edgeInfo)\n\n\t// Now add the original, unmodified edge policy, and make sure the edge\n\t// policies then become fully populated.\n\tif err := graph.UpdateEdgePolicy(edge1); err != nil {\n\t\tt.Fatalf(\"unable to update edge: %v\", err)\n\t}\n\n\tdbEdgeInfo, dbEdge1, dbEdge2, err = graph.FetchChannelEdgesByID(chanID)\n\trequire.NoError(t, err, \"unable to fetch channel by ID\")\n\tif err := compareEdgePolicies(dbEdge1, edge1); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tif err := compareEdgePolicies(dbEdge2, edge2); err != nil {\n\t\tt.Fatalf(\"edge doesn't match: %v\", err)\n\t}\n\tassertEdgeInfoEqual(t, dbEdgeInfo, edgeInfo)\n}\n\n// assertNumZombies queries the provided ChannelGraph for NumZombies, and\n// asserts that the returned number is equal to expZombies.",
      "length": 4365,
      "tokens": 593,
      "embedding": []
    },
    {
      "slug": "func assertNumZombies(t *testing.T, graph *ChannelGraph, expZombies uint64) {",
      "content": "func assertNumZombies(t *testing.T, graph *ChannelGraph, expZombies uint64) {\n\tt.Helper()\n\n\tnumZombies, err := graph.NumZombies()\n\trequire.NoError(t, err, \"unable to query number of zombies\")\n\n\tif numZombies != expZombies {\n\t\tt.Fatalf(\"expected %d zombies, found %d\",\n\t\t\texpZombies, numZombies)\n\t}\n}\n\n// TestGraphZombieIndex ensures that we can mark edges correctly as zombie/live.",
      "length": 292,
      "tokens": 38,
      "embedding": []
    },
    {
      "slug": "func TestGraphZombieIndex(t *testing.T) {",
      "content": "func TestGraphZombieIndex(t *testing.T) {\n\tt.Parallel()\n\n\t// We'll start by creating our test graph along with a test edge.\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to create test database\")\n\n\tnode1, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test vertex\")\n\tnode2, err := createTestVertex(graph.db)\n\trequire.NoError(t, err, \"unable to create test vertex\")\n\n\t// Swap the nodes if the second's pubkey is smaller than the first.\n\t// Without this, the comparisons at the end will fail probabilistically.\n\tif bytes.Compare(node2.PubKeyBytes[:], node1.PubKeyBytes[:]) < 0 {\n\t\tnode1, node2 = node2, node1\n\t}\n\n\tedge, _, _ := createChannelEdge(graph.db, node1, node2)\n\tif err := graph.AddChannelEdge(edge); err != nil {\n\t\tt.Fatalf(\"unable to create channel edge: %v\", err)\n\t}\n\n\t// Since the edge is known the graph and it isn't a zombie, IsZombieEdge\n\t// should not report the channel as a zombie.\n\tisZombie, _, _ := graph.IsZombieEdge(edge.ChannelID)\n\tif isZombie {\n\t\tt.Fatal(\"expected edge to not be marked as zombie\")\n\t}\n\tassertNumZombies(t, graph, 0)\n\n\t// If we delete the edge and mark it as a zombie, then we should expect\n\t// to see it within the index.\n\terr = graph.DeleteChannelEdges(false, true, edge.ChannelID)\n\trequire.NoError(t, err, \"unable to mark edge as zombie\")\n\tisZombie, pubKey1, pubKey2 := graph.IsZombieEdge(edge.ChannelID)\n\tif !isZombie {\n\t\tt.Fatal(\"expected edge to be marked as zombie\")\n\t}\n\tif pubKey1 != node1.PubKeyBytes {\n\t\tt.Fatalf(\"expected pubKey1 %x, got %x\", node1.PubKeyBytes,\n\t\t\tpubKey1)\n\t}\n\tif pubKey2 != node2.PubKeyBytes {\n\t\tt.Fatalf(\"expected pubKey2 %x, got %x\", node2.PubKeyBytes,\n\t\t\tpubKey2)\n\t}\n\tassertNumZombies(t, graph, 1)\n\n\t// Similarly, if we mark the same edge as live, we should no longer see\n\t// it within the index.\n\tif err := graph.MarkEdgeLive(edge.ChannelID); err != nil {\n\t\tt.Fatalf(\"unable to mark edge as live: %v\", err)\n\t}\n\tisZombie, _, _ = graph.IsZombieEdge(edge.ChannelID)\n\tif isZombie {\n\t\tt.Fatal(\"expected edge to not be marked as zombie\")\n\t}\n\tassertNumZombies(t, graph, 0)\n\n\t// If we mark the edge as a zombie manually, then it should show up as\n\t// being a zombie once again.\n\terr = graph.MarkEdgeZombie(\n\t\tedge.ChannelID, node1.PubKeyBytes, node2.PubKeyBytes,\n\t)\n\trequire.NoError(t, err, \"unable to mark edge as zombie\")\n\tisZombie, _, _ = graph.IsZombieEdge(edge.ChannelID)\n\tif !isZombie {\n\t\tt.Fatal(\"expected edge to be marked as zombie\")\n\t}\n\tassertNumZombies(t, graph, 1)\n}\n\n// compareNodes is used to compare two LightningNodes while excluding the\n// Features struct, which cannot be compared as the semantics for reserializing\n// the featuresMap have not been defined.",
      "length": 2571,
      "tokens": 374,
      "embedding": []
    },
    {
      "slug": "func compareNodes(a, b *LightningNode) error {",
      "content": "func compareNodes(a, b *LightningNode) error {\n\tif a.LastUpdate != b.LastUpdate {\n\t\treturn fmt.Errorf(\"node LastUpdate doesn't match: expected %v, \\n\"+\n\t\t\t\"got %v\", a.LastUpdate, b.LastUpdate)\n\t}\n\tif !reflect.DeepEqual(a.Addresses, b.Addresses) {\n\t\treturn fmt.Errorf(\"Addresses doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.Addresses, b.Addresses)\n\t}\n\tif !reflect.DeepEqual(a.PubKeyBytes, b.PubKeyBytes) {\n\t\treturn fmt.Errorf(\"PubKey doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.PubKeyBytes, b.PubKeyBytes)\n\t}\n\tif !reflect.DeepEqual(a.Color, b.Color) {\n\t\treturn fmt.Errorf(\"Color doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.Color, b.Color)\n\t}\n\tif !reflect.DeepEqual(a.Alias, b.Alias) {\n\t\treturn fmt.Errorf(\"Alias doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.Alias, b.Alias)\n\t}\n\tif !reflect.DeepEqual(a.db, b.db) {\n\t\treturn fmt.Errorf(\"db doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.db, b.db)\n\t}\n\tif !reflect.DeepEqual(a.HaveNodeAnnouncement, b.HaveNodeAnnouncement) {\n\t\treturn fmt.Errorf(\"HaveNodeAnnouncement doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.HaveNodeAnnouncement, b.HaveNodeAnnouncement)\n\t}\n\tif !bytes.Equal(a.ExtraOpaqueData, b.ExtraOpaqueData) {\n\t\treturn fmt.Errorf(\"extra data doesn't match: %v vs %v\",\n\t\t\ta.ExtraOpaqueData, b.ExtraOpaqueData)\n\t}\n\n\treturn nil\n}\n\n// compareEdgePolicies is used to compare two ChannelEdgePolices using\n// compareNodes, so as to exclude comparisons of the Nodes' Features struct.",
      "length": 1379,
      "tokens": 159,
      "embedding": []
    },
    {
      "slug": "func compareEdgePolicies(a, b *ChannelEdgePolicy) error {",
      "content": "func compareEdgePolicies(a, b *ChannelEdgePolicy) error {\n\tif a.ChannelID != b.ChannelID {\n\t\treturn fmt.Errorf(\"ChannelID doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.ChannelID, b.ChannelID)\n\t}\n\tif !reflect.DeepEqual(a.LastUpdate, b.LastUpdate) {\n\t\treturn fmt.Errorf(\"edge LastUpdate doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.LastUpdate, b.LastUpdate)\n\t}\n\tif a.MessageFlags != b.MessageFlags {\n\t\treturn fmt.Errorf(\"MessageFlags doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.MessageFlags, b.MessageFlags)\n\t}\n\tif a.ChannelFlags != b.ChannelFlags {\n\t\treturn fmt.Errorf(\"ChannelFlags doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.ChannelFlags, b.ChannelFlags)\n\t}\n\tif a.TimeLockDelta != b.TimeLockDelta {\n\t\treturn fmt.Errorf(\"TimeLockDelta doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.TimeLockDelta, b.TimeLockDelta)\n\t}\n\tif a.MinHTLC != b.MinHTLC {\n\t\treturn fmt.Errorf(\"MinHTLC doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.MinHTLC, b.MinHTLC)\n\t}\n\tif a.MaxHTLC != b.MaxHTLC {\n\t\treturn fmt.Errorf(\"MaxHTLC doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.MaxHTLC, b.MaxHTLC)\n\t}\n\tif a.FeeBaseMSat != b.FeeBaseMSat {\n\t\treturn fmt.Errorf(\"FeeBaseMSat doesn't match: expected %v, \"+\n\t\t\t\"got %v\", a.FeeBaseMSat, b.FeeBaseMSat)\n\t}\n\tif a.FeeProportionalMillionths != b.FeeProportionalMillionths {\n\t\treturn fmt.Errorf(\"FeeProportionalMillionths doesn't match: \"+\n\t\t\t\"expected %v, got %v\", a.FeeProportionalMillionths,\n\t\t\tb.FeeProportionalMillionths)\n\t}\n\tif !bytes.Equal(a.ExtraOpaqueData, b.ExtraOpaqueData) {\n\t\treturn fmt.Errorf(\"extra data doesn't match: %v vs %v\",\n\t\t\ta.ExtraOpaqueData, b.ExtraOpaqueData)\n\t}\n\tif err := compareNodes(a.Node, b.Node); err != nil {\n\t\treturn err\n\t}\n\tif !reflect.DeepEqual(a.db, b.db) {\n\t\treturn fmt.Errorf(\"db doesn't match: expected %#v, \\n \"+\n\t\t\t\"got %#v\", a.db, b.db)\n\t}\n\treturn nil\n}\n\n// TestLightningNodeSigVerification checks that we can use the LightningNode's\n// pubkey to verify signatures.",
      "length": 1816,
      "tokens": 215,
      "embedding": []
    },
    {
      "slug": "func TestLightningNodeSigVerification(t *testing.T) {",
      "content": "func TestLightningNodeSigVerification(t *testing.T) {\n\tt.Parallel()\n\n\t// Create some dummy data to sign.\n\tvar data [32]byte\n\tif _, err := prand.Read(data[:]); err != nil {\n\t\tt.Fatalf(\"unable to read prand: %v\", err)\n\t}\n\n\t// Create private key and sign the data with it.\n\tpriv, err := btcec.NewPrivateKey()\n\trequire.NoError(t, err, \"unable to crete priv key\")\n\n\tsign := ecdsa.Sign(priv, data[:])\n\n\t// Sanity check that the signature checks out.\n\tif !sign.Verify(data[:], priv.PubKey()) {\n\t\tt.Fatalf(\"signature doesn't check out\")\n\t}\n\n\t// Create a LightningNode from the same private key.\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err, \"unable to make test database\")\n\n\tnode, err := createLightningNode(graph.db, priv)\n\trequire.NoError(t, err, \"unable to create node\")\n\n\t// And finally check that we can verify the same signature from the\n\t// pubkey returned from the lightning node.\n\tnodePub, err := node.PubKey()\n\trequire.NoError(t, err, \"unable to get pubkey\")\n\n\tif !sign.Verify(data[:], nodePub) {\n\t\tt.Fatalf(\"unable to verify sig\")\n\t}\n}\n\n// TestComputeFee tests fee calculation based on both in- and outgoing amt.",
      "length": 1036,
      "tokens": 152,
      "embedding": []
    },
    {
      "slug": "func TestComputeFee(t *testing.T) {",
      "content": "func TestComputeFee(t *testing.T) {\n\tvar (\n\t\tpolicy = ChannelEdgePolicy{\n\t\t\tFeeBaseMSat:               10000,\n\t\t\tFeeProportionalMillionths: 30000,\n\t\t}\n\t\toutgoingAmt = lnwire.MilliSatoshi(1000000)\n\t\texpectedFee = lnwire.MilliSatoshi(40000)\n\t)\n\n\tfee := policy.ComputeFee(outgoingAmt)\n\tif fee != expectedFee {\n\t\tt.Fatalf(\"expected fee %v, got %v\", expectedFee, fee)\n\t}\n\n\tfwdFee := policy.ComputeFeeFromIncoming(outgoingAmt + fee)\n\tif fwdFee != expectedFee {\n\t\tt.Fatalf(\"expected fee %v, but got %v\", fee, fwdFee)\n\t}\n}\n\n// TestBatchedAddChannelEdge asserts that BatchedAddChannelEdge properly\n// executes multiple AddChannelEdge requests in a single txn.",
      "length": 593,
      "tokens": 68,
      "embedding": []
    },
    {
      "slug": "func TestBatchedAddChannelEdge(t *testing.T) {",
      "content": "func TestBatchedAddChannelEdge(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.Nil(t, err)\n\n\tsourceNode, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\terr = graph.SetSourceNode(sourceNode)\n\trequire.Nil(t, err)\n\n\t// We'd like to test the insertion/deletion of edges, so we create two\n\t// vertexes to connect.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\tnode2, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\n\t// In addition to the fake vertexes we create some fake channel\n\t// identifiers.\n\tvar spendOutputs []*wire.OutPoint\n\tvar blockHash chainhash.Hash\n\tcopy(blockHash[:], bytes.Repeat([]byte{1}, 32))\n\n\t// Prune the graph a few times to make sure we have entries in the\n\t// prune log.\n\t_, err = graph.PruneGraph(spendOutputs, &blockHash, 155)\n\trequire.Nil(t, err)\n\tvar blockHash2 chainhash.Hash\n\tcopy(blockHash2[:], bytes.Repeat([]byte{2}, 32))\n\n\t_, err = graph.PruneGraph(spendOutputs, &blockHash2, 156)\n\trequire.Nil(t, err)\n\n\t// We'll create 3 almost identical edges, so first create a helper\n\t// method containing all logic for doing so.\n\n\t// Create an edge which has its block height at 156.\n\theight := uint32(156)\n\tedgeInfo, _ := createEdge(height, 0, 0, 0, node1, node2)\n\n\t// Create an edge with block height 157. We give it\n\t// maximum values for tx index and position, to make\n\t// sure our database range scan get edges from the\n\t// entire range.\n\tedgeInfo2, _ := createEdge(\n\t\theight+1, math.MaxUint32&0x00ffffff, math.MaxUint16, 1,\n\t\tnode1, node2,\n\t)\n\n\t// Create a third edge, this with a block height of 155.\n\tedgeInfo3, _ := createEdge(height-1, 0, 0, 2, node1, node2)\n\n\tedges := []ChannelEdgeInfo{edgeInfo, edgeInfo2, edgeInfo3}\n\terrChan := make(chan error, len(edges))\n\terrTimeout := errors.New(\"timeout adding batched channel\")\n\n\t// Now add all these new edges to the database.\n\tvar wg sync.WaitGroup\n\tfor _, edge := range edges {\n\t\twg.Add(1)\n\t\tgo func(edge ChannelEdgeInfo) {\n\t\t\tdefer wg.Done()\n\n\t\t\tselect {\n\t\t\tcase errChan <- graph.AddChannelEdge(&edge):\n\t\t\tcase <-time.After(2 * time.Second):\n\t\t\t\terrChan <- errTimeout\n\t\t\t}\n\t\t}(edge)\n\t}\n\twg.Wait()\n\n\tfor i := 0; i < len(edges); i++ {\n\t\terr := <-errChan\n\t\trequire.Nil(t, err)\n\t}\n}\n\n// TestBatchedUpdateEdgePolicy asserts that BatchedUpdateEdgePolicy properly\n// executes multiple UpdateEdgePolicy requests in a single txn.",
      "length": 2227,
      "tokens": 310,
      "embedding": []
    },
    {
      "slug": "func TestBatchedUpdateEdgePolicy(t *testing.T) {",
      "content": "func TestBatchedUpdateEdgePolicy(t *testing.T) {\n\tt.Parallel()\n\n\tgraph, err := MakeTestGraph(t)\n\trequire.Nil(t, err)\n\n\t// We'd like to test the update of edges inserted into the database, so\n\t// we create two vertexes to connect.\n\tnode1, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\terr = graph.AddLightningNode(node1)\n\trequire.Nil(t, err)\n\tnode2, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\terr = graph.AddLightningNode(node2)\n\trequire.Nil(t, err)\n\n\t// Create an edge and add it to the db.\n\tedgeInfo, edge1, edge2 := createChannelEdge(graph.db, node1, node2)\n\n\t// Make sure inserting the policy at this point, before the edge info\n\t// is added, will fail.\n\terr = graph.UpdateEdgePolicy(edge1)\n\trequire.Error(t, ErrEdgeNotFound, err)\n\n\t// Add the edge info.\n\terr = graph.AddChannelEdge(edgeInfo)\n\trequire.Nil(t, err)\n\n\terrTimeout := errors.New(\"timeout adding batched channel\")\n\n\tupdates := []*ChannelEdgePolicy{edge1, edge2}\n\n\terrChan := make(chan error, len(updates))\n\n\t// Now add all these new edges to the database.\n\tvar wg sync.WaitGroup\n\tfor _, update := range updates {\n\t\twg.Add(1)\n\t\tgo func(update *ChannelEdgePolicy) {\n\t\t\tdefer wg.Done()\n\n\t\t\tselect {\n\t\t\tcase errChan <- graph.UpdateEdgePolicy(update):\n\t\t\tcase <-time.After(2 * time.Second):\n\t\t\t\terrChan <- errTimeout\n\t\t\t}\n\t\t}(update)\n\t}\n\twg.Wait()\n\n\tfor i := 0; i < len(updates); i++ {\n\t\terr := <-errChan\n\t\trequire.Nil(t, err)\n\t}\n}\n\n// BenchmarkForEachChannel is a benchmark test that measures the number of\n// allocations and the total memory consumed by the full graph traversal.",
      "length": 1457,
      "tokens": 199,
      "embedding": []
    },
    {
      "slug": "func BenchmarkForEachChannel(b *testing.B) {",
      "content": "func BenchmarkForEachChannel(b *testing.B) {\n\tgraph, err := MakeTestGraph(b)\n\trequire.Nil(b, err)\n\n\tconst numNodes = 100\n\tconst numChannels = 4\n\t_, _ = fillTestGraph(b, graph, numNodes, numChannels)\n\n\tb.ReportAllocs()\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tvar (\n\t\t\ttotalCapacity btcutil.Amount\n\t\t\tmaxHTLCs      lnwire.MilliSatoshi\n\t\t)\n\n\t\tvar nodes []GraphCacheNode\n\t\terr = graph.ForEachNodeCacheable(\n\t\t\tfunc(tx kvdb.RTx, node GraphCacheNode) error {\n\t\t\t\tnodes = append(nodes, node)\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t)\n\t\trequire.NoError(b, err)\n\n\t\terr = graph.db.View(func(tx kvdb.RTx) error {\n\t\t\tfor _, n := range nodes {\n\t\t\t\terr := n.ForEachChannel(\n\t\t\t\t\ttx, func(tx kvdb.RTx,\n\t\t\t\t\t\tinfo *ChannelEdgeInfo,\n\t\t\t\t\t\tpolicy *ChannelEdgePolicy,\n\t\t\t\t\t\tpolicy2 *ChannelEdgePolicy) error {\n\n\t\t\t\t\t\t// We need to do something with\n\t\t\t\t\t\t// the data here, otherwise the\n\t\t\t\t\t\t// compiler is going to optimize\n\t\t\t\t\t\t// this away, and we get bogus\n\t\t\t\t\t\t// results.\n\t\t\t\t\t\ttotalCapacity += info.Capacity\n\t\t\t\t\t\tmaxHTLCs += policy.MaxHTLC\n\t\t\t\t\t\tmaxHTLCs += policy2.MaxHTLC\n\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t},\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn nil\n\t\t}, func() {})\n\t\trequire.NoError(b, err)\n\t}\n}\n\n// TestGraphCacheForEachNodeChannel tests that the ForEachNodeChannel method\n// works as expected, and is able to handle nil self edges.",
      "length": 1232,
      "tokens": 166,
      "embedding": []
    },
    {
      "slug": "func TestGraphCacheForEachNodeChannel(t *testing.T) {",
      "content": "func TestGraphCacheForEachNodeChannel(t *testing.T) {\n\tgraph, err := MakeTestGraph(t)\n\trequire.NoError(t, err)\n\n\t// Unset the channel graph cache to simulate the user running with the\n\t// option turned off.\n\tgraph.graphCache = nil\n\n\tnode1, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\terr = graph.AddLightningNode(node1)\n\trequire.Nil(t, err)\n\tnode2, err := createTestVertex(graph.db)\n\trequire.Nil(t, err)\n\terr = graph.AddLightningNode(node2)\n\trequire.Nil(t, err)\n\n\t// Create an edge and add it to the db.\n\tedgeInfo, _, _ := createChannelEdge(graph.db, node1, node2)\n\n\t// Add the channel, but only insert a single edge into the graph.\n\trequire.NoError(t, graph.AddChannelEdge(edgeInfo))\n\n\t// We should be able to accumulate the single channel added, even\n\t// though we have a nil edge policy here.\n\tvar numChans int\n\terr = graph.ForEachNodeChannel(nil, node1.PubKeyBytes,\n\t\tfunc(channel *DirectedChannel) error {\n\t\t\tnumChans++\n\t\t\treturn nil\n\t\t})\n\trequire.NoError(t, err)\n\n\trequire.Equal(t, numChans, 1)\n}\n\n// TestGraphLoading asserts that the cache is properly reconstructed after a\n// restart.",
      "length": 1014,
      "tokens": 135,
      "embedding": []
    },
    {
      "slug": "func TestGraphLoading(t *testing.T) {",
      "content": "func TestGraphLoading(t *testing.T) {\n\t// First, create a temporary directory to be used for the duration of\n\t// this test.\n\ttempDirName := t.TempDir()\n\n\t// Next, create the graph for the first time.\n\tbackend, backendCleanup, err := kvdb.GetTestBackend(tempDirName, \"cgr\")\n\trequire.NoError(t, err)\n\tdefer backend.Close()\n\tdefer backendCleanup()\n\n\topts := DefaultOptions()\n\tgraph, err := NewChannelGraph(\n\t\tbackend, opts.RejectCacheSize, opts.ChannelCacheSize,\n\t\topts.BatchCommitInterval, opts.PreAllocCacheNumNodes,\n\t\ttrue, false,\n\t)\n\trequire.NoError(t, err)\n\n\t// Populate the graph with test data.\n\tconst numNodes = 100\n\tconst numChannels = 4\n\t_, _ = fillTestGraph(t, graph, numNodes, numChannels)\n\n\t// Recreate the graph. This should cause the graph cache to be\n\t// populated.\n\tgraphReloaded, err := NewChannelGraph(\n\t\tbackend, opts.RejectCacheSize, opts.ChannelCacheSize,\n\t\topts.BatchCommitInterval, opts.PreAllocCacheNumNodes,\n\t\ttrue, false,\n\t)\n\trequire.NoError(t, err)\n\n\t// Assert that the cache content is identical.\n\trequire.Equal(\n\t\tt, graph.graphCache.nodeChannels,\n\t\tgraphReloaded.graphCache.nodeChannels,\n\t)\n\n\trequire.Equal(\n\t\tt, graph.graphCache.nodeFeatures,\n\t\tgraphReloaded.graphCache.nodeFeatures,\n\t)\n}\n",
      "length": 1137,
      "tokens": 126,
      "embedding": []
    }
  ]
}