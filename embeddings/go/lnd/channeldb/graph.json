{
  "filepath": "../implementations/go/lnd/channeldb/graph.go",
  "package": "channeldb",
  "sections": [
    {
      "slug": "type ChannelGraph struct {",
      "content": "type ChannelGraph struct {\n\tdb kvdb.Backend\n\n\tcacheMu     sync.RWMutex\n\trejectCache *rejectCache\n\tchanCache   *channelCache\n\tgraphCache  *GraphCache\n\n\tchanScheduler batch.Scheduler\n\tnodeScheduler batch.Scheduler\n}\n\n// NewChannelGraph allocates a new ChannelGraph backed by a DB instance. The\n// returned instance has its own unique reject cache and channel cache.",
      "length": 324,
      "tokens": 39,
      "embedding": []
    },
    {
      "slug": "func NewChannelGraph(db kvdb.Backend, rejectCacheSize, chanCacheSize int,",
      "content": "func NewChannelGraph(db kvdb.Backend, rejectCacheSize, chanCacheSize int,\n\tbatchCommitInterval time.Duration, preAllocCacheNumNodes int,\n\tuseGraphCache, noMigrations bool) (*ChannelGraph, error) {\n\n\tif !noMigrations {\n\t\tif err := initChannelGraph(db); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tg := &ChannelGraph{\n\t\tdb:          db,\n\t\trejectCache: newRejectCache(rejectCacheSize),\n\t\tchanCache:   newChannelCache(chanCacheSize),\n\t}\n\tg.chanScheduler = batch.NewTimeScheduler(\n\t\tdb, &g.cacheMu, batchCommitInterval,\n\t)\n\tg.nodeScheduler = batch.NewTimeScheduler(\n\t\tdb, nil, batchCommitInterval,\n\t)\n\n\t// The graph cache can be turned off (e.g. for mobile users) for a\n\t// speed/memory usage tradeoff.\n\tif useGraphCache {\n\t\tg.graphCache = NewGraphCache(preAllocCacheNumNodes)\n\t\tstartTime := time.Now()\n\t\tlog.Debugf(\"Populating in-memory channel graph, this might \" +\n\t\t\t\"take a while...\")\n\n\t\terr := g.ForEachNodeCacheable(\n\t\t\tfunc(tx kvdb.RTx, node GraphCacheNode) error {\n\t\t\t\tg.graphCache.AddNodeFeatures(node)\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\terr = g.ForEachChannel(func(info *ChannelEdgeInfo,\n\t\t\tpolicy1, policy2 *ChannelEdgePolicy) error {\n\n\t\t\tg.graphCache.AddChannel(info, policy1, policy2)\n\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tlog.Debugf(\"Finished populating in-memory channel graph (took \"+\n\t\t\t\"%v, %s)\", time.Since(startTime), g.graphCache.Stats())\n\t}\n\n\treturn g, nil\n}\n\n// channelMapKey is the key structure used for storing channel edge policies.",
      "length": 1381,
      "tokens": 163,
      "embedding": []
    },
    {
      "slug": "type channelMapKey struct {",
      "content": "type channelMapKey struct {\n\tnodeKey route.Vertex\n\tchanID  [8]byte\n}\n\n// getChannelMap loads all channel edge policies from the database and stores\n// them in a map.",
      "length": 132,
      "tokens": 22,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) getChannelMap(edges kvdb.RBucket) (",
      "content": "func (c *ChannelGraph) getChannelMap(edges kvdb.RBucket) (\n\tmap[channelMapKey]*ChannelEdgePolicy, error) {\n\n\t// Create a map to store all channel edge policies.\n\tchannelMap := make(map[channelMapKey]*ChannelEdgePolicy)\n\n\terr := kvdb.ForAll(edges, func(k, edgeBytes []byte) error {\n\t\t// Skip embedded buckets.\n\t\tif bytes.Equal(k, edgeIndexBucket) ||\n\t\t\tbytes.Equal(k, edgeUpdateIndexBucket) ||\n\t\t\tbytes.Equal(k, zombieBucket) ||\n\t\t\tbytes.Equal(k, disabledEdgePolicyBucket) ||\n\t\t\tbytes.Equal(k, channelPointBucket) {\n\n\t\t\treturn nil\n\t\t}\n\n\t\t// Validate key length.\n\t\tif len(k) != 33+8 {\n\t\t\treturn fmt.Errorf(\"invalid edge key %x encountered\", k)\n\t\t}\n\n\t\tvar key channelMapKey\n\t\tcopy(key.nodeKey[:], k[:33])\n\t\tcopy(key.chanID[:], k[33:])\n\n\t\t// No need to deserialize unknown policy.\n\t\tif bytes.Equal(edgeBytes, unknownPolicy) {\n\t\t\treturn nil\n\t\t}\n\n\t\tedgeReader := bytes.NewReader(edgeBytes)\n\t\tedge, err := deserializeChanEdgePolicyRaw(\n\t\t\tedgeReader,\n\t\t)\n\n\t\tswitch {\n\t\t// If the db policy was missing an expected optional field, we\n\t\t// return nil as if the policy was unknown.\n\t\tcase err == ErrEdgePolicyOptionalFieldNotFound:\n\t\t\treturn nil\n\n\t\tcase err != nil:\n\t\t\treturn err\n\t\t}\n\n\t\tchannelMap[key] = edge\n\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn channelMap, nil\n}\n\nvar graphTopLevelBuckets = [][]byte{\n\tnodeBucket,\n\tedgeBucket,\n\tedgeIndexBucket,\n\tgraphMetaBucket,\n}\n\n// Wipe completely deletes all saved state within all used buckets within the\n// database. The deletion is done in a single transaction, therefore this\n// operation is fully atomic.",
      "length": 1442,
      "tokens": 188,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) Wipe() error {",
      "content": "func (c *ChannelGraph) Wipe() error {\n\terr := kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tfor _, tlb := range graphTopLevelBuckets {\n\t\t\terr := tx.DeleteTopLevelBucket(tlb)\n\t\t\tif err != nil && err != kvdb.ErrBucketNotFound {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn initChannelGraph(c.db)\n}\n\n// createChannelDB creates and initializes a fresh version of channeldb. In\n// the case that the target path has not yet been created or doesn't yet exist,\n// then the path is created. Additionally, all required top-level buckets used\n// within the database are created.",
      "length": 560,
      "tokens": 91,
      "embedding": []
    },
    {
      "slug": "func initChannelGraph(db kvdb.Backend) error {",
      "content": "func initChannelGraph(db kvdb.Backend) error {\n\terr := kvdb.Update(db, func(tx kvdb.RwTx) error {\n\t\tfor _, tlb := range graphTopLevelBuckets {\n\t\t\tif _, err := tx.CreateTopLevelBucket(tlb); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tnodes := tx.ReadWriteBucket(nodeBucket)\n\t\t_, err := nodes.CreateBucketIfNotExists(aliasIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t_, err = nodes.CreateBucketIfNotExists(nodeUpdateIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\t_, err = edges.CreateBucketIfNotExists(edgeIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t_, err = edges.CreateBucketIfNotExists(edgeUpdateIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t_, err = edges.CreateBucketIfNotExists(channelPointBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t_, err = edges.CreateBucketIfNotExists(zombieBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tgraphMeta := tx.ReadWriteBucket(graphMetaBucket)\n\t\t_, err = graphMeta.CreateBucketIfNotExists(pruneLogBucket)\n\t\treturn err\n\t}, func() {})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to create new channel graph: %v\", err)\n\t}\n\n\treturn nil\n}\n\n// NewPathFindTx returns a new read transaction that can be used for a single\n// path finding session. Will return nil if the graph cache is enabled.",
      "length": 1189,
      "tokens": 162,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) NewPathFindTx() (kvdb.RTx, error) {",
      "content": "func (c *ChannelGraph) NewPathFindTx() (kvdb.RTx, error) {\n\tif c.graphCache != nil {\n\t\treturn nil, nil\n\t}\n\n\treturn c.db.BeginReadTx()\n}\n\n// ForEachChannel iterates through all the channel edges stored within the\n// graph and invokes the passed callback for each edge. The callback takes two\n// edges as since this is a directed graph, both the in/out edges are visited.\n// If the callback returns an error, then the transaction is aborted and the\n// iteration stops early.\n//\n// NOTE: If an edge can't be found, or wasn't advertised, then a nil pointer\n// for that particular channel edge routing policy will be passed into the\n// callback.",
      "length": 566,
      "tokens": 101,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ForEachChannel(cb func(*ChannelEdgeInfo,",
      "content": "func (c *ChannelGraph) ForEachChannel(cb func(*ChannelEdgeInfo,\n\t*ChannelEdgePolicy, *ChannelEdgePolicy) error) error {\n\n\treturn c.db.View(func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// First, load all edges in memory indexed by node and channel\n\t\t// id.\n\t\tchannelMap, err := c.getChannelMap(edges)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// Load edge index, recombine each channel with the policies\n\t\t// loaded above and invoke the callback.\n\t\treturn kvdb.ForAll(edgeIndex, func(k, edgeInfoBytes []byte) error {\n\t\t\tvar chanID [8]byte\n\t\t\tcopy(chanID[:], k)\n\n\t\t\tedgeInfoReader := bytes.NewReader(edgeInfoBytes)\n\t\t\tinfo, err := deserializeChanEdgeInfo(edgeInfoReader)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tpolicy1 := channelMap[channelMapKey{\n\t\t\t\tnodeKey: info.NodeKey1Bytes,\n\t\t\t\tchanID:  chanID,\n\t\t\t}]\n\n\t\t\tpolicy2 := channelMap[channelMapKey{\n\t\t\t\tnodeKey: info.NodeKey2Bytes,\n\t\t\t\tchanID:  chanID,\n\t\t\t}]\n\n\t\t\treturn cb(&info, policy1, policy2)\n\t\t})\n\t}, func() {})\n}\n\n// ForEachNodeChannel iterates through all channels of a given node, executing the\n// passed callback with an edge info structure and the policies of each end\n// of the channel. The first edge policy is the outgoing edge *to* the\n// connecting node, while the second is the incoming edge *from* the\n// connecting node. If the callback returns an error, then the iteration is\n// halted with the error propagated back up to the caller.\n//\n// Unknown policies are passed into the callback as nil values.",
      "length": 1542,
      "tokens": 215,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ForEachNodeChannel(tx kvdb.RTx, node route.Vertex,",
      "content": "func (c *ChannelGraph) ForEachNodeChannel(tx kvdb.RTx, node route.Vertex,\n\tcb func(channel *DirectedChannel) error) error {\n\n\tif c.graphCache != nil {\n\t\treturn c.graphCache.ForEachChannel(node, cb)\n\t}\n\n\t// Fallback that uses the database.\n\ttoNodeCallback := func() route.Vertex {\n\t\treturn node\n\t}\n\ttoNodeFeatures, err := c.FetchNodeFeatures(node)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdbCallback := func(tx kvdb.RTx, e *ChannelEdgeInfo, p1,\n\t\tp2 *ChannelEdgePolicy) error {\n\n\t\tvar cachedInPolicy *CachedEdgePolicy\n\t\tif p2 != nil {\n\t\t\tcachedInPolicy = NewCachedPolicy(p2)\n\t\t\tcachedInPolicy.ToNodePubKey = toNodeCallback\n\t\t\tcachedInPolicy.ToNodeFeatures = toNodeFeatures\n\t\t}\n\n\t\tdirectedChannel := &DirectedChannel{\n\t\t\tChannelID:    e.ChannelID,\n\t\t\tIsNode1:      node == e.NodeKey1Bytes,\n\t\t\tOtherNode:    e.NodeKey2Bytes,\n\t\t\tCapacity:     e.Capacity,\n\t\t\tOutPolicySet: p1 != nil,\n\t\t\tInPolicy:     cachedInPolicy,\n\t\t}\n\n\t\tif node == e.NodeKey2Bytes {\n\t\t\tdirectedChannel.OtherNode = e.NodeKey1Bytes\n\t\t}\n\n\t\treturn cb(directedChannel)\n\t}\n\treturn nodeTraversal(tx, node[:], c.db, dbCallback)\n}\n\n// FetchNodeFeatures returns the features of a given node. If no features are\n// known for the node, an empty feature vector is returned.",
      "length": 1101,
      "tokens": 132,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FetchNodeFeatures(",
      "content": "func (c *ChannelGraph) FetchNodeFeatures(\n\tnode route.Vertex) (*lnwire.FeatureVector, error) {\n\n\tif c.graphCache != nil {\n\t\treturn c.graphCache.GetFeatures(node), nil\n\t}\n\n\t// Fallback that uses the database.\n\ttargetNode, err := c.FetchLightningNode(node)\n\tswitch err {\n\t// If the node exists and has features, return them directly.\n\tcase nil:\n\t\treturn targetNode.Features, nil\n\n\t// If we couldn't find a node announcement, populate a blank feature\n\t// vector.\n\tcase ErrGraphNodeNotFound:\n\t\treturn lnwire.EmptyFeatureVector(), nil\n\n\t// Otherwise, bubble the error up.\n\tdefault:\n\t\treturn nil, err\n\t}\n}\n\n// ForEachNodeCached is similar to ForEachNode, but it utilizes the channel\n// graph cache instead. Note that this doesn't return all the information the\n// regular ForEachNode method does.\n//\n// NOTE: The callback contents MUST not be modified.",
      "length": 776,
      "tokens": 113,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ForEachNodeCached(cb func(node route.Vertex,",
      "content": "func (c *ChannelGraph) ForEachNodeCached(cb func(node route.Vertex,\n\tchans map[uint64]*DirectedChannel) error) error {\n\n\tif c.graphCache != nil {\n\t\treturn c.graphCache.ForEachNode(cb)\n\t}\n\n\t// Otherwise call back to a version that uses the database directly.\n\t// We'll iterate over each node, then the set of channels for each\n\t// node, and construct a similar callback functiopn signature as the\n\t// main funcotin expects.\n\treturn c.ForEachNode(func(tx kvdb.RTx, node *LightningNode) error {\n\t\tchannels := make(map[uint64]*DirectedChannel)\n\n\t\terr := node.ForEachChannel(tx, func(tx kvdb.RTx,\n\t\t\te *ChannelEdgeInfo, p1 *ChannelEdgePolicy,\n\t\t\tp2 *ChannelEdgePolicy) error {\n\n\t\t\ttoNodeCallback := func() route.Vertex {\n\t\t\t\treturn node.PubKeyBytes\n\t\t\t}\n\t\t\ttoNodeFeatures, err := c.FetchNodeFeatures(\n\t\t\t\tnode.PubKeyBytes,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tvar cachedInPolicy *CachedEdgePolicy\n\t\t\tif p2 != nil {\n\t\t\t\tcachedInPolicy := NewCachedPolicy(p2)\n\t\t\t\tcachedInPolicy.ToNodePubKey = toNodeCallback\n\t\t\t\tcachedInPolicy.ToNodeFeatures = toNodeFeatures\n\t\t\t}\n\n\t\t\tdirectedChannel := &DirectedChannel{\n\t\t\t\tChannelID:    e.ChannelID,\n\t\t\t\tIsNode1:      node.PubKeyBytes == e.NodeKey1Bytes,\n\t\t\t\tOtherNode:    e.NodeKey2Bytes,\n\t\t\t\tCapacity:     e.Capacity,\n\t\t\t\tOutPolicySet: p1 != nil,\n\t\t\t\tInPolicy:     cachedInPolicy,\n\t\t\t}\n\n\t\t\tif node.PubKeyBytes == e.NodeKey2Bytes {\n\t\t\t\tdirectedChannel.OtherNode = e.NodeKey1Bytes\n\t\t\t}\n\n\t\t\tchannels[e.ChannelID] = directedChannel\n\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn cb(node.PubKeyBytes, channels)\n\t})\n}\n\n// DisabledChannelIDs returns the channel ids of disabled channels.\n// A channel is disabled when two of the associated ChanelEdgePolicies\n// have their disabled bit on.",
      "length": 1614,
      "tokens": 190,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) DisabledChannelIDs() ([]uint64, error) {",
      "content": "func (c *ChannelGraph) DisabledChannelIDs() ([]uint64, error) {\n\tvar disabledChanIDs []uint64\n\tvar chanEdgeFound map[uint64]struct{}\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\tdisabledEdgePolicyIndex := edges.NestedReadBucket(\n\t\t\tdisabledEdgePolicyBucket,\n\t\t)\n\t\tif disabledEdgePolicyIndex == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// We iterate over all disabled policies and we add each channel that\n\t\t// has more than one disabled policy to disabledChanIDs array.\n\t\treturn disabledEdgePolicyIndex.ForEach(func(k, v []byte) error {\n\t\t\tchanID := byteOrder.Uint64(k[:8])\n\t\t\t_, edgeFound := chanEdgeFound[chanID]\n\t\t\tif edgeFound {\n\t\t\t\tdelete(chanEdgeFound, chanID)\n\t\t\t\tdisabledChanIDs = append(disabledChanIDs, chanID)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tchanEdgeFound[chanID] = struct{}{}\n\t\t\treturn nil\n\t\t})\n\t}, func() {\n\t\tdisabledChanIDs = nil\n\t\tchanEdgeFound = make(map[uint64]struct{})\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn disabledChanIDs, nil\n}\n\n// ForEachNode iterates through all the stored vertices/nodes in the graph,\n// executing the passed callback with each node encountered. If the callback\n// returns an error, then the transaction is aborted and the iteration stops\n// early.\n//\n// TODO(roasbeef): add iterator interface to allow for memory efficient graph\n// traversal when graph gets mega",
      "length": 1285,
      "tokens": 170,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ForEachNode(",
      "content": "func (c *ChannelGraph) ForEachNode(\n\tcb func(kvdb.RTx, *LightningNode) error) error {\n\n\ttraversal := func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\treturn nodes.ForEach(func(pubKey, nodeBytes []byte) error {\n\t\t\t// If this is the source key, then we skip this\n\t\t\t// iteration as the value for this key is a pubKey\n\t\t\t// rather than raw node information.\n\t\t\tif bytes.Equal(pubKey, sourceKey) || len(pubKey) != 33 {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tnodeReader := bytes.NewReader(nodeBytes)\n\t\t\tnode, err := deserializeLightningNode(nodeReader)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tnode.db = c.db\n\n\t\t\t// Execute the callback, the transaction will abort if\n\t\t\t// this returns an error.\n\t\t\treturn cb(tx, &node)\n\t\t})\n\t}\n\n\treturn kvdb.View(c.db, traversal, func() {})\n}\n\n// ForEachNodeCacheable iterates through all the stored vertices/nodes in the\n// graph, executing the passed callback with each node encountered. If the\n// callback returns an error, then the transaction is aborted and the iteration\n// stops early.",
      "length": 1099,
      "tokens": 165,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ForEachNodeCacheable(cb func(kvdb.RTx,",
      "content": "func (c *ChannelGraph) ForEachNodeCacheable(cb func(kvdb.RTx,\n\tGraphCacheNode) error) error {\n\n\ttraversal := func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\treturn nodes.ForEach(func(pubKey, nodeBytes []byte) error {\n\t\t\t// If this is the source key, then we skip this\n\t\t\t// iteration as the value for this key is a pubKey\n\t\t\t// rather than raw node information.\n\t\t\tif bytes.Equal(pubKey, sourceKey) || len(pubKey) != 33 {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tnodeReader := bytes.NewReader(nodeBytes)\n\t\t\tcacheableNode, err := deserializeLightningNodeCacheable(\n\t\t\t\tnodeReader,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Execute the callback, the transaction will abort if\n\t\t\t// this returns an error.\n\t\t\treturn cb(tx, cacheableNode)\n\t\t})\n\t}\n\n\treturn kvdb.View(c.db, traversal, func() {})\n}\n\n// SourceNode returns the source node of the graph. The source node is treated\n// as the center node within a star-graph. This method may be used to kick off\n// a path finding algorithm in order to explore the reachability of another\n// node based off the source node.",
      "length": 1118,
      "tokens": 174,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) SourceNode() (*LightningNode, error) {",
      "content": "func (c *ChannelGraph) SourceNode() (*LightningNode, error) {\n\tvar source *LightningNode\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\tnode, err := c.sourceNode(nodes)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsource = node\n\n\t\treturn nil\n\t}, func() {\n\t\tsource = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn source, nil\n}\n\n// sourceNode uses an existing database transaction and returns the source node\n// of the graph. The source node is treated as the center node within a\n// star-graph. This method may be used to kick off a path finding algorithm in\n// order to explore the reachability of another node based off the source node.",
      "length": 738,
      "tokens": 130,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) sourceNode(nodes kvdb.RBucket) (*LightningNode, error) {",
      "content": "func (c *ChannelGraph) sourceNode(nodes kvdb.RBucket) (*LightningNode, error) {\n\tselfPub := nodes.Get(sourceKey)\n\tif selfPub == nil {\n\t\treturn nil, ErrSourceNodeNotSet\n\t}\n\n\t// With the pubKey of the source node retrieved, we're able to\n\t// fetch the full node information.\n\tnode, err := fetchLightningNode(nodes, selfPub)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnode.db = c.db\n\n\treturn &node, nil\n}\n\n// SetSourceNode sets the source node within the graph database. The source\n// node is to be used as the center of a star-graph within path finding\n// algorithms.",
      "length": 463,
      "tokens": 80,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) SetSourceNode(node *LightningNode) error {",
      "content": "func (c *ChannelGraph) SetSourceNode(node *LightningNode) error {\n\tnodePubBytes := node.PubKeyBytes[:]\n\n\treturn kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Next we create the mapping from source to the targeted\n\t\t// public key.\n\t\tif err := nodes.Put(sourceKey, nodePubBytes); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Finally, we commit the information of the lightning node\n\t\t// itself.\n\t\treturn addLightningNode(tx, node)\n\t}, func() {})\n}\n\n// AddLightningNode adds a vertex/node to the graph database. If the node is not\n// in the database from before, this will add a new, unconnected one to the\n// graph. If it is present from before, this will update that node's\n// information. Note that this method is expected to only be called to update an\n// already present node from a node announcement, or to insert a node found in a\n// channel update.\n//\n// TODO(roasbeef): also need sig of announcement",
      "length": 991,
      "tokens": 166,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) AddLightningNode(node *LightningNode,",
      "content": "func (c *ChannelGraph) AddLightningNode(node *LightningNode,\n\top ...batch.SchedulerOption) error {\n\n\tr := &batch.Request{\n\t\tUpdate: func(tx kvdb.RwTx) error {\n\t\t\tif c.graphCache != nil {\n\t\t\t\tcNode := newGraphCacheNode(\n\t\t\t\t\tnode.PubKeyBytes, node.Features,\n\t\t\t\t)\n\t\t\t\terr := c.graphCache.AddNode(tx, cNode)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn addLightningNode(tx, node)\n\t\t},\n\t}\n\n\tfor _, f := range op {\n\t\tf(r)\n\t}\n\n\treturn c.nodeScheduler.Execute(r)\n}\n",
      "length": 387,
      "tokens": 53,
      "embedding": []
    },
    {
      "slug": "func addLightningNode(tx kvdb.RwTx, node *LightningNode) error {",
      "content": "func addLightningNode(tx kvdb.RwTx, node *LightningNode) error {\n\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\taliases, err := nodes.CreateBucketIfNotExists(aliasIndexBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tupdateIndex, err := nodes.CreateBucketIfNotExists(\n\t\tnodeUpdateIndexBucket,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn putLightningNode(nodes, aliases, updateIndex, node)\n}\n\n// LookupAlias attempts to return the alias as advertised by the target node.\n// TODO(roasbeef): currently assumes that aliases are unique...",
      "length": 481,
      "tokens": 65,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) LookupAlias(pub *btcec.PublicKey) (string, error) {",
      "content": "func (c *ChannelGraph) LookupAlias(pub *btcec.PublicKey) (string, error) {\n\tvar alias string\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\n\t\taliases := nodes.NestedReadBucket(aliasIndexBucket)\n\t\tif aliases == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\n\t\tnodePub := pub.SerializeCompressed()\n\t\ta := aliases.Get(nodePub)\n\t\tif a == nil {\n\t\t\treturn ErrNodeAliasNotFound\n\t\t}\n\n\t\t// TODO(roasbeef): should actually be using the utf-8\n\t\t// package...\n\t\talias = string(a)\n\t\treturn nil\n\t}, func() {\n\t\talias = \"\"\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn alias, nil\n}\n\n// DeleteLightningNode starts a new database transaction to remove a vertex/node\n// from the database according to the node's public key.",
      "length": 693,
      "tokens": 102,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) DeleteLightningNode(nodePub route.Vertex) error {",
      "content": "func (c *ChannelGraph) DeleteLightningNode(nodePub route.Vertex) error {\n\t// TODO(roasbeef): ensure dangling edges are removed...\n\treturn kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tnodes := tx.ReadWriteBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodeNotFound\n\t\t}\n\n\t\tif c.graphCache != nil {\n\t\t\tc.graphCache.RemoveNode(nodePub)\n\t\t}\n\n\t\treturn c.deleteLightningNode(nodes, nodePub[:])\n\t}, func() {})\n}\n\n// deleteLightningNode uses an existing database transaction to remove a\n// vertex/node from the database according to the node's public key.",
      "length": 469,
      "tokens": 59,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) deleteLightningNode(nodes kvdb.RwBucket,",
      "content": "func (c *ChannelGraph) deleteLightningNode(nodes kvdb.RwBucket,\n\tcompressedPubKey []byte) error {\n\n\taliases := nodes.NestedReadWriteBucket(aliasIndexBucket)\n\tif aliases == nil {\n\t\treturn ErrGraphNodesNotFound\n\t}\n\n\tif err := aliases.Delete(compressedPubKey); err != nil {\n\t\treturn err\n\t}\n\n\t// Before we delete the node, we'll fetch its current state so we can\n\t// determine when its last update was to clear out the node update\n\t// index.\n\tnode, err := fetchLightningNode(nodes, compressedPubKey)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := nodes.Delete(compressedPubKey); err != nil {\n\t\treturn err\n\t}\n\n\t// Finally, we'll delete the index entry for the node within the\n\t// nodeUpdateIndexBucket as this node is no longer active, so we don't\n\t// need to track its last update.\n\tnodeUpdateIndex := nodes.NestedReadWriteBucket(nodeUpdateIndexBucket)\n\tif nodeUpdateIndex == nil {\n\t\treturn ErrGraphNodesNotFound\n\t}\n\n\t// In order to delete the entry, we'll need to reconstruct the key for\n\t// its last update.\n\tupdateUnix := uint64(node.LastUpdate.Unix())\n\tvar indexKey [8 + 33]byte\n\tbyteOrder.PutUint64(indexKey[:8], updateUnix)\n\tcopy(indexKey[8:], compressedPubKey)\n\n\treturn nodeUpdateIndex.Delete(indexKey[:])\n}\n\n// AddChannelEdge adds a new (undirected, blank) edge to the graph database. An\n// undirected edge from the two target nodes are created. The information stored\n// denotes the static attributes of the channel, such as the channelID, the keys\n// involved in creation of the channel, and the set of features that the channel\n// supports. The chanPoint and chanID are used to uniquely identify the edge\n// globally within the database.",
      "length": 1532,
      "tokens": 227,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) AddChannelEdge(edge *ChannelEdgeInfo,",
      "content": "func (c *ChannelGraph) AddChannelEdge(edge *ChannelEdgeInfo,\n\top ...batch.SchedulerOption) error {\n\n\tvar alreadyExists bool\n\tr := &batch.Request{\n\t\tReset: func() {\n\t\t\talreadyExists = false\n\t\t},\n\t\tUpdate: func(tx kvdb.RwTx) error {\n\t\t\terr := c.addChannelEdge(tx, edge)\n\n\t\t\t// Silence ErrEdgeAlreadyExist so that the batch can\n\t\t\t// succeed, but propagate the error via local state.\n\t\t\tif err == ErrEdgeAlreadyExist {\n\t\t\t\talreadyExists = true\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\treturn err\n\t\t},\n\t\tOnCommit: func(err error) error {\n\t\t\tswitch {\n\t\t\tcase err != nil:\n\t\t\t\treturn err\n\t\t\tcase alreadyExists:\n\t\t\t\treturn ErrEdgeAlreadyExist\n\t\t\tdefault:\n\t\t\t\tc.rejectCache.remove(edge.ChannelID)\n\t\t\t\tc.chanCache.remove(edge.ChannelID)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t},\n\t}\n\n\tfor _, f := range op {\n\t\tf(r)\n\t}\n\n\treturn c.chanScheduler.Execute(r)\n}\n\n// addChannelEdge is the private form of AddChannelEdge that allows callers to\n// utilize an existing db transaction.",
      "length": 827,
      "tokens": 112,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) addChannelEdge(tx kvdb.RwTx, edge *ChannelEdgeInfo) error {",
      "content": "func (c *ChannelGraph) addChannelEdge(tx kvdb.RwTx, edge *ChannelEdgeInfo) error {\n\t// Construct the channel's primary key which is the 8-byte channel ID.\n\tvar chanKey [8]byte\n\tbinary.BigEndian.PutUint64(chanKey[:], edge.ChannelID)\n\n\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\tedges, err := tx.CreateTopLevelBucket(edgeBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\tedgeIndex, err := edges.CreateBucketIfNotExists(edgeIndexBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\tchanIndex, err := edges.CreateBucketIfNotExists(channelPointBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// First, attempt to check if this edge has already been created. If\n\t// so, then we can exit early as this method is meant to be idempotent.\n\tif edgeInfo := edgeIndex.Get(chanKey[:]); edgeInfo != nil {\n\t\treturn ErrEdgeAlreadyExist\n\t}\n\n\tif c.graphCache != nil {\n\t\tc.graphCache.AddChannel(edge, nil, nil)\n\t}\n\n\t// Before we insert the channel into the database, we'll ensure that\n\t// both nodes already exist in the channel graph. If either node\n\t// doesn't, then we'll insert a \"shell\" node that just includes its\n\t// public key, so subsequent validation and queries can work properly.\n\t_, node1Err := fetchLightningNode(nodes, edge.NodeKey1Bytes[:])\n\tswitch {\n\tcase node1Err == ErrGraphNodeNotFound:\n\t\tnode1Shell := LightningNode{\n\t\t\tPubKeyBytes:          edge.NodeKey1Bytes,\n\t\t\tHaveNodeAnnouncement: false,\n\t\t}\n\t\terr := addLightningNode(tx, &node1Shell)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to create shell node \"+\n\t\t\t\t\"for: %x\", edge.NodeKey1Bytes)\n\t\t}\n\tcase node1Err != nil:\n\t\treturn err\n\t}\n\n\t_, node2Err := fetchLightningNode(nodes, edge.NodeKey2Bytes[:])\n\tswitch {\n\tcase node2Err == ErrGraphNodeNotFound:\n\t\tnode2Shell := LightningNode{\n\t\t\tPubKeyBytes:          edge.NodeKey2Bytes,\n\t\t\tHaveNodeAnnouncement: false,\n\t\t}\n\t\terr := addLightningNode(tx, &node2Shell)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to create shell node \"+\n\t\t\t\t\"for: %x\", edge.NodeKey2Bytes)\n\t\t}\n\tcase node2Err != nil:\n\t\treturn err\n\t}\n\n\t// If the edge hasn't been created yet, then we'll first add it to the\n\t// edge index in order to associate the edge between two nodes and also\n\t// store the static components of the channel.\n\tif err := putChanEdgeInfo(edgeIndex, edge, chanKey); err != nil {\n\t\treturn err\n\t}\n\n\t// Mark edge policies for both sides as unknown. This is to enable\n\t// efficient incoming channel lookup for a node.\n\tkeys := []*[33]byte{\n\t\t&edge.NodeKey1Bytes,\n\t\t&edge.NodeKey2Bytes,\n\t}\n\tfor _, key := range keys {\n\t\terr := putChanEdgePolicyUnknown(edges, edge.ChannelID, key[:])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Finally we add it to the channel index which maps channel points\n\t// (outpoints) to the shorter channel ID's.\n\tvar b bytes.Buffer\n\tif err := writeOutpoint(&b, &edge.ChannelPoint); err != nil {\n\t\treturn err\n\t}\n\treturn chanIndex.Put(b.Bytes(), chanKey[:])\n}\n\n// HasChannelEdge returns true if the database knows of a channel edge with the\n// passed channel ID, and false otherwise. If an edge with that ID is found\n// within the graph, then two time stamps representing the last time the edge\n// was updated for both directed edges are returned along with the boolean. If\n// it is not found, then the zombie index is checked and its result is returned\n// as the second boolean.",
      "length": 3123,
      "tokens": 467,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) HasChannelEdge(",
      "content": "func (c *ChannelGraph) HasChannelEdge(\n\tchanID uint64) (time.Time, time.Time, bool, bool, error) {\n\n\tvar (\n\t\tupd1Time time.Time\n\t\tupd2Time time.Time\n\t\texists   bool\n\t\tisZombie bool\n\t)\n\n\t// We'll query the cache with the shared lock held to allow multiple\n\t// readers to access values in the cache concurrently if they exist.\n\tc.cacheMu.RLock()\n\tif entry, ok := c.rejectCache.get(chanID); ok {\n\t\tc.cacheMu.RUnlock()\n\t\tupd1Time = time.Unix(entry.upd1Time, 0)\n\t\tupd2Time = time.Unix(entry.upd2Time, 0)\n\t\texists, isZombie = entry.flags.unpack()\n\t\treturn upd1Time, upd2Time, exists, isZombie, nil\n\t}\n\tc.cacheMu.RUnlock()\n\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\t// The item was not found with the shared lock, so we'll acquire the\n\t// exclusive lock and check the cache again in case another method added\n\t// the entry to the cache while no lock was held.\n\tif entry, ok := c.rejectCache.get(chanID); ok {\n\t\tupd1Time = time.Unix(entry.upd1Time, 0)\n\t\tupd2Time = time.Unix(entry.upd2Time, 0)\n\t\texists, isZombie = entry.flags.unpack()\n\t\treturn upd1Time, upd2Time, exists, isZombie, nil\n\t}\n\n\tif err := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\tvar channelID [8]byte\n\t\tbyteOrder.PutUint64(channelID[:], chanID)\n\n\t\t// If the edge doesn't exist, then we'll also check our zombie\n\t\t// index.\n\t\tif edgeIndex.Get(channelID[:]) == nil {\n\t\t\texists = false\n\t\t\tzombieIndex := edges.NestedReadBucket(zombieBucket)\n\t\t\tif zombieIndex != nil {\n\t\t\t\tisZombie, _, _ = isZombieEdge(\n\t\t\t\t\tzombieIndex, chanID,\n\t\t\t\t)\n\t\t\t}\n\n\t\t\treturn nil\n\t\t}\n\n\t\texists = true\n\t\tisZombie = false\n\n\t\t// If the channel has been found in the graph, then retrieve\n\t\t// the edges itself so we can return the last updated\n\t\t// timestamps.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodeNotFound\n\t\t}\n\n\t\te1, e2, err := fetchChanEdgePolicies(edgeIndex, edges, nodes,\n\t\t\tchannelID[:], c.db)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// As we may have only one of the edges populated, only set the\n\t\t// update time if the edge was found in the database.\n\t\tif e1 != nil {\n\t\t\tupd1Time = e1.LastUpdate\n\t\t}\n\t\tif e2 != nil {\n\t\t\tupd2Time = e2.LastUpdate\n\t\t}\n\n\t\treturn nil\n\t}, func() {}); err != nil {\n\t\treturn time.Time{}, time.Time{}, exists, isZombie, err\n\t}\n\n\tc.rejectCache.insert(chanID, rejectCacheEntry{\n\t\tupd1Time: upd1Time.Unix(),\n\t\tupd2Time: upd2Time.Unix(),\n\t\tflags:    packRejectFlags(exists, isZombie),\n\t})\n\n\treturn upd1Time, upd2Time, exists, isZombie, nil\n}\n\n// UpdateChannelEdge retrieves and update edge of the graph database. Method\n// only reserved for updating an edge info after its already been created.\n// In order to maintain this constraints, we return an error in the scenario\n// that an edge info hasn't yet been created yet, but someone attempts to update\n// it.",
      "length": 2823,
      "tokens": 407,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) UpdateChannelEdge(edge *ChannelEdgeInfo) error {",
      "content": "func (c *ChannelGraph) UpdateChannelEdge(edge *ChannelEdgeInfo) error {\n\t// Construct the channel's primary key which is the 8-byte channel ID.\n\tvar chanKey [8]byte\n\tbinary.BigEndian.PutUint64(chanKey[:], edge.ChannelID)\n\n\treturn kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\tif edge == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\n\t\tedgeIndex := edges.NestedReadWriteBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\n\t\tif edgeInfo := edgeIndex.Get(chanKey[:]); edgeInfo == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\n\t\tif c.graphCache != nil {\n\t\t\tc.graphCache.UpdateChannel(edge)\n\t\t}\n\n\t\treturn putChanEdgeInfo(edgeIndex, edge, chanKey)\n\t}, func() {})\n}\n\nconst (\n\t// pruneTipBytes is the total size of the value which stores a prune\n\t// entry of the graph in the prune log. The \"prune tip\" is the last\n\t// entry in the prune log, and indicates if the channel graph is in\n\t// sync with the current UTXO state. The structure of the value\n\t// is: blockHash, taking 32 bytes total.\n\tpruneTipBytes = 32\n)\n\n// PruneGraph prunes newly closed channels from the channel graph in response\n// to a new block being solved on the network. Any transactions which spend the\n// funding output of any known channels within he graph will be deleted.\n// Additionally, the \"prune tip\", or the last block which has been used to\n// prune the graph is stored so callers can ensure the graph is fully in sync\n// with the current UTXO state. A slice of channels that have been closed by\n// the target block are returned if the function succeeds without error.",
      "length": 1477,
      "tokens": 235,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) PruneGraph(spentOutputs []*wire.OutPoint,",
      "content": "func (c *ChannelGraph) PruneGraph(spentOutputs []*wire.OutPoint,\n\tblockHash *chainhash.Hash, blockHeight uint32) ([]*ChannelEdgeInfo, error) {\n\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\tvar chansClosed []*ChannelEdgeInfo\n\n\terr := kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\t// First grab the edges bucket which houses the information\n\t\t// we'd like to delete\n\t\tedges, err := tx.CreateTopLevelBucket(edgeBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Next grab the two edge indexes which will also need to be updated.\n\t\tedgeIndex, err := edges.CreateBucketIfNotExists(edgeIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tchanIndex, err := edges.CreateBucketIfNotExists(channelPointBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnodes := tx.ReadWriteBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrSourceNodeNotSet\n\t\t}\n\t\tzombieIndex, err := edges.CreateBucketIfNotExists(zombieBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// For each of the outpoints that have been spent within the\n\t\t// block, we attempt to delete them from the graph as if that\n\t\t// outpoint was a channel, then it has now been closed.\n\t\tfor _, chanPoint := range spentOutputs {\n\t\t\t// TODO(roasbeef): load channel bloom filter, continue\n\t\t\t// if NOT if filter\n\n\t\t\tvar opBytes bytes.Buffer\n\t\t\tif err := writeOutpoint(&opBytes, chanPoint); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// First attempt to see if the channel exists within\n\t\t\t// the database, if not, then we can exit early.\n\t\t\tchanID := chanIndex.Get(opBytes.Bytes())\n\t\t\tif chanID == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// However, if it does, then we'll read out the full\n\t\t\t// version so we can add it to the set of deleted\n\t\t\t// channels.\n\t\t\tedgeInfo, err := fetchChanEdgeInfo(edgeIndex, chanID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Attempt to delete the channel, an ErrEdgeNotFound\n\t\t\t// will be returned if that outpoint isn't known to be\n\t\t\t// a channel. If no error is returned, then a channel\n\t\t\t// was successfully pruned.\n\t\t\terr = c.delChannelEdge(\n\t\t\t\tedges, edgeIndex, chanIndex, zombieIndex, nodes,\n\t\t\t\tchanID, false, false,\n\t\t\t)\n\t\t\tif err != nil && err != ErrEdgeNotFound {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tchansClosed = append(chansClosed, &edgeInfo)\n\t\t}\n\n\t\tmetaBucket, err := tx.CreateTopLevelBucket(graphMetaBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpruneBucket, err := metaBucket.CreateBucketIfNotExists(pruneLogBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// With the graph pruned, add a new entry to the prune log,\n\t\t// which can be used to check if the graph is fully synced with\n\t\t// the current UTXO state.\n\t\tvar blockHeightBytes [4]byte\n\t\tbyteOrder.PutUint32(blockHeightBytes[:], blockHeight)\n\n\t\tvar newTip [pruneTipBytes]byte\n\t\tcopy(newTip[:], blockHash[:])\n\n\t\terr = pruneBucket.Put(blockHeightBytes[:], newTip[:])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Now that the graph has been pruned, we'll also attempt to\n\t\t// prune any nodes that have had a channel closed within the\n\t\t// latest block.\n\t\treturn c.pruneGraphNodes(nodes, edgeIndex)\n\t}, func() {\n\t\tchansClosed = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, channel := range chansClosed {\n\t\tc.rejectCache.remove(channel.ChannelID)\n\t\tc.chanCache.remove(channel.ChannelID)\n\t}\n\n\tif c.graphCache != nil {\n\t\tlog.Debugf(\"Pruned graph, cache now has %s\",\n\t\t\tc.graphCache.Stats())\n\t}\n\n\treturn chansClosed, nil\n}\n\n// PruneGraphNodes is a garbage collection method which attempts to prune out\n// any nodes from the channel graph that are currently unconnected. This ensure\n// that we only maintain a graph of reachable nodes. In the event that a pruned\n// node gains more channels, it will be re-added back to the graph.",
      "length": 3451,
      "tokens": 514,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) PruneGraphNodes() error {",
      "content": "func (c *ChannelGraph) PruneGraphNodes() error {\n\treturn kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tnodes := tx.ReadWriteBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadWriteBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\treturn c.pruneGraphNodes(nodes, edgeIndex)\n\t}, func() {})\n}\n\n// pruneGraphNodes attempts to remove any nodes from the graph who have had a\n// channel closed within the current block. If the node still has existing\n// channels in the graph, this will act as a no-op.",
      "length": 611,
      "tokens": 84,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) pruneGraphNodes(nodes kvdb.RwBucket,",
      "content": "func (c *ChannelGraph) pruneGraphNodes(nodes kvdb.RwBucket,\n\tedgeIndex kvdb.RwBucket) error {\n\n\tlog.Trace(\"Pruning nodes from graph with no open channels\")\n\n\t// We'll retrieve the graph's source node to ensure we don't remove it\n\t// even if it no longer has any open channels.\n\tsourceNode, err := c.sourceNode(nodes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// We'll use this map to keep count the number of references to a node\n\t// in the graph. A node should only be removed once it has no more\n\t// references in the graph.\n\tnodeRefCounts := make(map[[33]byte]int)\n\terr = nodes.ForEach(func(pubKey, nodeBytes []byte) error {\n\t\t// If this is the source key, then we skip this\n\t\t// iteration as the value for this key is a pubKey\n\t\t// rather than raw node information.\n\t\tif bytes.Equal(pubKey, sourceKey) || len(pubKey) != 33 {\n\t\t\treturn nil\n\t\t}\n\n\t\tvar nodePub [33]byte\n\t\tcopy(nodePub[:], pubKey)\n\t\tnodeRefCounts[nodePub] = 0\n\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// To ensure we never delete the source node, we'll start off by\n\t// bumping its ref count to 1.\n\tnodeRefCounts[sourceNode.PubKeyBytes] = 1\n\n\t// Next, we'll run through the edgeIndex which maps a channel ID to the\n\t// edge info. We'll use this scan to populate our reference count map\n\t// above.\n\terr = edgeIndex.ForEach(func(chanID, edgeInfoBytes []byte) error {\n\t\t// The first 66 bytes of the edge info contain the pubkeys of\n\t\t// the nodes that this edge attaches. We'll extract them, and\n\t\t// add them to the ref count map.\n\t\tvar node1, node2 [33]byte\n\t\tcopy(node1[:], edgeInfoBytes[:33])\n\t\tcopy(node2[:], edgeInfoBytes[33:])\n\n\t\t// With the nodes extracted, we'll increase the ref count of\n\t\t// each of the nodes.\n\t\tnodeRefCounts[node1]++\n\t\tnodeRefCounts[node2]++\n\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Finally, we'll make a second pass over the set of nodes, and delete\n\t// any nodes that have a ref count of zero.\n\tvar numNodesPruned int\n\tfor nodePubKey, refCount := range nodeRefCounts {\n\t\t// If the ref count of the node isn't zero, then we can safely\n\t\t// skip it as it still has edges to or from it within the\n\t\t// graph.\n\t\tif refCount != 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tif c.graphCache != nil {\n\t\t\tc.graphCache.RemoveNode(nodePubKey)\n\t\t}\n\n\t\t// If we reach this point, then there are no longer any edges\n\t\t// that connect this node, so we can delete it.\n\t\tif err := c.deleteLightningNode(nodes, nodePubKey[:]); err != nil {\n\t\t\tlog.Warnf(\"Unable to prune node %x from the \"+\n\t\t\t\t\"graph: %v\", nodePubKey, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tlog.Infof(\"Pruned unconnected node %x from channel graph\",\n\t\t\tnodePubKey[:])\n\n\t\tnumNodesPruned++\n\t}\n\n\tif numNodesPruned > 0 {\n\t\tlog.Infof(\"Pruned %v unconnected nodes from the channel graph\",\n\t\t\tnumNodesPruned)\n\t}\n\n\treturn nil\n}\n\n// DisconnectBlockAtHeight is used to indicate that the block specified\n// by the passed height has been disconnected from the main chain. This\n// will \"rewind\" the graph back to the height below, deleting channels\n// that are no longer confirmed from the graph. The prune log will be\n// set to the last prune height valid for the remaining chain.\n// Channels that were removed from the graph resulting from the\n// disconnected block are returned.",
      "length": 3033,
      "tokens": 507,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) DisconnectBlockAtHeight(height uint32) ([]*ChannelEdgeInfo,",
      "content": "func (c *ChannelGraph) DisconnectBlockAtHeight(height uint32) ([]*ChannelEdgeInfo,\n\terror) {\n\n\t// Every channel having a ShortChannelID starting at 'height'\n\t// will no longer be confirmed.\n\tstartShortChanID := lnwire.ShortChannelID{\n\t\tBlockHeight: height,\n\t}\n\n\t// Delete everything after this height from the db up until the\n\t// SCID alias range.\n\tendShortChanID := aliasmgr.StartingAlias\n\n\t// The block height will be the 3 first bytes of the channel IDs.\n\tvar chanIDStart [8]byte\n\tbyteOrder.PutUint64(chanIDStart[:], startShortChanID.ToUint64())\n\tvar chanIDEnd [8]byte\n\tbyteOrder.PutUint64(chanIDEnd[:], endShortChanID.ToUint64())\n\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\t// Keep track of the channels that are removed from the graph.\n\tvar removedChans []*ChannelEdgeInfo\n\n\tif err := kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tedges, err := tx.CreateTopLevelBucket(edgeBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tedgeIndex, err := edges.CreateBucketIfNotExists(edgeIndexBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tchanIndex, err := edges.CreateBucketIfNotExists(channelPointBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tzombieIndex, err := edges.CreateBucketIfNotExists(zombieBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Scan from chanIDStart to chanIDEnd, deleting every\n\t\t// found edge.\n\t\t// NOTE: we must delete the edges after the cursor loop, since\n\t\t// modifying the bucket while traversing is not safe.\n\t\t// NOTE: We use a < comparison in bytes.Compare instead of <=\n\t\t// so that the StartingAlias itself isn't deleted.\n\t\tvar keys [][]byte\n\t\tcursor := edgeIndex.ReadWriteCursor()\n\n\t\t//nolint:lll\n\t\tfor k, v := cursor.Seek(chanIDStart[:]); k != nil &&\n\t\t\tbytes.Compare(k, chanIDEnd[:]) < 0; k, v = cursor.Next() {\n\t\t\tedgeInfoReader := bytes.NewReader(v)\n\t\t\tedgeInfo, err := deserializeChanEdgeInfo(edgeInfoReader)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tkeys = append(keys, k)\n\t\t\tremovedChans = append(removedChans, &edgeInfo)\n\t\t}\n\n\t\tfor _, k := range keys {\n\t\t\terr = c.delChannelEdge(\n\t\t\t\tedges, edgeIndex, chanIndex, zombieIndex, nodes,\n\t\t\t\tk, false, false,\n\t\t\t)\n\t\t\tif err != nil && err != ErrEdgeNotFound {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// Delete all the entries in the prune log having a height\n\t\t// greater or equal to the block disconnected.\n\t\tmetaBucket, err := tx.CreateTopLevelBucket(graphMetaBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpruneBucket, err := metaBucket.CreateBucketIfNotExists(pruneLogBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar pruneKeyStart [4]byte\n\t\tbyteOrder.PutUint32(pruneKeyStart[:], height)\n\n\t\tvar pruneKeyEnd [4]byte\n\t\tbyteOrder.PutUint32(pruneKeyEnd[:], math.MaxUint32)\n\n\t\t// To avoid modifying the bucket while traversing, we delete\n\t\t// the keys in a second loop.\n\t\tvar pruneKeys [][]byte\n\t\tpruneCursor := pruneBucket.ReadWriteCursor()\n\t\tfor k, _ := pruneCursor.Seek(pruneKeyStart[:]); k != nil &&\n\t\t\tbytes.Compare(k, pruneKeyEnd[:]) <= 0; k, _ = pruneCursor.Next() {\n\n\t\t\tpruneKeys = append(pruneKeys, k)\n\t\t}\n\n\t\tfor _, k := range pruneKeys {\n\t\t\tif err := pruneBucket.Delete(k); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tremovedChans = nil\n\t}); err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, channel := range removedChans {\n\t\tc.rejectCache.remove(channel.ChannelID)\n\t\tc.chanCache.remove(channel.ChannelID)\n\t}\n\n\treturn removedChans, nil\n}\n\n// PruneTip returns the block height and hash of the latest block that has been\n// used to prune channels in the graph. Knowing the \"prune tip\" allows callers\n// to tell if the graph is currently in sync with the current best known UTXO\n// state.",
      "length": 3453,
      "tokens": 482,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) PruneTip() (*chainhash.Hash, uint32, error) {",
      "content": "func (c *ChannelGraph) PruneTip() (*chainhash.Hash, uint32, error) {\n\tvar (\n\t\ttipHash   chainhash.Hash\n\t\ttipHeight uint32\n\t)\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tgraphMeta := tx.ReadBucket(graphMetaBucket)\n\t\tif graphMeta == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\t\tpruneBucket := graphMeta.NestedReadBucket(pruneLogBucket)\n\t\tif pruneBucket == nil {\n\t\t\treturn ErrGraphNeverPruned\n\t\t}\n\n\t\tpruneCursor := pruneBucket.ReadCursor()\n\n\t\t// The prune key with the largest block height will be our\n\t\t// prune tip.\n\t\tk, v := pruneCursor.Last()\n\t\tif k == nil {\n\t\t\treturn ErrGraphNeverPruned\n\t\t}\n\n\t\t// Once we have the prune tip, the value will be the block hash,\n\t\t// and the key the block height.\n\t\tcopy(tipHash[:], v[:])\n\t\ttipHeight = byteOrder.Uint32(k[:])\n\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\treturn &tipHash, tipHeight, nil\n}\n\n// DeleteChannelEdges removes edges with the given channel IDs from the\n// database and marks them as zombies. This ensures that we're unable to re-add\n// it to our database once again. If an edge does not exist within the\n// database, then ErrEdgeNotFound will be returned. If strictZombiePruning is\n// true, then when we mark these edges as zombies, we'll set up the keys such\n// that we require the node that failed to send the fresh update to be the one\n// that resurrects the channel from its zombie state. The markZombie bool\n// denotes whether or not to mark the channel as a zombie.",
      "length": 1345,
      "tokens": 219,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) DeleteChannelEdges(strictZombiePruning, markZombie bool,",
      "content": "func (c *ChannelGraph) DeleteChannelEdges(strictZombiePruning, markZombie bool,\n\tchanIDs ...uint64) error {\n\n\t// TODO(roasbeef): possibly delete from node bucket if node has no more\n\t// channels\n\t// TODO(roasbeef): don't delete both edges?\n\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\terr := kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadWriteBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\t\tchanIndex := edges.NestedReadWriteBucket(channelPointBucket)\n\t\tif chanIndex == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\t\tnodes := tx.ReadWriteBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodeNotFound\n\t\t}\n\t\tzombieIndex, err := edges.CreateBucketIfNotExists(zombieBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar rawChanID [8]byte\n\t\tfor _, chanID := range chanIDs {\n\t\t\tbyteOrder.PutUint64(rawChanID[:], chanID)\n\t\t\terr := c.delChannelEdge(\n\t\t\t\tedges, edgeIndex, chanIndex, zombieIndex, nodes,\n\t\t\t\trawChanID[:], markZombie, strictZombiePruning,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, chanID := range chanIDs {\n\t\tc.rejectCache.remove(chanID)\n\t\tc.chanCache.remove(chanID)\n\t}\n\n\treturn nil\n}\n\n// ChannelID attempt to lookup the 8-byte compact channel ID which maps to the\n// passed channel point (outpoint). If the passed channel doesn't exist within\n// the database, then ErrEdgeNotFound is returned.",
      "length": 1391,
      "tokens": 182,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ChannelID(chanPoint *wire.OutPoint) (uint64, error) {",
      "content": "func (c *ChannelGraph) ChannelID(chanPoint *wire.OutPoint) (uint64, error) {\n\tvar chanID uint64\n\tif err := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tvar err error\n\t\tchanID, err = getChanID(tx, chanPoint)\n\t\treturn err\n\t}, func() {\n\t\tchanID = 0\n\t}); err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn chanID, nil\n}\n\n// getChanID returns the assigned channel ID for a given channel point.",
      "length": 286,
      "tokens": 52,
      "embedding": []
    },
    {
      "slug": "func getChanID(tx kvdb.RTx, chanPoint *wire.OutPoint) (uint64, error) {",
      "content": "func getChanID(tx kvdb.RTx, chanPoint *wire.OutPoint) (uint64, error) {\n\tvar b bytes.Buffer\n\tif err := writeOutpoint(&b, chanPoint); err != nil {\n\t\treturn 0, err\n\t}\n\n\tedges := tx.ReadBucket(edgeBucket)\n\tif edges == nil {\n\t\treturn 0, ErrGraphNoEdgesFound\n\t}\n\tchanIndex := edges.NestedReadBucket(channelPointBucket)\n\tif chanIndex == nil {\n\t\treturn 0, ErrGraphNoEdgesFound\n\t}\n\n\tchanIDBytes := chanIndex.Get(b.Bytes())\n\tif chanIDBytes == nil {\n\t\treturn 0, ErrEdgeNotFound\n\t}\n\n\tchanID := byteOrder.Uint64(chanIDBytes)\n\n\treturn chanID, nil\n}\n\n// TODO(roasbeef): allow updates to use Batch?\n\n// HighestChanID returns the \"highest\" known channel ID in the channel graph.\n// This represents the \"newest\" channel from the PoV of the chain. This method\n// can be used by peers to quickly determine if they're graphs are in sync.",
      "length": 717,
      "tokens": 107,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) HighestChanID() (uint64, error) {",
      "content": "func (c *ChannelGraph) HighestChanID() (uint64, error) {\n\tvar cid uint64\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// In order to find the highest chan ID, we'll fetch a cursor\n\t\t// and use that to seek to the \"end\" of our known rage.\n\t\tcidCursor := edgeIndex.ReadCursor()\n\n\t\tlastChanID, _ := cidCursor.Last()\n\n\t\t// If there's no key, then this means that we don't actually\n\t\t// know of any channels, so we'll return a predicable error.\n\t\tif lastChanID == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// Otherwise, we'll de serialize the channel ID and return it\n\t\t// to the caller.\n\t\tcid = byteOrder.Uint64(lastChanID)\n\t\treturn nil\n\t}, func() {\n\t\tcid = 0\n\t})\n\tif err != nil && err != ErrGraphNoEdgesFound {\n\t\treturn 0, err\n\t}\n\n\treturn cid, nil\n}\n\n// ChannelEdge represents the complete set of information for a channel edge in\n// the known channel graph. This struct couples the core information of the\n// edge as well as each of the known advertised edge policies.",
      "length": 1086,
      "tokens": 178,
      "embedding": []
    },
    {
      "slug": "type ChannelEdge struct {",
      "content": "type ChannelEdge struct {\n\t// Info contains all the static information describing the channel.\n\tInfo *ChannelEdgeInfo\n\n\t// Policy1 points to the \"first\" edge policy of the channel containing\n\t// the dynamic information required to properly route through the edge.\n\tPolicy1 *ChannelEdgePolicy\n\n\t// Policy2 points to the \"second\" edge policy of the channel containing\n\t// the dynamic information required to properly route through the edge.\n\tPolicy2 *ChannelEdgePolicy\n}\n\n// ChanUpdatesInHorizon returns all the known channel edges which have at least\n// one edge that has an update timestamp within the specified horizon.",
      "length": 581,
      "tokens": 87,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ChanUpdatesInHorizon(startTime,",
      "content": "func (c *ChannelGraph) ChanUpdatesInHorizon(startTime,\n\tendTime time.Time) ([]ChannelEdge, error) {\n\n\t// To ensure we don't return duplicate ChannelEdges, we'll use an\n\t// additional map to keep track of the edges already seen to prevent\n\t// re-adding it.\n\tvar edgesSeen map[uint64]struct{}\n\tvar edgesToCache map[uint64]ChannelEdge\n\tvar edgesInHorizon []ChannelEdge\n\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\tvar hits int\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeUpdateIndex := edges.NestedReadBucket(edgeUpdateIndexBucket)\n\t\tif edgeUpdateIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\n\t\t// We'll now obtain a cursor to perform a range query within\n\t\t// the index to find all channels within the horizon.\n\t\tupdateCursor := edgeUpdateIndex.ReadCursor()\n\n\t\tvar startTimeBytes, endTimeBytes [8 + 8]byte\n\t\tbyteOrder.PutUint64(\n\t\t\tstartTimeBytes[:8], uint64(startTime.Unix()),\n\t\t)\n\t\tbyteOrder.PutUint64(\n\t\t\tendTimeBytes[:8], uint64(endTime.Unix()),\n\t\t)\n\n\t\t// With our start and end times constructed, we'll step through\n\t\t// the index collecting the info and policy of each update of\n\t\t// each channel that has a last update within the time range.\n\t\tfor indexKey, _ := updateCursor.Seek(startTimeBytes[:]); indexKey != nil &&\n\t\t\tbytes.Compare(indexKey, endTimeBytes[:]) <= 0; indexKey, _ = updateCursor.Next() {\n\n\t\t\t// We have a new eligible entry, so we'll slice of the\n\t\t\t// chan ID so we can query it in the DB.\n\t\t\tchanID := indexKey[8:]\n\n\t\t\t// If we've already retrieved the info and policies for\n\t\t\t// this edge, then we can skip it as we don't need to do\n\t\t\t// so again.\n\t\t\tchanIDInt := byteOrder.Uint64(chanID)\n\t\t\tif _, ok := edgesSeen[chanIDInt]; ok {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif channel, ok := c.chanCache.get(chanIDInt); ok {\n\t\t\t\thits++\n\t\t\t\tedgesSeen[chanIDInt] = struct{}{}\n\t\t\t\tedgesInHorizon = append(edgesInHorizon, channel)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// First, we'll fetch the static edge information.\n\t\t\tedgeInfo, err := fetchChanEdgeInfo(edgeIndex, chanID)\n\t\t\tif err != nil {\n\t\t\t\tchanID := byteOrder.Uint64(chanID)\n\t\t\t\treturn fmt.Errorf(\"unable to fetch info for \"+\n\t\t\t\t\t\"edge with chan_id=%v: %v\", chanID, err)\n\t\t\t}\n\t\t\tedgeInfo.db = c.db\n\n\t\t\t// With the static information obtained, we'll now\n\t\t\t// fetch the dynamic policy info.\n\t\t\tedge1, edge2, err := fetchChanEdgePolicies(\n\t\t\t\tedgeIndex, edges, nodes, chanID, c.db,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\tchanID := byteOrder.Uint64(chanID)\n\t\t\t\treturn fmt.Errorf(\"unable to fetch policies \"+\n\t\t\t\t\t\"for edge with chan_id=%v: %v\", chanID,\n\t\t\t\t\terr)\n\t\t\t}\n\n\t\t\t// Finally, we'll collate this edge with the rest of\n\t\t\t// edges to be returned.\n\t\t\tedgesSeen[chanIDInt] = struct{}{}\n\t\t\tchannel := ChannelEdge{\n\t\t\t\tInfo:    &edgeInfo,\n\t\t\t\tPolicy1: edge1,\n\t\t\t\tPolicy2: edge2,\n\t\t\t}\n\t\t\tedgesInHorizon = append(edgesInHorizon, channel)\n\t\t\tedgesToCache[chanIDInt] = channel\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tedgesSeen = make(map[uint64]struct{})\n\t\tedgesToCache = make(map[uint64]ChannelEdge)\n\t\tedgesInHorizon = nil\n\t})\n\tswitch {\n\tcase err == ErrGraphNoEdgesFound:\n\t\tfallthrough\n\tcase err == ErrGraphNodesNotFound:\n\t\tbreak\n\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\t// Insert any edges loaded from disk into the cache.\n\tfor chanid, channel := range edgesToCache {\n\t\tc.chanCache.insert(chanid, channel)\n\t}\n\n\tlog.Debugf(\"ChanUpdatesInHorizon hit percentage: %f (%d/%d)\",\n\t\tfloat64(hits)/float64(len(edgesInHorizon)), hits,\n\t\tlen(edgesInHorizon))\n\n\treturn edgesInHorizon, nil\n}\n\n// NodeUpdatesInHorizon returns all the known lightning node which have an\n// update timestamp within the passed range. This method can be used by two\n// nodes to quickly determine if they have the same set of up to date node\n// announcements.",
      "length": 3782,
      "tokens": 503,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) NodeUpdatesInHorizon(startTime,",
      "content": "func (c *ChannelGraph) NodeUpdatesInHorizon(startTime,\n\tendTime time.Time) ([]LightningNode, error) {\n\n\tvar nodesInHorizon []LightningNode\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\n\t\tnodeUpdateIndex := nodes.NestedReadBucket(nodeUpdateIndexBucket)\n\t\tif nodeUpdateIndex == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\n\t\t// We'll now obtain a cursor to perform a range query within\n\t\t// the index to find all node announcements within the horizon.\n\t\tupdateCursor := nodeUpdateIndex.ReadCursor()\n\n\t\tvar startTimeBytes, endTimeBytes [8 + 33]byte\n\t\tbyteOrder.PutUint64(\n\t\t\tstartTimeBytes[:8], uint64(startTime.Unix()),\n\t\t)\n\t\tbyteOrder.PutUint64(\n\t\t\tendTimeBytes[:8], uint64(endTime.Unix()),\n\t\t)\n\n\t\t// With our start and end times constructed, we'll step through\n\t\t// the index collecting info for each node within the time\n\t\t// range.\n\t\tfor indexKey, _ := updateCursor.Seek(startTimeBytes[:]); indexKey != nil &&\n\t\t\tbytes.Compare(indexKey, endTimeBytes[:]) <= 0; indexKey, _ = updateCursor.Next() {\n\n\t\t\tnodePub := indexKey[8:]\n\t\t\tnode, err := fetchLightningNode(nodes, nodePub)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tnode.db = c.db\n\n\t\t\tnodesInHorizon = append(nodesInHorizon, node)\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tnodesInHorizon = nil\n\t})\n\tswitch {\n\tcase err == ErrGraphNoEdgesFound:\n\t\tfallthrough\n\tcase err == ErrGraphNodesNotFound:\n\t\tbreak\n\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\treturn nodesInHorizon, nil\n}\n\n// FilterKnownChanIDs takes a set of channel IDs and return the subset of chan\n// ID's that we don't know and are not known zombies of the passed set. In other\n// words, we perform a set difference of our set of chan ID's and the ones\n// passed in. This method can be used by callers to determine the set of\n// channels another peer knows of that we don't.",
      "length": 1751,
      "tokens": 247,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FilterKnownChanIDs(chanIDs []uint64) ([]uint64, error) {",
      "content": "func (c *ChannelGraph) FilterKnownChanIDs(chanIDs []uint64) ([]uint64, error) {\n\tvar newChanIDs []uint64\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// Fetch the zombie index, it may not exist if no edges have\n\t\t// ever been marked as zombies. If the index has been\n\t\t// initialized, we will use it later to skip known zombie edges.\n\t\tzombieIndex := edges.NestedReadBucket(zombieBucket)\n\n\t\t// We'll run through the set of chanIDs and collate only the\n\t\t// set of channel that are unable to be found within our db.\n\t\tvar cidBytes [8]byte\n\t\tfor _, cid := range chanIDs {\n\t\t\tbyteOrder.PutUint64(cidBytes[:], cid)\n\n\t\t\t// If the edge is already known, skip it.\n\t\t\tif v := edgeIndex.Get(cidBytes[:]); v != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If the edge is a known zombie, skip it.\n\t\t\tif zombieIndex != nil {\n\t\t\t\tisZombie, _, _ := isZombieEdge(zombieIndex, cid)\n\t\t\t\tif isZombie {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tnewChanIDs = append(newChanIDs, cid)\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tnewChanIDs = nil\n\t})\n\tswitch {\n\t// If we don't know of any edges yet, then we'll return the entire set\n\t// of chan IDs specified.\n\tcase err == ErrGraphNoEdgesFound:\n\t\treturn chanIDs, nil\n\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\treturn newChanIDs, nil\n}\n\n// BlockChannelRange represents a range of channels for a given block height.",
      "length": 1380,
      "tokens": 221,
      "embedding": []
    },
    {
      "slug": "type BlockChannelRange struct {",
      "content": "type BlockChannelRange struct {\n\t// Height is the height of the block all of the channels below were\n\t// included in.\n\tHeight uint32\n\n\t// Channels is the list of channels identified by their short ID\n\t// representation known to us that were included in the block height\n\t// above.\n\tChannels []lnwire.ShortChannelID\n}\n\n// FilterChannelRange returns the channel ID's of all known channels which were\n// mined in a block height within the passed range. The channel IDs are grouped\n// by their common block height. This method can be used to quickly share with a\n// peer the set of channels we know of within a particular range to catch them\n// up after a period of time offline.",
      "length": 629,
      "tokens": 115,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FilterChannelRange(startHeight,",
      "content": "func (c *ChannelGraph) FilterChannelRange(startHeight,\n\tendHeight uint32) ([]BlockChannelRange, error) {\n\n\tstartChanID := &lnwire.ShortChannelID{\n\t\tBlockHeight: startHeight,\n\t}\n\n\tendChanID := lnwire.ShortChannelID{\n\t\tBlockHeight: endHeight,\n\t\tTxIndex:     math.MaxUint32 & 0x00ffffff,\n\t\tTxPosition:  math.MaxUint16,\n\t}\n\n\t// As we need to perform a range scan, we'll convert the starting and\n\t// ending height to their corresponding values when encoded using short\n\t// channel ID's.\n\tvar chanIDStart, chanIDEnd [8]byte\n\tbyteOrder.PutUint64(chanIDStart[:], startChanID.ToUint64())\n\tbyteOrder.PutUint64(chanIDEnd[:], endChanID.ToUint64())\n\n\tvar channelsPerBlock map[uint32][]lnwire.ShortChannelID\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\tcursor := edgeIndex.ReadCursor()\n\n\t\t// We'll now iterate through the database, and find each\n\t\t// channel ID that resides within the specified range.\n\t\tfor k, v := cursor.Seek(chanIDStart[:]); k != nil &&\n\t\t\tbytes.Compare(k, chanIDEnd[:]) <= 0; k, v = cursor.Next() {\n\t\t\t// Don't send alias SCIDs during gossip sync.\n\t\t\tedgeReader := bytes.NewReader(v)\n\t\t\tedgeInfo, err := deserializeChanEdgeInfo(edgeReader)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tif edgeInfo.AuthProof == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// This channel ID rests within the target range, so\n\t\t\t// we'll add it to our returned set.\n\t\t\trawCid := byteOrder.Uint64(k)\n\t\t\tcid := lnwire.NewShortChanIDFromInt(rawCid)\n\t\t\tchannelsPerBlock[cid.BlockHeight] = append(\n\t\t\t\tchannelsPerBlock[cid.BlockHeight], cid,\n\t\t\t)\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tchannelsPerBlock = make(map[uint32][]lnwire.ShortChannelID)\n\t})\n\n\tswitch {\n\t// If we don't know of any channels yet, then there's nothing to\n\t// filter, so we'll return an empty slice.\n\tcase err == ErrGraphNoEdgesFound || len(channelsPerBlock) == 0:\n\t\treturn nil, nil\n\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\t// Return the channel ranges in ascending block height order.\n\tblocks := make([]uint32, 0, len(channelsPerBlock))\n\tfor block := range channelsPerBlock {\n\t\tblocks = append(blocks, block)\n\t}\n\tsort.Slice(blocks, func(i, j int) bool {\n\t\treturn blocks[i] < blocks[j]\n\t})\n\n\tchannelRanges := make([]BlockChannelRange, 0, len(channelsPerBlock))\n\tfor _, block := range blocks {\n\t\tchannelRanges = append(channelRanges, BlockChannelRange{\n\t\t\tHeight:   block,\n\t\t\tChannels: channelsPerBlock[block],\n\t\t})\n\t}\n\n\treturn channelRanges, nil\n}\n\n// FetchChanInfos returns the set of channel edges that correspond to the passed\n// channel ID's. If an edge is the query is unknown to the database, it will\n// skipped and the result will contain only those edges that exist at the time\n// of the query. This can be used to respond to peer queries that are seeking to\n// fill in gaps in their view of the channel graph.",
      "length": 2814,
      "tokens": 378,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FetchChanInfos(chanIDs []uint64) ([]ChannelEdge, error) {",
      "content": "func (c *ChannelGraph) FetchChanInfos(chanIDs []uint64) ([]ChannelEdge, error) {\n\t// TODO(roasbeef): sort cids?\n\n\tvar (\n\t\tchanEdges []ChannelEdge\n\t\tcidBytes  [8]byte\n\t)\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\tfor _, cid := range chanIDs {\n\t\t\tbyteOrder.PutUint64(cidBytes[:], cid)\n\n\t\t\t// First, we'll fetch the static edge information. If\n\t\t\t// the edge is unknown, we will skip the edge and\n\t\t\t// continue gathering all known edges.\n\t\t\tedgeInfo, err := fetchChanEdgeInfo(\n\t\t\t\tedgeIndex, cidBytes[:],\n\t\t\t)\n\t\t\tswitch {\n\t\t\tcase err == ErrEdgeNotFound:\n\t\t\t\tcontinue\n\t\t\tcase err != nil:\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tedgeInfo.db = c.db\n\n\t\t\t// With the static information obtained, we'll now\n\t\t\t// fetch the dynamic policy info.\n\t\t\tedge1, edge2, err := fetchChanEdgePolicies(\n\t\t\t\tedgeIndex, edges, nodes, cidBytes[:], c.db,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tchanEdges = append(chanEdges, ChannelEdge{\n\t\t\t\tInfo:    &edgeInfo,\n\t\t\t\tPolicy1: edge1,\n\t\t\t\tPolicy2: edge2,\n\t\t\t})\n\t\t}\n\t\treturn nil\n\t}, func() {\n\t\tchanEdges = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn chanEdges, nil\n}\n",
      "length": 1252,
      "tokens": 177,
      "embedding": []
    },
    {
      "slug": "func delEdgeUpdateIndexEntry(edgesBucket kvdb.RwBucket, chanID uint64,",
      "content": "func delEdgeUpdateIndexEntry(edgesBucket kvdb.RwBucket, chanID uint64,\n\tedge1, edge2 *ChannelEdgePolicy) error {\n\n\t// First, we'll fetch the edge update index bucket which currently\n\t// stores an entry for the channel we're about to delete.\n\tupdateIndex := edgesBucket.NestedReadWriteBucket(edgeUpdateIndexBucket)\n\tif updateIndex == nil {\n\t\t// No edges in bucket, return early.\n\t\treturn nil\n\t}\n\n\t// Now that we have the bucket, we'll attempt to construct a template\n\t// for the index key: updateTime || chanid.\n\tvar indexKey [8 + 8]byte\n\tbyteOrder.PutUint64(indexKey[8:], chanID)\n\n\t// With the template constructed, we'll attempt to delete an entry that\n\t// would have been created by both edges: we'll alternate the update\n\t// times, as one may had overridden the other.\n\tif edge1 != nil {\n\t\tbyteOrder.PutUint64(indexKey[:8], uint64(edge1.LastUpdate.Unix()))\n\t\tif err := updateIndex.Delete(indexKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// We'll also attempt to delete the entry that may have been created by\n\t// the second edge.\n\tif edge2 != nil {\n\t\tbyteOrder.PutUint64(indexKey[:8], uint64(edge2.LastUpdate.Unix()))\n\t\tif err := updateIndex.Delete(indexKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n",
      "length": 1109,
      "tokens": 165,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) delChannelEdge(edges, edgeIndex, chanIndex, zombieIndex,",
      "content": "func (c *ChannelGraph) delChannelEdge(edges, edgeIndex, chanIndex, zombieIndex,\n\tnodes kvdb.RwBucket, chanID []byte, isZombie, strictZombie bool) error {\n\n\tedgeInfo, err := fetchChanEdgeInfo(edgeIndex, chanID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif c.graphCache != nil {\n\t\tc.graphCache.RemoveChannel(\n\t\t\tedgeInfo.NodeKey1Bytes, edgeInfo.NodeKey2Bytes,\n\t\t\tedgeInfo.ChannelID,\n\t\t)\n\t}\n\n\t// We'll also remove the entry in the edge update index bucket before\n\t// we delete the edges themselves so we can access their last update\n\t// times.\n\tcid := byteOrder.Uint64(chanID)\n\tedge1, edge2, err := fetchChanEdgePolicies(\n\t\tedgeIndex, edges, nodes, chanID, nil,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = delEdgeUpdateIndexEntry(edges, cid, edge1, edge2)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The edge key is of the format pubKey || chanID. First we construct\n\t// the latter half, populating the channel ID.\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[33:], chanID)\n\n\t// With the latter half constructed, copy over the first public key to\n\t// delete the edge in this direction, then the second to delete the\n\t// edge in the opposite direction.\n\tcopy(edgeKey[:33], edgeInfo.NodeKey1Bytes[:])\n\tif edges.Get(edgeKey[:]) != nil {\n\t\tif err := edges.Delete(edgeKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tcopy(edgeKey[:33], edgeInfo.NodeKey2Bytes[:])\n\tif edges.Get(edgeKey[:]) != nil {\n\t\tif err := edges.Delete(edgeKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// As part of deleting the edge we also remove all disabled entries\n\t// from the edgePolicyDisabledIndex bucket. We do that for both directions.\n\tupdateEdgePolicyDisabledIndex(edges, cid, false, false)\n\tupdateEdgePolicyDisabledIndex(edges, cid, true, false)\n\n\t// With the edge data deleted, we can purge the information from the two\n\t// edge indexes.\n\tif err := edgeIndex.Delete(chanID); err != nil {\n\t\treturn err\n\t}\n\tvar b bytes.Buffer\n\tif err := writeOutpoint(&b, &edgeInfo.ChannelPoint); err != nil {\n\t\treturn err\n\t}\n\tif err := chanIndex.Delete(b.Bytes()); err != nil {\n\t\treturn err\n\t}\n\n\t// Finally, we'll mark the edge as a zombie within our index if it's\n\t// being removed due to the channel becoming a zombie. We do this to\n\t// ensure we don't store unnecessary data for spent channels.\n\tif !isZombie {\n\t\treturn nil\n\t}\n\n\tnodeKey1, nodeKey2 := edgeInfo.NodeKey1Bytes, edgeInfo.NodeKey2Bytes\n\tif strictZombie {\n\t\tnodeKey1, nodeKey2 = makeZombiePubkeys(&edgeInfo, edge1, edge2)\n\t}\n\n\treturn markEdgeZombie(\n\t\tzombieIndex, byteOrder.Uint64(chanID), nodeKey1, nodeKey2,\n\t)\n}\n\n// makeZombiePubkeys derives the node pubkeys to store in the zombie index for a\n// particular pair of channel policies. The return values are one of:\n//  1. (pubkey1, pubkey2)\n//  2. (pubkey1, blank)\n//  3. (blank, pubkey2)\n//\n// A blank pubkey means that corresponding node will be unable to resurrect a\n// channel on its own. For example, node1 may continue to publish recent\n// updates, but node2 has fallen way behind. After marking an edge as a zombie,\n// we don't want another fresh update from node1 to resurrect, as the edge can\n// only become live once node2 finally sends something recent.\n//\n// In the case where we have neither update, we allow either party to resurrect\n// the channel. If the channel were to be marked zombie again, it would be\n// marked with the correct lagging channel since we received an update from only\n// one side.",
      "length": 3188,
      "tokens": 503,
      "embedding": []
    },
    {
      "slug": "func makeZombiePubkeys(info *ChannelEdgeInfo,",
      "content": "func makeZombiePubkeys(info *ChannelEdgeInfo,\n\te1, e2 *ChannelEdgePolicy) ([33]byte, [33]byte) {\n\n\tswitch {\n\t// If we don't have either edge policy, we'll return both pubkeys so\n\t// that the channel can be resurrected by either party.\n\tcase e1 == nil && e2 == nil:\n\t\treturn info.NodeKey1Bytes, info.NodeKey2Bytes\n\n\t// If we're missing edge1, or if both edges are present but edge1 is\n\t// older, we'll return edge1's pubkey and a blank pubkey for edge2. This\n\t// means that only an update from edge1 will be able to resurrect the\n\t// channel.\n\tcase e1 == nil || (e2 != nil && e1.LastUpdate.Before(e2.LastUpdate)):\n\t\treturn info.NodeKey1Bytes, [33]byte{}\n\n\t// Otherwise, we're missing edge2 or edge2 is the older side, so we\n\t// return a blank pubkey for edge1. In this case, only an update from\n\t// edge2 can resurect the channel.\n\tdefault:\n\t\treturn [33]byte{}, info.NodeKey2Bytes\n\t}\n}\n\n// UpdateEdgePolicy updates the edge routing policy for a single directed edge\n// within the database for the referenced channel. The `flags` attribute within\n// the ChannelEdgePolicy determines which of the directed edges are being\n// updated. If the flag is 1, then the first node's information is being\n// updated, otherwise it's the second node's information. The node ordering is\n// determined by the lexicographical ordering of the identity public keys of the\n// nodes on either side of the channel.",
      "length": 1316,
      "tokens": 219,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) UpdateEdgePolicy(edge *ChannelEdgePolicy,",
      "content": "func (c *ChannelGraph) UpdateEdgePolicy(edge *ChannelEdgePolicy,\n\top ...batch.SchedulerOption) error {\n\n\tvar (\n\t\tisUpdate1    bool\n\t\tedgeNotFound bool\n\t)\n\n\tr := &batch.Request{\n\t\tReset: func() {\n\t\t\tisUpdate1 = false\n\t\t\tedgeNotFound = false\n\t\t},\n\t\tUpdate: func(tx kvdb.RwTx) error {\n\t\t\tvar err error\n\t\t\tisUpdate1, err = updateEdgePolicy(\n\t\t\t\ttx, edge, c.graphCache,\n\t\t\t)\n\n\t\t\t// Silence ErrEdgeNotFound so that the batch can\n\t\t\t// succeed, but propagate the error via local state.\n\t\t\tif err == ErrEdgeNotFound {\n\t\t\t\tedgeNotFound = true\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\treturn err\n\t\t},\n\t\tOnCommit: func(err error) error {\n\t\t\tswitch {\n\t\t\tcase err != nil:\n\t\t\t\treturn err\n\t\t\tcase edgeNotFound:\n\t\t\t\treturn ErrEdgeNotFound\n\t\t\tdefault:\n\t\t\t\tc.updateEdgeCache(edge, isUpdate1)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t},\n\t}\n\n\tfor _, f := range op {\n\t\tf(r)\n\t}\n\n\treturn c.chanScheduler.Execute(r)\n}\n",
      "length": 747,
      "tokens": 108,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) updateEdgeCache(e *ChannelEdgePolicy, isUpdate1 bool) {",
      "content": "func (c *ChannelGraph) updateEdgeCache(e *ChannelEdgePolicy, isUpdate1 bool) {\n\t// If an entry for this channel is found in reject cache, we'll modify\n\t// the entry with the updated timestamp for the direction that was just\n\t// written. If the edge doesn't exist, we'll load the cache entry lazily\n\t// during the next query for this edge.\n\tif entry, ok := c.rejectCache.get(e.ChannelID); ok {\n\t\tif isUpdate1 {\n\t\t\tentry.upd1Time = e.LastUpdate.Unix()\n\t\t} else {\n\t\t\tentry.upd2Time = e.LastUpdate.Unix()\n\t\t}\n\t\tc.rejectCache.insert(e.ChannelID, entry)\n\t}\n\n\t// If an entry for this channel is found in channel cache, we'll modify\n\t// the entry with the updated policy for the direction that was just\n\t// written. If the edge doesn't exist, we'll defer loading the info and\n\t// policies and lazily read from disk during the next query.\n\tif channel, ok := c.chanCache.get(e.ChannelID); ok {\n\t\tif isUpdate1 {\n\t\t\tchannel.Policy1 = e\n\t\t} else {\n\t\t\tchannel.Policy2 = e\n\t\t}\n\t\tc.chanCache.insert(e.ChannelID, channel)\n\t}\n}\n\n// updateEdgePolicy attempts to update an edge's policy within the relevant\n// buckets using an existing database transaction. The returned boolean will be\n// true if the updated policy belongs to node1, and false if the policy belonged\n// to node2.",
      "length": 1151,
      "tokens": 187,
      "embedding": []
    },
    {
      "slug": "func updateEdgePolicy(tx kvdb.RwTx, edge *ChannelEdgePolicy,",
      "content": "func updateEdgePolicy(tx kvdb.RwTx, edge *ChannelEdgePolicy,\n\tgraphCache *GraphCache) (bool, error) {\n\n\tedges := tx.ReadWriteBucket(edgeBucket)\n\tif edges == nil {\n\t\treturn false, ErrEdgeNotFound\n\t}\n\tedgeIndex := edges.NestedReadWriteBucket(edgeIndexBucket)\n\tif edgeIndex == nil {\n\t\treturn false, ErrEdgeNotFound\n\t}\n\tnodes, err := tx.CreateTopLevelBucket(nodeBucket)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t// Create the channelID key be converting the channel ID\n\t// integer into a byte slice.\n\tvar chanID [8]byte\n\tbyteOrder.PutUint64(chanID[:], edge.ChannelID)\n\n\t// With the channel ID, we then fetch the value storing the two\n\t// nodes which connect this channel edge.\n\tnodeInfo := edgeIndex.Get(chanID[:])\n\tif nodeInfo == nil {\n\t\treturn false, ErrEdgeNotFound\n\t}\n\n\t// Depending on the flags value passed above, either the first\n\t// or second edge policy is being updated.\n\tvar fromNode, toNode []byte\n\tvar isUpdate1 bool\n\tif edge.ChannelFlags&lnwire.ChanUpdateDirection == 0 {\n\t\tfromNode = nodeInfo[:33]\n\t\ttoNode = nodeInfo[33:66]\n\t\tisUpdate1 = true\n\t} else {\n\t\tfromNode = nodeInfo[33:66]\n\t\ttoNode = nodeInfo[:33]\n\t\tisUpdate1 = false\n\t}\n\n\t// Finally, with the direction of the edge being updated\n\t// identified, we update the on-disk edge representation.\n\terr = putChanEdgePolicy(edges, nodes, edge, fromNode, toNode)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tvar (\n\t\tfromNodePubKey route.Vertex\n\t\ttoNodePubKey   route.Vertex\n\t)\n\tcopy(fromNodePubKey[:], fromNode)\n\tcopy(toNodePubKey[:], toNode)\n\n\tif graphCache != nil {\n\t\tgraphCache.UpdatePolicy(\n\t\t\tedge, fromNodePubKey, toNodePubKey, isUpdate1,\n\t\t)\n\t}\n\n\treturn isUpdate1, nil\n}\n\n// LightningNode represents an individual vertex/node within the channel graph.\n// A node is connected to other nodes by one or more channel edges emanating\n// from it. As the graph is directed, a node will also have an incoming edge\n// attached to it for each outgoing edge.",
      "length": 1783,
      "tokens": 258,
      "embedding": []
    },
    {
      "slug": "type LightningNode struct {",
      "content": "type LightningNode struct {\n\t// PubKeyBytes is the raw bytes of the public key of the target node.\n\tPubKeyBytes [33]byte\n\tpubKey      *btcec.PublicKey\n\n\t// HaveNodeAnnouncement indicates whether we received a node\n\t// announcement for this particular node. If true, the remaining fields\n\t// will be set, if false only the PubKey is known for this node.\n\tHaveNodeAnnouncement bool\n\n\t// LastUpdate is the last time the vertex information for this node has\n\t// been updated.\n\tLastUpdate time.Time\n\n\t// Address is the TCP address this node is reachable over.\n\tAddresses []net.Addr\n\n\t// Color is the selected color for the node.\n\tColor color.RGBA\n\n\t// Alias is a nick-name for the node. The alias can be used to confirm\n\t// a node's identity or to serve as a short ID for an address book.\n\tAlias string\n\n\t// AuthSigBytes is the raw signature under the advertised public key\n\t// which serves to authenticate the attributes announced by this node.\n\tAuthSigBytes []byte\n\n\t// Features is the list of protocol features supported by this node.\n\tFeatures *lnwire.FeatureVector\n\n\t// ExtraOpaqueData is the set of data that was appended to this\n\t// message, some of which we may not actually know how to iterate or\n\t// parse. By holding onto this data, we ensure that we're able to\n\t// properly validate the set of signatures that cover these new fields,\n\t// and ensure we're able to make upgrades to the network in a forwards\n\t// compatible manner.\n\tExtraOpaqueData []byte\n\n\tdb kvdb.Backend\n\n\t// TODO(roasbeef): discovery will need storage to keep it's last IP\n\t// address and re-announce if interface changes?\n\n\t// TODO(roasbeef): add update method and fetch?\n}\n\n// PubKey is the node's long-term identity public key. This key will be used to\n// authenticated any advertisements/updates sent by the node.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the pubkey if absolutely necessary.",
      "length": 1855,
      "tokens": 311,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) PubKey() (*btcec.PublicKey, error) {",
      "content": "func (l *LightningNode) PubKey() (*btcec.PublicKey, error) {\n\tif l.pubKey != nil {\n\t\treturn l.pubKey, nil\n\t}\n\n\tkey, err := btcec.ParsePubKey(l.PubKeyBytes[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tl.pubKey = key\n\n\treturn key, nil\n}\n\n// AuthSig is a signature under the advertised public key which serves to\n// authenticate the attributes announced by this node.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the signature if absolutely necessary.",
      "length": 428,
      "tokens": 75,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) AuthSig() (*ecdsa.Signature, error) {",
      "content": "func (l *LightningNode) AuthSig() (*ecdsa.Signature, error) {\n\treturn ecdsa.ParseSignature(l.AuthSigBytes)\n}\n\n// AddPubKey is a setter-link method that can be used to swap out the public\n// key for a node.",
      "length": 139,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) AddPubKey(key *btcec.PublicKey) {",
      "content": "func (l *LightningNode) AddPubKey(key *btcec.PublicKey) {\n\tl.pubKey = key\n\tcopy(l.PubKeyBytes[:], key.SerializeCompressed())\n}\n\n// NodeAnnouncement retrieves the latest node announcement of the node.",
      "length": 137,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) NodeAnnouncement(signed bool) (*lnwire.NodeAnnouncement,",
      "content": "func (l *LightningNode) NodeAnnouncement(signed bool) (*lnwire.NodeAnnouncement,\n\terror) {\n\n\tif !l.HaveNodeAnnouncement {\n\t\treturn nil, fmt.Errorf(\"node does not have node announcement\")\n\t}\n\n\talias, err := lnwire.NewNodeAlias(l.Alias)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnodeAnn := &lnwire.NodeAnnouncement{\n\t\tFeatures:        l.Features.RawFeatureVector,\n\t\tNodeID:          l.PubKeyBytes,\n\t\tRGBColor:        l.Color,\n\t\tAlias:           alias,\n\t\tAddresses:       l.Addresses,\n\t\tTimestamp:       uint32(l.LastUpdate.Unix()),\n\t\tExtraOpaqueData: l.ExtraOpaqueData,\n\t}\n\n\tif !signed {\n\t\treturn nodeAnn, nil\n\t}\n\n\tsig, err := lnwire.NewSigFromRawSignature(l.AuthSigBytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnodeAnn.Signature = sig\n\n\treturn nodeAnn, nil\n}\n\n// isPublic determines whether the node is seen as public within the graph from\n// the source node's point of view. An existing database transaction can also be\n// specified.",
      "length": 814,
      "tokens": 102,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) isPublic(tx kvdb.RTx, sourcePubKey []byte) (bool, error) {",
      "content": "func (l *LightningNode) isPublic(tx kvdb.RTx, sourcePubKey []byte) (bool, error) {\n\t// In order to determine whether this node is publicly advertised within\n\t// the graph, we'll need to look at all of its edges and check whether\n\t// they extend to any other node than the source node. errDone will be\n\t// used to terminate the check early.\n\tnodeIsPublic := false\n\terrDone := errors.New(\"done\")\n\terr := l.ForEachChannel(tx, func(_ kvdb.RTx, info *ChannelEdgeInfo,\n\t\t_, _ *ChannelEdgePolicy) error {\n\n\t\t// If this edge doesn't extend to the source node, we'll\n\t\t// terminate our search as we can now conclude that the node is\n\t\t// publicly advertised within the graph due to the local node\n\t\t// knowing of the current edge.\n\t\tif !bytes.Equal(info.NodeKey1Bytes[:], sourcePubKey) &&\n\t\t\t!bytes.Equal(info.NodeKey2Bytes[:], sourcePubKey) {\n\n\t\t\tnodeIsPublic = true\n\t\t\treturn errDone\n\t\t}\n\n\t\t// Since the edge _does_ extend to the source node, we'll also\n\t\t// need to ensure that this is a public edge.\n\t\tif info.AuthProof != nil {\n\t\t\tnodeIsPublic = true\n\t\t\treturn errDone\n\t\t}\n\n\t\t// Otherwise, we'll continue our search.\n\t\treturn nil\n\t})\n\tif err != nil && err != errDone {\n\t\treturn false, err\n\t}\n\n\treturn nodeIsPublic, nil\n}\n\n// FetchLightningNode attempts to look up a target node by its identity public\n// key. If the node isn't found in the database, then ErrGraphNodeNotFound is\n// returned.",
      "length": 1265,
      "tokens": 207,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FetchLightningNode(nodePub route.Vertex) (",
      "content": "func (c *ChannelGraph) FetchLightningNode(nodePub route.Vertex) (\n\t*LightningNode, error) {\n\n\tvar node *LightningNode\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\t// If a key for this serialized public key isn't found, then\n\t\t// the target node doesn't exist within the database.\n\t\tnodeBytes := nodes.Get(nodePub[:])\n\t\tif nodeBytes == nil {\n\t\t\treturn ErrGraphNodeNotFound\n\t\t}\n\n\t\t// If the node is found, then we can de deserialize the node\n\t\t// information to return to the user.\n\t\tnodeReader := bytes.NewReader(nodeBytes)\n\t\tn, err := deserializeLightningNode(nodeReader)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tn.db = c.db\n\n\t\tnode = &n\n\n\t\treturn nil\n\t}, func() {\n\t\tnode = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn node, nil\n}\n\n// graphCacheNode is a struct that wraps a LightningNode in a way that it can be\n// cached in the graph cache.",
      "length": 934,
      "tokens": 157,
      "embedding": []
    },
    {
      "slug": "type graphCacheNode struct {",
      "content": "type graphCacheNode struct {\n\tpubKeyBytes route.Vertex\n\tfeatures    *lnwire.FeatureVector\n}\n\n// newGraphCacheNode returns a new cache optimized node.",
      "length": 116,
      "tokens": 13,
      "embedding": []
    },
    {
      "slug": "func newGraphCacheNode(pubKey route.Vertex,",
      "content": "func newGraphCacheNode(pubKey route.Vertex,\n\tfeatures *lnwire.FeatureVector) *graphCacheNode {\n\n\treturn &graphCacheNode{\n\t\tpubKeyBytes: pubKey,\n\t\tfeatures:    features,\n\t}\n}\n\n// PubKey returns the node's public identity key.",
      "length": 172,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func (n *graphCacheNode) PubKey() route.Vertex {",
      "content": "func (n *graphCacheNode) PubKey() route.Vertex {\n\treturn n.pubKeyBytes\n}\n\n// Features returns the node's features.",
      "length": 62,
      "tokens": 9,
      "embedding": []
    },
    {
      "slug": "func (n *graphCacheNode) Features() *lnwire.FeatureVector {",
      "content": "func (n *graphCacheNode) Features() *lnwire.FeatureVector {\n\treturn n.features\n}\n\n// ForEachChannel iterates through all channels of this node, executing the\n// passed callback with an edge info structure and the policies of each end\n// of the channel. The first edge policy is the outgoing edge *to* the\n// connecting node, while the second is the incoming edge *from* the\n// connecting node. If the callback returns an error, then the iteration is\n// halted with the error propagated back up to the caller.\n//\n// Unknown policies are passed into the callback as nil values.",
      "length": 505,
      "tokens": 90,
      "embedding": []
    },
    {
      "slug": "func (n *graphCacheNode) ForEachChannel(tx kvdb.RTx,",
      "content": "func (n *graphCacheNode) ForEachChannel(tx kvdb.RTx,\n\tcb func(kvdb.RTx, *ChannelEdgeInfo, *ChannelEdgePolicy,\n\t\t*ChannelEdgePolicy) error) error {\n\n\treturn nodeTraversal(tx, n.pubKeyBytes[:], nil, cb)\n}\n\nvar _ GraphCacheNode = (*graphCacheNode)(nil)\n\n// HasLightningNode determines if the graph has a vertex identified by the\n// target node identity public key. If the node exists in the database, a\n// timestamp of when the data for the node was lasted updated is returned along\n// with a true boolean. Otherwise, an empty time.Time is returned with a false\n// boolean.",
      "length": 505,
      "tokens": 76,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) HasLightningNode(nodePub [33]byte) (time.Time, bool, error) {",
      "content": "func (c *ChannelGraph) HasLightningNode(nodePub [33]byte) (time.Time, bool, error) {\n\tvar (\n\t\tupdateTime time.Time\n\t\texists     bool\n\t)\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\t// If a key for this serialized public key isn't found, we can\n\t\t// exit early.\n\t\tnodeBytes := nodes.Get(nodePub[:])\n\t\tif nodeBytes == nil {\n\t\t\texists = false\n\t\t\treturn nil\n\t\t}\n\n\t\t// Otherwise we continue on to obtain the time stamp\n\t\t// representing the last time the data for this node was\n\t\t// updated.\n\t\tnodeReader := bytes.NewReader(nodeBytes)\n\t\tnode, err := deserializeLightningNode(nodeReader)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\texists = true\n\t\tupdateTime = node.LastUpdate\n\t\treturn nil\n\t}, func() {\n\t\tupdateTime = time.Time{}\n\t\texists = false\n\t})\n\tif err != nil {\n\t\treturn time.Time{}, exists, err\n\t}\n\n\treturn updateTime, exists, nil\n}\n\n// nodeTraversal is used to traverse all channels of a node given by its\n// public key and passes channel information into the specified callback.",
      "length": 1039,
      "tokens": 167,
      "embedding": []
    },
    {
      "slug": "func nodeTraversal(tx kvdb.RTx, nodePub []byte, db kvdb.Backend,",
      "content": "func nodeTraversal(tx kvdb.RTx, nodePub []byte, db kvdb.Backend,\n\tcb func(kvdb.RTx, *ChannelEdgeInfo, *ChannelEdgePolicy, *ChannelEdgePolicy) error) error {\n\n\ttraversal := func(tx kvdb.RTx) error {\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// In order to reach all the edges for this node, we take\n\t\t// advantage of the construction of the key-space within the\n\t\t// edge bucket. The keys are stored in the form: pubKey ||\n\t\t// chanID. Therefore, starting from a chanID of zero, we can\n\t\t// scan forward in the bucket, grabbing all the edges for the\n\t\t// node. Once the prefix no longer matches, then we know we're\n\t\t// done.\n\t\tvar nodeStart [33 + 8]byte\n\t\tcopy(nodeStart[:], nodePub)\n\t\tcopy(nodeStart[33:], chanStart[:])\n\n\t\t// Starting from the key pubKey || 0, we seek forward in the\n\t\t// bucket until the retrieved key no longer has the public key\n\t\t// as its prefix. This indicates that we've stepped over into\n\t\t// another node's edges, so we can terminate our scan.\n\t\tedgeCursor := edges.ReadCursor()\n\t\tfor nodeEdge, _ := edgeCursor.Seek(nodeStart[:]); bytes.HasPrefix(nodeEdge, nodePub); nodeEdge, _ = edgeCursor.Next() {\n\t\t\t// If the prefix still matches, the channel id is\n\t\t\t// returned in nodeEdge. Channel id is used to lookup\n\t\t\t// the node at the other end of the channel and both\n\t\t\t// edge policies.\n\t\t\tchanID := nodeEdge[33:]\n\t\t\tedgeInfo, err := fetchChanEdgeInfo(edgeIndex, chanID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tedgeInfo.db = db\n\n\t\t\toutgoingPolicy, err := fetchChanEdgePolicy(\n\t\t\t\tedges, chanID, nodePub, nodes,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\totherNode, err := edgeInfo.OtherNodeKeyBytes(nodePub)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tincomingPolicy, err := fetchChanEdgePolicy(\n\t\t\t\tedges, chanID, otherNode[:], nodes,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Finally, we execute the callback.\n\t\t\terr = cb(tx, &edgeInfo, outgoingPolicy, incomingPolicy)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n\n\t// If no transaction was provided, then we'll create a new transaction\n\t// to execute the transaction within.\n\tif tx == nil {\n\t\treturn kvdb.View(db, traversal, func() {})\n\t}\n\n\t// Otherwise, we re-use the existing transaction to execute the graph\n\t// traversal.\n\treturn traversal(tx)\n}\n\n// ForEachChannel iterates through all channels of this node, executing the\n// passed callback with an edge info structure and the policies of each end\n// of the channel. The first edge policy is the outgoing edge *to* the\n// connecting node, while the second is the incoming edge *from* the\n// connecting node. If the callback returns an error, then the iteration is\n// halted with the error propagated back up to the caller.\n//\n// Unknown policies are passed into the callback as nil values.\n//\n// If the caller wishes to re-use an existing boltdb transaction, then it\n// should be passed as the first argument.  Otherwise the first argument should\n// be nil and a fresh transaction will be created to execute the graph\n// traversal.",
      "length": 3087,
      "tokens": 488,
      "embedding": []
    },
    {
      "slug": "func (l *LightningNode) ForEachChannel(tx kvdb.RTx,",
      "content": "func (l *LightningNode) ForEachChannel(tx kvdb.RTx,\n\tcb func(kvdb.RTx, *ChannelEdgeInfo, *ChannelEdgePolicy,\n\t\t*ChannelEdgePolicy) error) error {\n\n\tnodePub := l.PubKeyBytes[:]\n\tdb := l.db\n\n\treturn nodeTraversal(tx, nodePub, db, cb)\n}\n\n// ChannelEdgeInfo represents a fully authenticated channel along with all its\n// unique attributes. Once an authenticated channel announcement has been\n// processed on the network, then an instance of ChannelEdgeInfo encapsulating\n// the channels attributes is stored. The other portions relevant to routing\n// policy of a channel are stored within a ChannelEdgePolicy for each direction\n// of the channel.",
      "length": 576,
      "tokens": 81,
      "embedding": []
    },
    {
      "slug": "type ChannelEdgeInfo struct {",
      "content": "type ChannelEdgeInfo struct {\n\t// ChannelID is the unique channel ID for the channel. The first 3\n\t// bytes are the block height, the next 3 the index within the block,\n\t// and the last 2 bytes are the output index for the channel.\n\tChannelID uint64\n\n\t// ChainHash is the hash that uniquely identifies the chain that this\n\t// channel was opened within.\n\t//\n\t// TODO(roasbeef): need to modify db keying for multi-chain\n\t//  * must add chain hash to prefix as well\n\tChainHash chainhash.Hash\n\n\t// NodeKey1Bytes is the raw public key of the first node.\n\tNodeKey1Bytes [33]byte\n\tnodeKey1      *btcec.PublicKey\n\n\t// NodeKey2Bytes is the raw public key of the first node.\n\tNodeKey2Bytes [33]byte\n\tnodeKey2      *btcec.PublicKey\n\n\t// BitcoinKey1Bytes is the raw public key of the first node.\n\tBitcoinKey1Bytes [33]byte\n\tbitcoinKey1      *btcec.PublicKey\n\n\t// BitcoinKey2Bytes is the raw public key of the first node.\n\tBitcoinKey2Bytes [33]byte\n\tbitcoinKey2      *btcec.PublicKey\n\n\t// Features is an opaque byte slice that encodes the set of channel\n\t// specific features that this channel edge supports.\n\tFeatures []byte\n\n\t// AuthProof is the authentication proof for this channel. This proof\n\t// contains a set of signatures binding four identities, which attests\n\t// to the legitimacy of the advertised channel.\n\tAuthProof *ChannelAuthProof\n\n\t// ChannelPoint is the funding outpoint of the channel. This can be\n\t// used to uniquely identify the channel within the channel graph.\n\tChannelPoint wire.OutPoint\n\n\t// Capacity is the total capacity of the channel, this is determined by\n\t// the value output in the outpoint that created this channel.\n\tCapacity btcutil.Amount\n\n\t// ExtraOpaqueData is the set of data that was appended to this\n\t// message, some of which we may not actually know how to iterate or\n\t// parse. By holding onto this data, we ensure that we're able to\n\t// properly validate the set of signatures that cover these new fields,\n\t// and ensure we're able to make upgrades to the network in a forwards\n\t// compatible manner.\n\tExtraOpaqueData []byte\n\n\tdb kvdb.Backend\n}\n\n// AddNodeKeys is a setter-like method that can be used to replace the set of\n// keys for the target ChannelEdgeInfo.",
      "length": 2110,
      "tokens": 341,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) AddNodeKeys(nodeKey1, nodeKey2, bitcoinKey1,",
      "content": "func (c *ChannelEdgeInfo) AddNodeKeys(nodeKey1, nodeKey2, bitcoinKey1,\n\tbitcoinKey2 *btcec.PublicKey) {\n\n\tc.nodeKey1 = nodeKey1\n\tcopy(c.NodeKey1Bytes[:], c.nodeKey1.SerializeCompressed())\n\n\tc.nodeKey2 = nodeKey2\n\tcopy(c.NodeKey2Bytes[:], nodeKey2.SerializeCompressed())\n\n\tc.bitcoinKey1 = bitcoinKey1\n\tcopy(c.BitcoinKey1Bytes[:], c.bitcoinKey1.SerializeCompressed())\n\n\tc.bitcoinKey2 = bitcoinKey2\n\tcopy(c.BitcoinKey2Bytes[:], bitcoinKey2.SerializeCompressed())\n}\n\n// NodeKey1 is the identity public key of the \"first\" node that was involved in\n// the creation of this channel. A node is considered \"first\" if the\n// lexicographical ordering the its serialized public key is \"smaller\" than\n// that of the other node involved in channel creation.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the pubkey if absolutely necessary.",
      "length": 792,
      "tokens": 98,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) NodeKey1() (*btcec.PublicKey, error) {",
      "content": "func (c *ChannelEdgeInfo) NodeKey1() (*btcec.PublicKey, error) {\n\tif c.nodeKey1 != nil {\n\t\treturn c.nodeKey1, nil\n\t}\n\n\tkey, err := btcec.ParsePubKey(c.NodeKey1Bytes[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.nodeKey1 = key\n\n\treturn key, nil\n}\n\n// NodeKey2 is the identity public key of the \"second\" node that was\n// involved in the creation of this channel. A node is considered\n// \"second\" if the lexicographical ordering the its serialized public\n// key is \"larger\" than that of the other node involved in channel\n// creation.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the pubkey if absolutely necessary.",
      "length": 586,
      "tokens": 104,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) NodeKey2() (*btcec.PublicKey, error) {",
      "content": "func (c *ChannelEdgeInfo) NodeKey2() (*btcec.PublicKey, error) {\n\tif c.nodeKey2 != nil {\n\t\treturn c.nodeKey2, nil\n\t}\n\n\tkey, err := btcec.ParsePubKey(c.NodeKey2Bytes[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.nodeKey2 = key\n\n\treturn key, nil\n}\n\n// BitcoinKey1 is the Bitcoin multi-sig key belonging to the first\n// node, that was involved in the funding transaction that originally\n// created the channel that this struct represents.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the pubkey if absolutely necessary.",
      "length": 492,
      "tokens": 84,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) BitcoinKey1() (*btcec.PublicKey, error) {",
      "content": "func (c *ChannelEdgeInfo) BitcoinKey1() (*btcec.PublicKey, error) {\n\tif c.bitcoinKey1 != nil {\n\t\treturn c.bitcoinKey1, nil\n\t}\n\n\tkey, err := btcec.ParsePubKey(c.BitcoinKey1Bytes[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.bitcoinKey1 = key\n\n\treturn key, nil\n}\n\n// BitcoinKey2 is the Bitcoin multi-sig key belonging to the second\n// node, that was involved in the funding transaction that originally\n// created the channel that this struct represents.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the pubkey if absolutely necessary.",
      "length": 505,
      "tokens": 84,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) BitcoinKey2() (*btcec.PublicKey, error) {",
      "content": "func (c *ChannelEdgeInfo) BitcoinKey2() (*btcec.PublicKey, error) {\n\tif c.bitcoinKey2 != nil {\n\t\treturn c.bitcoinKey2, nil\n\t}\n\n\tkey, err := btcec.ParsePubKey(c.BitcoinKey2Bytes[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.bitcoinKey2 = key\n\n\treturn key, nil\n}\n\n// OtherNodeKeyBytes returns the node key bytes of the other end of\n// the channel.",
      "length": 262,
      "tokens": 44,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) OtherNodeKeyBytes(thisNodeKey []byte) (",
      "content": "func (c *ChannelEdgeInfo) OtherNodeKeyBytes(thisNodeKey []byte) (\n\t[33]byte, error) {\n\n\tswitch {\n\tcase bytes.Equal(c.NodeKey1Bytes[:], thisNodeKey):\n\t\treturn c.NodeKey2Bytes, nil\n\tcase bytes.Equal(c.NodeKey2Bytes[:], thisNodeKey):\n\t\treturn c.NodeKey1Bytes, nil\n\tdefault:\n\t\treturn [33]byte{}, fmt.Errorf(\"node not participating in this channel\")\n\t}\n}\n\n// FetchOtherNode attempts to fetch the full LightningNode that's opposite of\n// the target node in the channel. This is useful when one knows the pubkey of\n// one of the nodes, and wishes to obtain the full LightningNode for the other\n// end of the channel.",
      "length": 528,
      "tokens": 75,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgeInfo) FetchOtherNode(tx kvdb.RTx,",
      "content": "func (c *ChannelEdgeInfo) FetchOtherNode(tx kvdb.RTx,\n\tthisNodeKey []byte) (*LightningNode, error) {\n\n\t// Ensure that the node passed in is actually a member of the channel.\n\tvar targetNodeBytes [33]byte\n\tswitch {\n\tcase bytes.Equal(c.NodeKey1Bytes[:], thisNodeKey):\n\t\ttargetNodeBytes = c.NodeKey2Bytes\n\tcase bytes.Equal(c.NodeKey2Bytes[:], thisNodeKey):\n\t\ttargetNodeBytes = c.NodeKey1Bytes\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"node not participating in this channel\")\n\t}\n\n\tvar targetNode *LightningNode\n\tfetchNodeFunc := func(tx kvdb.RTx) error {\n\t\t// First grab the nodes bucket which stores the mapping from\n\t\t// pubKey to node information.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\tnode, err := fetchLightningNode(nodes, targetNodeBytes[:])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnode.db = c.db\n\n\t\ttargetNode = &node\n\n\t\treturn nil\n\t}\n\n\t// If the transaction is nil, then we'll need to create a new one,\n\t// otherwise we can use the existing db transaction.\n\tvar err error\n\tif tx == nil {\n\t\terr = kvdb.View(c.db, fetchNodeFunc, func() { targetNode = nil })\n\t} else {\n\t\terr = fetchNodeFunc(tx)\n\t}\n\n\treturn targetNode, err\n}\n\n// ChannelAuthProof is the authentication proof (the signature portion) for a\n// channel. Using the four signatures contained in the struct, and some\n// auxiliary knowledge (the funding script, node identities, and outpoint) nodes\n// on the network are able to validate the authenticity and existence of a\n// channel. Each of these signatures signs the following digest: chanID ||\n// nodeID1 || nodeID2 || bitcoinKey1|| bitcoinKey2 || 2-byte-feature-len ||\n// features.",
      "length": 1537,
      "tokens": 228,
      "embedding": []
    },
    {
      "slug": "type ChannelAuthProof struct {",
      "content": "type ChannelAuthProof struct {\n\t// nodeSig1 is a cached instance of the first node signature.\n\tnodeSig1 *ecdsa.Signature\n\n\t// NodeSig1Bytes are the raw bytes of the first node signature encoded\n\t// in DER format.\n\tNodeSig1Bytes []byte\n\n\t// nodeSig2 is a cached instance of the second node signature.\n\tnodeSig2 *ecdsa.Signature\n\n\t// NodeSig2Bytes are the raw bytes of the second node signature\n\t// encoded in DER format.\n\tNodeSig2Bytes []byte\n\n\t// bitcoinSig1 is a cached instance of the first bitcoin signature.\n\tbitcoinSig1 *ecdsa.Signature\n\n\t// BitcoinSig1Bytes are the raw bytes of the first bitcoin signature\n\t// encoded in DER format.\n\tBitcoinSig1Bytes []byte\n\n\t// bitcoinSig2 is a cached instance of the second bitcoin signature.\n\tbitcoinSig2 *ecdsa.Signature\n\n\t// BitcoinSig2Bytes are the raw bytes of the second bitcoin signature\n\t// encoded in DER format.\n\tBitcoinSig2Bytes []byte\n}\n\n// Node1Sig is the signature using the identity key of the node that is first\n// in a lexicographical ordering of the serialized public keys of the two nodes\n// that created the channel.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the signature if absolutely necessary.",
      "length": 1158,
      "tokens": 184,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelAuthProof) Node1Sig() (*ecdsa.Signature, error) {",
      "content": "func (c *ChannelAuthProof) Node1Sig() (*ecdsa.Signature, error) {\n\tif c.nodeSig1 != nil {\n\t\treturn c.nodeSig1, nil\n\t}\n\n\tsig, err := ecdsa.ParseSignature(c.NodeSig1Bytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc.nodeSig1 = sig\n\n\treturn sig, nil\n}\n\n// Node2Sig is the signature using the identity key of the node that is second\n// in a lexicographical ordering of the serialized public keys of the two nodes\n// that created the channel.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the signature if absolutely necessary.",
      "length": 494,
      "tokens": 88,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelAuthProof) Node2Sig() (*ecdsa.Signature, error) {",
      "content": "func (c *ChannelAuthProof) Node2Sig() (*ecdsa.Signature, error) {\n\tif c.nodeSig2 != nil {\n\t\treturn c.nodeSig2, nil\n\t}\n\n\tsig, err := ecdsa.ParseSignature(c.NodeSig2Bytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc.nodeSig2 = sig\n\n\treturn sig, nil\n}\n\n// BitcoinSig1 is the signature using the public key of the first node that was\n// used in the channel's multi-sig output.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the signature if absolutely necessary.",
      "length": 430,
      "tokens": 76,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelAuthProof) BitcoinSig1() (*ecdsa.Signature, error) {",
      "content": "func (c *ChannelAuthProof) BitcoinSig1() (*ecdsa.Signature, error) {\n\tif c.bitcoinSig1 != nil {\n\t\treturn c.bitcoinSig1, nil\n\t}\n\n\tsig, err := ecdsa.ParseSignature(c.BitcoinSig1Bytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc.bitcoinSig1 = sig\n\n\treturn sig, nil\n}\n\n// BitcoinSig2 is the signature using the public key of the second node that\n// was used in the channel's multi-sig output.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the signature if absolutely necessary.",
      "length": 443,
      "tokens": 76,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelAuthProof) BitcoinSig2() (*ecdsa.Signature, error) {",
      "content": "func (c *ChannelAuthProof) BitcoinSig2() (*ecdsa.Signature, error) {\n\tif c.bitcoinSig2 != nil {\n\t\treturn c.bitcoinSig2, nil\n\t}\n\n\tsig, err := ecdsa.ParseSignature(c.BitcoinSig2Bytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc.bitcoinSig2 = sig\n\n\treturn sig, nil\n}\n\n// IsEmpty check is the authentication proof is empty Proof is empty if at\n// least one of the signatures are equal to nil.",
      "length": 302,
      "tokens": 53,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelAuthProof) IsEmpty() bool {",
      "content": "func (c *ChannelAuthProof) IsEmpty() bool {\n\treturn len(c.NodeSig1Bytes) == 0 ||\n\t\tlen(c.NodeSig2Bytes) == 0 ||\n\t\tlen(c.BitcoinSig1Bytes) == 0 ||\n\t\tlen(c.BitcoinSig2Bytes) == 0\n}\n\n// ChannelEdgePolicy represents a *directed* edge within the channel graph. For\n// each channel in the database, there are two distinct edges: one for each\n// possible direction of travel along the channel. The edges themselves hold\n// information concerning fees, and minimum time-lock information which is\n// utilized during path finding.",
      "length": 466,
      "tokens": 69,
      "embedding": []
    },
    {
      "slug": "type ChannelEdgePolicy struct {",
      "content": "type ChannelEdgePolicy struct {\n\t// SigBytes is the raw bytes of the signature of the channel edge\n\t// policy. We'll only parse these if the caller needs to access the\n\t// signature for validation purposes. Do not set SigBytes directly, but\n\t// use SetSigBytes instead to make sure that the cache is invalidated.\n\tSigBytes []byte\n\n\t// sig is a cached fully parsed signature.\n\tsig *ecdsa.Signature\n\n\t// ChannelID is the unique channel ID for the channel. The first 3\n\t// bytes are the block height, the next 3 the index within the block,\n\t// and the last 2 bytes are the output index for the channel.\n\tChannelID uint64\n\n\t// LastUpdate is the last time an authenticated edge for this channel\n\t// was received.\n\tLastUpdate time.Time\n\n\t// MessageFlags is a bitfield which indicates the presence of optional\n\t// fields (like max_htlc) in the policy.\n\tMessageFlags lnwire.ChanUpdateMsgFlags\n\n\t// ChannelFlags is a bitfield which signals the capabilities of the\n\t// channel as well as the directed edge this update applies to.\n\tChannelFlags lnwire.ChanUpdateChanFlags\n\n\t// TimeLockDelta is the number of blocks this node will subtract from\n\t// the expiry of an incoming HTLC. This value expresses the time buffer\n\t// the node would like to HTLC exchanges.\n\tTimeLockDelta uint16\n\n\t// MinHTLC is the smallest value HTLC this node will forward, expressed\n\t// in millisatoshi.\n\tMinHTLC lnwire.MilliSatoshi\n\n\t// MaxHTLC is the largest value HTLC this node will forward, expressed\n\t// in millisatoshi.\n\tMaxHTLC lnwire.MilliSatoshi\n\n\t// FeeBaseMSat is the base HTLC fee that will be charged for forwarding\n\t// ANY HTLC, expressed in mSAT's.\n\tFeeBaseMSat lnwire.MilliSatoshi\n\n\t// FeeProportionalMillionths is the rate that the node will charge for\n\t// HTLCs for each millionth of a satoshi forwarded.\n\tFeeProportionalMillionths lnwire.MilliSatoshi\n\n\t// Node is the LightningNode that this directed edge leads to. Using\n\t// this pointer the channel graph can further be traversed.\n\tNode *LightningNode\n\n\t// ExtraOpaqueData is the set of data that was appended to this\n\t// message, some of which we may not actually know how to iterate or\n\t// parse. By holding onto this data, we ensure that we're able to\n\t// properly validate the set of signatures that cover these new fields,\n\t// and ensure we're able to make upgrades to the network in a forwards\n\t// compatible manner.\n\tExtraOpaqueData []byte\n\n\tdb kvdb.Backend\n}\n\n// Signature is a channel announcement signature, which is needed for proper\n// edge policy announcement.\n//\n// NOTE: By having this method to access an attribute, we ensure we only need\n// to fully deserialize the signature if absolutely necessary.",
      "length": 2553,
      "tokens": 415,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgePolicy) Signature() (*ecdsa.Signature, error) {",
      "content": "func (c *ChannelEdgePolicy) Signature() (*ecdsa.Signature, error) {\n\tif c.sig != nil {\n\t\treturn c.sig, nil\n\t}\n\n\tsig, err := ecdsa.ParseSignature(c.SigBytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc.sig = sig\n\n\treturn sig, nil\n}\n\n// SetSigBytes updates the signature and invalidates the cached parsed\n// signature.",
      "length": 231,
      "tokens": 41,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgePolicy) SetSigBytes(sig []byte) {",
      "content": "func (c *ChannelEdgePolicy) SetSigBytes(sig []byte) {\n\tc.SigBytes = sig\n\tc.sig = nil\n}\n\n// IsDisabled determines whether the edge has the disabled bit set.",
      "length": 97,
      "tokens": 18,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgePolicy) IsDisabled() bool {",
      "content": "func (c *ChannelEdgePolicy) IsDisabled() bool {\n\treturn c.ChannelFlags.IsDisabled()\n}\n\n// ComputeFee computes the fee to forward an HTLC of `amt` milli-satoshis over\n// the passed active payment channel. This value is currently computed as\n// specified in BOLT07, but will likely change in the near future.",
      "length": 253,
      "tokens": 40,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgePolicy) ComputeFee(",
      "content": "func (c *ChannelEdgePolicy) ComputeFee(\n\tamt lnwire.MilliSatoshi) lnwire.MilliSatoshi {\n\n\treturn c.FeeBaseMSat + (amt*c.FeeProportionalMillionths)/feeRateParts\n}\n\n// divideCeil divides dividend by factor and rounds the result up.",
      "length": 184,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func divideCeil(dividend, factor lnwire.MilliSatoshi) lnwire.MilliSatoshi {",
      "content": "func divideCeil(dividend, factor lnwire.MilliSatoshi) lnwire.MilliSatoshi {\n\treturn (dividend + factor - 1) / factor\n}\n\n// ComputeFeeFromIncoming computes the fee to forward an HTLC given the incoming\n// amount.",
      "length": 131,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelEdgePolicy) ComputeFeeFromIncoming(",
      "content": "func (c *ChannelEdgePolicy) ComputeFeeFromIncoming(\n\tincomingAmt lnwire.MilliSatoshi) lnwire.MilliSatoshi {\n\n\treturn incomingAmt - divideCeil(\n\t\tfeeRateParts*(incomingAmt-c.FeeBaseMSat),\n\t\tfeeRateParts+c.FeeProportionalMillionths,\n\t)\n}\n\n// FetchChannelEdgesByOutpoint attempts to lookup the two directed edges for\n// the channel identified by the funding outpoint. If the channel can't be\n// found, then ErrEdgeNotFound is returned. A struct which houses the general\n// information for the channel itself is returned as well as two structs that\n// contain the routing policies for the channel in either direction.",
      "length": 549,
      "tokens": 72,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FetchChannelEdgesByOutpoint(op *wire.OutPoint,",
      "content": "func (c *ChannelGraph) FetchChannelEdgesByOutpoint(op *wire.OutPoint,\n) (*ChannelEdgeInfo, *ChannelEdgePolicy, *ChannelEdgePolicy, error) {\n\n\tvar (\n\t\tedgeInfo *ChannelEdgeInfo\n\t\tpolicy1  *ChannelEdgePolicy\n\t\tpolicy2  *ChannelEdgePolicy\n\t)\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// First, grab the node bucket. This will be used to populate\n\t\t// the Node pointers in each edge read from disk.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\t// Next, grab the edge bucket which stores the edges, and also\n\t\t// the index itself so we can group the directed edges together\n\t\t// logically.\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// If the channel's outpoint doesn't exist within the outpoint\n\t\t// index, then the edge does not exist.\n\t\tchanIndex := edges.NestedReadBucket(channelPointBucket)\n\t\tif chanIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tvar b bytes.Buffer\n\t\tif err := writeOutpoint(&b, op); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tchanID := chanIndex.Get(b.Bytes())\n\t\tif chanID == nil {\n\t\t\treturn ErrEdgeNotFound\n\t\t}\n\n\t\t// If the channel is found to exists, then we'll first retrieve\n\t\t// the general information for the channel.\n\t\tedge, err := fetchChanEdgeInfo(edgeIndex, chanID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tedgeInfo = &edge\n\t\tedgeInfo.db = c.db\n\n\t\t// Once we have the information about the channels' parameters,\n\t\t// we'll fetch the routing policies for each for the directed\n\t\t// edges.\n\t\te1, e2, err := fetchChanEdgePolicies(\n\t\t\tedgeIndex, edges, nodes, chanID, c.db,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpolicy1 = e1\n\t\tpolicy2 = e2\n\t\treturn nil\n\t}, func() {\n\t\tedgeInfo = nil\n\t\tpolicy1 = nil\n\t\tpolicy2 = nil\n\t})\n\tif err != nil {\n\t\treturn nil, nil, nil, err\n\t}\n\n\treturn edgeInfo, policy1, policy2, nil\n}\n\n// FetchChannelEdgesByID attempts to lookup the two directed edges for the\n// channel identified by the channel ID. If the channel can't be found, then\n// ErrEdgeNotFound is returned. A struct which houses the general information\n// for the channel itself is returned as well as two structs that contain the\n// routing policies for the channel in either direction.\n//\n// ErrZombieEdge an be returned if the edge is currently marked as a zombie\n// within the database. In this case, the ChannelEdgePolicy's will be nil, and\n// the ChannelEdgeInfo will only include the public keys of each node.",
      "length": 2394,
      "tokens": 376,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) FetchChannelEdgesByID(chanID uint64,",
      "content": "func (c *ChannelGraph) FetchChannelEdgesByID(chanID uint64,\n) (*ChannelEdgeInfo, *ChannelEdgePolicy, *ChannelEdgePolicy, error) {\n\n\tvar (\n\t\tedgeInfo  *ChannelEdgeInfo\n\t\tpolicy1   *ChannelEdgePolicy\n\t\tpolicy2   *ChannelEdgePolicy\n\t\tchannelID [8]byte\n\t)\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// First, grab the node bucket. This will be used to populate\n\t\t// the Node pointers in each edge read from disk.\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNotFound\n\t\t}\n\n\t\t// Next, grab the edge bucket which stores the edges, and also\n\t\t// the index itself so we can group the directed edges together\n\t\t// logically.\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\tbyteOrder.PutUint64(channelID[:], chanID)\n\n\t\t// Now, attempt to fetch edge.\n\t\tedge, err := fetchChanEdgeInfo(edgeIndex, channelID[:])\n\n\t\t// If it doesn't exist, we'll quickly check our zombie index to\n\t\t// see if we've previously marked it as so.\n\t\tif err == ErrEdgeNotFound {\n\t\t\t// If the zombie index doesn't exist, or the edge is not\n\t\t\t// marked as a zombie within it, then we'll return the\n\t\t\t// original ErrEdgeNotFound error.\n\t\t\tzombieIndex := edges.NestedReadBucket(zombieBucket)\n\t\t\tif zombieIndex == nil {\n\t\t\t\treturn ErrEdgeNotFound\n\t\t\t}\n\n\t\t\tisZombie, pubKey1, pubKey2 := isZombieEdge(\n\t\t\t\tzombieIndex, chanID,\n\t\t\t)\n\t\t\tif !isZombie {\n\t\t\t\treturn ErrEdgeNotFound\n\t\t\t}\n\n\t\t\t// Otherwise, the edge is marked as a zombie, so we'll\n\t\t\t// populate the edge info with the public keys of each\n\t\t\t// party as this is the only information we have about\n\t\t\t// it and return an error signaling so.\n\t\t\tedgeInfo = &ChannelEdgeInfo{\n\t\t\t\tNodeKey1Bytes: pubKey1,\n\t\t\t\tNodeKey2Bytes: pubKey2,\n\t\t\t}\n\t\t\treturn ErrZombieEdge\n\t\t}\n\n\t\t// Otherwise, we'll just return the error if any.\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tedgeInfo = &edge\n\t\tedgeInfo.db = c.db\n\n\t\t// Then we'll attempt to fetch the accompanying policies of this\n\t\t// edge.\n\t\te1, e2, err := fetchChanEdgePolicies(\n\t\t\tedgeIndex, edges, nodes, channelID[:], c.db,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpolicy1 = e1\n\t\tpolicy2 = e2\n\t\treturn nil\n\t}, func() {\n\t\tedgeInfo = nil\n\t\tpolicy1 = nil\n\t\tpolicy2 = nil\n\t})\n\tif err == ErrZombieEdge {\n\t\treturn edgeInfo, nil, nil, err\n\t}\n\tif err != nil {\n\t\treturn nil, nil, nil, err\n\t}\n\n\treturn edgeInfo, policy1, policy2, nil\n}\n\n// IsPublicNode is a helper method that determines whether the node with the\n// given public key is seen as a public node in the graph from the graph's\n// source node's point of view.",
      "length": 2503,
      "tokens": 387,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) IsPublicNode(pubKey [33]byte) (bool, error) {",
      "content": "func (c *ChannelGraph) IsPublicNode(pubKey [33]byte) (bool, error) {\n\tvar nodeIsPublic bool\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tnodes := tx.ReadBucket(nodeBucket)\n\t\tif nodes == nil {\n\t\t\treturn ErrGraphNodesNotFound\n\t\t}\n\t\tourPubKey := nodes.Get(sourceKey)\n\t\tif ourPubKey == nil {\n\t\t\treturn ErrSourceNodeNotSet\n\t\t}\n\t\tnode, err := fetchLightningNode(nodes, pubKey[:])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tnodeIsPublic, err = node.isPublic(tx, ourPubKey)\n\t\treturn err\n\t}, func() {\n\t\tnodeIsPublic = false\n\t})\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn nodeIsPublic, nil\n}\n\n// genMultiSigP2WSH generates the p2wsh'd multisig script for 2 of 2 pubkeys.",
      "length": 573,
      "tokens": 84,
      "embedding": []
    },
    {
      "slug": "func genMultiSigP2WSH(aPub, bPub []byte) ([]byte, error) {",
      "content": "func genMultiSigP2WSH(aPub, bPub []byte) ([]byte, error) {\n\tif len(aPub) != 33 || len(bPub) != 33 {\n\t\treturn nil, fmt.Errorf(\"pubkey size error. Compressed \" +\n\t\t\t\"pubkeys only\")\n\t}\n\n\t// Swap to sort pubkeys if needed. Keys are sorted in lexicographical\n\t// order. The signatures within the scriptSig must also adhere to the\n\t// order, ensuring that the signatures for each public key appears in\n\t// the proper order on the stack.\n\tif bytes.Compare(aPub, bPub) == 1 {\n\t\taPub, bPub = bPub, aPub\n\t}\n\n\t// First, we'll generate the witness script for the multi-sig.\n\tbldr := txscript.NewScriptBuilder()\n\tbldr.AddOp(txscript.OP_2)\n\tbldr.AddData(aPub) // Add both pubkeys (sorted).\n\tbldr.AddData(bPub)\n\tbldr.AddOp(txscript.OP_2)\n\tbldr.AddOp(txscript.OP_CHECKMULTISIG)\n\twitnessScript, err := bldr.Script()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// With the witness script generated, we'll now turn it into a p2sh\n\t// script:\n\t//  * OP_0 <sha256(script)>\n\tbldr = txscript.NewScriptBuilder()\n\tbldr.AddOp(txscript.OP_0)\n\tscriptHash := sha256.Sum256(witnessScript)\n\tbldr.AddData(scriptHash[:])\n\n\treturn bldr.Script()\n}\n\n// EdgePoint couples the outpoint of a channel with the funding script that it\n// creates. The FilteredChainView will use this to watch for spends of this\n// edge point on chain. We require both of these values as depending on the\n// concrete implementation, either the pkScript, or the out point will be used.",
      "length": 1322,
      "tokens": 196,
      "embedding": []
    },
    {
      "slug": "type EdgePoint struct {",
      "content": "type EdgePoint struct {\n\t// FundingPkScript is the p2wsh multi-sig script of the target channel.\n\tFundingPkScript []byte\n\n\t// OutPoint is the outpoint of the target channel.\n\tOutPoint wire.OutPoint\n}\n\n// String returns a human readable version of the target EdgePoint. We return\n// the outpoint directly as it is enough to uniquely identify the edge point.",
      "length": 324,
      "tokens": 52,
      "embedding": []
    },
    {
      "slug": "func (e *EdgePoint) String() string {",
      "content": "func (e *EdgePoint) String() string {\n\treturn e.OutPoint.String()\n}\n\n// ChannelView returns the verifiable edge information for each active channel\n// within the known channel graph. The set of UTXO's (along with their scripts)\n// returned are the ones that need to be watched on chain to detect channel\n// closes on the resident blockchain.",
      "length": 297,
      "tokens": 49,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) ChannelView() ([]EdgePoint, error) {",
      "content": "func (c *ChannelGraph) ChannelView() ([]EdgePoint, error) {\n\tvar edgePoints []EdgePoint\n\tif err := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\t// We're going to iterate over the entire channel index, so\n\t\t// we'll need to fetch the edgeBucket to get to the index as\n\t\t// it's a sub-bucket.\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tchanIndex := edges.NestedReadBucket(channelPointBucket)\n\t\tif chanIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tedgeIndex := edges.NestedReadBucket(edgeIndexBucket)\n\t\tif edgeIndex == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\n\t\t// Once we have the proper bucket, we'll range over each key\n\t\t// (which is the channel point for the channel) and decode it,\n\t\t// accumulating each entry.\n\t\treturn chanIndex.ForEach(func(chanPointBytes, chanID []byte) error {\n\t\t\tchanPointReader := bytes.NewReader(chanPointBytes)\n\n\t\t\tvar chanPoint wire.OutPoint\n\t\t\terr := readOutpoint(chanPointReader, &chanPoint)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tedgeInfo, err := fetchChanEdgeInfo(\n\t\t\t\tedgeIndex, chanID,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tpkScript, err := genMultiSigP2WSH(\n\t\t\t\tedgeInfo.BitcoinKey1Bytes[:],\n\t\t\t\tedgeInfo.BitcoinKey2Bytes[:],\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tedgePoints = append(edgePoints, EdgePoint{\n\t\t\t\tFundingPkScript: pkScript,\n\t\t\t\tOutPoint:        chanPoint,\n\t\t\t})\n\n\t\t\treturn nil\n\t\t})\n\t}, func() {\n\t\tedgePoints = nil\n\t}); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn edgePoints, nil\n}\n\n// NewChannelEdgePolicy returns a new blank ChannelEdgePolicy.",
      "length": 1454,
      "tokens": 192,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) NewChannelEdgePolicy() *ChannelEdgePolicy {",
      "content": "func (c *ChannelGraph) NewChannelEdgePolicy() *ChannelEdgePolicy {\n\treturn &ChannelEdgePolicy{db: c.db}\n}\n\n// MarkEdgeZombie attempts to mark a channel identified by its channel ID as a\n// zombie. This method is used on an ad-hoc basis, when channels need to be\n// marked as zombies outside the normal pruning cycle.",
      "length": 244,
      "tokens": 42,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) MarkEdgeZombie(chanID uint64,",
      "content": "func (c *ChannelGraph) MarkEdgeZombie(chanID uint64,\n\tpubKey1, pubKey2 [33]byte) error {\n\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\terr := kvdb.Batch(c.db, func(tx kvdb.RwTx) error {\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tzombieIndex, err := edges.CreateBucketIfNotExists(zombieBucket)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to create zombie \"+\n\t\t\t\t\"bucket: %w\", err)\n\t\t}\n\n\t\tif c.graphCache != nil {\n\t\t\tc.graphCache.RemoveChannel(pubKey1, pubKey2, chanID)\n\t\t}\n\n\t\treturn markEdgeZombie(zombieIndex, chanID, pubKey1, pubKey2)\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.rejectCache.remove(chanID)\n\tc.chanCache.remove(chanID)\n\n\treturn nil\n}\n\n// markEdgeZombie marks an edge as a zombie within our zombie index. The public\n// keys should represent the node public keys of the two parties involved in the\n// edge.",
      "length": 790,
      "tokens": 104,
      "embedding": []
    },
    {
      "slug": "func markEdgeZombie(zombieIndex kvdb.RwBucket, chanID uint64, pubKey1,",
      "content": "func markEdgeZombie(zombieIndex kvdb.RwBucket, chanID uint64, pubKey1,\n\tpubKey2 [33]byte) error {\n\n\tvar k [8]byte\n\tbyteOrder.PutUint64(k[:], chanID)\n\n\tvar v [66]byte\n\tcopy(v[:33], pubKey1[:])\n\tcopy(v[33:], pubKey2[:])\n\n\treturn zombieIndex.Put(k[:], v[:])\n}\n\n// MarkEdgeLive clears an edge from our zombie index, deeming it as live.",
      "length": 248,
      "tokens": 33,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) MarkEdgeLive(chanID uint64) error {",
      "content": "func (c *ChannelGraph) MarkEdgeLive(chanID uint64) error {\n\tc.cacheMu.Lock()\n\tdefer c.cacheMu.Unlock()\n\n\terr := kvdb.Update(c.db, func(tx kvdb.RwTx) error {\n\t\tedges := tx.ReadWriteBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tzombieIndex := edges.NestedReadWriteBucket(zombieBucket)\n\t\tif zombieIndex == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tvar k [8]byte\n\t\tbyteOrder.PutUint64(k[:], chanID)\n\t\treturn zombieIndex.Delete(k[:])\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc.rejectCache.remove(chanID)\n\tc.chanCache.remove(chanID)\n\n\t// We need to add the channel back into our graph cache, otherwise we\n\t// won't use it for path finding.\n\tedgeInfos, err := c.FetchChanInfos([]uint64{chanID})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif c.graphCache != nil {\n\t\tfor _, edgeInfo := range edgeInfos {\n\t\t\tc.graphCache.AddChannel(\n\t\t\t\tedgeInfo.Info, edgeInfo.Policy1,\n\t\t\t\tedgeInfo.Policy2,\n\t\t\t)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// IsZombieEdge returns whether the edge is considered zombie. If it is a\n// zombie, then the two node public keys corresponding to this edge are also\n// returned.",
      "length": 985,
      "tokens": 136,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) IsZombieEdge(chanID uint64) (bool, [33]byte, [33]byte) {",
      "content": "func (c *ChannelGraph) IsZombieEdge(chanID uint64) (bool, [33]byte, [33]byte) {\n\tvar (\n\t\tisZombie         bool\n\t\tpubKey1, pubKey2 [33]byte\n\t)\n\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn ErrGraphNoEdgesFound\n\t\t}\n\t\tzombieIndex := edges.NestedReadBucket(zombieBucket)\n\t\tif zombieIndex == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tisZombie, pubKey1, pubKey2 = isZombieEdge(zombieIndex, chanID)\n\t\treturn nil\n\t}, func() {\n\t\tisZombie = false\n\t\tpubKey1 = [33]byte{}\n\t\tpubKey2 = [33]byte{}\n\t})\n\tif err != nil {\n\t\treturn false, [33]byte{}, [33]byte{}\n\t}\n\n\treturn isZombie, pubKey1, pubKey2\n}\n\n// isZombieEdge returns whether an entry exists for the given channel in the\n// zombie index. If an entry exists, then the two node public keys corresponding\n// to this edge are also returned.",
      "length": 723,
      "tokens": 107,
      "embedding": []
    },
    {
      "slug": "func isZombieEdge(zombieIndex kvdb.RBucket,",
      "content": "func isZombieEdge(zombieIndex kvdb.RBucket,\n\tchanID uint64) (bool, [33]byte, [33]byte) {\n\n\tvar k [8]byte\n\tbyteOrder.PutUint64(k[:], chanID)\n\n\tv := zombieIndex.Get(k[:])\n\tif v == nil {\n\t\treturn false, [33]byte{}, [33]byte{}\n\t}\n\n\tvar pubKey1, pubKey2 [33]byte\n\tcopy(pubKey1[:], v[:33])\n\tcopy(pubKey2[:], v[33:])\n\n\treturn true, pubKey1, pubKey2\n}\n\n// NumZombies returns the current number of zombie channels in the graph.",
      "length": 357,
      "tokens": 49,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelGraph) NumZombies() (uint64, error) {",
      "content": "func (c *ChannelGraph) NumZombies() (uint64, error) {\n\tvar numZombies uint64\n\terr := kvdb.View(c.db, func(tx kvdb.RTx) error {\n\t\tedges := tx.ReadBucket(edgeBucket)\n\t\tif edges == nil {\n\t\t\treturn nil\n\t\t}\n\t\tzombieIndex := edges.NestedReadBucket(zombieBucket)\n\t\tif zombieIndex == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\treturn zombieIndex.ForEach(func(_, _ []byte) error {\n\t\t\tnumZombies++\n\t\t\treturn nil\n\t\t})\n\t}, func() {\n\t\tnumZombies = 0\n\t})\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn numZombies, nil\n}\n",
      "length": 410,
      "tokens": 62,
      "embedding": []
    },
    {
      "slug": "func putLightningNode(nodeBucket kvdb.RwBucket, aliasBucket kvdb.RwBucket, // nolint:dupl",
      "content": "func putLightningNode(nodeBucket kvdb.RwBucket, aliasBucket kvdb.RwBucket, // nolint:dupl\n\tupdateIndex kvdb.RwBucket, node *LightningNode) error {\n\n\tvar (\n\t\tscratch [16]byte\n\t\tb       bytes.Buffer\n\t)\n\n\tpub, err := node.PubKey()\n\tif err != nil {\n\t\treturn err\n\t}\n\tnodePub := pub.SerializeCompressed()\n\n\t// If the node has the update time set, write it, else write 0.\n\tupdateUnix := uint64(0)\n\tif node.LastUpdate.Unix() > 0 {\n\t\tupdateUnix = uint64(node.LastUpdate.Unix())\n\t}\n\n\tbyteOrder.PutUint64(scratch[:8], updateUnix)\n\tif _, err := b.Write(scratch[:8]); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := b.Write(nodePub); err != nil {\n\t\treturn err\n\t}\n\n\t// If we got a node announcement for this node, we will have the rest\n\t// of the data available. If not we don't have more data to write.\n\tif !node.HaveNodeAnnouncement {\n\t\t// Write HaveNodeAnnouncement=0.\n\t\tbyteOrder.PutUint16(scratch[:2], 0)\n\t\tif _, err := b.Write(scratch[:2]); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn nodeBucket.Put(nodePub, b.Bytes())\n\t}\n\n\t// Write HaveNodeAnnouncement=1.\n\tbyteOrder.PutUint16(scratch[:2], 1)\n\tif _, err := b.Write(scratch[:2]); err != nil {\n\t\treturn err\n\t}\n\n\tif err := binary.Write(&b, byteOrder, node.Color.R); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(&b, byteOrder, node.Color.G); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(&b, byteOrder, node.Color.B); err != nil {\n\t\treturn err\n\t}\n\n\tif err := wire.WriteVarString(&b, 0, node.Alias); err != nil {\n\t\treturn err\n\t}\n\n\tif err := node.Features.Encode(&b); err != nil {\n\t\treturn err\n\t}\n\n\tnumAddresses := uint16(len(node.Addresses))\n\tbyteOrder.PutUint16(scratch[:2], numAddresses)\n\tif _, err := b.Write(scratch[:2]); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, address := range node.Addresses {\n\t\tif err := serializeAddr(&b, address); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tsigLen := len(node.AuthSigBytes)\n\tif sigLen > 80 {\n\t\treturn fmt.Errorf(\"max sig len allowed is 80, had %v\",\n\t\t\tsigLen)\n\t}\n\n\terr = wire.WriteVarBytes(&b, 0, node.AuthSigBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(node.ExtraOpaqueData) > MaxAllowedExtraOpaqueBytes {\n\t\treturn ErrTooManyExtraOpaqueBytes(len(node.ExtraOpaqueData))\n\t}\n\terr = wire.WriteVarBytes(&b, 0, node.ExtraOpaqueData)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := aliasBucket.Put(nodePub, []byte(node.Alias)); err != nil {\n\t\treturn err\n\t}\n\n\t// With the alias bucket updated, we'll now update the index that\n\t// tracks the time series of node updates.\n\tvar indexKey [8 + 33]byte\n\tbyteOrder.PutUint64(indexKey[:8], updateUnix)\n\tcopy(indexKey[8:], nodePub)\n\n\t// If there was already an old index entry for this node, then we'll\n\t// delete the old one before we write the new entry.\n\tif nodeBytes := nodeBucket.Get(nodePub); nodeBytes != nil {\n\t\t// Extract out the old update time to we can reconstruct the\n\t\t// prior index key to delete it from the index.\n\t\toldUpdateTime := nodeBytes[:8]\n\n\t\tvar oldIndexKey [8 + 33]byte\n\t\tcopy(oldIndexKey[:8], oldUpdateTime)\n\t\tcopy(oldIndexKey[8:], nodePub)\n\n\t\tif err := updateIndex.Delete(oldIndexKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := updateIndex.Put(indexKey[:], nil); err != nil {\n\t\treturn err\n\t}\n\n\treturn nodeBucket.Put(nodePub, b.Bytes())\n}\n",
      "length": 2971,
      "tokens": 439,
      "embedding": []
    },
    {
      "slug": "func fetchLightningNode(nodeBucket kvdb.RBucket,",
      "content": "func fetchLightningNode(nodeBucket kvdb.RBucket,\n\tnodePub []byte) (LightningNode, error) {\n\n\tnodeBytes := nodeBucket.Get(nodePub)\n\tif nodeBytes == nil {\n\t\treturn LightningNode{}, ErrGraphNodeNotFound\n\t}\n\n\tnodeReader := bytes.NewReader(nodeBytes)\n\treturn deserializeLightningNode(nodeReader)\n}\n",
      "length": 234,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func deserializeLightningNodeCacheable(r io.Reader) (*graphCacheNode, error) {",
      "content": "func deserializeLightningNodeCacheable(r io.Reader) (*graphCacheNode, error) {\n\t// Always populate a feature vector, even if we don't have a node\n\t// announcement and short circuit below.\n\tnode := newGraphCacheNode(\n\t\troute.Vertex{},\n\t\tlnwire.EmptyFeatureVector(),\n\t)\n\n\tvar nodeScratch [8]byte\n\n\t// Skip ahead:\n\t// - LastUpdate (8 bytes)\n\tif _, err := r.Read(nodeScratch[:]); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, err := io.ReadFull(r, node.pubKeyBytes[:]); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Read the node announcement flag.\n\tif _, err := r.Read(nodeScratch[:2]); err != nil {\n\t\treturn nil, err\n\t}\n\thasNodeAnn := byteOrder.Uint16(nodeScratch[:2])\n\n\t// The rest of the data is optional, and will only be there if we got a\n\t// node announcement for this node.\n\tif hasNodeAnn == 0 {\n\t\treturn node, nil\n\t}\n\n\t// We did get a node announcement for this node, so we'll have the rest\n\t// of the data available.\n\tvar rgb uint8\n\tif err := binary.Read(r, byteOrder, &rgb); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := binary.Read(r, byteOrder, &rgb); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := binary.Read(r, byteOrder, &rgb); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, err := wire.ReadVarString(r, 0); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := node.features.Decode(r); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn node, nil\n}\n",
      "length": 1195,
      "tokens": 212,
      "embedding": []
    },
    {
      "slug": "func deserializeLightningNode(r io.Reader) (LightningNode, error) {",
      "content": "func deserializeLightningNode(r io.Reader) (LightningNode, error) {\n\tvar (\n\t\tnode    LightningNode\n\t\tscratch [8]byte\n\t\terr     error\n\t)\n\n\t// Always populate a feature vector, even if we don't have a node\n\t// announcement and short circuit below.\n\tnode.Features = lnwire.EmptyFeatureVector()\n\n\tif _, err := r.Read(scratch[:]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tunix := int64(byteOrder.Uint64(scratch[:]))\n\tnode.LastUpdate = time.Unix(unix, 0)\n\n\tif _, err := io.ReadFull(r, node.PubKeyBytes[:]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tif _, err := r.Read(scratch[:2]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\thasNodeAnn := byteOrder.Uint16(scratch[:2])\n\tif hasNodeAnn == 1 {\n\t\tnode.HaveNodeAnnouncement = true\n\t} else {\n\t\tnode.HaveNodeAnnouncement = false\n\t}\n\n\t// The rest of the data is optional, and will only be there if we got a node\n\t// announcement for this node.\n\tif !node.HaveNodeAnnouncement {\n\t\treturn node, nil\n\t}\n\n\t// We did get a node announcement for this node, so we'll have the rest\n\t// of the data available.\n\tif err := binary.Read(r, byteOrder, &node.Color.R); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &node.Color.G); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &node.Color.B); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tnode.Alias, err = wire.ReadVarString(r, 0)\n\tif err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\terr = node.Features.Decode(r)\n\tif err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\tif _, err := r.Read(scratch[:2]); err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\tnumAddresses := int(byteOrder.Uint16(scratch[:2]))\n\n\tvar addresses []net.Addr\n\tfor i := 0; i < numAddresses; i++ {\n\t\taddress, err := deserializeAddr(r)\n\t\tif err != nil {\n\t\t\treturn LightningNode{}, err\n\t\t}\n\t\taddresses = append(addresses, address)\n\t}\n\tnode.Addresses = addresses\n\n\tnode.AuthSigBytes, err = wire.ReadVarBytes(r, 0, 80, \"sig\")\n\tif err != nil {\n\t\treturn LightningNode{}, err\n\t}\n\n\t// We'll try and see if there are any opaque bytes left, if not, then\n\t// we'll ignore the EOF error and return the node as is.\n\tnode.ExtraOpaqueData, err = wire.ReadVarBytes(\n\t\tr, 0, MaxAllowedExtraOpaqueBytes, \"blob\",\n\t)\n\tswitch {\n\tcase err == io.ErrUnexpectedEOF:\n\tcase err == io.EOF:\n\tcase err != nil:\n\t\treturn LightningNode{}, err\n\t}\n\n\treturn node, nil\n}\n",
      "length": 2201,
      "tokens": 337,
      "embedding": []
    },
    {
      "slug": "func putChanEdgeInfo(edgeIndex kvdb.RwBucket, edgeInfo *ChannelEdgeInfo, chanID [8]byte) error {",
      "content": "func putChanEdgeInfo(edgeIndex kvdb.RwBucket, edgeInfo *ChannelEdgeInfo, chanID [8]byte) error {\n\tvar b bytes.Buffer\n\n\tif _, err := b.Write(edgeInfo.NodeKey1Bytes[:]); err != nil {\n\t\treturn err\n\t}\n\tif _, err := b.Write(edgeInfo.NodeKey2Bytes[:]); err != nil {\n\t\treturn err\n\t}\n\tif _, err := b.Write(edgeInfo.BitcoinKey1Bytes[:]); err != nil {\n\t\treturn err\n\t}\n\tif _, err := b.Write(edgeInfo.BitcoinKey2Bytes[:]); err != nil {\n\t\treturn err\n\t}\n\n\tif err := wire.WriteVarBytes(&b, 0, edgeInfo.Features); err != nil {\n\t\treturn err\n\t}\n\n\tauthProof := edgeInfo.AuthProof\n\tvar nodeSig1, nodeSig2, bitcoinSig1, bitcoinSig2 []byte\n\tif authProof != nil {\n\t\tnodeSig1 = authProof.NodeSig1Bytes\n\t\tnodeSig2 = authProof.NodeSig2Bytes\n\t\tbitcoinSig1 = authProof.BitcoinSig1Bytes\n\t\tbitcoinSig2 = authProof.BitcoinSig2Bytes\n\t}\n\n\tif err := wire.WriteVarBytes(&b, 0, nodeSig1); err != nil {\n\t\treturn err\n\t}\n\tif err := wire.WriteVarBytes(&b, 0, nodeSig2); err != nil {\n\t\treturn err\n\t}\n\tif err := wire.WriteVarBytes(&b, 0, bitcoinSig1); err != nil {\n\t\treturn err\n\t}\n\tif err := wire.WriteVarBytes(&b, 0, bitcoinSig2); err != nil {\n\t\treturn err\n\t}\n\n\tif err := writeOutpoint(&b, &edgeInfo.ChannelPoint); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(&b, byteOrder, uint64(edgeInfo.Capacity)); err != nil {\n\t\treturn err\n\t}\n\tif _, err := b.Write(chanID[:]); err != nil {\n\t\treturn err\n\t}\n\tif _, err := b.Write(edgeInfo.ChainHash[:]); err != nil {\n\t\treturn err\n\t}\n\n\tif len(edgeInfo.ExtraOpaqueData) > MaxAllowedExtraOpaqueBytes {\n\t\treturn ErrTooManyExtraOpaqueBytes(len(edgeInfo.ExtraOpaqueData))\n\t}\n\terr := wire.WriteVarBytes(&b, 0, edgeInfo.ExtraOpaqueData)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn edgeIndex.Put(chanID[:], b.Bytes())\n}\n",
      "length": 1552,
      "tokens": 217,
      "embedding": []
    },
    {
      "slug": "func fetchChanEdgeInfo(edgeIndex kvdb.RBucket,",
      "content": "func fetchChanEdgeInfo(edgeIndex kvdb.RBucket,\n\tchanID []byte) (ChannelEdgeInfo, error) {\n\n\tedgeInfoBytes := edgeIndex.Get(chanID)\n\tif edgeInfoBytes == nil {\n\t\treturn ChannelEdgeInfo{}, ErrEdgeNotFound\n\t}\n\n\tedgeInfoReader := bytes.NewReader(edgeInfoBytes)\n\treturn deserializeChanEdgeInfo(edgeInfoReader)\n}\n",
      "length": 249,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func deserializeChanEdgeInfo(r io.Reader) (ChannelEdgeInfo, error) {",
      "content": "func deserializeChanEdgeInfo(r io.Reader) (ChannelEdgeInfo, error) {\n\tvar (\n\t\terr      error\n\t\tedgeInfo ChannelEdgeInfo\n\t)\n\n\tif _, err := io.ReadFull(r, edgeInfo.NodeKey1Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif _, err := io.ReadFull(r, edgeInfo.NodeKey2Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif _, err := io.ReadFull(r, edgeInfo.BitcoinKey1Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif _, err := io.ReadFull(r, edgeInfo.BitcoinKey2Bytes[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tedgeInfo.Features, err = wire.ReadVarBytes(r, 0, 900, \"features\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tproof := &ChannelAuthProof{}\n\n\tproof.NodeSig1Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tproof.NodeSig2Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tproof.BitcoinSig1Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tproof.BitcoinSig2Bytes, err = wire.ReadVarBytes(r, 0, 80, \"sigs\")\n\tif err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tif !proof.IsEmpty() {\n\t\tedgeInfo.AuthProof = proof\n\t}\n\n\tedgeInfo.ChannelPoint = wire.OutPoint{}\n\tif err := readOutpoint(r, &edgeInfo.ChannelPoint); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edgeInfo.Capacity); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edgeInfo.ChannelID); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\tif _, err := io.ReadFull(r, edgeInfo.ChainHash[:]); err != nil {\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\t// We'll try and see if there are any opaque bytes left, if not, then\n\t// we'll ignore the EOF error and return the edge as is.\n\tedgeInfo.ExtraOpaqueData, err = wire.ReadVarBytes(\n\t\tr, 0, MaxAllowedExtraOpaqueBytes, \"blob\",\n\t)\n\tswitch {\n\tcase err == io.ErrUnexpectedEOF:\n\tcase err == io.EOF:\n\tcase err != nil:\n\t\treturn ChannelEdgeInfo{}, err\n\t}\n\n\treturn edgeInfo, nil\n}\n",
      "length": 1913,
      "tokens": 269,
      "embedding": []
    },
    {
      "slug": "func putChanEdgePolicy(edges, nodes kvdb.RwBucket, edge *ChannelEdgePolicy,",
      "content": "func putChanEdgePolicy(edges, nodes kvdb.RwBucket, edge *ChannelEdgePolicy,\n\tfrom, to []byte) error {\n\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[:], from)\n\tbyteOrder.PutUint64(edgeKey[33:], edge.ChannelID)\n\n\tvar b bytes.Buffer\n\tif err := serializeChanEdgePolicy(&b, edge, to); err != nil {\n\t\treturn err\n\t}\n\n\t// Before we write out the new edge, we'll create a new entry in the\n\t// update index in order to keep it fresh.\n\tupdateUnix := uint64(edge.LastUpdate.Unix())\n\tvar indexKey [8 + 8]byte\n\tbyteOrder.PutUint64(indexKey[:8], updateUnix)\n\tbyteOrder.PutUint64(indexKey[8:], edge.ChannelID)\n\n\tupdateIndex, err := edges.CreateBucketIfNotExists(edgeUpdateIndexBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If there was already an entry for this edge, then we'll need to\n\t// delete the old one to ensure we don't leave around any after-images.\n\t// An unknown policy value does not have a update time recorded, so\n\t// it also does not need to be removed.\n\tif edgeBytes := edges.Get(edgeKey[:]); edgeBytes != nil &&\n\t\t!bytes.Equal(edgeBytes[:], unknownPolicy) {\n\n\t\t// In order to delete the old entry, we'll need to obtain the\n\t\t// *prior* update time in order to delete it. To do this, we'll\n\t\t// need to deserialize the existing policy within the database\n\t\t// (now outdated by the new one), and delete its corresponding\n\t\t// entry within the update index. We'll ignore any\n\t\t// ErrEdgePolicyOptionalFieldNotFound error, as we only need\n\t\t// the channel ID and update time to delete the entry.\n\t\t// TODO(halseth): get rid of these invalid policies in a\n\t\t// migration.\n\t\toldEdgePolicy, err := deserializeChanEdgePolicy(\n\t\t\tbytes.NewReader(edgeBytes), nodes,\n\t\t)\n\t\tif err != nil && err != ErrEdgePolicyOptionalFieldNotFound {\n\t\t\treturn err\n\t\t}\n\n\t\toldUpdateTime := uint64(oldEdgePolicy.LastUpdate.Unix())\n\n\t\tvar oldIndexKey [8 + 8]byte\n\t\tbyteOrder.PutUint64(oldIndexKey[:8], oldUpdateTime)\n\t\tbyteOrder.PutUint64(oldIndexKey[8:], edge.ChannelID)\n\n\t\tif err := updateIndex.Delete(oldIndexKey[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := updateIndex.Put(indexKey[:], nil); err != nil {\n\t\treturn err\n\t}\n\n\tupdateEdgePolicyDisabledIndex(\n\t\tedges, edge.ChannelID,\n\t\tedge.ChannelFlags&lnwire.ChanUpdateDirection > 0,\n\t\tedge.IsDisabled(),\n\t)\n\n\treturn edges.Put(edgeKey[:], b.Bytes()[:])\n}\n\n// updateEdgePolicyDisabledIndex is used to update the disabledEdgePolicyIndex\n// bucket by either add a new disabled ChannelEdgePolicy or remove an existing\n// one.\n// The direction represents the direction of the edge and disabled is used for\n// deciding whether to remove or add an entry to the bucket.\n// In general a channel is disabled if two entries for the same chanID exist\n// in this bucket.\n// Maintaining the bucket this way allows a fast retrieval of disabled\n// channels, for example when prune is needed.",
      "length": 2644,
      "tokens": 379,
      "embedding": []
    },
    {
      "slug": "func updateEdgePolicyDisabledIndex(edges kvdb.RwBucket, chanID uint64,",
      "content": "func updateEdgePolicyDisabledIndex(edges kvdb.RwBucket, chanID uint64,\n\tdirection bool, disabled bool) error {\n\n\tvar disabledEdgeKey [8 + 1]byte\n\tbyteOrder.PutUint64(disabledEdgeKey[0:], chanID)\n\tif direction {\n\t\tdisabledEdgeKey[8] = 1\n\t}\n\n\tdisabledEdgePolicyIndex, err := edges.CreateBucketIfNotExists(\n\t\tdisabledEdgePolicyBucket,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif disabled {\n\t\treturn disabledEdgePolicyIndex.Put(disabledEdgeKey[:], []byte{})\n\t}\n\n\treturn disabledEdgePolicyIndex.Delete(disabledEdgeKey[:])\n}\n\n// putChanEdgePolicyUnknown marks the edge policy as unknown\n// in the edges bucket.",
      "length": 507,
      "tokens": 57,
      "embedding": []
    },
    {
      "slug": "func putChanEdgePolicyUnknown(edges kvdb.RwBucket, channelID uint64,",
      "content": "func putChanEdgePolicyUnknown(edges kvdb.RwBucket, channelID uint64,\n\tfrom []byte) error {\n\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[:], from)\n\tbyteOrder.PutUint64(edgeKey[33:], channelID)\n\n\tif edges.Get(edgeKey[:]) != nil {\n\t\treturn fmt.Errorf(\"cannot write unknown policy for channel %v \"+\n\t\t\t\" when there is already a policy present\", channelID)\n\t}\n\n\treturn edges.Put(edgeKey[:], unknownPolicy)\n}\n",
      "length": 317,
      "tokens": 41,
      "embedding": []
    },
    {
      "slug": "func fetchChanEdgePolicy(edges kvdb.RBucket, chanID []byte,",
      "content": "func fetchChanEdgePolicy(edges kvdb.RBucket, chanID []byte,\n\tnodePub []byte, nodes kvdb.RBucket) (*ChannelEdgePolicy, error) {\n\n\tvar edgeKey [33 + 8]byte\n\tcopy(edgeKey[:], nodePub)\n\tcopy(edgeKey[33:], chanID[:])\n\n\tedgeBytes := edges.Get(edgeKey[:])\n\tif edgeBytes == nil {\n\t\treturn nil, ErrEdgeNotFound\n\t}\n\n\t// No need to deserialize unknown policy.\n\tif bytes.Equal(edgeBytes[:], unknownPolicy) {\n\t\treturn nil, nil\n\t}\n\n\tedgeReader := bytes.NewReader(edgeBytes)\n\n\tep, err := deserializeChanEdgePolicy(edgeReader, nodes)\n\tswitch {\n\t// If the db policy was missing an expected optional field, we return\n\t// nil as if the policy was unknown.\n\tcase err == ErrEdgePolicyOptionalFieldNotFound:\n\t\treturn nil, nil\n\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\treturn ep, nil\n}\n",
      "length": 672,
      "tokens": 93,
      "embedding": []
    },
    {
      "slug": "func fetchChanEdgePolicies(edgeIndex kvdb.RBucket, edges kvdb.RBucket,",
      "content": "func fetchChanEdgePolicies(edgeIndex kvdb.RBucket, edges kvdb.RBucket,\n\tnodes kvdb.RBucket, chanID []byte,\n\tdb kvdb.Backend) (*ChannelEdgePolicy, *ChannelEdgePolicy, error) {\n\n\tedgeInfo := edgeIndex.Get(chanID)\n\tif edgeInfo == nil {\n\t\treturn nil, nil, ErrEdgeNotFound\n\t}\n\n\t// The first node is contained within the first half of the edge\n\t// information. We only propagate the error here and below if it's\n\t// something other than edge non-existence.\n\tnode1Pub := edgeInfo[:33]\n\tedge1, err := fetchChanEdgePolicy(edges, chanID, node1Pub, nodes)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// As we may have a single direction of the edge but not the other,\n\t// only fill in the database pointers if the edge is found.\n\tif edge1 != nil {\n\t\tedge1.db = db\n\t\tedge1.Node.db = db\n\t}\n\n\t// Similarly, the second node is contained within the latter\n\t// half of the edge information.\n\tnode2Pub := edgeInfo[33:66]\n\tedge2, err := fetchChanEdgePolicy(edges, chanID, node2Pub, nodes)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tif edge2 != nil {\n\t\tedge2.db = db\n\t\tedge2.Node.db = db\n\t}\n\n\treturn edge1, edge2, nil\n}\n",
      "length": 993,
      "tokens": 166,
      "embedding": []
    },
    {
      "slug": "func serializeChanEdgePolicy(w io.Writer, edge *ChannelEdgePolicy,",
      "content": "func serializeChanEdgePolicy(w io.Writer, edge *ChannelEdgePolicy,\n\tto []byte) error {\n\n\terr := wire.WriteVarBytes(w, 0, edge.SigBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := binary.Write(w, byteOrder, edge.ChannelID); err != nil {\n\t\treturn err\n\t}\n\n\tvar scratch [8]byte\n\tupdateUnix := uint64(edge.LastUpdate.Unix())\n\tbyteOrder.PutUint64(scratch[:], updateUnix)\n\tif _, err := w.Write(scratch[:]); err != nil {\n\t\treturn err\n\t}\n\n\tif err := binary.Write(w, byteOrder, edge.MessageFlags); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, edge.ChannelFlags); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, edge.TimeLockDelta); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, uint64(edge.MinHTLC)); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, uint64(edge.FeeBaseMSat)); err != nil {\n\t\treturn err\n\t}\n\tif err := binary.Write(w, byteOrder, uint64(edge.FeeProportionalMillionths)); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := w.Write(to); err != nil {\n\t\treturn err\n\t}\n\n\t// If the max_htlc field is present, we write it. To be compatible with\n\t// older versions that wasn't aware of this field, we write it as part\n\t// of the opaque data.\n\t// TODO(halseth): clean up when moving to TLV.\n\tvar opaqueBuf bytes.Buffer\n\tif edge.MessageFlags.HasMaxHtlc() {\n\t\terr := binary.Write(&opaqueBuf, byteOrder, uint64(edge.MaxHTLC))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif len(edge.ExtraOpaqueData) > MaxAllowedExtraOpaqueBytes {\n\t\treturn ErrTooManyExtraOpaqueBytes(len(edge.ExtraOpaqueData))\n\t}\n\tif _, err := opaqueBuf.Write(edge.ExtraOpaqueData); err != nil {\n\t\treturn err\n\t}\n\n\tif err := wire.WriteVarBytes(w, 0, opaqueBuf.Bytes()); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
      "length": 1610,
      "tokens": 237,
      "embedding": []
    },
    {
      "slug": "func deserializeChanEdgePolicy(r io.Reader,",
      "content": "func deserializeChanEdgePolicy(r io.Reader,\n\tnodes kvdb.RBucket) (*ChannelEdgePolicy, error) {\n\n\t// Deserialize the policy. Note that in case an optional field is not\n\t// found, both an error and a populated policy object are returned.\n\tedge, deserializeErr := deserializeChanEdgePolicyRaw(r)\n\tif deserializeErr != nil &&\n\t\tdeserializeErr != ErrEdgePolicyOptionalFieldNotFound {\n\n\t\treturn nil, deserializeErr\n\t}\n\n\t// Populate full LightningNode struct.\n\tpub := edge.Node.PubKeyBytes[:]\n\tnode, err := fetchLightningNode(nodes, pub)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to fetch node: %x, %v\", pub, err)\n\t}\n\tedge.Node = &node\n\n\treturn edge, deserializeErr\n}\n",
      "length": 604,
      "tokens": 83,
      "embedding": []
    },
    {
      "slug": "func deserializeChanEdgePolicyRaw(r io.Reader) (*ChannelEdgePolicy, error) {",
      "content": "func deserializeChanEdgePolicyRaw(r io.Reader) (*ChannelEdgePolicy, error) {\n\tedge := &ChannelEdgePolicy{}\n\n\tvar err error\n\tedge.SigBytes, err = wire.ReadVarBytes(r, 0, 80, \"sig\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := binary.Read(r, byteOrder, &edge.ChannelID); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar scratch [8]byte\n\tif _, err := r.Read(scratch[:]); err != nil {\n\t\treturn nil, err\n\t}\n\tunix := int64(byteOrder.Uint64(scratch[:]))\n\tedge.LastUpdate = time.Unix(unix, 0)\n\n\tif err := binary.Read(r, byteOrder, &edge.MessageFlags); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edge.ChannelFlags); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := binary.Read(r, byteOrder, &edge.TimeLockDelta); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar n uint64\n\tif err := binary.Read(r, byteOrder, &n); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.MinHTLC = lnwire.MilliSatoshi(n)\n\n\tif err := binary.Read(r, byteOrder, &n); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.FeeBaseMSat = lnwire.MilliSatoshi(n)\n\n\tif err := binary.Read(r, byteOrder, &n); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.FeeProportionalMillionths = lnwire.MilliSatoshi(n)\n\n\tvar pub [33]byte\n\tif _, err := r.Read(pub[:]); err != nil {\n\t\treturn nil, err\n\t}\n\tedge.Node = &LightningNode{\n\t\tPubKeyBytes: pub,\n\t}\n\n\t// We'll try and see if there are any opaque bytes left, if not, then\n\t// we'll ignore the EOF error and return the edge as is.\n\tedge.ExtraOpaqueData, err = wire.ReadVarBytes(\n\t\tr, 0, MaxAllowedExtraOpaqueBytes, \"blob\",\n\t)\n\tswitch {\n\tcase err == io.ErrUnexpectedEOF:\n\tcase err == io.EOF:\n\tcase err != nil:\n\t\treturn nil, err\n\t}\n\n\t// See if optional fields are present.\n\tif edge.MessageFlags.HasMaxHtlc() {\n\t\t// The max_htlc field should be at the beginning of the opaque\n\t\t// bytes.\n\t\topq := edge.ExtraOpaqueData\n\n\t\t// If the max_htlc field is not present, it might be old data\n\t\t// stored before this field was validated. We'll return the\n\t\t// edge along with an error.\n\t\tif len(opq) < 8 {\n\t\t\treturn edge, ErrEdgePolicyOptionalFieldNotFound\n\t\t}\n\n\t\tmaxHtlc := byteOrder.Uint64(opq[:8])\n\t\tedge.MaxHTLC = lnwire.MilliSatoshi(maxHtlc)\n\n\t\t// Exclude the parsed field from the rest of the opaque data.\n\t\tedge.ExtraOpaqueData = opq[8:]\n\t}\n\n\treturn edge, nil\n}\n",
      "length": 2069,
      "tokens": 322,
      "embedding": []
    }
  ]
}