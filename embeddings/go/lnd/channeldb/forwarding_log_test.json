{
  "filepath": "../implementations/go/lnd/channeldb/forwarding_log_test.go",
  "package": "channeldb",
  "sections": [
    {
      "slug": "func TestForwardingLogBasicStorageAndQuery(t *testing.T) {",
      "content": "func TestForwardingLogBasicStorageAndQuery(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll set up a test database, and use that to instantiate the\n\t// forwarding event log that we'll be using for the duration of the\n\t// test.\n\tdb, err := MakeTestDB(t)\n\trequire.NoError(t, err, \"unable to make test db\")\n\n\tlog := ForwardingLog{\n\t\tdb: db,\n\t}\n\n\tinitialTime := time.Unix(1234, 0)\n\ttimestamp := time.Unix(1234, 0)\n\n\t// We'll create 100 random events, which each event being spaced 10\n\t// minutes after the prior event.\n\tnumEvents := 100\n\tevents := make([]ForwardingEvent, numEvents)\n\tfor i := 0; i < numEvents; i++ {\n\t\tevents[i] = ForwardingEvent{\n\t\t\tTimestamp:      timestamp,\n\t\t\tIncomingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tOutgoingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tAmtIn:          lnwire.MilliSatoshi(rand.Int63()),\n\t\t\tAmtOut:         lnwire.MilliSatoshi(rand.Int63()),\n\t\t}\n\n\t\ttimestamp = timestamp.Add(time.Minute * 10)\n\t}\n\n\t// Now that all of our set of events constructed, we'll add them to the\n\t// database in a batch manner.\n\tif err := log.AddForwardingEvents(events); err != nil {\n\t\tt.Fatalf(\"unable to add events: %v\", err)\n\t}\n\n\t// With our events added we'll now construct a basic query to retrieve\n\t// all of the events.\n\teventQuery := ForwardingEventQuery{\n\t\tStartTime:    initialTime,\n\t\tEndTime:      timestamp,\n\t\tIndexOffset:  0,\n\t\tNumMaxEvents: 1000,\n\t}\n\ttimeSlice, err := log.Query(eventQuery)\n\trequire.NoError(t, err, \"unable to query for events\")\n\n\t// The set of returned events should match identically, as they should\n\t// be returned in sorted order.\n\tif !reflect.DeepEqual(events, timeSlice.ForwardingEvents) {\n\t\tt.Fatalf(\"event mismatch: expected %v vs %v\",\n\t\t\tspew.Sdump(events), spew.Sdump(timeSlice.ForwardingEvents))\n\t}\n\n\t// The offset index of the final entry should be numEvents, so the\n\t// number of total events we've written.\n\tif timeSlice.LastIndexOffset != uint32(numEvents) {\n\t\tt.Fatalf(\"wrong final offset: expected %v, got %v\",\n\t\t\ttimeSlice.LastIndexOffset, numEvents)\n\t}\n}\n\n// TestForwardingLogQueryOptions tests that the query offset works properly. So\n// if we add a series of events, then we should be able to seek within the\n// timeslice accordingly. This exercises the index offset and num max event\n// field in the query, and also the last index offset field int he response.",
      "length": 2244,
      "tokens": 307,
      "embedding": []
    },
    {
      "slug": "func TestForwardingLogQueryOptions(t *testing.T) {",
      "content": "func TestForwardingLogQueryOptions(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll set up a test database, and use that to instantiate the\n\t// forwarding event log that we'll be using for the duration of the\n\t// test.\n\tdb, err := MakeTestDB(t)\n\trequire.NoError(t, err, \"unable to make test db\")\n\n\tlog := ForwardingLog{\n\t\tdb: db,\n\t}\n\n\tinitialTime := time.Unix(1234, 0)\n\tendTime := time.Unix(1234, 0)\n\n\t// We'll create 20 random events, which each event being spaced 10\n\t// minutes after the prior event.\n\tnumEvents := 20\n\tevents := make([]ForwardingEvent, numEvents)\n\tfor i := 0; i < numEvents; i++ {\n\t\tevents[i] = ForwardingEvent{\n\t\t\tTimestamp:      endTime,\n\t\t\tIncomingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tOutgoingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tAmtIn:          lnwire.MilliSatoshi(rand.Int63()),\n\t\t\tAmtOut:         lnwire.MilliSatoshi(rand.Int63()),\n\t\t}\n\n\t\tendTime = endTime.Add(time.Minute * 10)\n\t}\n\n\t// Now that all of our set of events constructed, we'll add them to the\n\t// database in a batch manner.\n\tif err := log.AddForwardingEvents(events); err != nil {\n\t\tt.Fatalf(\"unable to add events: %v\", err)\n\t}\n\n\t// With all of our events added, we should be able to query for the\n\t// first 10 events using the max event query field.\n\teventQuery := ForwardingEventQuery{\n\t\tStartTime:    initialTime,\n\t\tEndTime:      endTime,\n\t\tIndexOffset:  0,\n\t\tNumMaxEvents: 10,\n\t}\n\ttimeSlice, err := log.Query(eventQuery)\n\trequire.NoError(t, err, \"unable to query for events\")\n\n\t// We should get exactly 10 events back.\n\tif len(timeSlice.ForwardingEvents) != 10 {\n\t\tt.Fatalf(\"wrong number of events: expected %v, got %v\", 10,\n\t\t\tlen(timeSlice.ForwardingEvents))\n\t}\n\n\t// The set of events returned should be the first 10 events that we\n\t// added.\n\tif !reflect.DeepEqual(events[:10], timeSlice.ForwardingEvents) {\n\t\tt.Fatalf(\"wrong response: expected %v, got %v\",\n\t\t\tspew.Sdump(events[:10]),\n\t\t\tspew.Sdump(timeSlice.ForwardingEvents))\n\t}\n\n\t// The final offset should be the exact number of events returned.\n\tif timeSlice.LastIndexOffset != 10 {\n\t\tt.Fatalf(\"wrong index offset: expected %v, got %v\", 10,\n\t\t\ttimeSlice.LastIndexOffset)\n\t}\n\n\t// If we use the final offset to query again, then we should get 10\n\t// more events, that are the last 10 events we wrote.\n\teventQuery.IndexOffset = 10\n\ttimeSlice, err = log.Query(eventQuery)\n\trequire.NoError(t, err, \"unable to query for events\")\n\n\t// We should get exactly 10 events back once again.\n\tif len(timeSlice.ForwardingEvents) != 10 {\n\t\tt.Fatalf(\"wrong number of events: expected %v, got %v\", 10,\n\t\t\tlen(timeSlice.ForwardingEvents))\n\t}\n\n\t// The events that we got back should be the last 10 events that we\n\t// wrote out.\n\tif !reflect.DeepEqual(events[10:], timeSlice.ForwardingEvents) {\n\t\tt.Fatalf(\"wrong response: expected %v, got %v\",\n\t\t\tspew.Sdump(events[10:]),\n\t\t\tspew.Sdump(timeSlice.ForwardingEvents))\n\t}\n\n\t// Finally, the last index offset should be 20, or the number of\n\t// records we've written out.\n\tif timeSlice.LastIndexOffset != 20 {\n\t\tt.Fatalf(\"wrong index offset: expected %v, got %v\", 20,\n\t\t\ttimeSlice.LastIndexOffset)\n\t}\n}\n\n// TestForwardingLogQueryLimit tests that we're able to properly limit the\n// number of events that are returned as part of a query.",
      "length": 3115,
      "tokens": 426,
      "embedding": []
    },
    {
      "slug": "func TestForwardingLogQueryLimit(t *testing.T) {",
      "content": "func TestForwardingLogQueryLimit(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll set up a test database, and use that to instantiate the\n\t// forwarding event log that we'll be using for the duration of the\n\t// test.\n\tdb, err := MakeTestDB(t)\n\trequire.NoError(t, err, \"unable to make test db\")\n\n\tlog := ForwardingLog{\n\t\tdb: db,\n\t}\n\n\tinitialTime := time.Unix(1234, 0)\n\tendTime := time.Unix(1234, 0)\n\n\t// We'll create 200 random events, which each event being spaced 10\n\t// minutes after the prior event.\n\tnumEvents := 200\n\tevents := make([]ForwardingEvent, numEvents)\n\tfor i := 0; i < numEvents; i++ {\n\t\tevents[i] = ForwardingEvent{\n\t\t\tTimestamp:      endTime,\n\t\t\tIncomingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tOutgoingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tAmtIn:          lnwire.MilliSatoshi(rand.Int63()),\n\t\t\tAmtOut:         lnwire.MilliSatoshi(rand.Int63()),\n\t\t}\n\n\t\tendTime = endTime.Add(time.Minute * 10)\n\t}\n\n\t// Now that all of our set of events constructed, we'll add them to the\n\t// database in a batch manner.\n\tif err := log.AddForwardingEvents(events); err != nil {\n\t\tt.Fatalf(\"unable to add events: %v\", err)\n\t}\n\n\t// Once the events have been written out, we'll issue a query over the\n\t// entire range, but restrict the number of events to the first 100.\n\teventQuery := ForwardingEventQuery{\n\t\tStartTime:    initialTime,\n\t\tEndTime:      endTime,\n\t\tIndexOffset:  0,\n\t\tNumMaxEvents: 100,\n\t}\n\ttimeSlice, err := log.Query(eventQuery)\n\trequire.NoError(t, err, \"unable to query for events\")\n\n\t// We should get exactly 100 events back.\n\tif len(timeSlice.ForwardingEvents) != 100 {\n\t\tt.Fatalf(\"wrong number of events: expected %v, got %v\", 10,\n\t\t\tlen(timeSlice.ForwardingEvents))\n\t}\n\n\t// The set of events returned should be the first 100 events that we\n\t// added.\n\tif !reflect.DeepEqual(events[:100], timeSlice.ForwardingEvents) {\n\t\tt.Fatalf(\"wrong response: expected %v, got %v\",\n\t\t\tspew.Sdump(events[:100]),\n\t\t\tspew.Sdump(timeSlice.ForwardingEvents))\n\t}\n\n\t// The final offset should be the exact number of events returned.\n\tif timeSlice.LastIndexOffset != 100 {\n\t\tt.Fatalf(\"wrong index offset: expected %v, got %v\", 100,\n\t\t\ttimeSlice.LastIndexOffset)\n\t}\n}\n\n// TestForwardingLogMakeUniqueTimestamps makes sure the function that creates\n// unique timestamps does it job correctly.",
      "length": 2211,
      "tokens": 291,
      "embedding": []
    },
    {
      "slug": "func TestForwardingLogMakeUniqueTimestamps(t *testing.T) {",
      "content": "func TestForwardingLogMakeUniqueTimestamps(t *testing.T) {\n\tt.Parallel()\n\n\t// Create a list of events where some of the timestamps collide. We\n\t// expect no existing timestamp to be overwritten, instead the \"gaps\"\n\t// between them should be filled.\n\tinputSlice := []ForwardingEvent{\n\t\t{Timestamp: time.Unix(0, 1001)},\n\t\t{Timestamp: time.Unix(0, 2001)},\n\t\t{Timestamp: time.Unix(0, 1001)},\n\t\t{Timestamp: time.Unix(0, 1002)},\n\t\t{Timestamp: time.Unix(0, 1004)},\n\t\t{Timestamp: time.Unix(0, 1004)},\n\t\t{Timestamp: time.Unix(0, 1007)},\n\t\t{Timestamp: time.Unix(0, 1001)},\n\t}\n\texpectedSlice := []ForwardingEvent{\n\t\t{Timestamp: time.Unix(0, 1001)},\n\t\t{Timestamp: time.Unix(0, 1002)},\n\t\t{Timestamp: time.Unix(0, 1003)},\n\t\t{Timestamp: time.Unix(0, 1004)},\n\t\t{Timestamp: time.Unix(0, 1005)},\n\t\t{Timestamp: time.Unix(0, 1006)},\n\t\t{Timestamp: time.Unix(0, 1007)},\n\t\t{Timestamp: time.Unix(0, 2001)},\n\t}\n\n\tmakeUniqueTimestamps(inputSlice)\n\n\tfor idx, in := range inputSlice {\n\t\texpect := expectedSlice[idx]\n\t\tassert.Equal(\n\t\t\tt, expect.Timestamp.UnixNano(), in.Timestamp.UnixNano(),\n\t\t)\n\t}\n}\n\n// TestForwardingLogStoreEvent makes sure forwarding events are stored without\n// colliding on duplicate timestamps.",
      "length": 1094,
      "tokens": 119,
      "embedding": []
    },
    {
      "slug": "func TestForwardingLogStoreEvent(t *testing.T) {",
      "content": "func TestForwardingLogStoreEvent(t *testing.T) {\n\tt.Parallel()\n\n\t// First, we'll set up a test database, and use that to instantiate the\n\t// forwarding event log that we'll be using for the duration of the\n\t// test.\n\tdb, err := MakeTestDB(t)\n\trequire.NoError(t, err, \"unable to make test db\")\n\n\tlog := ForwardingLog{\n\t\tdb: db,\n\t}\n\n\t// We'll create 20 random events, with each event having a timestamp\n\t// with just one nanosecond apart.\n\tnumEvents := 20\n\tevents := make([]ForwardingEvent, numEvents)\n\tts := time.Now().UnixNano()\n\tfor i := 0; i < numEvents; i++ {\n\t\tevents[i] = ForwardingEvent{\n\t\t\tTimestamp:      time.Unix(0, ts+int64(i)),\n\t\t\tIncomingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tOutgoingChanID: lnwire.NewShortChanIDFromInt(uint64(rand.Int63())),\n\t\t\tAmtIn:          lnwire.MilliSatoshi(rand.Int63()),\n\t\t\tAmtOut:         lnwire.MilliSatoshi(rand.Int63()),\n\t\t}\n\t}\n\n\t// Now that all of our events are constructed, we'll add them to the\n\t// database in a batched manner.\n\tif err := log.AddForwardingEvents(events); err != nil {\n\t\tt.Fatalf(\"unable to add events: %v\", err)\n\t}\n\n\t// Because timestamps are de-duplicated when adding them in a single\n\t// batch before they even hit the DB, we add the same events again but\n\t// in a new batch. They now have to be de-duplicated on the DB level.\n\tif err := log.AddForwardingEvents(events); err != nil {\n\t\tt.Fatalf(\"unable to add second batch of events: %v\", err)\n\t}\n\n\t// With all of our events added, we should be able to query for all\n\t// events with a range of just 40 nanoseconds (2 times 20 events, all\n\t// spaced one nanosecond apart).\n\teventQuery := ForwardingEventQuery{\n\t\tStartTime:    time.Unix(0, ts),\n\t\tEndTime:      time.Unix(0, ts+int64(numEvents*2)),\n\t\tIndexOffset:  0,\n\t\tNumMaxEvents: uint32(numEvents * 3),\n\t}\n\ttimeSlice, err := log.Query(eventQuery)\n\trequire.NoError(t, err, \"unable to query for events\")\n\n\t// We should get exactly 40 events back.\n\tif len(timeSlice.ForwardingEvents) != numEvents*2 {\n\t\tt.Fatalf(\"wrong number of events: expected %v, got %v\",\n\t\t\tnumEvents*2, len(timeSlice.ForwardingEvents))\n\t}\n\n\t// The timestamps should be spaced out evenly and in order.\n\tfor i := 0; i < numEvents*2; i++ {\n\t\teventTs := timeSlice.ForwardingEvents[i].Timestamp.UnixNano()\n\t\tif eventTs != ts+int64(i) {\n\t\t\tt.Fatalf(\"unexpected timestamp of event %d: expected \"+\n\t\t\t\t\"%d, got %d\", i, ts+int64(i), eventTs)\n\t\t}\n\t}\n}\n",
      "length": 2289,
      "tokens": 323,
      "embedding": []
    }
  ]
}