{
  "filepath": "../implementations/go/lnd/channeldb/channel.go",
  "package": "channeldb",
  "sections": [
    {
      "slug": "type indexStatus uint8",
      "content": "type indexStatus uint8\n\nconst (\n\t// outpointOpen represents an outpoint that is open in the outpoint index.\n\toutpointOpen indexStatus = 0\n\n\t// outpointClosed represents an outpoint that is closed in the outpoint\n\t// index.\n\toutpointClosed indexStatus = 1\n)\n\n// ChannelType is an enum-like type that describes one of several possible\n// channel types. Each open channel is associated with a particular type as the\n// channel type may determine how higher level operations are conducted such as\n// fee negotiation, channel closing, the format of HTLCs, etc. Structure-wise,\n// a ChannelType is a bit field, with each bit denoting a modification from the\n// base channel type of single funder.",
      "length": 652,
      "tokens": 108,
      "embedding": []
    },
    {
      "slug": "type ChannelType uint64",
      "content": "type ChannelType uint64\n\nconst (\n\t// NOTE: iota isn't used here for this enum needs to be stable\n\t// long-term as it will be persisted to the database.\n\n\t// SingleFunderBit represents a channel wherein one party solely funds\n\t// the entire capacity of the channel.\n\tSingleFunderBit ChannelType = 0\n\n\t// DualFunderBit represents a channel wherein both parties contribute\n\t// funds towards the total capacity of the channel. The channel may be\n\t// funded symmetrically or asymmetrically.\n\tDualFunderBit ChannelType = 1 << 0\n\n\t// SingleFunderTweaklessBit is similar to the basic SingleFunder channel\n\t// type, but it omits the tweak for one's key in the commitment\n\t// transaction of the remote party.\n\tSingleFunderTweaklessBit ChannelType = 1 << 1\n\n\t// NoFundingTxBit denotes if we have the funding transaction locally on\n\t// disk. This bit may be on if the funding transaction was crafted by a\n\t// wallet external to the primary daemon.\n\tNoFundingTxBit ChannelType = 1 << 2\n\n\t// AnchorOutputsBit indicates that the channel makes use of anchor\n\t// outputs to bump the commitment transaction's effective feerate. This\n\t// channel type also uses a delayed to_remote output script.\n\tAnchorOutputsBit ChannelType = 1 << 3\n\n\t// FrozenBit indicates that the channel is a frozen channel, meaning\n\t// that only the responder can decide to cooperatively close the\n\t// channel.\n\tFrozenBit ChannelType = 1 << 4\n\n\t// ZeroHtlcTxFeeBit indicates that the channel should use zero-fee\n\t// second-level HTLC transactions.\n\tZeroHtlcTxFeeBit ChannelType = 1 << 5\n\n\t// LeaseExpirationBit indicates that the channel has been leased for a\n\t// period of time, constraining every output that pays to the channel\n\t// initiator with an additional CLTV of the lease maturity.\n\tLeaseExpirationBit ChannelType = 1 << 6\n\n\t// ZeroConfBit indicates that the channel is a zero-conf channel.\n\tZeroConfBit ChannelType = 1 << 7\n\n\t// ScidAliasChanBit indicates that the channel has negotiated the\n\t// scid-alias channel type.\n\tScidAliasChanBit ChannelType = 1 << 8\n\n\t// ScidAliasFeatureBit indicates that the scid-alias feature bit was\n\t// negotiated during the lifetime of this channel.\n\tScidAliasFeatureBit ChannelType = 1 << 9\n)\n\n// IsSingleFunder returns true if the channel type if one of the known single\n// funder variants.",
      "length": 2211,
      "tokens": 352,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) IsSingleFunder() bool {",
      "content": "func (c ChannelType) IsSingleFunder() bool {\n\treturn c&DualFunderBit == 0\n}\n\n// IsDualFunder returns true if the ChannelType has the DualFunderBit set.",
      "length": 103,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) IsDualFunder() bool {",
      "content": "func (c ChannelType) IsDualFunder() bool {\n\treturn c&DualFunderBit == DualFunderBit\n}\n\n// IsTweakless returns true if the target channel uses a commitment that\n// doesn't tweak the key for the remote party.",
      "length": 159,
      "tokens": 26,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) IsTweakless() bool {",
      "content": "func (c ChannelType) IsTweakless() bool {\n\treturn c&SingleFunderTweaklessBit == SingleFunderTweaklessBit\n}\n\n// HasFundingTx returns true if this channel type is one that has a funding\n// transaction stored locally.",
      "length": 168,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) HasFundingTx() bool {",
      "content": "func (c ChannelType) HasFundingTx() bool {\n\treturn c&NoFundingTxBit == 0\n}\n\n// HasAnchors returns true if this channel type has anchor outputs on its\n// commitment.",
      "length": 117,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) HasAnchors() bool {",
      "content": "func (c ChannelType) HasAnchors() bool {\n\treturn c&AnchorOutputsBit == AnchorOutputsBit\n}\n\n// ZeroHtlcTxFee returns true if this channel type uses second-level HTLC\n// transactions signed with zero-fee.",
      "length": 157,
      "tokens": 21,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) ZeroHtlcTxFee() bool {",
      "content": "func (c ChannelType) ZeroHtlcTxFee() bool {\n\treturn c&ZeroHtlcTxFeeBit == ZeroHtlcTxFeeBit\n}\n\n// IsFrozen returns true if the channel is considered to be \"frozen\". A frozen\n// channel means that only the responder can initiate a cooperative channel\n// closure.",
      "length": 211,
      "tokens": 33,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) IsFrozen() bool {",
      "content": "func (c ChannelType) IsFrozen() bool {\n\treturn c&FrozenBit == FrozenBit\n}\n\n// HasLeaseExpiration returns true if the channel originated from a lease.",
      "length": 107,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) HasLeaseExpiration() bool {",
      "content": "func (c ChannelType) HasLeaseExpiration() bool {\n\treturn c&LeaseExpirationBit == LeaseExpirationBit\n}\n\n// HasZeroConf returns true if the channel is a zero-conf channel.",
      "length": 117,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) HasZeroConf() bool {",
      "content": "func (c ChannelType) HasZeroConf() bool {\n\treturn c&ZeroConfBit == ZeroConfBit\n}\n\n// HasScidAliasChan returns true if the scid-alias channel type was negotiated.",
      "length": 116,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) HasScidAliasChan() bool {",
      "content": "func (c ChannelType) HasScidAliasChan() bool {\n\treturn c&ScidAliasChanBit == ScidAliasChanBit\n}\n\n// HasScidAliasFeature returns true if the scid-alias feature bit was\n// negotiated during the lifetime of this channel.",
      "length": 166,
      "tokens": 23,
      "embedding": []
    },
    {
      "slug": "func (c ChannelType) HasScidAliasFeature() bool {",
      "content": "func (c ChannelType) HasScidAliasFeature() bool {\n\treturn c&ScidAliasFeatureBit == ScidAliasFeatureBit\n}\n\n// ChannelConstraints represents a set of constraints meant to allow a node to\n// limit their exposure, enact flow control and ensure that all HTLCs are\n// economically relevant. This struct will be mirrored for both sides of the\n// channel, as each side will enforce various constraints that MUST be adhered\n// to for the life time of the channel. The parameters for each of these\n// constraints are static for the duration of the channel, meaning the channel\n// must be torn down for them to change.",
      "length": 548,
      "tokens": 94,
      "embedding": []
    },
    {
      "slug": "type ChannelConstraints struct {",
      "content": "type ChannelConstraints struct {\n\t// DustLimit is the threshold (in satoshis) below which any outputs\n\t// should be trimmed. When an output is trimmed, it isn't materialized\n\t// as an actual output, but is instead burned to miner's fees.\n\tDustLimit btcutil.Amount\n\n\t// ChanReserve is an absolute reservation on the channel for the\n\t// owner of this set of constraints. This means that the current\n\t// settled balance for this node CANNOT dip below the reservation\n\t// amount. This acts as a defense against costless attacks when\n\t// either side no longer has any skin in the game.\n\tChanReserve btcutil.Amount\n\n\t// MaxPendingAmount is the maximum pending HTLC value that the\n\t// owner of these constraints can offer the remote node at a\n\t// particular time.\n\tMaxPendingAmount lnwire.MilliSatoshi\n\n\t// MinHTLC is the minimum HTLC value that the owner of these\n\t// constraints can offer the remote node. If any HTLCs below this\n\t// amount are offered, then the HTLC will be rejected. This, in\n\t// tandem with the dust limit allows a node to regulate the\n\t// smallest HTLC that it deems economically relevant.\n\tMinHTLC lnwire.MilliSatoshi\n\n\t// MaxAcceptedHtlcs is the maximum number of HTLCs that the owner of\n\t// this set of constraints can offer the remote node. This allows each\n\t// node to limit their over all exposure to HTLCs that may need to be\n\t// acted upon in the case of a unilateral channel closure or a contract\n\t// breach.\n\tMaxAcceptedHtlcs uint16\n\n\t// CsvDelay is the relative time lock delay expressed in blocks. Any\n\t// settled outputs that pay to the owner of this channel configuration\n\t// MUST ensure that the delay branch uses this value as the relative\n\t// time lock. Similarly, any HTLC's offered by this node should use\n\t// this value as well.\n\tCsvDelay uint16\n}\n\n// ChannelConfig is a struct that houses the various configuration opens for\n// channels. Each side maintains an instance of this configuration file as it\n// governs: how the funding and commitment transaction to be created, the\n// nature of HTLC's allotted, the keys to be used for delivery, and relative\n// time lock parameters.",
      "length": 2039,
      "tokens": 350,
      "embedding": []
    },
    {
      "slug": "type ChannelConfig struct {",
      "content": "type ChannelConfig struct {\n\t// ChannelConstraints is the set of constraints that must be upheld for\n\t// the duration of the channel for the owner of this channel\n\t// configuration. Constraints govern a number of flow control related\n\t// parameters, also including the smallest HTLC that will be accepted\n\t// by a participant.\n\tChannelConstraints\n\n\t// MultiSigKey is the key to be used within the 2-of-2 output script\n\t// for the owner of this channel config.\n\tMultiSigKey keychain.KeyDescriptor\n\n\t// RevocationBasePoint is the base public key to be used when deriving\n\t// revocation keys for the remote node's commitment transaction. This\n\t// will be combined along with a per commitment secret to derive a\n\t// unique revocation key for each state.\n\tRevocationBasePoint keychain.KeyDescriptor\n\n\t// PaymentBasePoint is the base public key to be used when deriving\n\t// the key used within the non-delayed pay-to-self output on the\n\t// commitment transaction for a node. This will be combined with a\n\t// tweak derived from the per-commitment point to ensure unique keys\n\t// for each commitment transaction.\n\tPaymentBasePoint keychain.KeyDescriptor\n\n\t// DelayBasePoint is the base public key to be used when deriving the\n\t// key used within the delayed pay-to-self output on the commitment\n\t// transaction for a node. This will be combined with a tweak derived\n\t// from the per-commitment point to ensure unique keys for each\n\t// commitment transaction.\n\tDelayBasePoint keychain.KeyDescriptor\n\n\t// HtlcBasePoint is the base public key to be used when deriving the\n\t// local HTLC key. The derived key (combined with the tweak derived\n\t// from the per-commitment point) is used within the \"to self\" clause\n\t// within any HTLC output scripts.\n\tHtlcBasePoint keychain.KeyDescriptor\n}\n\n// ChannelCommitment is a snapshot of the commitment state at a particular\n// point in the commitment chain. With each state transition, a snapshot of the\n// current state along with all non-settled HTLCs are recorded. These snapshots\n// detail the state of the _remote_ party's commitment at a particular state\n// number.  For ourselves (the local node) we ONLY store our most recent\n// (unrevoked) state for safety purposes.",
      "length": 2133,
      "tokens": 339,
      "embedding": []
    },
    {
      "slug": "type ChannelCommitment struct {",
      "content": "type ChannelCommitment struct {\n\t// CommitHeight is the update number that this ChannelDelta represents\n\t// the total number of commitment updates to this point. This can be\n\t// viewed as sort of a \"commitment height\" as this number is\n\t// monotonically increasing.\n\tCommitHeight uint64\n\n\t// LocalLogIndex is the cumulative log index index of the local node at\n\t// this point in the commitment chain. This value will be incremented\n\t// for each _update_ added to the local update log.\n\tLocalLogIndex uint64\n\n\t// LocalHtlcIndex is the current local running HTLC index. This value\n\t// will be incremented for each outgoing HTLC the local node offers.\n\tLocalHtlcIndex uint64\n\n\t// RemoteLogIndex is the cumulative log index index of the remote node\n\t// at this point in the commitment chain. This value will be\n\t// incremented for each _update_ added to the remote update log.\n\tRemoteLogIndex uint64\n\n\t// RemoteHtlcIndex is the current remote running HTLC index. This value\n\t// will be incremented for each outgoing HTLC the remote node offers.\n\tRemoteHtlcIndex uint64\n\n\t// LocalBalance is the current available settled balance within the\n\t// channel directly spendable by us.\n\t//\n\t// NOTE: This is the balance *after* subtracting any commitment fee,\n\t// AND anchor output values.\n\tLocalBalance lnwire.MilliSatoshi\n\n\t// RemoteBalance is the current available settled balance within the\n\t// channel directly spendable by the remote node.\n\t//\n\t// NOTE: This is the balance *after* subtracting any commitment fee,\n\t// AND anchor output values.\n\tRemoteBalance lnwire.MilliSatoshi\n\n\t// CommitFee is the amount calculated to be paid in fees for the\n\t// current set of commitment transactions. The fee amount is persisted\n\t// with the channel in order to allow the fee amount to be removed and\n\t// recalculated with each channel state update, including updates that\n\t// happen after a system restart.\n\tCommitFee btcutil.Amount\n\n\t// FeePerKw is the min satoshis/kilo-weight that should be paid within\n\t// the commitment transaction for the entire duration of the channel's\n\t// lifetime. This field may be updated during normal operation of the\n\t// channel as on-chain conditions change.\n\t//\n\t// TODO(halseth): make this SatPerKWeight. Cannot be done atm because\n\t// this will cause the import cycle lnwallet<->channeldb. Fee\n\t// estimation stuff should be in its own package.\n\tFeePerKw btcutil.Amount\n\n\t// CommitTx is the latest version of the commitment state, broadcast\n\t// able by us.\n\tCommitTx *wire.MsgTx\n\n\t// CommitSig is one half of the signature required to fully complete\n\t// the script for the commitment transaction above. This is the\n\t// signature signed by the remote party for our version of the\n\t// commitment transactions.\n\tCommitSig []byte\n\n\t// Htlcs is the set of HTLC's that are pending at this particular\n\t// commitment height.\n\tHtlcs []HTLC\n\n\t// TODO(roasbeef): pending commit pointer?\n\t//  * lets just walk through\n}\n\n// ChannelStatus is a bit vector used to indicate whether an OpenChannel is in\n// the default usable state, or a state where it shouldn't be used.",
      "length": 2968,
      "tokens": 478,
      "embedding": []
    },
    {
      "slug": "type ChannelStatus uint64",
      "content": "type ChannelStatus uint64\n\nvar (\n\t// ChanStatusDefault is the normal state of an open channel.\n\tChanStatusDefault ChannelStatus\n\n\t// ChanStatusBorked indicates that the channel has entered an\n\t// irreconcilable state, triggered by a state desynchronization or\n\t// channel breach.  Channels in this state should never be added to the\n\t// htlc switch.\n\tChanStatusBorked ChannelStatus = 1\n\n\t// ChanStatusCommitBroadcasted indicates that a commitment for this\n\t// channel has been broadcasted.\n\tChanStatusCommitBroadcasted ChannelStatus = 1 << 1\n\n\t// ChanStatusLocalDataLoss indicates that we have lost channel state\n\t// for this channel, and broadcasting our latest commitment might be\n\t// considered a breach.\n\t//\n\t// TODO(halseh): actually enforce that we are not force closing such a\n\t// channel.\n\tChanStatusLocalDataLoss ChannelStatus = 1 << 2\n\n\t// ChanStatusRestored is a status flag that signals that the channel\n\t// has been restored, and doesn't have all the fields a typical channel\n\t// will have.\n\tChanStatusRestored ChannelStatus = 1 << 3\n\n\t// ChanStatusCoopBroadcasted indicates that a cooperative close for\n\t// this channel has been broadcasted. Older cooperatively closed\n\t// channels will only have this status set. Newer ones will also have\n\t// close initiator information stored using the local/remote initiator\n\t// status. This status is set in conjunction with the initiator status\n\t// so that we do not need to check multiple channel statues for\n\t// cooperative closes.\n\tChanStatusCoopBroadcasted ChannelStatus = 1 << 4\n\n\t// ChanStatusLocalCloseInitiator indicates that we initiated closing\n\t// the channel.\n\tChanStatusLocalCloseInitiator ChannelStatus = 1 << 5\n\n\t// ChanStatusRemoteCloseInitiator indicates that the remote node\n\t// initiated closing the channel.\n\tChanStatusRemoteCloseInitiator ChannelStatus = 1 << 6\n)\n\n// chanStatusStrings maps a ChannelStatus to a human friendly string that\n// describes that status.\nvar chanStatusStrings = map[ChannelStatus]string{\n\tChanStatusDefault:              \"ChanStatusDefault\",\n\tChanStatusBorked:               \"ChanStatusBorked\",\n\tChanStatusCommitBroadcasted:    \"ChanStatusCommitBroadcasted\",\n\tChanStatusLocalDataLoss:        \"ChanStatusLocalDataLoss\",\n\tChanStatusRestored:             \"ChanStatusRestored\",\n\tChanStatusCoopBroadcasted:      \"ChanStatusCoopBroadcasted\",\n\tChanStatusLocalCloseInitiator:  \"ChanStatusLocalCloseInitiator\",\n\tChanStatusRemoteCloseInitiator: \"ChanStatusRemoteCloseInitiator\",\n}\n\n// orderedChanStatusFlags is an in-order list of all that channel status flags.\nvar orderedChanStatusFlags = []ChannelStatus{\n\tChanStatusBorked,\n\tChanStatusCommitBroadcasted,\n\tChanStatusLocalDataLoss,\n\tChanStatusRestored,\n\tChanStatusCoopBroadcasted,\n\tChanStatusLocalCloseInitiator,\n\tChanStatusRemoteCloseInitiator,\n}\n\n// String returns a human-readable representation of the ChannelStatus.",
      "length": 2766,
      "tokens": 326,
      "embedding": []
    },
    {
      "slug": "func (c ChannelStatus) String() string {",
      "content": "func (c ChannelStatus) String() string {\n\t// If no flags are set, then this is the default case.\n\tif c == ChanStatusDefault {\n\t\treturn chanStatusStrings[ChanStatusDefault]\n\t}\n\n\t// Add individual bit flags.\n\tstatusStr := \"\"\n\tfor _, flag := range orderedChanStatusFlags {\n\t\tif c&flag == flag {\n\t\t\tstatusStr += chanStatusStrings[flag] + \"|\"\n\t\t\tc -= flag\n\t\t}\n\t}\n\n\t// Remove anything to the right of the final bar, including it as well.\n\tstatusStr = strings.TrimRight(statusStr, \"|\")\n\n\t// Add any remaining flags which aren't accounted for as hex.\n\tif c != 0 {\n\t\tstatusStr += \"|0x\" + strconv.FormatUint(uint64(c), 16)\n\t}\n\n\t// If this was purely an unknown flag, then remove the extra bar at the\n\t// start of the string.\n\tstatusStr = strings.TrimLeft(statusStr, \"|\")\n\n\treturn statusStr\n}\n\n// FinalHtlcByte defines a byte type that encodes information about the final\n// htlc resolution.",
      "length": 809,
      "tokens": 133,
      "embedding": []
    },
    {
      "slug": "type FinalHtlcByte byte",
      "content": "type FinalHtlcByte byte\n\nconst (\n\t// FinalHtlcSettledBit is the bit that encodes whether the htlc was\n\t// settled or failed.\n\tFinalHtlcSettledBit FinalHtlcByte = 1 << 0\n\n\t// FinalHtlcOffchainBit is the bit that encodes whether the htlc was\n\t// resolved offchain or onchain.\n\tFinalHtlcOffchainBit FinalHtlcByte = 1 << 1\n)\n\n// OpenChannel encapsulates the persistent and dynamic state of an open channel\n// with a remote node. An open channel supports several options for on-disk\n// serialization depending on the exact context. Full (upon channel creation)\n// state commitments, and partial (due to a commitment update) writes are\n// supported. Each partial write due to a state update appends the new update\n// to an on-disk log, which can then subsequently be queried in order to\n// \"time-travel\" to a prior state.",
      "length": 774,
      "tokens": 128,
      "embedding": []
    },
    {
      "slug": "type OpenChannel struct {",
      "content": "type OpenChannel struct {\n\t// ChanType denotes which type of channel this is.\n\tChanType ChannelType\n\n\t// ChainHash is a hash which represents the blockchain that this\n\t// channel will be opened within. This value is typically the genesis\n\t// hash. In the case that the original chain went through a contentious\n\t// hard-fork, then this value will be tweaked using the unique fork\n\t// point on each branch.\n\tChainHash chainhash.Hash\n\n\t// FundingOutpoint is the outpoint of the final funding transaction.\n\t// This value uniquely and globally identifies the channel within the\n\t// target blockchain as specified by the chain hash parameter.\n\tFundingOutpoint wire.OutPoint\n\n\t// ShortChannelID encodes the exact location in the chain in which the\n\t// channel was initially confirmed. This includes: the block height,\n\t// transaction index, and the output within the target transaction.\n\t//\n\t// If IsZeroConf(), then this will the \"base\" (very first) ALIAS scid\n\t// and the confirmed SCID will be stored in ConfirmedScid.\n\tShortChannelID lnwire.ShortChannelID\n\n\t// IsPending indicates whether a channel's funding transaction has been\n\t// confirmed.\n\tIsPending bool\n\n\t// IsInitiator is a bool which indicates if we were the original\n\t// initiator for the channel. This value may affect how higher levels\n\t// negotiate fees, or close the channel.\n\tIsInitiator bool\n\n\t// chanStatus is the current status of this channel. If it is not in\n\t// the state Default, it should not be used for forwarding payments.\n\tchanStatus ChannelStatus\n\n\t// FundingBroadcastHeight is the height in which the funding\n\t// transaction was broadcast. This value can be used by higher level\n\t// sub-systems to determine if a channel is stale and/or should have\n\t// been confirmed before a certain height.\n\tFundingBroadcastHeight uint32\n\n\t// NumConfsRequired is the number of confirmations a channel's funding\n\t// transaction must have received in order to be considered available\n\t// for normal transactional use.\n\tNumConfsRequired uint16\n\n\t// ChannelFlags holds the flags that were sent as part of the\n\t// open_channel message.\n\tChannelFlags lnwire.FundingFlag\n\n\t// IdentityPub is the identity public key of the remote node this\n\t// channel has been established with.\n\tIdentityPub *btcec.PublicKey\n\n\t// Capacity is the total capacity of this channel.\n\tCapacity btcutil.Amount\n\n\t// TotalMSatSent is the total number of milli-satoshis we've sent\n\t// within this channel.\n\tTotalMSatSent lnwire.MilliSatoshi\n\n\t// TotalMSatReceived is the total number of milli-satoshis we've\n\t// received within this channel.\n\tTotalMSatReceived lnwire.MilliSatoshi\n\n\t// InitialLocalBalance is the balance we have during the channel\n\t// opening. When we are not the initiator, this value represents the\n\t// push amount.\n\tInitialLocalBalance lnwire.MilliSatoshi\n\n\t// InitialRemoteBalance is the balance they have during the channel\n\t// opening.\n\tInitialRemoteBalance lnwire.MilliSatoshi\n\n\t// LocalChanCfg is the channel configuration for the local node.\n\tLocalChanCfg ChannelConfig\n\n\t// RemoteChanCfg is the channel configuration for the remote node.\n\tRemoteChanCfg ChannelConfig\n\n\t// LocalCommitment is the current local commitment state for the local\n\t// party. This is stored distinct from the state of the remote party\n\t// as there are certain asymmetric parameters which affect the\n\t// structure of each commitment.\n\tLocalCommitment ChannelCommitment\n\n\t// RemoteCommitment is the current remote commitment state for the\n\t// remote party. This is stored distinct from the state of the local\n\t// party as there are certain asymmetric parameters which affect the\n\t// structure of each commitment.\n\tRemoteCommitment ChannelCommitment\n\n\t// RemoteCurrentRevocation is the current revocation for their\n\t// commitment transaction. However, since this the derived public key,\n\t// we don't yet have the private key so we aren't yet able to verify\n\t// that it's actually in the hash chain.\n\tRemoteCurrentRevocation *btcec.PublicKey\n\n\t// RemoteNextRevocation is the revocation key to be used for the *next*\n\t// commitment transaction we create for the local node. Within the\n\t// specification, this value is referred to as the\n\t// per-commitment-point.\n\tRemoteNextRevocation *btcec.PublicKey\n\n\t// RevocationProducer is used to generate the revocation in such a way\n\t// that remote side might store it efficiently and have the ability to\n\t// restore the revocation by index if needed. Current implementation of\n\t// secret producer is shachain producer.\n\tRevocationProducer shachain.Producer\n\n\t// RevocationStore is used to efficiently store the revocations for\n\t// previous channels states sent to us by remote side. Current\n\t// implementation of secret store is shachain store.\n\tRevocationStore shachain.Store\n\n\t// Packager is used to create and update forwarding packages for this\n\t// channel, which encodes all necessary information to recover from\n\t// failures and reforward HTLCs that were not fully processed.\n\tPackager FwdPackager\n\n\t// FundingTxn is the transaction containing this channel's funding\n\t// outpoint. Upon restarts, this txn will be rebroadcast if the channel\n\t// is found to be pending.\n\t//\n\t// NOTE: This value will only be populated for single-funder channels\n\t// for which we are the initiator, and that we also have the funding\n\t// transaction for. One can check this by using the HasFundingTx()\n\t// method on the ChanType field.\n\tFundingTxn *wire.MsgTx\n\n\t// LocalShutdownScript is set to a pre-set script if the channel was opened\n\t// by the local node with option_upfront_shutdown_script set. If the option\n\t// was not set, the field is empty.\n\tLocalShutdownScript lnwire.DeliveryAddress\n\n\t// RemoteShutdownScript is set to a pre-set script if the channel was opened\n\t// by the remote node with option_upfront_shutdown_script set. If the option\n\t// was not set, the field is empty.\n\tRemoteShutdownScript lnwire.DeliveryAddress\n\n\t// ThawHeight is the height when a frozen channel once again becomes a\n\t// normal channel. If this is zero, then there're no restrictions on\n\t// this channel. If the value is lower than 500,000, then it's\n\t// interpreted as a relative height, or an absolute height otherwise.\n\tThawHeight uint32\n\n\t// LastWasRevoke is a boolean that determines if the last update we sent\n\t// was a revocation (true) or a commitment signature (false).\n\tLastWasRevoke bool\n\n\t// RevocationKeyLocator stores the KeyLocator information that we will\n\t// need to derive the shachain root for this channel. This allows us to\n\t// have private key isolation from lnd.\n\tRevocationKeyLocator keychain.KeyLocator\n\n\t// confirmedScid is the confirmed ShortChannelID for a zero-conf\n\t// channel. If the channel is unconfirmed, then this will be the\n\t// default ShortChannelID. This is only set for zero-conf channels.\n\tconfirmedScid lnwire.ShortChannelID\n\n\t// TODO(roasbeef): eww\n\tDb *ChannelStateDB\n\n\t// TODO(roasbeef): just need to store local and remote HTLC's?\n\n\tsync.RWMutex\n}\n\n// ShortChanID returns the current ShortChannelID of this channel.",
      "length": 6812,
      "tokens": 1022,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ShortChanID() lnwire.ShortChannelID {",
      "content": "func (c *OpenChannel) ShortChanID() lnwire.ShortChannelID {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.ShortChannelID\n}\n\n// ZeroConfRealScid returns the zero-conf channel's confirmed scid. This should\n// only be called if IsZeroConf returns true.",
      "length": 177,
      "tokens": 24,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ZeroConfRealScid() lnwire.ShortChannelID {",
      "content": "func (c *OpenChannel) ZeroConfRealScid() lnwire.ShortChannelID {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.confirmedScid\n}\n\n// ZeroConfConfirmed returns whether the zero-conf channel has confirmed. This\n// should only be called if IsZeroConf returns true.",
      "length": 182,
      "tokens": 25,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ZeroConfConfirmed() bool {",
      "content": "func (c *OpenChannel) ZeroConfConfirmed() bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.confirmedScid != hop.Source\n}\n\n// IsZeroConf returns whether the option_zeroconf channel type was negotiated.",
      "length": 144,
      "tokens": 18,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) IsZeroConf() bool {",
      "content": "func (c *OpenChannel) IsZeroConf() bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.ChanType.HasZeroConf()\n}\n\n// IsOptionScidAlias returns whether the option_scid_alias channel type was\n// negotiated.",
      "length": 150,
      "tokens": 17,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) IsOptionScidAlias() bool {",
      "content": "func (c *OpenChannel) IsOptionScidAlias() bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.ChanType.HasScidAliasChan()\n}\n\n// NegotiatedAliasFeature returns whether the option-scid-alias feature bit was\n// negotiated.",
      "length": 159,
      "tokens": 17,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) NegotiatedAliasFeature() bool {",
      "content": "func (c *OpenChannel) NegotiatedAliasFeature() bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.ChanType.HasScidAliasFeature()\n}\n\n// ChanStatus returns the current ChannelStatus of this channel.",
      "length": 133,
      "tokens": 15,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ChanStatus() ChannelStatus {",
      "content": "func (c *OpenChannel) ChanStatus() ChannelStatus {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.chanStatus\n}\n\n// ApplyChanStatus allows the caller to modify the internal channel state in a\n// thead-safe manner.",
      "length": 148,
      "tokens": 22,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ApplyChanStatus(status ChannelStatus) error {",
      "content": "func (c *OpenChannel) ApplyChanStatus(status ChannelStatus) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn c.putChanStatus(status)\n}\n\n// ClearChanStatus allows the caller to clear a particular channel status from\n// the primary channel status bit field. After this method returns, a call to\n// HasChanStatus(status) should return false.",
      "length": 258,
      "tokens": 37,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ClearChanStatus(status ChannelStatus) error {",
      "content": "func (c *OpenChannel) ClearChanStatus(status ChannelStatus) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn c.clearChanStatus(status)\n}\n\n// HasChanStatus returns true if the internal bitfield channel status of the\n// target channel has the specified status bit set.",
      "length": 187,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) HasChanStatus(status ChannelStatus) bool {",
      "content": "func (c *OpenChannel) HasChanStatus(status ChannelStatus) bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.hasChanStatus(status)\n}\n",
      "length": 60,
      "tokens": 6,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) hasChanStatus(status ChannelStatus) bool {",
      "content": "func (c *OpenChannel) hasChanStatus(status ChannelStatus) bool {\n\t// Special case ChanStatusDefualt since it isn't actually flag, but a\n\t// particular combination (or lack-there-of) of flags.\n\tif status == ChanStatusDefault {\n\t\treturn c.chanStatus == ChanStatusDefault\n\t}\n\n\treturn c.chanStatus&status == status\n}\n\n// BroadcastHeight returns the height at which the funding tx was broadcast.",
      "length": 316,
      "tokens": 45,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) BroadcastHeight() uint32 {",
      "content": "func (c *OpenChannel) BroadcastHeight() uint32 {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\treturn c.FundingBroadcastHeight\n}\n\n// SetBroadcastHeight sets the FundingBroadcastHeight.",
      "length": 115,
      "tokens": 11,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) SetBroadcastHeight(height uint32) {",
      "content": "func (c *OpenChannel) SetBroadcastHeight(height uint32) {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tc.FundingBroadcastHeight = height\n}\n\n// Refresh updates the in-memory channel state using the latest state observed\n// on disk.",
      "length": 150,
      "tokens": 22,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) Refresh() error {",
      "content": "func (c *OpenChannel) Refresh() error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// We'll re-populating the in-memory channel with the info\n\t\t// fetched from disk.\n\t\tif err := fetchChanInfo(chanBucket, c); err != nil {\n\t\t\treturn fmt.Errorf(\"unable to fetch chan info: %v\", err)\n\t\t}\n\n\t\t// Also populate the channel's commitment states for both sides\n\t\t// of the channel.\n\t\tif err := fetchChanCommitments(chanBucket, c); err != nil {\n\t\t\treturn fmt.Errorf(\"unable to fetch chan commitments: \"+\n\t\t\t\t\"%v\", err)\n\t\t}\n\n\t\t// Also retrieve the current revocation state.\n\t\tif err := fetchChanRevocationState(chanBucket, c); err != nil {\n\t\t\treturn fmt.Errorf(\"unable to fetch chan revocations: \"+\n\t\t\t\t\"%v\", err)\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// fetchChanBucket is a helper function that returns the bucket where a\n// channel's data resides in given: the public key for the node, the outpoint,\n// and the chainhash that the channel resides on.",
      "length": 1083,
      "tokens": 168,
      "embedding": []
    },
    {
      "slug": "func fetchChanBucket(tx kvdb.RTx, nodeKey *btcec.PublicKey,",
      "content": "func fetchChanBucket(tx kvdb.RTx, nodeKey *btcec.PublicKey,\n\toutPoint *wire.OutPoint, chainHash chainhash.Hash) (kvdb.RBucket, error) {\n\n\t// First fetch the top level bucket which stores all data related to\n\t// current, active channels.\n\topenChanBucket := tx.ReadBucket(openChannelBucket)\n\tif openChanBucket == nil {\n\t\treturn nil, ErrNoChanDBExists\n\t}\n\n\t// TODO(roasbeef): CreateTopLevelBucket on the interface isn't like\n\t// CreateIfNotExists, will return error\n\n\t// Within this top level bucket, fetch the bucket dedicated to storing\n\t// open channel data specific to the remote node.\n\tnodePub := nodeKey.SerializeCompressed()\n\tnodeChanBucket := openChanBucket.NestedReadBucket(nodePub)\n\tif nodeChanBucket == nil {\n\t\treturn nil, ErrNoActiveChannels\n\t}\n\n\t// We'll then recurse down an additional layer in order to fetch the\n\t// bucket for this particular chain.\n\tchainBucket := nodeChanBucket.NestedReadBucket(chainHash[:])\n\tif chainBucket == nil {\n\t\treturn nil, ErrNoActiveChannels\n\t}\n\n\t// With the bucket for the node and chain fetched, we can now go down\n\t// another level, for this channel itself.\n\tvar chanPointBuf bytes.Buffer\n\tif err := writeOutpoint(&chanPointBuf, outPoint); err != nil {\n\t\treturn nil, err\n\t}\n\tchanBucket := chainBucket.NestedReadBucket(chanPointBuf.Bytes())\n\tif chanBucket == nil {\n\t\treturn nil, ErrChannelNotFound\n\t}\n\n\treturn chanBucket, nil\n}\n\n// fetchChanBucketRw is a helper function that returns the bucket where a\n// channel's data resides in given: the public key for the node, the outpoint,\n// and the chainhash that the channel resides on. This differs from\n// fetchChanBucket in that it returns a writeable bucket.",
      "length": 1547,
      "tokens": 217,
      "embedding": []
    },
    {
      "slug": "func fetchChanBucketRw(tx kvdb.RwTx, nodeKey *btcec.PublicKey,",
      "content": "func fetchChanBucketRw(tx kvdb.RwTx, nodeKey *btcec.PublicKey,\n\toutPoint *wire.OutPoint, chainHash chainhash.Hash) (kvdb.RwBucket,\n\terror) {\n\n\t// First fetch the top level bucket which stores all data related to\n\t// current, active channels.\n\topenChanBucket := tx.ReadWriteBucket(openChannelBucket)\n\tif openChanBucket == nil {\n\t\treturn nil, ErrNoChanDBExists\n\t}\n\n\t// TODO(roasbeef): CreateTopLevelBucket on the interface isn't like\n\t// CreateIfNotExists, will return error\n\n\t// Within this top level bucket, fetch the bucket dedicated to storing\n\t// open channel data specific to the remote node.\n\tnodePub := nodeKey.SerializeCompressed()\n\tnodeChanBucket := openChanBucket.NestedReadWriteBucket(nodePub)\n\tif nodeChanBucket == nil {\n\t\treturn nil, ErrNoActiveChannels\n\t}\n\n\t// We'll then recurse down an additional layer in order to fetch the\n\t// bucket for this particular chain.\n\tchainBucket := nodeChanBucket.NestedReadWriteBucket(chainHash[:])\n\tif chainBucket == nil {\n\t\treturn nil, ErrNoActiveChannels\n\t}\n\n\t// With the bucket for the node and chain fetched, we can now go down\n\t// another level, for this channel itself.\n\tvar chanPointBuf bytes.Buffer\n\tif err := writeOutpoint(&chanPointBuf, outPoint); err != nil {\n\t\treturn nil, err\n\t}\n\tchanBucket := chainBucket.NestedReadWriteBucket(chanPointBuf.Bytes())\n\tif chanBucket == nil {\n\t\treturn nil, ErrChannelNotFound\n\t}\n\n\treturn chanBucket, nil\n}\n",
      "length": 1293,
      "tokens": 170,
      "embedding": []
    },
    {
      "slug": "func fetchFinalHtlcsBucketRw(tx kvdb.RwTx,",
      "content": "func fetchFinalHtlcsBucketRw(tx kvdb.RwTx,\n\tchanID lnwire.ShortChannelID) (kvdb.RwBucket, error) {\n\n\tfinalHtlcsBucket, err := tx.CreateTopLevelBucket(finalHtlcsBucket)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar chanIDBytes [8]byte\n\tbyteOrder.PutUint64(chanIDBytes[:], chanID.ToUint64())\n\tchanBucket, err := finalHtlcsBucket.CreateBucketIfNotExists(\n\t\tchanIDBytes[:],\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn chanBucket, nil\n}\n\n// fullSync syncs the contents of an OpenChannel while re-using an existing\n// database transaction.",
      "length": 474,
      "tokens": 57,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) fullSync(tx kvdb.RwTx) error {",
      "content": "func (c *OpenChannel) fullSync(tx kvdb.RwTx) error {\n\t// Fetch the outpoint bucket and check if the outpoint already exists.\n\topBucket := tx.ReadWriteBucket(outpointBucket)\n\tcidBucket := tx.ReadWriteBucket(chanIDBucket)\n\n\tvar chanPointBuf bytes.Buffer\n\tif err := writeOutpoint(&chanPointBuf, &c.FundingOutpoint); err != nil {\n\t\treturn err\n\t}\n\n\t// Now, check if the outpoint exists in our index.\n\tif opBucket.Get(chanPointBuf.Bytes()) != nil {\n\t\treturn ErrChanAlreadyExists\n\t}\n\n\tcid := lnwire.NewChanIDFromOutPoint(&c.FundingOutpoint)\n\tif cidBucket.Get(cid[:]) != nil {\n\t\treturn ErrChanAlreadyExists\n\t}\n\n\tstatus := uint8(outpointOpen)\n\n\t// Write the status of this outpoint as the first entry in a tlv\n\t// stream.\n\tstatusRecord := tlv.MakePrimitiveRecord(indexStatusType, &status)\n\topStream, err := tlv.NewStream(statusRecord)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar b bytes.Buffer\n\tif err := opStream.Encode(&b); err != nil {\n\t\treturn err\n\t}\n\n\t// Add the outpoint to our outpoint index with the tlv stream.\n\tif err := opBucket.Put(chanPointBuf.Bytes(), b.Bytes()); err != nil {\n\t\treturn err\n\t}\n\n\tif err := cidBucket.Put(cid[:], []byte{}); err != nil {\n\t\treturn err\n\t}\n\n\t// First fetch the top level bucket which stores all data related to\n\t// current, active channels.\n\topenChanBucket, err := tx.CreateTopLevelBucket(openChannelBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Within this top level bucket, fetch the bucket dedicated to storing\n\t// open channel data specific to the remote node.\n\tnodePub := c.IdentityPub.SerializeCompressed()\n\tnodeChanBucket, err := openChanBucket.CreateBucketIfNotExists(nodePub)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// We'll then recurse down an additional layer in order to fetch the\n\t// bucket for this particular chain.\n\tchainBucket, err := nodeChanBucket.CreateBucketIfNotExists(c.ChainHash[:])\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// With the bucket for the node fetched, we can now go down another\n\t// level, creating the bucket for this channel itself.\n\tchanBucket, err := chainBucket.CreateBucket(\n\t\tchanPointBuf.Bytes(),\n\t)\n\tswitch {\n\tcase err == kvdb.ErrBucketExists:\n\t\t// If this channel already exists, then in order to avoid\n\t\t// overriding it, we'll return an error back up to the caller.\n\t\treturn ErrChanAlreadyExists\n\tcase err != nil:\n\t\treturn err\n\t}\n\n\treturn putOpenChannel(chanBucket, c)\n}\n\n// MarkAsOpen marks a channel as fully open given a locator that uniquely\n// describes its location within the chain.",
      "length": 2319,
      "tokens": 334,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkAsOpen(openLoc lnwire.ShortChannelID) error {",
      "content": "func (c *OpenChannel) MarkAsOpen(openLoc lnwire.ShortChannelID) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tif err := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel, err := fetchOpenChannel(chanBucket, &c.FundingOutpoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel.IsPending = false\n\t\tchannel.ShortChannelID = openLoc\n\n\t\treturn putOpenChannel(chanBucket, channel)\n\t}, func() {}); err != nil {\n\t\treturn err\n\t}\n\n\tc.IsPending = false\n\tc.ShortChannelID = openLoc\n\tc.Packager = NewChannelPackager(openLoc)\n\n\treturn nil\n}\n\n// MarkRealScid marks the zero-conf channel's confirmed ShortChannelID. This\n// should only be done if IsZeroConf returns true.",
      "length": 690,
      "tokens": 90,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkRealScid(realScid lnwire.ShortChannelID) error {",
      "content": "func (c *OpenChannel) MarkRealScid(realScid lnwire.ShortChannelID) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tif err := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel, err := fetchOpenChannel(\n\t\t\tchanBucket, &c.FundingOutpoint,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel.confirmedScid = realScid\n\n\t\treturn putOpenChannel(chanBucket, channel)\n\t}, func() {}); err != nil {\n\t\treturn err\n\t}\n\n\tc.confirmedScid = realScid\n\n\treturn nil\n}\n\n// MarkScidAliasNegotiated adds ScidAliasFeatureBit to ChanType in-memory and\n// in the database.",
      "length": 578,
      "tokens": 77,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkScidAliasNegotiated() error {",
      "content": "func (c *OpenChannel) MarkScidAliasNegotiated() error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tif err := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel, err := fetchOpenChannel(\n\t\t\tchanBucket, &c.FundingOutpoint,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel.ChanType |= ScidAliasFeatureBit\n\t\treturn putOpenChannel(chanBucket, channel)\n\t}, func() {}); err != nil {\n\t\treturn err\n\t}\n\n\tc.ChanType |= ScidAliasFeatureBit\n\n\treturn nil\n}\n\n// MarkDataLoss marks sets the channel status to LocalDataLoss and stores the\n// passed commitPoint for use to retrieve funds in case the remote force closes\n// the channel.",
      "length": 667,
      "tokens": 94,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkDataLoss(commitPoint *btcec.PublicKey) error {",
      "content": "func (c *OpenChannel) MarkDataLoss(commitPoint *btcec.PublicKey) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tvar b bytes.Buffer\n\tif err := WriteElement(&b, commitPoint); err != nil {\n\t\treturn err\n\t}\n\n\tputCommitPoint := func(chanBucket kvdb.RwBucket) error {\n\t\treturn chanBucket.Put(dataLossCommitPointKey, b.Bytes())\n\t}\n\n\treturn c.putChanStatus(ChanStatusLocalDataLoss, putCommitPoint)\n}\n\n// DataLossCommitPoint retrieves the stored commit point set during\n// MarkDataLoss. If not found ErrNoCommitPoint is returned.",
      "length": 421,
      "tokens": 49,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) DataLossCommitPoint() (*btcec.PublicKey, error) {",
      "content": "func (c *OpenChannel) DataLossCommitPoint() (*btcec.PublicKey, error) {\n\tvar commitPoint *btcec.PublicKey\n\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tswitch err {\n\t\tcase nil:\n\t\tcase ErrNoChanDBExists, ErrNoActiveChannels, ErrChannelNotFound:\n\t\t\treturn ErrNoCommitPoint\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\n\t\tbs := chanBucket.Get(dataLossCommitPointKey)\n\t\tif bs == nil {\n\t\t\treturn ErrNoCommitPoint\n\t\t}\n\t\tr := bytes.NewReader(bs)\n\t\tif err := ReadElements(r, &commitPoint); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tcommitPoint = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn commitPoint, nil\n}\n\n// MarkBorked marks the event when the channel as reached an irreconcilable\n// state, such as a channel breach or state desynchronization. Borked channels\n// should never be added to the switch.",
      "length": 813,
      "tokens": 114,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkBorked() error {",
      "content": "func (c *OpenChannel) MarkBorked() error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn c.putChanStatus(ChanStatusBorked)\n}\n\n// SecondCommitmentPoint returns the second per-commitment-point for use in the\n// funding_locked message.",
      "length": 173,
      "tokens": 19,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) SecondCommitmentPoint() (*btcec.PublicKey, error) {",
      "content": "func (c *OpenChannel) SecondCommitmentPoint() (*btcec.PublicKey, error) {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\t// Since we start at commitment height = 0, the second per commitment\n\t// point is actually at the 1st index.\n\trevocation, err := c.RevocationProducer.AtIndex(1)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn input.ComputeCommitmentPoint(revocation[:]), nil\n}\n\n// ChanSyncMsg returns the ChannelReestablish message that should be sent upon\n// reconnection with the remote peer that we're maintaining this channel with.\n// The information contained within this message is necessary to re-sync our\n// commitment chains in the case of a last or only partially processed message.\n// When the remote party receives this message one of three things may happen:\n//\n//  1. We're fully synced and no messages need to be sent.\n//  2. We didn't get the last CommitSig message they sent, so they'll re-send\n//     it.\n//  3. We didn't get the last RevokeAndAck message they sent, so they'll\n//     re-send it.\n//\n// If this is a restored channel, having status ChanStatusRestored, then we'll\n// modify our typical chan sync message to ensure they force close even if\n// we're on the very first state.",
      "length": 1093,
      "tokens": 183,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ChanSyncMsg() (*lnwire.ChannelReestablish, error) {",
      "content": "func (c *OpenChannel) ChanSyncMsg() (*lnwire.ChannelReestablish, error) {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// The remote commitment height that we'll send in the\n\t// ChannelReestablish message is our current commitment height plus\n\t// one. If the receiver thinks that our commitment height is actually\n\t// *equal* to this value, then they'll re-send the last commitment that\n\t// they sent but we never fully processed.\n\tlocalHeight := c.LocalCommitment.CommitHeight\n\tnextLocalCommitHeight := localHeight + 1\n\n\t// The second value we'll send is the height of the remote commitment\n\t// from our PoV. If the receiver thinks that their height is actually\n\t// *one plus* this value, then they'll re-send their last revocation.\n\tremoteChainTipHeight := c.RemoteCommitment.CommitHeight\n\n\t// If this channel has undergone a commitment update, then in order to\n\t// prove to the remote party our knowledge of their prior commitment\n\t// state, we'll also send over the last commitment secret that the\n\t// remote party sent.\n\tvar lastCommitSecret [32]byte\n\tif remoteChainTipHeight != 0 {\n\t\tremoteSecret, err := c.RevocationStore.LookUp(\n\t\t\tremoteChainTipHeight - 1,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlastCommitSecret = [32]byte(*remoteSecret)\n\t}\n\n\t// Additionally, we'll send over the current unrevoked commitment on\n\t// our local commitment transaction.\n\tcurrentCommitSecret, err := c.RevocationProducer.AtIndex(\n\t\tlocalHeight,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If we've restored this channel, then we'll purposefully give them an\n\t// invalid LocalUnrevokedCommitPoint so they'll force close the channel\n\t// allowing us to sweep our funds.\n\tif c.hasChanStatus(ChanStatusRestored) {\n\t\tcurrentCommitSecret[0] ^= 1\n\n\t\t// If this is a tweakless channel, then we'll purposefully send\n\t\t// a next local height taht's invalid to trigger a force close\n\t\t// on their end. We do this as tweakless channels don't require\n\t\t// that the commitment point is valid, only that it's present.\n\t\tif c.ChanType.IsTweakless() {\n\t\t\tnextLocalCommitHeight = 0\n\t\t}\n\t}\n\n\treturn &lnwire.ChannelReestablish{\n\t\tChanID: lnwire.NewChanIDFromOutPoint(\n\t\t\t&c.FundingOutpoint,\n\t\t),\n\t\tNextLocalCommitHeight:  nextLocalCommitHeight,\n\t\tRemoteCommitTailHeight: remoteChainTipHeight,\n\t\tLastRemoteCommitSecret: lastCommitSecret,\n\t\tLocalUnrevokedCommitPoint: input.ComputeCommitmentPoint(\n\t\t\tcurrentCommitSecret[:],\n\t\t),\n\t}, nil\n}\n\n// isBorked returns true if the channel has been marked as borked in the\n// database. This requires an existing database transaction to already be\n// active.\n//\n// NOTE: The primary mutex should already be held before this method is called.",
      "length": 2496,
      "tokens": 351,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) isBorked(chanBucket kvdb.RBucket) (bool, error) {",
      "content": "func (c *OpenChannel) isBorked(chanBucket kvdb.RBucket) (bool, error) {\n\tchannel, err := fetchOpenChannel(chanBucket, &c.FundingOutpoint)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn channel.chanStatus != ChanStatusDefault, nil\n}\n\n// MarkCommitmentBroadcasted marks the channel as a commitment transaction has\n// been broadcast, either our own or the remote, and we should watch the chain\n// for it to confirm before taking any further action. It takes as argument the\n// closing tx _we believe_ will appear in the chain. This is only used to\n// republish this tx at startup to ensure propagation, and we should still\n// handle the case where a different tx actually hits the chain.",
      "length": 601,
      "tokens": 100,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkCommitmentBroadcasted(closeTx *wire.MsgTx,",
      "content": "func (c *OpenChannel) MarkCommitmentBroadcasted(closeTx *wire.MsgTx,\n\tlocallyInitiated bool) error {\n\n\treturn c.markBroadcasted(\n\t\tChanStatusCommitBroadcasted, forceCloseTxKey, closeTx,\n\t\tlocallyInitiated,\n\t)\n}\n\n// MarkCoopBroadcasted marks the channel to indicate that a cooperative close\n// transaction has been broadcast, either our own or the remote, and that we\n// should watch the chain for it to confirm before taking further action. It\n// takes as argument a cooperative close tx that could appear on chain, and\n// should be rebroadcast upon startup. This is only used to republish and\n// ensure propagation, and we should still handle the case where a different tx\n// actually hits the chain.",
      "length": 618,
      "tokens": 97,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) MarkCoopBroadcasted(closeTx *wire.MsgTx,",
      "content": "func (c *OpenChannel) MarkCoopBroadcasted(closeTx *wire.MsgTx,\n\tlocallyInitiated bool) error {\n\n\treturn c.markBroadcasted(\n\t\tChanStatusCoopBroadcasted, coopCloseTxKey, closeTx,\n\t\tlocallyInitiated,\n\t)\n}\n\n// markBroadcasted is a helper function which modifies the channel status of the\n// receiving channel and inserts a close transaction under the requested key,\n// which should specify either a coop or force close. It adds a status which\n// indicates the party that initiated the channel close.",
      "length": 421,
      "tokens": 61,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) markBroadcasted(status ChannelStatus, key []byte,",
      "content": "func (c *OpenChannel) markBroadcasted(status ChannelStatus, key []byte,\n\tcloseTx *wire.MsgTx, locallyInitiated bool) error {\n\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// If a closing tx is provided, we'll generate a closure to write the\n\t// transaction in the appropriate bucket under the given key.\n\tvar putClosingTx func(kvdb.RwBucket) error\n\tif closeTx != nil {\n\t\tvar b bytes.Buffer\n\t\tif err := WriteElement(&b, closeTx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tputClosingTx = func(chanBucket kvdb.RwBucket) error {\n\t\t\treturn chanBucket.Put(key, b.Bytes())\n\t\t}\n\t}\n\n\t// Add the initiator status to the status provided. These statuses are\n\t// set in addition to the broadcast status so that we do not need to\n\t// migrate the original logic which does not store initiator.\n\tif locallyInitiated {\n\t\tstatus |= ChanStatusLocalCloseInitiator\n\t} else {\n\t\tstatus |= ChanStatusRemoteCloseInitiator\n\t}\n\n\treturn c.putChanStatus(status, putClosingTx)\n}\n\n// BroadcastedCommitment retrieves the stored unilateral closing tx set during\n// MarkCommitmentBroadcasted. If not found ErrNoCloseTx is returned.",
      "length": 970,
      "tokens": 140,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) BroadcastedCommitment() (*wire.MsgTx, error) {",
      "content": "func (c *OpenChannel) BroadcastedCommitment() (*wire.MsgTx, error) {\n\treturn c.getClosingTx(forceCloseTxKey)\n}\n\n// BroadcastedCooperative retrieves the stored cooperative closing tx set during\n// MarkCoopBroadcasted. If not found ErrNoCloseTx is returned.",
      "length": 182,
      "tokens": 21,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) BroadcastedCooperative() (*wire.MsgTx, error) {",
      "content": "func (c *OpenChannel) BroadcastedCooperative() (*wire.MsgTx, error) {\n\treturn c.getClosingTx(coopCloseTxKey)\n}\n\n// getClosingTx is a helper method which returns the stored closing transaction\n// for key. The caller should use either the force or coop closing keys.",
      "length": 190,
      "tokens": 29,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) getClosingTx(key []byte) (*wire.MsgTx, error) {",
      "content": "func (c *OpenChannel) getClosingTx(key []byte) (*wire.MsgTx, error) {\n\tvar closeTx *wire.MsgTx\n\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tswitch err {\n\t\tcase nil:\n\t\tcase ErrNoChanDBExists, ErrNoActiveChannels, ErrChannelNotFound:\n\t\t\treturn ErrNoCloseTx\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\n\t\tbs := chanBucket.Get(key)\n\t\tif bs == nil {\n\t\t\treturn ErrNoCloseTx\n\t\t}\n\t\tr := bytes.NewReader(bs)\n\t\treturn ReadElement(r, &closeTx)\n\t}, func() {\n\t\tcloseTx = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn closeTx, nil\n}\n\n// putChanStatus appends the given status to the channel. fs is an optional\n// list of closures that are given the chanBucket in order to atomically add\n// extra information together with the new status.",
      "length": 728,
      "tokens": 106,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) putChanStatus(status ChannelStatus,",
      "content": "func (c *OpenChannel) putChanStatus(status ChannelStatus,\n\tfs ...func(kvdb.RwBucket) error) error {\n\n\tif err := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel, err := fetchOpenChannel(chanBucket, &c.FundingOutpoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Add this status to the existing bitvector found in the DB.\n\t\tstatus = channel.chanStatus | status\n\t\tchannel.chanStatus = status\n\n\t\tif err := putOpenChannel(chanBucket, channel); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfor _, f := range fs {\n\t\t\t// Skip execution of nil closures.\n\t\t\tif f == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err := f(chanBucket); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}, func() {}); err != nil {\n\t\treturn err\n\t}\n\n\t// Update the in-memory representation to keep it in sync with the DB.\n\tc.chanStatus = status\n\n\treturn nil\n}\n",
      "length": 852,
      "tokens": 138,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) clearChanStatus(status ChannelStatus) error {",
      "content": "func (c *OpenChannel) clearChanStatus(status ChannelStatus) error {\n\tif err := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel, err := fetchOpenChannel(chanBucket, &c.FundingOutpoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Unset this bit in the bitvector on disk.\n\t\tstatus = channel.chanStatus & ^status\n\t\tchannel.chanStatus = status\n\n\t\treturn putOpenChannel(chanBucket, channel)\n\t}, func() {}); err != nil {\n\t\treturn err\n\t}\n\n\t// Update the in-memory representation to keep it in sync with the DB.\n\tc.chanStatus = status\n\n\treturn nil\n}\n\n// putOpenChannel serializes, and stores the current state of the channel in its\n// entirety.",
      "length": 687,
      "tokens": 102,
      "embedding": []
    },
    {
      "slug": "func putOpenChannel(chanBucket kvdb.RwBucket, channel *OpenChannel) error {",
      "content": "func putOpenChannel(chanBucket kvdb.RwBucket, channel *OpenChannel) error {\n\t// First, we'll write out all the relatively static fields, that are\n\t// decided upon initial channel creation.\n\tif err := putChanInfo(chanBucket, channel); err != nil {\n\t\treturn fmt.Errorf(\"unable to store chan info: %v\", err)\n\t}\n\n\t// With the static channel info written out, we'll now write out the\n\t// current commitment state for both parties.\n\tif err := putChanCommitments(chanBucket, channel); err != nil {\n\t\treturn fmt.Errorf(\"unable to store chan commitments: %v\", err)\n\t}\n\n\t// Next, if this is a frozen channel, we'll add in the axillary\n\t// information we need to store.\n\tif channel.ChanType.IsFrozen() || channel.ChanType.HasLeaseExpiration() {\n\t\terr := storeThawHeight(\n\t\t\tchanBucket, channel.ThawHeight,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to store thaw height: %v\", err)\n\t\t}\n\t}\n\n\t// Finally, we'll write out the revocation state for both parties\n\t// within a distinct key space.\n\tif err := putChanRevocationState(chanBucket, channel); err != nil {\n\t\treturn fmt.Errorf(\"unable to store chan revocations: %v\", err)\n\t}\n\n\treturn nil\n}\n\n// fetchOpenChannel retrieves, and deserializes (including decrypting\n// sensitive) the complete channel currently active with the passed nodeID.",
      "length": 1175,
      "tokens": 175,
      "embedding": []
    },
    {
      "slug": "func fetchOpenChannel(chanBucket kvdb.RBucket,",
      "content": "func fetchOpenChannel(chanBucket kvdb.RBucket,\n\tchanPoint *wire.OutPoint) (*OpenChannel, error) {\n\n\tchannel := &OpenChannel{\n\t\tFundingOutpoint: *chanPoint,\n\t}\n\n\t// First, we'll read all the static information that changes less\n\t// frequently from disk.\n\tif err := fetchChanInfo(chanBucket, channel); err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to fetch chan info: %v\", err)\n\t}\n\n\t// With the static information read, we'll now read the current\n\t// commitment state for both sides of the channel.\n\tif err := fetchChanCommitments(chanBucket, channel); err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to fetch chan commitments: %v\", err)\n\t}\n\n\t// Next, if this is a frozen channel, we'll add in the axillary\n\t// information we need to store.\n\tif channel.ChanType.IsFrozen() || channel.ChanType.HasLeaseExpiration() {\n\t\tthawHeight, err := fetchThawHeight(chanBucket)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"unable to store thaw \"+\n\t\t\t\t\"height: %v\", err)\n\t\t}\n\n\t\tchannel.ThawHeight = thawHeight\n\t}\n\n\t// Finally, we'll retrieve the current revocation state so we can\n\t// properly\n\tif err := fetchChanRevocationState(chanBucket, channel); err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to fetch chan revocations: %v\", err)\n\t}\n\n\tchannel.Packager = NewChannelPackager(channel.ShortChannelID)\n\n\treturn channel, nil\n}\n\n// SyncPending writes the contents of the channel to the database while it's in\n// the pending (waiting for funding confirmation) state. The IsPending flag\n// will be set to true. When the channel's funding transaction is confirmed,\n// the channel should be marked as \"open\" and the IsPending flag set to false.\n// Note that this function also creates a LinkNode relationship between this\n// newly created channel and a new LinkNode instance. This allows listing all\n// channels in the database globally, or according to the LinkNode they were\n// created with.\n//\n// TODO(roasbeef): addr param should eventually be an lnwire.NetAddress type\n// that includes service bits.",
      "length": 1882,
      "tokens": 281,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) SyncPending(addr net.Addr, pendingHeight uint32) error {",
      "content": "func (c *OpenChannel) SyncPending(addr net.Addr, pendingHeight uint32) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tc.FundingBroadcastHeight = pendingHeight\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\treturn syncNewChannel(tx, c, []net.Addr{addr})\n\t}, func() {})\n}\n\n// syncNewChannel will write the passed channel to disk, and also create a\n// LinkNode (if needed) for the channel peer.",
      "length": 309,
      "tokens": 41,
      "embedding": []
    },
    {
      "slug": "func syncNewChannel(tx kvdb.RwTx, c *OpenChannel, addrs []net.Addr) error {",
      "content": "func syncNewChannel(tx kvdb.RwTx, c *OpenChannel, addrs []net.Addr) error {\n\t// First, sync all the persistent channel state to disk.\n\tif err := c.fullSync(tx); err != nil {\n\t\treturn err\n\t}\n\n\tnodeInfoBucket, err := tx.CreateTopLevelBucket(nodeInfoBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If a LinkNode for this identity public key already exists,\n\t// then we can exit early.\n\tnodePub := c.IdentityPub.SerializeCompressed()\n\tif nodeInfoBucket.Get(nodePub) != nil {\n\t\treturn nil\n\t}\n\n\t// Next, we need to establish a (possibly) new LinkNode relationship\n\t// for this channel. The LinkNode metadata contains reachability,\n\t// up-time, and service bits related information.\n\tlinkNode := NewLinkNode(\n\t\t&LinkNodeDB{backend: c.Db.backend},\n\t\twire.MainNet, c.IdentityPub, addrs...,\n\t)\n\n\t// TODO(roasbeef): do away with link node all together?\n\n\treturn putLinkNode(nodeInfoBucket, linkNode)\n}\n\n// UpdateCommitment updates the local commitment state. It locks in the pending\n// local updates that were received by us from the remote party. The commitment\n// state completely describes the balance state at this point in the commitment\n// chain. In addition to that, it persists all the remote log updates that we\n// have acked, but not signed a remote commitment for yet. These need to be\n// persisted to be able to produce a valid commit signature if a restart would\n// occur. This method its to be called when we revoke our prior commitment\n// state.\n//\n// A map is returned of all the htlc resolutions that were locked in this\n// commitment. Keys correspond to htlc indices and values indicate whether the\n// htlc was settled or failed.",
      "length": 1517,
      "tokens": 244,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) UpdateCommitment(newCommitment *ChannelCommitment,",
      "content": "func (c *OpenChannel) UpdateCommitment(newCommitment *ChannelCommitment,\n\tunsignedAckedUpdates []LogUpdate) (map[uint64]bool, error) {\n\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// If this is a restored channel, then we want to avoid mutating the\n\t// state as all, as it's impossible to do so in a protocol compliant\n\t// manner.\n\tif c.hasChanStatus(ChanStatusRestored) {\n\t\treturn nil, ErrNoRestoredChannelMutation\n\t}\n\n\tvar finalHtlcs = make(map[uint64]bool)\n\n\terr := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// If the channel is marked as borked, then for safety reasons,\n\t\t// we shouldn't attempt any further updates.\n\t\tisBorked, err := c.isBorked(chanBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif isBorked {\n\t\t\treturn ErrChanBorked\n\t\t}\n\n\t\tif err = putChanInfo(chanBucket, c); err != nil {\n\t\t\treturn fmt.Errorf(\"unable to store chan info: %v\", err)\n\t\t}\n\n\t\t// With the proper bucket fetched, we'll now write the latest\n\t\t// commitment state to disk for the target party.\n\t\terr = putChanCommitment(\n\t\t\tchanBucket, newCommitment, true,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to store chan \"+\n\t\t\t\t\"revocations: %v\", err)\n\t\t}\n\n\t\t// Persist unsigned but acked remote updates that need to be\n\t\t// restored after a restart.\n\t\tvar b bytes.Buffer\n\t\terr = serializeLogUpdates(&b, unsignedAckedUpdates)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = chanBucket.Put(unsignedAckedUpdatesKey, b.Bytes())\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to store dangline remote \"+\n\t\t\t\t\"updates: %v\", err)\n\t\t}\n\n\t\t// Since we have just sent the counterparty a revocation, store true\n\t\t// under lastWasRevokeKey.\n\t\tvar b2 bytes.Buffer\n\t\tif err := WriteElements(&b2, true); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := chanBucket.Put(lastWasRevokeKey, b2.Bytes()); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Persist the remote unsigned local updates that are not included\n\t\t// in our new commitment.\n\t\tupdateBytes := chanBucket.Get(remoteUnsignedLocalUpdatesKey)\n\t\tif updateBytes == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tr := bytes.NewReader(updateBytes)\n\t\tupdates, err := deserializeLogUpdates(r)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Get the bucket where settled htlcs are recorded if the user\n\t\t// opted in to storing this information.\n\t\tvar finalHtlcsBucket kvdb.RwBucket\n\t\tif c.Db.parent.storeFinalHtlcResolutions {\n\t\t\tbucket, err := fetchFinalHtlcsBucketRw(\n\t\t\t\ttx, c.ShortChannelID,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tfinalHtlcsBucket = bucket\n\t\t}\n\n\t\tvar unsignedUpdates []LogUpdate\n\t\tfor _, upd := range updates {\n\t\t\t// Gather updates that are not on our local commitment.\n\t\t\tif upd.LogIndex >= newCommitment.LocalLogIndex {\n\t\t\t\tunsignedUpdates = append(unsignedUpdates, upd)\n\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// The update was locked in. If the update was a\n\t\t\t// resolution, then store it in the database.\n\t\t\terr := processFinalHtlc(\n\t\t\t\tfinalHtlcsBucket, upd, finalHtlcs,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tvar b3 bytes.Buffer\n\t\terr = serializeLogUpdates(&b3, unsignedUpdates)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to serialize log updates: %v\", err)\n\t\t}\n\n\t\terr = chanBucket.Put(remoteUnsignedLocalUpdatesKey, b3.Bytes())\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to restore chanbucket: %v\", err)\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\tfinalHtlcs = make(map[uint64]bool)\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc.LocalCommitment = *newCommitment\n\n\treturn finalHtlcs, nil\n}\n\n// processFinalHtlc stores a final htlc outcome in the database if signaled via\n// the supplied log update. An in-memory htlcs map is updated too.",
      "length": 3463,
      "tokens": 503,
      "embedding": []
    },
    {
      "slug": "func processFinalHtlc(finalHtlcsBucket walletdb.ReadWriteBucket, upd LogUpdate,",
      "content": "func processFinalHtlc(finalHtlcsBucket walletdb.ReadWriteBucket, upd LogUpdate,\n\tfinalHtlcs map[uint64]bool) error {\n\n\tvar (\n\t\tsettled bool\n\t\tid      uint64\n\t)\n\n\tswitch msg := upd.UpdateMsg.(type) {\n\tcase *lnwire.UpdateFulfillHTLC:\n\t\tsettled = true\n\t\tid = msg.ID\n\n\tcase *lnwire.UpdateFailHTLC:\n\t\tsettled = false\n\t\tid = msg.ID\n\n\tcase *lnwire.UpdateFailMalformedHTLC:\n\t\tsettled = false\n\t\tid = msg.ID\n\n\tdefault:\n\t\treturn nil\n\t}\n\n\t// Store the final resolution in the database if a bucket is provided.\n\tif finalHtlcsBucket != nil {\n\t\terr := putFinalHtlc(\n\t\t\tfinalHtlcsBucket, id,\n\t\t\tFinalHtlcInfo{\n\t\t\t\tSettled:  settled,\n\t\t\t\tOffchain: true,\n\t\t\t},\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfinalHtlcs[id] = settled\n\n\treturn nil\n}\n\n// ActiveHtlcs returns a slice of HTLC's which are currently active on *both*\n// commitment transactions.",
      "length": 710,
      "tokens": 105,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) ActiveHtlcs() []HTLC {",
      "content": "func (c *OpenChannel) ActiveHtlcs() []HTLC {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\t// We'll only return HTLC's that are locked into *both* commitment\n\t// transactions. So we'll iterate through their set of HTLC's to note\n\t// which ones are present on their commitment.\n\tremoteHtlcs := make(map[[32]byte]struct{})\n\tfor _, htlc := range c.RemoteCommitment.Htlcs {\n\t\tonionHash := sha256.Sum256(htlc.OnionBlob)\n\t\tremoteHtlcs[onionHash] = struct{}{}\n\t}\n\n\t// Now that we know which HTLC's they have, we'll only mark the HTLC's\n\t// as active if *we* know them as well.\n\tactiveHtlcs := make([]HTLC, 0, len(remoteHtlcs))\n\tfor _, htlc := range c.LocalCommitment.Htlcs {\n\t\tonionHash := sha256.Sum256(htlc.OnionBlob)\n\t\tif _, ok := remoteHtlcs[onionHash]; !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tactiveHtlcs = append(activeHtlcs, htlc)\n\t}\n\n\treturn activeHtlcs\n}\n\n// HTLC is the on-disk representation of a hash time-locked contract. HTLCs are\n// contained within ChannelDeltas which encode the current state of the\n// commitment between state updates.\n//\n// TODO(roasbeef): save space by using smaller ints at tail end?",
      "length": 1009,
      "tokens": 147,
      "embedding": []
    },
    {
      "slug": "type HTLC struct {",
      "content": "type HTLC struct {\n\t// TODO(yy): can embed an HTLCEntry here.\n\n\t// Signature is the signature for the second level covenant transaction\n\t// for this HTLC. The second level transaction is a timeout tx in the\n\t// case that this is an outgoing HTLC, and a success tx in the case\n\t// that this is an incoming HTLC.\n\t//\n\t// TODO(roasbeef): make [64]byte instead?\n\tSignature []byte\n\n\t// RHash is the payment hash of the HTLC.\n\tRHash [32]byte\n\n\t// Amt is the amount of milli-satoshis this HTLC escrows.\n\tAmt lnwire.MilliSatoshi\n\n\t// RefundTimeout is the absolute timeout on the HTLC that the sender\n\t// must wait before reclaiming the funds in limbo.\n\tRefundTimeout uint32\n\n\t// OutputIndex is the output index for this particular HTLC output\n\t// within the commitment transaction.\n\tOutputIndex int32\n\n\t// Incoming denotes whether we're the receiver or the sender of this\n\t// HTLC.\n\tIncoming bool\n\n\t// OnionBlob is an opaque blob which is used to complete multi-hop\n\t// routing.\n\tOnionBlob []byte\n\n\t// HtlcIndex is the HTLC counter index of this active, outstanding\n\t// HTLC. This differs from the LogIndex, as the HtlcIndex is only\n\t// incremented for each offered HTLC, while they LogIndex is\n\t// incremented for each update (includes settle+fail).\n\tHtlcIndex uint64\n\n\t// LogIndex is the cumulative log index of this HTLC. This differs\n\t// from the HtlcIndex as this will be incremented for each new log\n\t// update added.\n\tLogIndex uint64\n}\n\n// SerializeHtlcs writes out the passed set of HTLC's into the passed writer\n// using the current default on-disk serialization format.\n//\n// NOTE: This API is NOT stable, the on-disk format will likely change in the\n// future.",
      "length": 1596,
      "tokens": 270,
      "embedding": []
    },
    {
      "slug": "func SerializeHtlcs(b io.Writer, htlcs ...HTLC) error {",
      "content": "func SerializeHtlcs(b io.Writer, htlcs ...HTLC) error {\n\tnumHtlcs := uint16(len(htlcs))\n\tif err := WriteElement(b, numHtlcs); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, htlc := range htlcs {\n\t\tif err := WriteElements(b,\n\t\t\thtlc.Signature, htlc.RHash, htlc.Amt, htlc.RefundTimeout,\n\t\t\thtlc.OutputIndex, htlc.Incoming, htlc.OnionBlob[:],\n\t\t\thtlc.HtlcIndex, htlc.LogIndex,\n\t\t); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// DeserializeHtlcs attempts to read out a slice of HTLC's from the passed\n// io.Reader. The bytes within the passed reader MUST have been previously\n// written to using the SerializeHtlcs function.\n//\n// NOTE: This API is NOT stable, the on-disk format will likely change in the\n// future.",
      "length": 631,
      "tokens": 97,
      "embedding": []
    },
    {
      "slug": "func DeserializeHtlcs(r io.Reader) ([]HTLC, error) {",
      "content": "func DeserializeHtlcs(r io.Reader) ([]HTLC, error) {\n\tvar numHtlcs uint16\n\tif err := ReadElement(r, &numHtlcs); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar htlcs []HTLC\n\tif numHtlcs == 0 {\n\t\treturn htlcs, nil\n\t}\n\n\thtlcs = make([]HTLC, numHtlcs)\n\tfor i := uint16(0); i < numHtlcs; i++ {\n\t\tif err := ReadElements(r,\n\t\t\t&htlcs[i].Signature, &htlcs[i].RHash, &htlcs[i].Amt,\n\t\t\t&htlcs[i].RefundTimeout, &htlcs[i].OutputIndex,\n\t\t\t&htlcs[i].Incoming, &htlcs[i].OnionBlob,\n\t\t\t&htlcs[i].HtlcIndex, &htlcs[i].LogIndex,\n\t\t); err != nil {\n\t\t\treturn htlcs, err\n\t\t}\n\t}\n\n\treturn htlcs, nil\n}\n\n// Copy returns a full copy of the target HTLC.",
      "length": 543,
      "tokens": 78,
      "embedding": []
    },
    {
      "slug": "func (h *HTLC) Copy() HTLC {",
      "content": "func (h *HTLC) Copy() HTLC {\n\tclone := HTLC{\n\t\tIncoming:      h.Incoming,\n\t\tAmt:           h.Amt,\n\t\tRefundTimeout: h.RefundTimeout,\n\t\tOutputIndex:   h.OutputIndex,\n\t}\n\tcopy(clone.Signature[:], h.Signature)\n\tcopy(clone.RHash[:], h.RHash[:])\n\n\treturn clone\n}\n\n// LogUpdate represents a pending update to the remote commitment chain. The\n// log update may be an add, fail, or settle entry. We maintain this data in\n// order to be able to properly retransmit our proposed state if necessary.",
      "length": 444,
      "tokens": 60,
      "embedding": []
    },
    {
      "slug": "type LogUpdate struct {",
      "content": "type LogUpdate struct {\n\t// LogIndex is the log index of this proposed commitment update entry.\n\tLogIndex uint64\n\n\t// UpdateMsg is the update message that was included within our\n\t// local update log. The LogIndex value denotes the log index of this\n\t// update which will be used when restoring our local update log if\n\t// we're left with a dangling update on restart.\n\tUpdateMsg lnwire.Message\n}\n\n// serializeLogUpdate writes a log update to the provided io.Writer.",
      "length": 432,
      "tokens": 73,
      "embedding": []
    },
    {
      "slug": "func serializeLogUpdate(w io.Writer, l *LogUpdate) error {",
      "content": "func serializeLogUpdate(w io.Writer, l *LogUpdate) error {\n\treturn WriteElements(w, l.LogIndex, l.UpdateMsg)\n}\n\n// deserializeLogUpdate reads a log update from the provided io.Reader.",
      "length": 121,
      "tokens": 15,
      "embedding": []
    },
    {
      "slug": "func deserializeLogUpdate(r io.Reader) (*LogUpdate, error) {",
      "content": "func deserializeLogUpdate(r io.Reader) (*LogUpdate, error) {\n\tl := &LogUpdate{}\n\tif err := ReadElements(r, &l.LogIndex, &l.UpdateMsg); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn l, nil\n}\n\n// CommitDiff represents the delta needed to apply the state transition between\n// two subsequent commitment states. Given state N and state N+1, one is able\n// to apply the set of messages contained within the CommitDiff to N to arrive\n// at state N+1. Each time a new commitment is extended, we'll write a new\n// commitment (along with the full commitment state) to disk so we can\n// re-transmit the state in the case of a connection loss or message drop.",
      "length": 571,
      "tokens": 104,
      "embedding": []
    },
    {
      "slug": "type CommitDiff struct {",
      "content": "type CommitDiff struct {\n\t// ChannelCommitment is the full commitment state that one would arrive\n\t// at by applying the set of messages contained in the UpdateDiff to\n\t// the prior accepted commitment.\n\tCommitment ChannelCommitment\n\n\t// LogUpdates is the set of messages sent prior to the commitment state\n\t// transition in question. Upon reconnection, if we detect that they\n\t// don't have the commitment, then we re-send this along with the\n\t// proper signature.\n\tLogUpdates []LogUpdate\n\n\t// CommitSig is the exact CommitSig message that should be sent after\n\t// the set of LogUpdates above has been retransmitted. The signatures\n\t// within this message should properly cover the new commitment state\n\t// and also the HTLC's within the new commitment state.\n\tCommitSig *lnwire.CommitSig\n\n\t// OpenedCircuitKeys is a set of unique identifiers for any downstream\n\t// Add packets included in this commitment txn. After a restart, this\n\t// set of htlcs is acked from the link's incoming mailbox to ensure\n\t// there isn't an attempt to re-add them to this commitment txn.\n\tOpenedCircuitKeys []models.CircuitKey\n\n\t// ClosedCircuitKeys records the unique identifiers for any settle/fail\n\t// packets that were resolved by this commitment txn. After a restart,\n\t// this is used to ensure those circuits are removed from the circuit\n\t// map, and the downstream packets in the link's mailbox are removed.\n\tClosedCircuitKeys []models.CircuitKey\n\n\t// AddAcks specifies the locations (commit height, pkg index) of any\n\t// Adds that were failed/settled in this commit diff. This will ack\n\t// entries in *this* channel's forwarding packages.\n\t//\n\t// NOTE: This value is not serialized, it is used to atomically mark the\n\t// resolution of adds, such that they will not be reprocessed after a\n\t// restart.\n\tAddAcks []AddRef\n\n\t// SettleFailAcks specifies the locations (chan id, commit height, pkg\n\t// index) of any Settles or Fails that were locked into this commit\n\t// diff, and originate from *another* channel, i.e. the outgoing link.\n\t//\n\t// NOTE: This value is not serialized, it is used to atomically acks\n\t// settles and fails from the forwarding packages of other channels,\n\t// such that they will not be reforwarded internally after a restart.\n\tSettleFailAcks []SettleFailRef\n}\n\n// serializeLogUpdates serializes provided list of updates to a stream.",
      "length": 2270,
      "tokens": 362,
      "embedding": []
    },
    {
      "slug": "func serializeLogUpdates(w io.Writer, logUpdates []LogUpdate) error {",
      "content": "func serializeLogUpdates(w io.Writer, logUpdates []LogUpdate) error {\n\tnumUpdates := uint16(len(logUpdates))\n\tif err := binary.Write(w, byteOrder, numUpdates); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, diff := range logUpdates {\n\t\terr := WriteElements(w, diff.LogIndex, diff.UpdateMsg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// deserializeLogUpdates deserializes a list of updates from a stream.",
      "length": 322,
      "tokens": 50,
      "embedding": []
    },
    {
      "slug": "func deserializeLogUpdates(r io.Reader) ([]LogUpdate, error) {",
      "content": "func deserializeLogUpdates(r io.Reader) ([]LogUpdate, error) {\n\tvar numUpdates uint16\n\tif err := binary.Read(r, byteOrder, &numUpdates); err != nil {\n\t\treturn nil, err\n\t}\n\n\tlogUpdates := make([]LogUpdate, numUpdates)\n\tfor i := 0; i < int(numUpdates); i++ {\n\t\terr := ReadElements(r,\n\t\t\t&logUpdates[i].LogIndex, &logUpdates[i].UpdateMsg,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn logUpdates, nil\n}\n",
      "length": 331,
      "tokens": 50,
      "embedding": []
    },
    {
      "slug": "func serializeCommitDiff(w io.Writer, diff *CommitDiff) error { // nolint: dupl",
      "content": "func serializeCommitDiff(w io.Writer, diff *CommitDiff) error { // nolint: dupl\n\tif err := serializeChanCommit(w, &diff.Commitment); err != nil {\n\t\treturn err\n\t}\n\n\tif err := WriteElements(w, diff.CommitSig); err != nil {\n\t\treturn err\n\t}\n\n\tif err := serializeLogUpdates(w, diff.LogUpdates); err != nil {\n\t\treturn err\n\t}\n\n\tnumOpenRefs := uint16(len(diff.OpenedCircuitKeys))\n\tif err := binary.Write(w, byteOrder, numOpenRefs); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, openRef := range diff.OpenedCircuitKeys {\n\t\terr := WriteElements(w, openRef.ChanID, openRef.HtlcID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tnumClosedRefs := uint16(len(diff.ClosedCircuitKeys))\n\tif err := binary.Write(w, byteOrder, numClosedRefs); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, closedRef := range diff.ClosedCircuitKeys {\n\t\terr := WriteElements(w, closedRef.ChanID, closedRef.HtlcID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n",
      "length": 790,
      "tokens": 113,
      "embedding": []
    },
    {
      "slug": "func deserializeCommitDiff(r io.Reader) (*CommitDiff, error) {",
      "content": "func deserializeCommitDiff(r io.Reader) (*CommitDiff, error) {\n\tvar (\n\t\td   CommitDiff\n\t\terr error\n\t)\n\n\td.Commitment, err = deserializeChanCommit(r)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar msg lnwire.Message\n\tif err := ReadElements(r, &msg); err != nil {\n\t\treturn nil, err\n\t}\n\tcommitSig, ok := msg.(*lnwire.CommitSig)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"expected lnwire.CommitSig, instead \"+\n\t\t\t\"read: %T\", msg)\n\t}\n\td.CommitSig = commitSig\n\n\td.LogUpdates, err = deserializeLogUpdates(r)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar numOpenRefs uint16\n\tif err := binary.Read(r, byteOrder, &numOpenRefs); err != nil {\n\t\treturn nil, err\n\t}\n\n\td.OpenedCircuitKeys = make([]models.CircuitKey, numOpenRefs)\n\tfor i := 0; i < int(numOpenRefs); i++ {\n\t\terr := ReadElements(r,\n\t\t\t&d.OpenedCircuitKeys[i].ChanID,\n\t\t\t&d.OpenedCircuitKeys[i].HtlcID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tvar numClosedRefs uint16\n\tif err := binary.Read(r, byteOrder, &numClosedRefs); err != nil {\n\t\treturn nil, err\n\t}\n\n\td.ClosedCircuitKeys = make([]models.CircuitKey, numClosedRefs)\n\tfor i := 0; i < int(numClosedRefs); i++ {\n\t\terr := ReadElements(r,\n\t\t\t&d.ClosedCircuitKeys[i].ChanID,\n\t\t\t&d.ClosedCircuitKeys[i].HtlcID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &d, nil\n}\n\n// AppendRemoteCommitChain appends a new CommitDiff to the end of the\n// commitment chain for the remote party. This method is to be used once we\n// have prepared a new commitment state for the remote party, but before we\n// transmit it to the remote party. The contents of the argument should be\n// sufficient to retransmit the updates and signature needed to reconstruct the\n// state in full, in the case that we need to retransmit.",
      "length": 1572,
      "tokens": 241,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) AppendRemoteCommitChain(diff *CommitDiff) error {",
      "content": "func (c *OpenChannel) AppendRemoteCommitChain(diff *CommitDiff) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// If this is a restored channel, then we want to avoid mutating the\n\t// state at all, as it's impossible to do so in a protocol compliant\n\t// manner.\n\tif c.hasChanStatus(ChanStatusRestored) {\n\t\treturn ErrNoRestoredChannelMutation\n\t}\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\t// First, we'll grab the writable bucket where this channel's\n\t\t// data resides.\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// If the channel is marked as borked, then for safety reasons,\n\t\t// we shouldn't attempt any further updates.\n\t\tisBorked, err := c.isBorked(chanBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif isBorked {\n\t\t\treturn ErrChanBorked\n\t\t}\n\n\t\t// Any outgoing settles and fails necessarily have a\n\t\t// corresponding adds in this channel's forwarding packages.\n\t\t// Mark all of these as being fully processed in our forwarding\n\t\t// package, which prevents us from reprocessing them after\n\t\t// startup.\n\t\terr = c.Packager.AckAddHtlcs(tx, diff.AddAcks...)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Additionally, we ack from any fails or settles that are\n\t\t// persisted in another channel's forwarding package. This\n\t\t// prevents the same fails and settles from being retransmitted\n\t\t// after restarts. The actual fail or settle we need to\n\t\t// propagate to the remote party is now in the commit diff.\n\t\terr = c.Packager.AckSettleFails(tx, diff.SettleFailAcks...)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// We are sending a commitment signature so lastWasRevokeKey should\n\t\t// store false.\n\t\tvar b bytes.Buffer\n\t\tif err := WriteElements(&b, false); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := chanBucket.Put(lastWasRevokeKey, b.Bytes()); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// TODO(roasbeef): use seqno to derive key for later LCP\n\n\t\t// With the bucket retrieved, we'll now serialize the commit\n\t\t// diff itself, and write it to disk.\n\t\tvar b2 bytes.Buffer\n\t\tif err := serializeCommitDiff(&b2, diff); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn chanBucket.Put(commitDiffKey, b2.Bytes())\n\t}, func() {})\n}\n\n// RemoteCommitChainTip returns the \"tip\" of the current remote commitment\n// chain. This value will be non-nil iff, we've created a new commitment for\n// the remote party that they haven't yet ACK'd. In this case, their commitment\n// chain will have a length of two: their current unrevoked commitment, and\n// this new pending commitment. Once they revoked their prior state, we'll swap\n// these pointers, causing the tip and the tail to point to the same entry.",
      "length": 2518,
      "tokens": 397,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) RemoteCommitChainTip() (*CommitDiff, error) {",
      "content": "func (c *OpenChannel) RemoteCommitChainTip() (*CommitDiff, error) {\n\tvar cd *CommitDiff\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tswitch err {\n\t\tcase nil:\n\t\tcase ErrNoChanDBExists, ErrNoActiveChannels, ErrChannelNotFound:\n\t\t\treturn ErrNoPendingCommit\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\n\t\ttipBytes := chanBucket.Get(commitDiffKey)\n\t\tif tipBytes == nil {\n\t\t\treturn ErrNoPendingCommit\n\t\t}\n\n\t\ttipReader := bytes.NewReader(tipBytes)\n\t\tdcd, err := deserializeCommitDiff(tipReader)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tcd = dcd\n\t\treturn nil\n\t}, func() {\n\t\tcd = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn cd, err\n}\n\n// UnsignedAckedUpdates retrieves the persisted unsigned acked remote log\n// updates that still need to be signed for.",
      "length": 745,
      "tokens": 103,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) UnsignedAckedUpdates() ([]LogUpdate, error) {",
      "content": "func (c *OpenChannel) UnsignedAckedUpdates() ([]LogUpdate, error) {\n\tvar updates []LogUpdate\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tswitch err {\n\t\tcase nil:\n\t\tcase ErrNoChanDBExists, ErrNoActiveChannels, ErrChannelNotFound:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\n\t\tupdateBytes := chanBucket.Get(unsignedAckedUpdatesKey)\n\t\tif updateBytes == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tr := bytes.NewReader(updateBytes)\n\t\tupdates, err = deserializeLogUpdates(r)\n\t\treturn err\n\t}, func() {\n\t\tupdates = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn updates, nil\n}\n\n// RemoteUnsignedLocalUpdates retrieves the persisted, unsigned local log\n// updates that the remote still needs to sign for.",
      "length": 700,
      "tokens": 92,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) RemoteUnsignedLocalUpdates() ([]LogUpdate, error) {",
      "content": "func (c *OpenChannel) RemoteUnsignedLocalUpdates() ([]LogUpdate, error) {\n\tvar updates []LogUpdate\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tswitch err {\n\t\tcase nil:\n\t\t\tbreak\n\t\tcase ErrNoChanDBExists, ErrNoActiveChannels, ErrChannelNotFound:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\n\t\tupdateBytes := chanBucket.Get(remoteUnsignedLocalUpdatesKey)\n\t\tif updateBytes == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tr := bytes.NewReader(updateBytes)\n\t\tupdates, err = deserializeLogUpdates(r)\n\t\treturn err\n\t}, func() {\n\t\tupdates = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn updates, nil\n}\n\n// InsertNextRevocation inserts the _next_ commitment point (revocation) into\n// the database, and also modifies the internal RemoteNextRevocation attribute\n// to point to the passed key. This method is to be using during final channel\n// set up, _after_ the channel has been fully confirmed.\n//\n// NOTE: If this method isn't called, then the target channel won't be able to\n// propose new states for the commitment state of the remote party.",
      "length": 1026,
      "tokens": 148,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) InsertNextRevocation(revKey *btcec.PublicKey) error {",
      "content": "func (c *OpenChannel) InsertNextRevocation(revKey *btcec.PublicKey) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tc.RemoteNextRevocation = revKey\n\n\terr := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn putChanRevocationState(chanBucket, c)\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// AdvanceCommitChainTail records the new state transition within an on-disk\n// append-only log which records all state transitions by the remote peer. In\n// the case of an uncooperative broadcast of a prior state by the remote peer,\n// this log can be consulted in order to reconstruct the state needed to\n// rectify the situation. This method will add the current commitment for the\n// remote party to the revocation log, and promote the current pending\n// commitment to the current remote commitment. The updates parameter is the\n// set of local updates that the peer still needs to send us a signature for.\n// We store this set of updates in case we go down.",
      "length": 1003,
      "tokens": 164,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) AdvanceCommitChainTail(fwdPkg *FwdPkg,",
      "content": "func (c *OpenChannel) AdvanceCommitChainTail(fwdPkg *FwdPkg,\n\tupdates []LogUpdate, ourOutputIndex, theirOutputIndex uint32) error {\n\n\tc.Lock()\n\tdefer c.Unlock()\n\n\t// If this is a restored channel, then we want to avoid mutating the\n\t// state at all, as it's impossible to do so in a protocol compliant\n\t// manner.\n\tif c.hasChanStatus(ChanStatusRestored) {\n\t\treturn ErrNoRestoredChannelMutation\n\t}\n\n\tvar newRemoteCommit *ChannelCommitment\n\n\terr := kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tchanBucket, err := fetchChanBucketRw(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// If the channel is marked as borked, then for safety reasons,\n\t\t// we shouldn't attempt any further updates.\n\t\tisBorked, err := c.isBorked(chanBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif isBorked {\n\t\t\treturn ErrChanBorked\n\t\t}\n\n\t\t// Persist the latest preimage state to disk as the remote peer\n\t\t// has just added to our local preimage store, and given us a\n\t\t// new pending revocation key.\n\t\tif err := putChanRevocationState(chanBucket, c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// With the current preimage producer/store state updated,\n\t\t// append a new log entry recording this the delta of this\n\t\t// state transition.\n\t\t//\n\t\t// TODO(roasbeef): could make the deltas relative, would save\n\t\t// space, but then tradeoff for more disk-seeks to recover the\n\t\t// full state.\n\t\tlogKey := revocationLogBucket\n\t\tlogBucket, err := chanBucket.CreateBucketIfNotExists(logKey)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Before we append this revoked state to the revocation log,\n\t\t// we'll swap out what's currently the tail of the commit tip,\n\t\t// with the current locked-in commitment for the remote party.\n\t\ttipBytes := chanBucket.Get(commitDiffKey)\n\t\ttipReader := bytes.NewReader(tipBytes)\n\t\tnewCommit, err := deserializeCommitDiff(tipReader)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = putChanCommitment(\n\t\t\tchanBucket, &newCommit.Commitment, false,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := chanBucket.Delete(commitDiffKey); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// With the commitment pointer swapped, we can now add the\n\t\t// revoked (prior) state to the revocation log.\n\t\terr = putRevocationLog(\n\t\t\tlogBucket, &c.RemoteCommitment, ourOutputIndex,\n\t\t\ttheirOutputIndex, c.Db.parent.noRevLogAmtData,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Lastly, we write the forwarding package to disk so that we\n\t\t// can properly recover from failures and reforward HTLCs that\n\t\t// have not received a corresponding settle/fail.\n\t\tif err := c.Packager.AddFwdPkg(tx, fwdPkg); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Persist the unsigned acked updates that are not included\n\t\t// in their new commitment.\n\t\tupdateBytes := chanBucket.Get(unsignedAckedUpdatesKey)\n\t\tif updateBytes == nil {\n\t\t\t// This shouldn't normally happen as we always store\n\t\t\t// the number of updates, but could still be\n\t\t\t// encountered by nodes that are upgrading.\n\t\t\tnewRemoteCommit = &newCommit.Commitment\n\t\t\treturn nil\n\t\t}\n\n\t\tr := bytes.NewReader(updateBytes)\n\t\tunsignedUpdates, err := deserializeLogUpdates(r)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar validUpdates []LogUpdate\n\t\tfor _, upd := range unsignedUpdates {\n\t\t\tlIdx := upd.LogIndex\n\n\t\t\t// Filter for updates that are not on the remote\n\t\t\t// commitment.\n\t\t\tif lIdx >= newCommit.Commitment.RemoteLogIndex {\n\t\t\t\tvalidUpdates = append(validUpdates, upd)\n\t\t\t}\n\t\t}\n\n\t\tvar b bytes.Buffer\n\t\terr = serializeLogUpdates(&b, validUpdates)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to serialize log updates: %v\", err)\n\t\t}\n\n\t\terr = chanBucket.Put(unsignedAckedUpdatesKey, b.Bytes())\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to store under unsignedAckedUpdatesKey: %v\", err)\n\t\t}\n\n\t\t// Persist the local updates the peer hasn't yet signed so they\n\t\t// can be restored after restart.\n\t\tvar b2 bytes.Buffer\n\t\terr = serializeLogUpdates(&b2, updates)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = chanBucket.Put(remoteUnsignedLocalUpdatesKey, b2.Bytes())\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to restore remote unsigned \"+\n\t\t\t\t\"local updates: %v\", err)\n\t\t}\n\n\t\tnewRemoteCommit = &newCommit.Commitment\n\n\t\treturn nil\n\t}, func() {\n\t\tnewRemoteCommit = nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// With the db transaction complete, we'll swap over the in-memory\n\t// pointer of the new remote commitment, which was previously the tip\n\t// of the commit chain.\n\tc.RemoteCommitment = *newRemoteCommit\n\n\treturn nil\n}\n\n// FinalHtlcInfo contains information about the final outcome of an htlc.",
      "length": 4327,
      "tokens": 631,
      "embedding": []
    },
    {
      "slug": "type FinalHtlcInfo struct {",
      "content": "type FinalHtlcInfo struct {\n\t// Settled is true is the htlc was settled. If false, the htlc was\n\t// failed.\n\tSettled bool\n\n\t// Offchain indicates whether the htlc was resolved off-chain or\n\t// on-chain.\n\tOffchain bool\n}\n\n// putFinalHtlc writes the final htlc outcome to the database. Additionally it\n// records whether the htlc was resolved off-chain or on-chain.",
      "length": 325,
      "tokens": 55,
      "embedding": []
    },
    {
      "slug": "func putFinalHtlc(finalHtlcsBucket kvdb.RwBucket, id uint64,",
      "content": "func putFinalHtlc(finalHtlcsBucket kvdb.RwBucket, id uint64,\n\tinfo FinalHtlcInfo) error {\n\n\tvar key [8]byte\n\tbyteOrder.PutUint64(key[:], id)\n\n\tvar finalHtlcByte FinalHtlcByte\n\tif info.Settled {\n\t\tfinalHtlcByte |= FinalHtlcSettledBit\n\t}\n\tif info.Offchain {\n\t\tfinalHtlcByte |= FinalHtlcOffchainBit\n\t}\n\n\treturn finalHtlcsBucket.Put(key[:], []byte{byte(finalHtlcByte)})\n}\n\n// NextLocalHtlcIndex returns the next unallocated local htlc index. To ensure\n// this always returns the next index that has been not been allocated, this\n// will first try to examine any pending commitments, before falling back to the\n// last locked-in remote commitment.",
      "length": 562,
      "tokens": 74,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) NextLocalHtlcIndex() (uint64, error) {",
      "content": "func (c *OpenChannel) NextLocalHtlcIndex() (uint64, error) {\n\t// First, load the most recent commit diff that we initiated for the\n\t// remote party. If no pending commit is found, this is not treated as\n\t// a critical error, since we can always fall back.\n\tpendingRemoteCommit, err := c.RemoteCommitChainTip()\n\tif err != nil && err != ErrNoPendingCommit {\n\t\treturn 0, err\n\t}\n\n\t// If a pending commit was found, its local htlc index will be at least\n\t// as large as the one on our local commitment.\n\tif pendingRemoteCommit != nil {\n\t\treturn pendingRemoteCommit.Commitment.LocalHtlcIndex, nil\n\t}\n\n\t// Otherwise, fallback to using the local htlc index of their commitment.\n\treturn c.RemoteCommitment.LocalHtlcIndex, nil\n}\n\n// LoadFwdPkgs scans the forwarding log for any packages that haven't been\n// processed, and returns their deserialized log updates in map indexed by the\n// remote commitment height at which the updates were locked in.",
      "length": 857,
      "tokens": 140,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) LoadFwdPkgs() ([]*FwdPkg, error) {",
      "content": "func (c *OpenChannel) LoadFwdPkgs() ([]*FwdPkg, error) {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\tvar fwdPkgs []*FwdPkg\n\tif err := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tvar err error\n\t\tfwdPkgs, err = c.Packager.LoadFwdPkgs(tx)\n\t\treturn err\n\t}, func() {\n\t\tfwdPkgs = nil\n\t}); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn fwdPkgs, nil\n}\n\n// AckAddHtlcs updates the AckAddFilter containing any of the provided AddRefs\n// indicating that a response to this Add has been committed to the remote party.\n// Doing so will prevent these Add HTLCs from being reforwarded internally.",
      "length": 498,
      "tokens": 80,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) AckAddHtlcs(addRefs ...AddRef) error {",
      "content": "func (c *OpenChannel) AckAddHtlcs(addRefs ...AddRef) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\treturn c.Packager.AckAddHtlcs(tx, addRefs...)\n\t}, func() {})\n}\n\n// AckSettleFails updates the SettleFailFilter containing any of the provided\n// SettleFailRefs, indicating that the response has been delivered to the\n// incoming link, corresponding to a particular AddRef. Doing so will prevent\n// the responses from being retransmitted internally.",
      "length": 428,
      "tokens": 56,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) AckSettleFails(settleFailRefs ...SettleFailRef) error {",
      "content": "func (c *OpenChannel) AckSettleFails(settleFailRefs ...SettleFailRef) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\treturn c.Packager.AckSettleFails(tx, settleFailRefs...)\n\t}, func() {})\n}\n\n// SetFwdFilter atomically sets the forwarding filter for the forwarding package\n// identified by `height`.",
      "length": 264,
      "tokens": 31,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) SetFwdFilter(height uint64, fwdFilter *PkgFilter) error {",
      "content": "func (c *OpenChannel) SetFwdFilter(height uint64, fwdFilter *PkgFilter) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\treturn c.Packager.SetFwdFilter(tx, height, fwdFilter)\n\t}, func() {})\n}\n\n// RemoveFwdPkgs atomically removes forwarding packages specified by the remote\n// commitment heights. If one of the intermediate RemovePkg calls fails, then the\n// later packages won't be removed.\n//\n// NOTE: This method should only be called on packages marked FwdStateCompleted.",
      "length": 433,
      "tokens": 59,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) RemoveFwdPkgs(heights ...uint64) error {",
      "content": "func (c *OpenChannel) RemoveFwdPkgs(heights ...uint64) error {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\tfor _, height := range heights {\n\t\t\terr := c.Packager.RemovePkg(tx, height)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n}\n\n// revocationLogTailCommitHeight returns the commit height at the end of the\n// revocation log. This entry represents the last previous state for the remote\n// node's commitment chain. The ChannelDelta returned by this method will\n// always lag one state behind the most current (unrevoked) state of the remote\n// node's commitment chain.\n// NOTE: used in unit test only.",
      "length": 594,
      "tokens": 95,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) revocationLogTailCommitHeight() (uint64, error) {",
      "content": "func (c *OpenChannel) revocationLogTailCommitHeight() (uint64, error) {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\tvar height uint64\n\n\t// If we haven't created any state updates yet, then we'll exit early as\n\t// there's nothing to be found on disk in the revocation bucket.\n\tif c.RemoteCommitment.CommitHeight == 0 {\n\t\treturn height, nil\n\t}\n\n\tif err := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tlogBucket, err := fetchLogBucket(chanBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Once we have the bucket that stores the revocation log from\n\t\t// this channel, we'll jump to the _last_ key in bucket. Since\n\t\t// the key is the commit height, we'll decode the bytes and\n\t\t// return it.\n\t\tcursor := logBucket.ReadCursor()\n\t\trawHeight, _ := cursor.Last()\n\t\theight = byteOrder.Uint64(rawHeight)\n\n\t\treturn nil\n\t}, func() {}); err != nil {\n\t\treturn height, err\n\t}\n\n\treturn height, nil\n}\n\n// CommitmentHeight returns the current commitment height. The commitment\n// height represents the number of updates to the commitment state to date.\n// This value is always monotonically increasing. This method is provided in\n// order to allow multiple instances of a particular open channel to obtain a\n// consistent view of the number of channel updates to date.",
      "length": 1264,
      "tokens": 203,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) CommitmentHeight() (uint64, error) {",
      "content": "func (c *OpenChannel) CommitmentHeight() (uint64, error) {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\tvar height uint64\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\t// Get the bucket dedicated to storing the metadata for open\n\t\t// channels.\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tcommit, err := fetchChanCommitment(chanBucket, true)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\theight = commit.CommitHeight\n\t\treturn nil\n\t}, func() {\n\t\theight = 0\n\t})\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn height, nil\n}\n\n// FindPreviousState scans through the append-only log in an attempt to recover\n// the previous channel state indicated by the update number. This method is\n// intended to be used for obtaining the relevant data needed to claim all\n// funds rightfully spendable in the case of an on-chain broadcast of the\n// commitment transaction.",
      "length": 843,
      "tokens": 136,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) FindPreviousState(",
      "content": "func (c *OpenChannel) FindPreviousState(\n\tupdateNum uint64) (*RevocationLog, *ChannelCommitment, error) {\n\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\tcommit := &ChannelCommitment{}\n\trl := &RevocationLog{}\n\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Find the revocation log from both the new and the old\n\t\t// bucket.\n\t\tr, c, err := fetchRevocationLogCompatible(chanBucket, updateNum)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\trl = r\n\t\tcommit = c\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Either the `rl` or the `commit` is nil here. We return them as-is\n\t// and leave it to the caller to decide its following action.\n\treturn rl, commit, nil\n}\n\n// ClosureType is an enum like structure that details exactly _how_ a channel\n// was closed. Three closure types are currently possible: none, cooperative,\n// local force close, remote force close, and (remote) breach.",
      "length": 956,
      "tokens": 153,
      "embedding": []
    },
    {
      "slug": "type ClosureType uint8",
      "content": "type ClosureType uint8\n\nconst (\n\t// CooperativeClose indicates that a channel has been closed\n\t// cooperatively.  This means that both channel peers were online and\n\t// signed a new transaction paying out the settled balance of the\n\t// contract.\n\tCooperativeClose ClosureType = 0\n\n\t// LocalForceClose indicates that we have unilaterally broadcast our\n\t// current commitment state on-chain.\n\tLocalForceClose ClosureType = 1\n\n\t// RemoteForceClose indicates that the remote peer has unilaterally\n\t// broadcast their current commitment state on-chain.\n\tRemoteForceClose ClosureType = 4\n\n\t// BreachClose indicates that the remote peer attempted to broadcast a\n\t// prior _revoked_ channel state.\n\tBreachClose ClosureType = 2\n\n\t// FundingCanceled indicates that the channel never was fully opened\n\t// before it was marked as closed in the database. This can happen if\n\t// we or the remote fail at some point during the opening workflow, or\n\t// we timeout waiting for the funding transaction to be confirmed.\n\tFundingCanceled ClosureType = 3\n\n\t// Abandoned indicates that the channel state was removed without\n\t// any further actions. This is intended to clean up unusable\n\t// channels during development.\n\tAbandoned ClosureType = 5\n)\n\n// ChannelCloseSummary contains the final state of a channel at the point it\n// was closed. Once a channel is closed, all the information pertaining to that\n// channel within the openChannelBucket is deleted, and a compact summary is\n// put in place instead.",
      "length": 1428,
      "tokens": 225,
      "embedding": []
    },
    {
      "slug": "type ChannelCloseSummary struct {",
      "content": "type ChannelCloseSummary struct {\n\t// ChanPoint is the outpoint for this channel's funding transaction,\n\t// and is used as a unique identifier for the channel.\n\tChanPoint wire.OutPoint\n\n\t// ShortChanID encodes the exact location in the chain in which the\n\t// channel was initially confirmed. This includes: the block height,\n\t// transaction index, and the output within the target transaction.\n\tShortChanID lnwire.ShortChannelID\n\n\t// ChainHash is the hash of the genesis block that this channel resides\n\t// within.\n\tChainHash chainhash.Hash\n\n\t// ClosingTXID is the txid of the transaction which ultimately closed\n\t// this channel.\n\tClosingTXID chainhash.Hash\n\n\t// RemotePub is the public key of the remote peer that we formerly had\n\t// a channel with.\n\tRemotePub *btcec.PublicKey\n\n\t// Capacity was the total capacity of the channel.\n\tCapacity btcutil.Amount\n\n\t// CloseHeight is the height at which the funding transaction was\n\t// spent.\n\tCloseHeight uint32\n\n\t// SettledBalance is our total balance settled balance at the time of\n\t// channel closure. This _does not_ include the sum of any outputs that\n\t// have been time-locked as a result of the unilateral channel closure.\n\tSettledBalance btcutil.Amount\n\n\t// TimeLockedBalance is the sum of all the time-locked outputs at the\n\t// time of channel closure. If we triggered the force closure of this\n\t// channel, then this value will be non-zero if our settled output is\n\t// above the dust limit. If we were on the receiving side of a channel\n\t// force closure, then this value will be non-zero if we had any\n\t// outstanding outgoing HTLC's at the time of channel closure.\n\tTimeLockedBalance btcutil.Amount\n\n\t// CloseType details exactly _how_ the channel was closed. Five closure\n\t// types are possible: cooperative, local force, remote force, breach\n\t// and funding canceled.\n\tCloseType ClosureType\n\n\t// IsPending indicates whether this channel is in the 'pending close'\n\t// state, which means the channel closing transaction has been\n\t// confirmed, but not yet been fully resolved. In the case of a channel\n\t// that has been cooperatively closed, it will go straight into the\n\t// fully resolved state as soon as the closing transaction has been\n\t// confirmed. However, for channels that have been force closed, they'll\n\t// stay marked as \"pending\" until _all_ the pending funds have been\n\t// swept.\n\tIsPending bool\n\n\t// RemoteCurrentRevocation is the current revocation for their\n\t// commitment transaction. However, since this is the derived public key,\n\t// we don't yet have the private key so we aren't yet able to verify\n\t// that it's actually in the hash chain.\n\tRemoteCurrentRevocation *btcec.PublicKey\n\n\t// RemoteNextRevocation is the revocation key to be used for the *next*\n\t// commitment transaction we create for the local node. Within the\n\t// specification, this value is referred to as the\n\t// per-commitment-point.\n\tRemoteNextRevocation *btcec.PublicKey\n\n\t// LocalChanCfg is the channel configuration for the local node.\n\tLocalChanConfig ChannelConfig\n\n\t// LastChanSyncMsg is the ChannelReestablish message for this channel\n\t// for the state at the point where it was closed.\n\tLastChanSyncMsg *lnwire.ChannelReestablish\n}\n\n// CloseChannel closes a previously active Lightning channel. Closing a channel\n// entails deleting all saved state within the database concerning this\n// channel. This method also takes a struct that summarizes the state of the\n// channel at closing, this compact representation will be the only component\n// of a channel left over after a full closing. It takes an optional set of\n// channel statuses which will be written to the historical channel bucket.\n// These statuses are used to record close initiators.",
      "length": 3586,
      "tokens": 566,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) CloseChannel(summary *ChannelCloseSummary,",
      "content": "func (c *OpenChannel) CloseChannel(summary *ChannelCloseSummary,\n\tstatuses ...ChannelStatus) error {\n\n\tc.Lock()\n\tdefer c.Unlock()\n\n\treturn kvdb.Update(c.Db.backend, func(tx kvdb.RwTx) error {\n\t\topenChanBucket := tx.ReadWriteBucket(openChannelBucket)\n\t\tif openChanBucket == nil {\n\t\t\treturn ErrNoChanDBExists\n\t\t}\n\n\t\tnodePub := c.IdentityPub.SerializeCompressed()\n\t\tnodeChanBucket := openChanBucket.NestedReadWriteBucket(nodePub)\n\t\tif nodeChanBucket == nil {\n\t\t\treturn ErrNoActiveChannels\n\t\t}\n\n\t\tchainBucket := nodeChanBucket.NestedReadWriteBucket(c.ChainHash[:])\n\t\tif chainBucket == nil {\n\t\t\treturn ErrNoActiveChannels\n\t\t}\n\n\t\tvar chanPointBuf bytes.Buffer\n\t\terr := writeOutpoint(&chanPointBuf, &c.FundingOutpoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tchanKey := chanPointBuf.Bytes()\n\t\tchanBucket := chainBucket.NestedReadWriteBucket(\n\t\t\tchanKey,\n\t\t)\n\t\tif chanBucket == nil {\n\t\t\treturn ErrNoActiveChannels\n\t\t}\n\n\t\t// Before we delete the channel state, we'll read out the full\n\t\t// details, as we'll also store portions of this information\n\t\t// for record keeping.\n\t\tchanState, err := fetchOpenChannel(\n\t\t\tchanBucket, &c.FundingOutpoint,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Delete all the forwarding packages stored for this particular\n\t\t// channel.\n\t\tif err = chanState.Packager.Wipe(tx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Now that the index to this channel has been deleted, purge\n\t\t// the remaining channel metadata from the database.\n\t\terr = deleteOpenChannel(chanBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// We'll also remove the channel from the frozen channel bucket\n\t\t// if we need to.\n\t\tif c.ChanType.IsFrozen() || c.ChanType.HasLeaseExpiration() {\n\t\t\terr := deleteThawHeight(chanBucket)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// With the base channel data deleted, attempt to delete the\n\t\t// information stored within the revocation log.\n\t\tif err := deleteLogBucket(chanBucket); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = chainBucket.DeleteNestedBucket(chanPointBuf.Bytes())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Fetch the outpoint bucket to see if the outpoint exists or\n\t\t// not.\n\t\topBucket := tx.ReadWriteBucket(outpointBucket)\n\n\t\t// Add the closed outpoint to our outpoint index. This should\n\t\t// replace an open outpoint in the index.\n\t\tif opBucket.Get(chanPointBuf.Bytes()) == nil {\n\t\t\treturn ErrMissingIndexEntry\n\t\t}\n\n\t\tstatus := uint8(outpointClosed)\n\n\t\t// Write the IndexStatus of this outpoint as the first entry in a tlv\n\t\t// stream.\n\t\tstatusRecord := tlv.MakePrimitiveRecord(indexStatusType, &status)\n\t\topStream, err := tlv.NewStream(statusRecord)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar b bytes.Buffer\n\t\tif err := opStream.Encode(&b); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Finally add the closed outpoint and tlv stream to the index.\n\t\tif err := opBucket.Put(chanPointBuf.Bytes(), b.Bytes()); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Add channel state to the historical channel bucket.\n\t\thistoricalBucket, err := tx.CreateTopLevelBucket(\n\t\t\thistoricalChannelBucket,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thistoricalChanBucket, err :=\n\t\t\thistoricalBucket.CreateBucketIfNotExists(chanKey)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Apply any additional statuses to the channel state.\n\t\tfor _, status := range statuses {\n\t\t\tchanState.chanStatus |= status\n\t\t}\n\n\t\terr = putOpenChannel(historicalChanBucket, chanState)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Finally, create a summary of this channel in the closed\n\t\t// channel bucket for this node.\n\t\treturn putChannelCloseSummary(\n\t\t\ttx, chanPointBuf.Bytes(), summary, chanState,\n\t\t)\n\t}, func() {})\n}\n\n// ChannelSnapshot is a frozen snapshot of the current channel state. A\n// snapshot is detached from the original channel that generated it, providing\n// read-only access to the current or prior state of an active channel.\n//\n// TODO(roasbeef): remove all together? pretty much just commitment",
      "length": 3681,
      "tokens": 507,
      "embedding": []
    },
    {
      "slug": "type ChannelSnapshot struct {",
      "content": "type ChannelSnapshot struct {\n\t// RemoteIdentity is the identity public key of the remote node that we\n\t// are maintaining the open channel with.\n\tRemoteIdentity btcec.PublicKey\n\n\t// ChanPoint is the outpoint that created the channel. This output is\n\t// found within the funding transaction and uniquely identified the\n\t// channel on the resident chain.\n\tChannelPoint wire.OutPoint\n\n\t// ChainHash is the genesis hash of the chain that the channel resides\n\t// within.\n\tChainHash chainhash.Hash\n\n\t// Capacity is the total capacity of the channel.\n\tCapacity btcutil.Amount\n\n\t// TotalMSatSent is the total number of milli-satoshis we've sent\n\t// within this channel.\n\tTotalMSatSent lnwire.MilliSatoshi\n\n\t// TotalMSatReceived is the total number of milli-satoshis we've\n\t// received within this channel.\n\tTotalMSatReceived lnwire.MilliSatoshi\n\n\t// ChannelCommitment is the current up-to-date commitment for the\n\t// target channel.\n\tChannelCommitment\n}\n\n// Snapshot returns a read-only snapshot of the current channel state. This\n// snapshot includes information concerning the current settled balance within\n// the channel, metadata detailing total flows, and any outstanding HTLCs.",
      "length": 1116,
      "tokens": 159,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) Snapshot() *ChannelSnapshot {",
      "content": "func (c *OpenChannel) Snapshot() *ChannelSnapshot {\n\tc.RLock()\n\tdefer c.RUnlock()\n\n\tlocalCommit := c.LocalCommitment\n\tsnapshot := &ChannelSnapshot{\n\t\tRemoteIdentity:    *c.IdentityPub,\n\t\tChannelPoint:      c.FundingOutpoint,\n\t\tCapacity:          c.Capacity,\n\t\tTotalMSatSent:     c.TotalMSatSent,\n\t\tTotalMSatReceived: c.TotalMSatReceived,\n\t\tChainHash:         c.ChainHash,\n\t\tChannelCommitment: ChannelCommitment{\n\t\t\tLocalBalance:  localCommit.LocalBalance,\n\t\t\tRemoteBalance: localCommit.RemoteBalance,\n\t\t\tCommitHeight:  localCommit.CommitHeight,\n\t\t\tCommitFee:     localCommit.CommitFee,\n\t\t},\n\t}\n\n\t// Copy over the current set of HTLCs to ensure the caller can't mutate\n\t// our internal state.\n\tsnapshot.Htlcs = make([]HTLC, len(localCommit.Htlcs))\n\tfor i, h := range localCommit.Htlcs {\n\t\tsnapshot.Htlcs[i] = h.Copy()\n\t}\n\n\treturn snapshot\n}\n\n// LatestCommitments returns the two latest commitments for both the local and\n// remote party. These commitments are read from disk to ensure that only the\n// latest fully committed state is returned. The first commitment returned is\n// the local commitment, and the second returned is the remote commitment.",
      "length": 1066,
      "tokens": 119,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) LatestCommitments() (*ChannelCommitment, *ChannelCommitment, error) {",
      "content": "func (c *OpenChannel) LatestCommitments() (*ChannelCommitment, *ChannelCommitment, error) {\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn fetchChanCommitments(chanBucket, c)\n\t}, func() {})\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn &c.LocalCommitment, &c.RemoteCommitment, nil\n}\n\n// RemoteRevocationStore returns the most up to date commitment version of the\n// revocation storage tree for the remote party. This method can be used when\n// acting on a possible contract breach to ensure, that the caller has the most\n// up to date information required to deliver justice.",
      "length": 623,
      "tokens": 95,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) RemoteRevocationStore() (shachain.Store, error) {",
      "content": "func (c *OpenChannel) RemoteRevocationStore() (shachain.Store, error) {\n\terr := kvdb.View(c.Db.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchChanBucket(\n\t\t\ttx, c.IdentityPub, &c.FundingOutpoint, c.ChainHash,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn fetchChanRevocationState(chanBucket, c)\n\t}, func() {})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c.RevocationStore, nil\n}\n\n// AbsoluteThawHeight determines a frozen channel's absolute thaw height. If the\n// channel is not frozen, then 0 is returned.",
      "length": 437,
      "tokens": 63,
      "embedding": []
    },
    {
      "slug": "func (c *OpenChannel) AbsoluteThawHeight() (uint32, error) {",
      "content": "func (c *OpenChannel) AbsoluteThawHeight() (uint32, error) {\n\t// Only frozen channels have a thaw height.\n\tif !c.ChanType.IsFrozen() && !c.ChanType.HasLeaseExpiration() {\n\t\treturn 0, nil\n\t}\n\n\t// If the channel has the frozen bit set and it's thaw height is below\n\t// the absolute threshold, then it's interpreted as a relative height to\n\t// the chain's current height.\n\tif c.ChanType.IsFrozen() && c.ThawHeight < AbsoluteThawHeightThreshold {\n\t\t// We'll only known of the channel's short ID once it's\n\t\t// confirmed.\n\t\tif c.IsPending {\n\t\t\treturn 0, errors.New(\"cannot use relative thaw \" +\n\t\t\t\t\"height for unconfirmed channel\")\n\t\t}\n\n\t\t// For non-zero-conf channels, this is the base height to use.\n\t\tblockHeightBase := c.ShortChannelID.BlockHeight\n\n\t\t// If this is a zero-conf channel, the ShortChannelID will be\n\t\t// an alias.\n\t\tif c.IsZeroConf() {\n\t\t\tif !c.ZeroConfConfirmed() {\n\t\t\t\treturn 0, errors.New(\"cannot use relative \" +\n\t\t\t\t\t\"height for unconfirmed zero-conf \" +\n\t\t\t\t\t\"channel\")\n\t\t\t}\n\n\t\t\t// Use the confirmed SCID's BlockHeight.\n\t\t\tblockHeightBase = c.confirmedScid.BlockHeight\n\t\t}\n\n\t\treturn blockHeightBase + c.ThawHeight, nil\n\t}\n\n\treturn c.ThawHeight, nil\n}\n",
      "length": 1073,
      "tokens": 154,
      "embedding": []
    },
    {
      "slug": "func putChannelCloseSummary(tx kvdb.RwTx, chanID []byte,",
      "content": "func putChannelCloseSummary(tx kvdb.RwTx, chanID []byte,\n\tsummary *ChannelCloseSummary, lastChanState *OpenChannel) error {\n\n\tclosedChanBucket, err := tx.CreateTopLevelBucket(closedChannelBucket)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsummary.RemoteCurrentRevocation = lastChanState.RemoteCurrentRevocation\n\tsummary.RemoteNextRevocation = lastChanState.RemoteNextRevocation\n\tsummary.LocalChanConfig = lastChanState.LocalChanCfg\n\n\tvar b bytes.Buffer\n\tif err := serializeChannelCloseSummary(&b, summary); err != nil {\n\t\treturn err\n\t}\n\n\treturn closedChanBucket.Put(chanID, b.Bytes())\n}\n",
      "length": 504,
      "tokens": 46,
      "embedding": []
    },
    {
      "slug": "func serializeChannelCloseSummary(w io.Writer, cs *ChannelCloseSummary) error {",
      "content": "func serializeChannelCloseSummary(w io.Writer, cs *ChannelCloseSummary) error {\n\terr := WriteElements(w,\n\t\tcs.ChanPoint, cs.ShortChanID, cs.ChainHash, cs.ClosingTXID,\n\t\tcs.CloseHeight, cs.RemotePub, cs.Capacity, cs.SettledBalance,\n\t\tcs.TimeLockedBalance, cs.CloseType, cs.IsPending,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If this is a close channel summary created before the addition of\n\t// the new fields, then we can exit here.\n\tif cs.RemoteCurrentRevocation == nil {\n\t\treturn WriteElements(w, false)\n\t}\n\n\t// If fields are present, write boolean to indicate this, and continue.\n\tif err := WriteElements(w, true); err != nil {\n\t\treturn err\n\t}\n\n\tif err := WriteElements(w, cs.RemoteCurrentRevocation); err != nil {\n\t\treturn err\n\t}\n\n\tif err := writeChanConfig(w, &cs.LocalChanConfig); err != nil {\n\t\treturn err\n\t}\n\n\t// The RemoteNextRevocation field is optional, as it's possible for a\n\t// channel to be closed before we learn of the next unrevoked\n\t// revocation point for the remote party. Write a boolean indicating\n\t// whether this field is present or not.\n\tif err := WriteElements(w, cs.RemoteNextRevocation != nil); err != nil {\n\t\treturn err\n\t}\n\n\t// Write the field, if present.\n\tif cs.RemoteNextRevocation != nil {\n\t\tif err = WriteElements(w, cs.RemoteNextRevocation); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Write whether the channel sync message is present.\n\tif err := WriteElements(w, cs.LastChanSyncMsg != nil); err != nil {\n\t\treturn err\n\t}\n\n\t// Write the channel sync message, if present.\n\tif cs.LastChanSyncMsg != nil {\n\t\tif err := WriteElements(w, cs.LastChanSyncMsg); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n",
      "length": 1496,
      "tokens": 234,
      "embedding": []
    },
    {
      "slug": "func deserializeCloseChannelSummary(r io.Reader) (*ChannelCloseSummary, error) {",
      "content": "func deserializeCloseChannelSummary(r io.Reader) (*ChannelCloseSummary, error) {\n\tc := &ChannelCloseSummary{}\n\n\terr := ReadElements(r,\n\t\t&c.ChanPoint, &c.ShortChanID, &c.ChainHash, &c.ClosingTXID,\n\t\t&c.CloseHeight, &c.RemotePub, &c.Capacity, &c.SettledBalance,\n\t\t&c.TimeLockedBalance, &c.CloseType, &c.IsPending,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We'll now check to see if the channel close summary was encoded with\n\t// any of the additional optional fields.\n\tvar hasNewFields bool\n\terr = ReadElements(r, &hasNewFields)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If fields are not present, we can return.\n\tif !hasNewFields {\n\t\treturn c, nil\n\t}\n\n\t// Otherwise read the new fields.\n\tif err := ReadElements(r, &c.RemoteCurrentRevocation); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := readChanConfig(r, &c.LocalChanConfig); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Finally, we'll attempt to read the next unrevoked commitment point\n\t// for the remote party. If we closed the channel before receiving a\n\t// funding locked message then this might not be present. A boolean\n\t// indicating whether the field is present will come first.\n\tvar hasRemoteNextRevocation bool\n\terr = ReadElements(r, &hasRemoteNextRevocation)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If this field was written, read it.\n\tif hasRemoteNextRevocation {\n\t\terr = ReadElements(r, &c.RemoteNextRevocation)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Check if we have a channel sync message to read.\n\tvar hasChanSyncMsg bool\n\terr = ReadElements(r, &hasChanSyncMsg)\n\tif err == io.EOF {\n\t\treturn c, nil\n\t} else if err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If a chan sync message is present, read it.\n\tif hasChanSyncMsg {\n\t\t// We must pass in reference to a lnwire.Message for the codec\n\t\t// to support it.\n\t\tvar msg lnwire.Message\n\t\tif err := ReadElements(r, &msg); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tchanSync, ok := msg.(*lnwire.ChannelReestablish)\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"unable cast db Message to \" +\n\t\t\t\t\"ChannelReestablish\")\n\t\t}\n\t\tc.LastChanSyncMsg = chanSync\n\t}\n\n\treturn c, nil\n}\n",
      "length": 1917,
      "tokens": 307,
      "embedding": []
    },
    {
      "slug": "func writeChanConfig(b io.Writer, c *ChannelConfig) error {",
      "content": "func writeChanConfig(b io.Writer, c *ChannelConfig) error {\n\treturn WriteElements(b,\n\t\tc.DustLimit, c.MaxPendingAmount, c.ChanReserve, c.MinHTLC,\n\t\tc.MaxAcceptedHtlcs, c.CsvDelay, c.MultiSigKey,\n\t\tc.RevocationBasePoint, c.PaymentBasePoint, c.DelayBasePoint,\n\t\tc.HtlcBasePoint,\n\t)\n}\n\n// fundingTxPresent returns true if expect the funding transcation to be found\n// on disk or already populated within the passed open channel struct.",
      "length": 363,
      "tokens": 39,
      "embedding": []
    },
    {
      "slug": "func fundingTxPresent(channel *OpenChannel) bool {",
      "content": "func fundingTxPresent(channel *OpenChannel) bool {\n\tchanType := channel.ChanType\n\n\treturn chanType.IsSingleFunder() && chanType.HasFundingTx() &&\n\t\tchannel.IsInitiator &&\n\t\t!channel.hasChanStatus(ChanStatusRestored)\n}\n",
      "length": 161,
      "tokens": 12,
      "embedding": []
    },
    {
      "slug": "func putChanInfo(chanBucket kvdb.RwBucket, channel *OpenChannel) error {",
      "content": "func putChanInfo(chanBucket kvdb.RwBucket, channel *OpenChannel) error {\n\tvar w bytes.Buffer\n\tif err := WriteElements(&w,\n\t\tchannel.ChanType, channel.ChainHash, channel.FundingOutpoint,\n\t\tchannel.ShortChannelID, channel.IsPending, channel.IsInitiator,\n\t\tchannel.chanStatus, channel.FundingBroadcastHeight,\n\t\tchannel.NumConfsRequired, channel.ChannelFlags,\n\t\tchannel.IdentityPub, channel.Capacity, channel.TotalMSatSent,\n\t\tchannel.TotalMSatReceived,\n\t); err != nil {\n\t\treturn err\n\t}\n\n\t// For single funder channels that we initiated, and we have the\n\t// funding transaction, then write the funding txn.\n\tif fundingTxPresent(channel) {\n\t\tif err := WriteElement(&w, channel.FundingTxn); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := writeChanConfig(&w, &channel.LocalChanCfg); err != nil {\n\t\treturn err\n\t}\n\tif err := writeChanConfig(&w, &channel.RemoteChanCfg); err != nil {\n\t\treturn err\n\t}\n\n\t// Convert balance fields into uint64.\n\tlocalBalance := uint64(channel.InitialLocalBalance)\n\tremoteBalance := uint64(channel.InitialRemoteBalance)\n\n\t// Create the tlv stream.\n\ttlvStream, err := tlv.NewStream(\n\t\t// Write the RevocationKeyLocator as the first entry in a tlv\n\t\t// stream.\n\t\tMakeKeyLocRecord(\n\t\t\tkeyLocType, &channel.RevocationKeyLocator,\n\t\t),\n\t\ttlv.MakePrimitiveRecord(\n\t\t\tinitialLocalBalanceType, &localBalance,\n\t\t),\n\t\ttlv.MakePrimitiveRecord(\n\t\t\tinitialRemoteBalanceType, &remoteBalance,\n\t\t),\n\t\tMakeScidRecord(realScidType, &channel.confirmedScid),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := tlvStream.Encode(&w); err != nil {\n\t\treturn err\n\t}\n\n\tif err := chanBucket.Put(chanInfoKey, w.Bytes()); err != nil {\n\t\treturn err\n\t}\n\n\t// Finally, add optional shutdown scripts for the local and remote peer if\n\t// they are present.\n\tif err := putOptionalUpfrontShutdownScript(\n\t\tchanBucket, localUpfrontShutdownKey, channel.LocalShutdownScript,\n\t); err != nil {\n\t\treturn err\n\t}\n\n\treturn putOptionalUpfrontShutdownScript(\n\t\tchanBucket, remoteUpfrontShutdownKey, channel.RemoteShutdownScript,\n\t)\n}\n\n// putOptionalUpfrontShutdownScript adds a shutdown script under the key\n// provided if it has a non-zero length.",
      "length": 1967,
      "tokens": 225,
      "embedding": []
    },
    {
      "slug": "func putOptionalUpfrontShutdownScript(chanBucket kvdb.RwBucket, key []byte,",
      "content": "func putOptionalUpfrontShutdownScript(chanBucket kvdb.RwBucket, key []byte,\n\tscript []byte) error {\n\t// If the script is empty, we do not need to add anything.\n\tif len(script) == 0 {\n\t\treturn nil\n\t}\n\n\tvar w bytes.Buffer\n\tif err := WriteElement(&w, script); err != nil {\n\t\treturn err\n\t}\n\n\treturn chanBucket.Put(key, w.Bytes())\n}\n\n// getOptionalUpfrontShutdownScript reads the shutdown script stored under the\n// key provided if it is present. Upfront shutdown scripts are optional, so the\n// function returns with no error if the key is not present.",
      "length": 456,
      "tokens": 79,
      "embedding": []
    },
    {
      "slug": "func getOptionalUpfrontShutdownScript(chanBucket kvdb.RBucket, key []byte,",
      "content": "func getOptionalUpfrontShutdownScript(chanBucket kvdb.RBucket, key []byte,\n\tscript *lnwire.DeliveryAddress) error {\n\n\t// Return early if the bucket does not exit, a shutdown script was not set.\n\tbs := chanBucket.Get(key)\n\tif bs == nil {\n\t\treturn nil\n\t}\n\n\tvar tempScript []byte\n\tr := bytes.NewReader(bs)\n\tif err := ReadElement(r, &tempScript); err != nil {\n\t\treturn err\n\t}\n\t*script = tempScript\n\n\treturn nil\n}\n",
      "length": 317,
      "tokens": 54,
      "embedding": []
    },
    {
      "slug": "func serializeChanCommit(w io.Writer, c *ChannelCommitment) error {",
      "content": "func serializeChanCommit(w io.Writer, c *ChannelCommitment) error {\n\tif err := WriteElements(w,\n\t\tc.CommitHeight, c.LocalLogIndex, c.LocalHtlcIndex,\n\t\tc.RemoteLogIndex, c.RemoteHtlcIndex, c.LocalBalance,\n\t\tc.RemoteBalance, c.CommitFee, c.FeePerKw, c.CommitTx,\n\t\tc.CommitSig,\n\t); err != nil {\n\t\treturn err\n\t}\n\n\treturn SerializeHtlcs(w, c.Htlcs...)\n}\n",
      "length": 270,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func putChanCommitment(chanBucket kvdb.RwBucket, c *ChannelCommitment,",
      "content": "func putChanCommitment(chanBucket kvdb.RwBucket, c *ChannelCommitment,\n\tlocal bool) error {\n\n\tvar commitKey []byte\n\tif local {\n\t\tcommitKey = append(chanCommitmentKey, byte(0x00))\n\t} else {\n\t\tcommitKey = append(chanCommitmentKey, byte(0x01))\n\t}\n\n\tvar b bytes.Buffer\n\tif err := serializeChanCommit(&b, c); err != nil {\n\t\treturn err\n\t}\n\n\treturn chanBucket.Put(commitKey, b.Bytes())\n}\n",
      "length": 294,
      "tokens": 41,
      "embedding": []
    },
    {
      "slug": "func putChanCommitments(chanBucket kvdb.RwBucket, channel *OpenChannel) error {",
      "content": "func putChanCommitments(chanBucket kvdb.RwBucket, channel *OpenChannel) error {\n\t// If this is a restored channel, then we don't have any commitments to\n\t// write.\n\tif channel.hasChanStatus(ChanStatusRestored) {\n\t\treturn nil\n\t}\n\n\terr := putChanCommitment(\n\t\tchanBucket, &channel.LocalCommitment, true,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn putChanCommitment(\n\t\tchanBucket, &channel.RemoteCommitment, false,\n\t)\n}\n",
      "length": 322,
      "tokens": 44,
      "embedding": []
    },
    {
      "slug": "func putChanRevocationState(chanBucket kvdb.RwBucket, channel *OpenChannel) error {",
      "content": "func putChanRevocationState(chanBucket kvdb.RwBucket, channel *OpenChannel) error {\n\tvar b bytes.Buffer\n\terr := WriteElements(\n\t\t&b, channel.RemoteCurrentRevocation, channel.RevocationProducer,\n\t\tchannel.RevocationStore,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// TODO(roasbeef): don't keep producer on disk\n\n\t// If the next revocation is present, which is only the case after the\n\t// FundingLocked message has been sent, then we'll write it to disk.\n\tif channel.RemoteNextRevocation != nil {\n\t\terr = WriteElements(&b, channel.RemoteNextRevocation)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn chanBucket.Put(revocationStateKey, b.Bytes())\n}\n",
      "length": 537,
      "tokens": 74,
      "embedding": []
    },
    {
      "slug": "func readChanConfig(b io.Reader, c *ChannelConfig) error {",
      "content": "func readChanConfig(b io.Reader, c *ChannelConfig) error {\n\treturn ReadElements(b,\n\t\t&c.DustLimit, &c.MaxPendingAmount, &c.ChanReserve,\n\t\t&c.MinHTLC, &c.MaxAcceptedHtlcs, &c.CsvDelay,\n\t\t&c.MultiSigKey, &c.RevocationBasePoint,\n\t\t&c.PaymentBasePoint, &c.DelayBasePoint,\n\t\t&c.HtlcBasePoint,\n\t)\n}\n",
      "length": 226,
      "tokens": 15,
      "embedding": []
    },
    {
      "slug": "func fetchChanInfo(chanBucket kvdb.RBucket, channel *OpenChannel) error {",
      "content": "func fetchChanInfo(chanBucket kvdb.RBucket, channel *OpenChannel) error {\n\tinfoBytes := chanBucket.Get(chanInfoKey)\n\tif infoBytes == nil {\n\t\treturn ErrNoChanInfoFound\n\t}\n\tr := bytes.NewReader(infoBytes)\n\n\tif err := ReadElements(r,\n\t\t&channel.ChanType, &channel.ChainHash, &channel.FundingOutpoint,\n\t\t&channel.ShortChannelID, &channel.IsPending, &channel.IsInitiator,\n\t\t&channel.chanStatus, &channel.FundingBroadcastHeight,\n\t\t&channel.NumConfsRequired, &channel.ChannelFlags,\n\t\t&channel.IdentityPub, &channel.Capacity, &channel.TotalMSatSent,\n\t\t&channel.TotalMSatReceived,\n\t); err != nil {\n\t\treturn err\n\t}\n\n\t// For single funder channels that we initiated and have the funding\n\t// transaction to, read the funding txn.\n\tif fundingTxPresent(channel) {\n\t\tif err := ReadElement(r, &channel.FundingTxn); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := readChanConfig(r, &channel.LocalChanCfg); err != nil {\n\t\treturn err\n\t}\n\tif err := readChanConfig(r, &channel.RemoteChanCfg); err != nil {\n\t\treturn err\n\t}\n\n\t// Retrieve the boolean stored under lastWasRevokeKey.\n\tlastWasRevokeBytes := chanBucket.Get(lastWasRevokeKey)\n\tif lastWasRevokeBytes == nil {\n\t\t// If nothing has been stored under this key, we store false in the\n\t\t// OpenChannel struct.\n\t\tchannel.LastWasRevoke = false\n\t} else {\n\t\t// Otherwise, read the value into the LastWasRevoke field.\n\t\trevokeReader := bytes.NewReader(lastWasRevokeBytes)\n\t\terr := ReadElements(revokeReader, &channel.LastWasRevoke)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Create balance fields in uint64.\n\tvar (\n\t\tlocalBalance  uint64\n\t\tremoteBalance uint64\n\t)\n\n\t// Create the tlv stream.\n\ttlvStream, err := tlv.NewStream(\n\t\t// Write the RevocationKeyLocator as the first entry in a tlv\n\t\t// stream.\n\t\tMakeKeyLocRecord(\n\t\t\tkeyLocType, &channel.RevocationKeyLocator,\n\t\t),\n\t\ttlv.MakePrimitiveRecord(\n\t\t\tinitialLocalBalanceType, &localBalance,\n\t\t),\n\t\ttlv.MakePrimitiveRecord(\n\t\t\tinitialRemoteBalanceType, &remoteBalance,\n\t\t),\n\t\tMakeScidRecord(realScidType, &channel.confirmedScid),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := tlvStream.Decode(r); err != nil {\n\t\treturn err\n\t}\n\n\t// Attach the balance fields.\n\tchannel.InitialLocalBalance = lnwire.MilliSatoshi(localBalance)\n\tchannel.InitialRemoteBalance = lnwire.MilliSatoshi(remoteBalance)\n\n\tchannel.Packager = NewChannelPackager(channel.ShortChannelID)\n\n\t// Finally, read the optional shutdown scripts.\n\tif err := getOptionalUpfrontShutdownScript(\n\t\tchanBucket, localUpfrontShutdownKey, &channel.LocalShutdownScript,\n\t); err != nil {\n\t\treturn err\n\t}\n\n\treturn getOptionalUpfrontShutdownScript(\n\t\tchanBucket, remoteUpfrontShutdownKey, &channel.RemoteShutdownScript,\n\t)\n}\n",
      "length": 2482,
      "tokens": 274,
      "embedding": []
    },
    {
      "slug": "func deserializeChanCommit(r io.Reader) (ChannelCommitment, error) {",
      "content": "func deserializeChanCommit(r io.Reader) (ChannelCommitment, error) {\n\tvar c ChannelCommitment\n\n\terr := ReadElements(r,\n\t\t&c.CommitHeight, &c.LocalLogIndex, &c.LocalHtlcIndex, &c.RemoteLogIndex,\n\t\t&c.RemoteHtlcIndex, &c.LocalBalance, &c.RemoteBalance,\n\t\t&c.CommitFee, &c.FeePerKw, &c.CommitTx, &c.CommitSig,\n\t)\n\tif err != nil {\n\t\treturn c, err\n\t}\n\n\tc.Htlcs, err = DeserializeHtlcs(r)\n\tif err != nil {\n\t\treturn c, err\n\t}\n\n\treturn c, nil\n}\n",
      "length": 350,
      "tokens": 44,
      "embedding": []
    },
    {
      "slug": "func fetchChanCommitment(chanBucket kvdb.RBucket, local bool) (ChannelCommitment, error) {",
      "content": "func fetchChanCommitment(chanBucket kvdb.RBucket, local bool) (ChannelCommitment, error) {\n\tvar commitKey []byte\n\tif local {\n\t\tcommitKey = append(chanCommitmentKey, byte(0x00))\n\t} else {\n\t\tcommitKey = append(chanCommitmentKey, byte(0x01))\n\t}\n\n\tcommitBytes := chanBucket.Get(commitKey)\n\tif commitBytes == nil {\n\t\treturn ChannelCommitment{}, ErrNoCommitmentsFound\n\t}\n\n\tr := bytes.NewReader(commitBytes)\n\treturn deserializeChanCommit(r)\n}\n",
      "length": 330,
      "tokens": 36,
      "embedding": []
    },
    {
      "slug": "func fetchChanCommitments(chanBucket kvdb.RBucket, channel *OpenChannel) error {",
      "content": "func fetchChanCommitments(chanBucket kvdb.RBucket, channel *OpenChannel) error {\n\tvar err error\n\n\t// If this is a restored channel, then we don't have any commitments to\n\t// read.\n\tif channel.hasChanStatus(ChanStatusRestored) {\n\t\treturn nil\n\t}\n\n\tchannel.LocalCommitment, err = fetchChanCommitment(chanBucket, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\tchannel.RemoteCommitment, err = fetchChanCommitment(chanBucket, false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n",
      "length": 368,
      "tokens": 54,
      "embedding": []
    },
    {
      "slug": "func fetchChanRevocationState(chanBucket kvdb.RBucket, channel *OpenChannel) error {",
      "content": "func fetchChanRevocationState(chanBucket kvdb.RBucket, channel *OpenChannel) error {\n\trevBytes := chanBucket.Get(revocationStateKey)\n\tif revBytes == nil {\n\t\treturn ErrNoRevocationsFound\n\t}\n\tr := bytes.NewReader(revBytes)\n\n\terr := ReadElements(\n\t\tr, &channel.RemoteCurrentRevocation, &channel.RevocationProducer,\n\t\t&channel.RevocationStore,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If there aren't any bytes left in the buffer, then we don't yet have\n\t// the next remote revocation, so we can exit early here.\n\tif r.Len() == 0 {\n\t\treturn nil\n\t}\n\n\t// Otherwise we'll read the next revocation for the remote party which\n\t// is always the last item within the buffer.\n\treturn ReadElements(r, &channel.RemoteNextRevocation)\n}\n",
      "length": 612,
      "tokens": 89,
      "embedding": []
    },
    {
      "slug": "func deleteOpenChannel(chanBucket kvdb.RwBucket) error {",
      "content": "func deleteOpenChannel(chanBucket kvdb.RwBucket) error {\n\tif err := chanBucket.Delete(chanInfoKey); err != nil {\n\t\treturn err\n\t}\n\n\terr := chanBucket.Delete(append(chanCommitmentKey, byte(0x00)))\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = chanBucket.Delete(append(chanCommitmentKey, byte(0x01)))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := chanBucket.Delete(revocationStateKey); err != nil {\n\t\treturn err\n\t}\n\n\tif diff := chanBucket.Get(commitDiffKey); diff != nil {\n\t\treturn chanBucket.Delete(commitDiffKey)\n\t}\n\n\treturn nil\n}\n\n// makeLogKey converts a uint64 into an 8 byte array.",
      "length": 496,
      "tokens": 70,
      "embedding": []
    },
    {
      "slug": "func makeLogKey(updateNum uint64) [8]byte {",
      "content": "func makeLogKey(updateNum uint64) [8]byte {\n\tvar key [8]byte\n\tbyteOrder.PutUint64(key[:], updateNum)\n\treturn key\n}\n",
      "length": 67,
      "tokens": 8,
      "embedding": []
    },
    {
      "slug": "func fetchThawHeight(chanBucket kvdb.RBucket) (uint32, error) {",
      "content": "func fetchThawHeight(chanBucket kvdb.RBucket) (uint32, error) {\n\tvar height uint32\n\n\theightBytes := chanBucket.Get(frozenChanKey)\n\theightReader := bytes.NewReader(heightBytes)\n\n\tif err := ReadElements(heightReader, &height); err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn height, nil\n}\n",
      "length": 205,
      "tokens": 26,
      "embedding": []
    },
    {
      "slug": "func storeThawHeight(chanBucket kvdb.RwBucket, height uint32) error {",
      "content": "func storeThawHeight(chanBucket kvdb.RwBucket, height uint32) error {\n\tvar heightBuf bytes.Buffer\n\tif err := WriteElements(&heightBuf, height); err != nil {\n\t\treturn err\n\t}\n\n\treturn chanBucket.Put(frozenChanKey, heightBuf.Bytes())\n}\n",
      "length": 156,
      "tokens": 19,
      "embedding": []
    },
    {
      "slug": "func deleteThawHeight(chanBucket kvdb.RwBucket) error {",
      "content": "func deleteThawHeight(chanBucket kvdb.RwBucket) error {\n\treturn chanBucket.Delete(frozenChanKey)\n}\n\n// EKeyLocator is an encoder for keychain.KeyLocator.",
      "length": 94,
      "tokens": 10,
      "embedding": []
    },
    {
      "slug": "func EKeyLocator(w io.Writer, val interface{}, buf *[8]byte) error {",
      "content": "func EKeyLocator(w io.Writer, val interface{}, buf *[8]byte) error {\n\tif v, ok := val.(*keychain.KeyLocator); ok {\n\t\terr := tlv.EUint32T(w, uint32(v.Family), buf)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn tlv.EUint32T(w, v.Index, buf)\n\t}\n\treturn tlv.NewTypeForEncodingErr(val, \"keychain.KeyLocator\")\n}\n\n// DKeyLocator is a decoder for keychain.KeyLocator.",
      "length": 279,
      "tokens": 36,
      "embedding": []
    },
    {
      "slug": "func DKeyLocator(r io.Reader, val interface{}, buf *[8]byte, l uint64) error {",
      "content": "func DKeyLocator(r io.Reader, val interface{}, buf *[8]byte, l uint64) error {\n\tif v, ok := val.(*keychain.KeyLocator); ok {\n\t\tvar family uint32\n\t\terr := tlv.DUint32(r, &family, buf, 4)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tv.Family = keychain.KeyFamily(family)\n\n\t\treturn tlv.DUint32(r, &v.Index, buf, 4)\n\t}\n\treturn tlv.NewTypeForDecodingErr(val, \"keychain.KeyLocator\", l, 8)\n}\n\n// MakeKeyLocRecord creates a Record out of a KeyLocator using the passed\n// Type and the EKeyLocator and DKeyLocator functions. The size will always be\n// 8 as KeyFamily is uint32 and the Index is uint32.",
      "length": 490,
      "tokens": 75,
      "embedding": []
    },
    {
      "slug": "func MakeKeyLocRecord(typ tlv.Type, keyLoc *keychain.KeyLocator) tlv.Record {",
      "content": "func MakeKeyLocRecord(typ tlv.Type, keyLoc *keychain.KeyLocator) tlv.Record {\n\treturn tlv.MakeStaticRecord(typ, keyLoc, 8, EKeyLocator, DKeyLocator)\n}\n\n// MakeScidRecord creates a Record out of a ShortChannelID using the passed\n// Type and the EShortChannelID and DShortChannelID functions. The size will\n// always be 8 for the ShortChannelID.",
      "length": 260,
      "tokens": 37,
      "embedding": []
    },
    {
      "slug": "func MakeScidRecord(typ tlv.Type, scid *lnwire.ShortChannelID) tlv.Record {",
      "content": "func MakeScidRecord(typ tlv.Type, scid *lnwire.ShortChannelID) tlv.Record {\n\treturn tlv.MakeStaticRecord(\n\t\ttyp, scid, 8, lnwire.EShortChannelID, lnwire.DShortChannelID,\n\t)\n}\n",
      "length": 95,
      "tokens": 9,
      "embedding": []
    }
  ]
}