{
  "filepath": "../implementations/go/lnd/channeldb/db.go",
  "package": "channeldb",
  "sections": [
    {
      "slug": "type migration func(tx kvdb.RwTx) error",
      "content": "type migration func(tx kvdb.RwTx) error\n\n// mandatoryVersion defines a db version that must be applied before the lnd\n// starts.",
      "length": 86,
      "tokens": 15,
      "embedding": []
    },
    {
      "slug": "type mandatoryVersion struct {",
      "content": "type mandatoryVersion struct {\n\tnumber    uint32\n\tmigration migration\n}\n\n// MigrationConfig is an interface combines the config interfaces of all\n// optional migrations.",
      "length": 133,
      "tokens": 19,
      "embedding": []
    },
    {
      "slug": "type MigrationConfig interface {",
      "content": "type MigrationConfig interface {\n\tmigration30.MigrateRevLogConfig\n}\n\n// MigrationConfigImpl is a super set of all the various migration configs and\n// an implementation of MigrationConfig.",
      "length": 151,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "type MigrationConfigImpl struct {",
      "content": "type MigrationConfigImpl struct {\n\tmigration30.MigrateRevLogConfigImpl\n}\n\n// optionalMigration defines an optional migration function. When a migration\n// is optional, it usually involves a large scale of changes that might touch\n// millions of keys. Due to OOM concern, the update cannot be safely done\n// within one db transaction. Thus, for optional migrations, they must take the\n// db backend and construct transactions as needed.",
      "length": 394,
      "tokens": 61,
      "embedding": []
    },
    {
      "slug": "type optionalMigration func(db kvdb.Backend, cfg MigrationConfig) error",
      "content": "type optionalMigration func(db kvdb.Backend, cfg MigrationConfig) error\n\n// optionalVersion defines a db version that can be optionally applied. When\n// applying migrations, we must apply all the mandatory migrations first before\n// attempting optional ones.",
      "length": 183,
      "tokens": 28,
      "embedding": []
    },
    {
      "slug": "type optionalVersion struct {",
      "content": "type optionalVersion struct {\n\tname      string\n\tmigration optionalMigration\n}\n\nvar (\n\t// dbVersions is storing all mandatory versions of database. If current\n\t// version of database don't match with latest version this list will\n\t// be used for retrieving all migration function that are need to apply\n\t// to the current db.\n\tdbVersions = []mandatoryVersion{\n\t\t{\n\t\t\t// The base DB version requires no migration.\n\t\t\tnumber:    0,\n\t\t\tmigration: nil,\n\t\t},\n\t\t{\n\t\t\t// The version of the database where two new indexes\n\t\t\t// for the update time of node and channel updates were\n\t\t\t// added.\n\t\t\tnumber:    1,\n\t\t\tmigration: migration_01_to_11.MigrateNodeAndEdgeUpdateIndex,\n\t\t},\n\t\t{\n\t\t\t// The DB version that added the invoice event time\n\t\t\t// series.\n\t\t\tnumber:    2,\n\t\t\tmigration: migration_01_to_11.MigrateInvoiceTimeSeries,\n\t\t},\n\t\t{\n\t\t\t// The DB version that updated the embedded invoice in\n\t\t\t// outgoing payments to match the new format.\n\t\t\tnumber:    3,\n\t\t\tmigration: migration_01_to_11.MigrateInvoiceTimeSeriesOutgoingPayments,\n\t\t},\n\t\t{\n\t\t\t// The version of the database where every channel\n\t\t\t// always has two entries in the edges bucket. If\n\t\t\t// a policy is unknown, this will be represented\n\t\t\t// by a special byte sequence.\n\t\t\tnumber:    4,\n\t\t\tmigration: migration_01_to_11.MigrateEdgePolicies,\n\t\t},\n\t\t{\n\t\t\t// The DB version where we persist each attempt to send\n\t\t\t// an HTLC to a payment hash, and track whether the\n\t\t\t// payment is in-flight, succeeded, or failed.\n\t\t\tnumber:    5,\n\t\t\tmigration: migration_01_to_11.PaymentStatusesMigration,\n\t\t},\n\t\t{\n\t\t\t// The DB version that properly prunes stale entries\n\t\t\t// from the edge update index.\n\t\t\tnumber:    6,\n\t\t\tmigration: migration_01_to_11.MigratePruneEdgeUpdateIndex,\n\t\t},\n\t\t{\n\t\t\t// The DB version that migrates the ChannelCloseSummary\n\t\t\t// to a format where optional fields are indicated with\n\t\t\t// boolean flags.\n\t\t\tnumber:    7,\n\t\t\tmigration: migration_01_to_11.MigrateOptionalChannelCloseSummaryFields,\n\t\t},\n\t\t{\n\t\t\t// The DB version that changes the gossiper's message\n\t\t\t// store keys to account for the message's type and\n\t\t\t// ShortChannelID.\n\t\t\tnumber:    8,\n\t\t\tmigration: migration_01_to_11.MigrateGossipMessageStoreKeys,\n\t\t},\n\t\t{\n\t\t\t// The DB version where the payments and payment\n\t\t\t// statuses are moved to being stored in a combined\n\t\t\t// bucket.\n\t\t\tnumber:    9,\n\t\t\tmigration: migration_01_to_11.MigrateOutgoingPayments,\n\t\t},\n\t\t{\n\t\t\t// The DB version where we started to store legacy\n\t\t\t// payload information for all routes, as well as the\n\t\t\t// optional TLV records.\n\t\t\tnumber:    10,\n\t\t\tmigration: migration_01_to_11.MigrateRouteSerialization,\n\t\t},\n\t\t{\n\t\t\t// Add invoice htlc and cltv delta fields.\n\t\t\tnumber:    11,\n\t\t\tmigration: migration_01_to_11.MigrateInvoices,\n\t\t},\n\t\t{\n\t\t\t// Migrate to TLV invoice bodies, add payment address\n\t\t\t// and features, remove receipt.\n\t\t\tnumber:    12,\n\t\t\tmigration: migration12.MigrateInvoiceTLV,\n\t\t},\n\t\t{\n\t\t\t// Migrate to multi-path payments.\n\t\t\tnumber:    13,\n\t\t\tmigration: migration13.MigrateMPP,\n\t\t},\n\t\t{\n\t\t\t// Initialize payment address index and begin using it\n\t\t\t// as the default index, falling back to payment hash\n\t\t\t// index.\n\t\t\tnumber:    14,\n\t\t\tmigration: mig.CreateTLB(payAddrIndexBucket),\n\t\t},\n\t\t{\n\t\t\t// Initialize payment index bucket which will be used\n\t\t\t// to index payments by sequence number. This index will\n\t\t\t// be used to allow more efficient ListPayments queries.\n\t\t\tnumber:    15,\n\t\t\tmigration: mig.CreateTLB(paymentsIndexBucket),\n\t\t},\n\t\t{\n\t\t\t// Add our existing payments to the index bucket created\n\t\t\t// in migration 15.\n\t\t\tnumber:    16,\n\t\t\tmigration: migration16.MigrateSequenceIndex,\n\t\t},\n\t\t{\n\t\t\t// Create a top level bucket which will store extra\n\t\t\t// information about channel closes.\n\t\t\tnumber:    17,\n\t\t\tmigration: mig.CreateTLB(closeSummaryBucket),\n\t\t},\n\t\t{\n\t\t\t// Create a top level bucket which holds information\n\t\t\t// about our peers.\n\t\t\tnumber:    18,\n\t\t\tmigration: mig.CreateTLB(peersBucket),\n\t\t},\n\t\t{\n\t\t\t// Create a top level bucket which holds outpoint\n\t\t\t// information.\n\t\t\tnumber:    19,\n\t\t\tmigration: mig.CreateTLB(outpointBucket),\n\t\t},\n\t\t{\n\t\t\t// Migrate some data to the outpoint index.\n\t\t\tnumber:    20,\n\t\t\tmigration: migration20.MigrateOutpointIndex,\n\t\t},\n\t\t{\n\t\t\t// Migrate to length prefixed wire messages everywhere\n\t\t\t// in the database.\n\t\t\tnumber:    21,\n\t\t\tmigration: migration21.MigrateDatabaseWireMessages,\n\t\t},\n\t\t{\n\t\t\t// Initialize set id index so that invoices can be\n\t\t\t// queried by individual htlc sets.\n\t\t\tnumber:    22,\n\t\t\tmigration: mig.CreateTLB(setIDIndexBucket),\n\t\t},\n\t\t{\n\t\t\tnumber:    23,\n\t\t\tmigration: migration23.MigrateHtlcAttempts,\n\t\t},\n\t\t{\n\t\t\t// Remove old forwarding packages of closed channels.\n\t\t\tnumber:    24,\n\t\t\tmigration: migration24.MigrateFwdPkgCleanup,\n\t\t},\n\t\t{\n\t\t\t// Save the initial local/remote balances in channel\n\t\t\t// info.\n\t\t\tnumber:    25,\n\t\t\tmigration: migration25.MigrateInitialBalances,\n\t\t},\n\t\t{\n\t\t\t// Migrate the initial local/remote balance fields into\n\t\t\t// tlv records.\n\t\t\tnumber:    26,\n\t\t\tmigration: migration26.MigrateBalancesToTlvRecords,\n\t\t},\n\t\t{\n\t\t\t// Patch the initial local/remote balance fields with\n\t\t\t// empty values for historical channels.\n\t\t\tnumber:    27,\n\t\t\tmigration: migration27.MigrateHistoricalBalances,\n\t\t},\n\t\t{\n\t\t\tnumber:    28,\n\t\t\tmigration: mig.CreateTLB(chanIDBucket),\n\t\t},\n\t\t{\n\t\t\tnumber:    29,\n\t\t\tmigration: migration29.MigrateChanID,\n\t\t},\n\t}\n\n\t// optionalVersions stores all optional migrations that are applied\n\t// after dbVersions.\n\t//\n\t// NOTE: optional migrations must be fault-tolerant and re-run already\n\t// migrated data must be noop, which means the migration must be able\n\t// to determine its state.\n\toptionalVersions = []optionalVersion{\n\t\t{\n\t\t\tname: \"prune revocation log\",\n\t\t\tmigration: func(db kvdb.Backend,\n\t\t\t\tcfg MigrationConfig) error {\n\n\t\t\t\treturn migration30.MigrateRevocationLog(db, cfg)\n\t\t\t},\n\t\t},\n\t}\n\n\t// Big endian is the preferred byte order, due to cursor scans over\n\t// integer keys iterating in order.\n\tbyteOrder = binary.BigEndian\n\n\t// channelOpeningStateBucket is the database bucket used to store the\n\t// channelOpeningState for each channel that is currently in the process\n\t// of being opened.\n\tchannelOpeningStateBucket = []byte(\"channelOpeningState\")\n\n\t// initialChannelFwdingPolicyBucket is the database bucket used to store\n\t// the forwarding policy for each permanent channel that is currently\n\t// in the process of being opened.\n\tinitialChannelFwdingPolicyBucket = []byte(\"initialChannelFwdingPolicy\")\n)\n\n// DB is the primary datastore for the lnd daemon. The database stores\n// information related to nodes, routing data, open/closed channels, fee\n// schedules, and reputation data.",
      "length": 6408,
      "tokens": 837,
      "embedding": []
    },
    {
      "slug": "type DB struct {",
      "content": "type DB struct {\n\tkvdb.Backend\n\n\t// channelStateDB separates all DB operations on channel state.\n\tchannelStateDB *ChannelStateDB\n\n\tdbPath                    string\n\tgraph                     *ChannelGraph\n\tclock                     clock.Clock\n\tdryRun                    bool\n\tkeepFailedPaymentAttempts bool\n\tstoreFinalHtlcResolutions bool\n\n\t// noRevLogAmtData if true, means that commitment transaction amount\n\t// data should not be stored in the revocation log.\n\tnoRevLogAmtData bool\n}\n\n// Open opens or creates channeldb. Any necessary schemas migrations due\n// to updates will take place as necessary.\n// TODO(bhandras): deprecate this function.",
      "length": 613,
      "tokens": 70,
      "embedding": []
    },
    {
      "slug": "func Open(dbPath string, modifiers ...OptionModifier) (*DB, error) {",
      "content": "func Open(dbPath string, modifiers ...OptionModifier) (*DB, error) {\n\topts := DefaultOptions()\n\tfor _, modifier := range modifiers {\n\t\tmodifier(&opts)\n\t}\n\n\tbackend, err := kvdb.GetBoltBackend(&kvdb.BoltBackendConfig{\n\t\tDBPath:            dbPath,\n\t\tDBFileName:        dbName,\n\t\tNoFreelistSync:    opts.NoFreelistSync,\n\t\tAutoCompact:       opts.AutoCompact,\n\t\tAutoCompactMinAge: opts.AutoCompactMinAge,\n\t\tDBTimeout:         opts.DBTimeout,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdb, err := CreateWithBackend(backend, modifiers...)\n\tif err == nil {\n\t\tdb.dbPath = dbPath\n\t}\n\treturn db, err\n}\n\n// CreateWithBackend creates channeldb instance using the passed kvdb.Backend.\n// Any necessary schemas migrations due to updates will take place as necessary.",
      "length": 659,
      "tokens": 78,
      "embedding": []
    },
    {
      "slug": "func CreateWithBackend(backend kvdb.Backend,",
      "content": "func CreateWithBackend(backend kvdb.Backend,\n\tmodifiers ...OptionModifier) (*DB, error) {\n\n\topts := DefaultOptions()\n\tfor _, modifier := range modifiers {\n\t\tmodifier(&opts)\n\t}\n\n\tif !opts.NoMigration {\n\t\tif err := initChannelDB(backend); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tchanDB := &DB{\n\t\tBackend: backend,\n\t\tchannelStateDB: &ChannelStateDB{\n\t\t\tlinkNodeDB: &LinkNodeDB{\n\t\t\t\tbackend: backend,\n\t\t\t},\n\t\t\tbackend: backend,\n\t\t},\n\t\tclock:                     opts.clock,\n\t\tdryRun:                    opts.dryRun,\n\t\tkeepFailedPaymentAttempts: opts.keepFailedPaymentAttempts,\n\t\tstoreFinalHtlcResolutions: opts.storeFinalHtlcResolutions,\n\t\tnoRevLogAmtData:           opts.NoRevLogAmtData,\n\t}\n\n\t// Set the parent pointer (only used in tests).\n\tchanDB.channelStateDB.parent = chanDB\n\n\tvar err error\n\tchanDB.graph, err = NewChannelGraph(\n\t\tbackend, opts.RejectCacheSize, opts.ChannelCacheSize,\n\t\topts.BatchCommitInterval, opts.PreAllocCacheNumNodes,\n\t\topts.UseGraphCache, opts.NoMigration,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Synchronize the version of database and apply migrations if needed.\n\tif !opts.NoMigration {\n\t\tif err := chanDB.syncVersions(dbVersions); err != nil {\n\t\t\tbackend.Close()\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Grab the optional migration config.\n\t\tomc := opts.OptionalMiragtionConfig\n\t\tif err := chanDB.applyOptionalVersions(omc); err != nil {\n\t\t\tbackend.Close()\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn chanDB, nil\n}\n\n// Path returns the file path to the channel database.",
      "length": 1381,
      "tokens": 159,
      "embedding": []
    },
    {
      "slug": "func (d *DB) Path() string {",
      "content": "func (d *DB) Path() string {\n\treturn d.dbPath\n}\n\nvar dbTopLevelBuckets = [][]byte{\n\topenChannelBucket,\n\tclosedChannelBucket,\n\tforwardingLogBucket,\n\tfwdPackagesKey,\n\tinvoiceBucket,\n\tpayAddrIndexBucket,\n\tsetIDIndexBucket,\n\tpaymentsIndexBucket,\n\tpeersBucket,\n\tnodeInfoBucket,\n\tmetaBucket,\n\tcloseSummaryBucket,\n\toutpointBucket,\n\tchanIDBucket,\n\thistoricalChannelBucket,\n}\n\n// Wipe completely deletes all saved state within all used buckets within the\n// database. The deletion is done in a single transaction, therefore this\n// operation is fully atomic.",
      "length": 497,
      "tokens": 53,
      "embedding": []
    },
    {
      "slug": "func (d *DB) Wipe() error {",
      "content": "func (d *DB) Wipe() error {\n\terr := kvdb.Update(d, func(tx kvdb.RwTx) error {\n\t\tfor _, tlb := range dbTopLevelBuckets {\n\t\t\terr := tx.DeleteTopLevelBucket(tlb)\n\t\t\tif err != nil && err != kvdb.ErrBucketNotFound {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn initChannelDB(d.Backend)\n}\n\n// initChannelDB creates and initializes a fresh version of channeldb. In the\n// case that the target path has not yet been created or doesn't yet exist, then\n// the path is created. Additionally, all required top-level buckets used within\n// the database are created.",
      "length": 554,
      "tokens": 91,
      "embedding": []
    },
    {
      "slug": "func initChannelDB(db kvdb.Backend) error {",
      "content": "func initChannelDB(db kvdb.Backend) error {\n\terr := kvdb.Update(db, func(tx kvdb.RwTx) error {\n\t\t// Check if DB was marked as inactive with a tomb stone.\n\t\tif err := EnsureNoTombstone(tx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tmeta := &Meta{}\n\t\t// Check if DB is already initialized.\n\t\terr := FetchMeta(meta, tx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tfor _, tlb := range dbTopLevelBuckets {\n\t\t\tif _, err := tx.CreateTopLevelBucket(tlb); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tmeta.DbVersionNumber = getLatestDBVersion(dbVersions)\n\t\treturn putMeta(meta, tx)\n\t}, func() {})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to create new channeldb: %v\", err)\n\t}\n\n\treturn nil\n}\n\n// fileExists returns true if the file exists, and false otherwise.",
      "length": 663,
      "tokens": 109,
      "embedding": []
    },
    {
      "slug": "func fileExists(path string) bool {",
      "content": "func fileExists(path string) bool {\n\tif _, err := os.Stat(path); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\n// ChannelStateDB is a database that keeps track of all channel state.",
      "length": 169,
      "tokens": 31,
      "embedding": []
    },
    {
      "slug": "type ChannelStateDB struct {",
      "content": "type ChannelStateDB struct {\n\t// linkNodeDB separates all DB operations on LinkNodes.\n\tlinkNodeDB *LinkNodeDB\n\n\t// parent holds a pointer to the \"main\" channeldb.DB object. This is\n\t// only used for testing and should never be used in production code.\n\t// For testing use the ChannelStateDB.GetParentDB() function to retrieve\n\t// this pointer.\n\tparent *DB\n\n\t// backend points to the actual backend holding the channel state\n\t// database. This may be a real backend or a cache middleware.\n\tbackend kvdb.Backend\n}\n\n// GetParentDB returns the \"main\" channeldb.DB object that is the owner of this\n// ChannelStateDB instance. Use this function only in tests where passing around\n// pointers makes testing less readable. Never to be used in production code!",
      "length": 706,
      "tokens": 113,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) GetParentDB() *DB {",
      "content": "func (c *ChannelStateDB) GetParentDB() *DB {\n\treturn c.parent\n}\n\n// LinkNodeDB returns the current instance of the link node database.",
      "length": 86,
      "tokens": 14,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) LinkNodeDB() *LinkNodeDB {",
      "content": "func (c *ChannelStateDB) LinkNodeDB() *LinkNodeDB {\n\treturn c.linkNodeDB\n}\n\n// FetchOpenChannels starts a new database transaction and returns all stored\n// currently active/open channels associated with the target nodeID. In the case\n// that no active channels are known to have been created with this node, then a\n// zero-length slice is returned.",
      "length": 291,
      "tokens": 47,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchOpenChannels(nodeID *btcec.PublicKey) (",
      "content": "func (c *ChannelStateDB) FetchOpenChannels(nodeID *btcec.PublicKey) (\n\t[]*OpenChannel, error) {\n\n\tvar channels []*OpenChannel\n\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tvar err error\n\t\tchannels, err = c.fetchOpenChannels(tx, nodeID)\n\t\treturn err\n\t}, func() {\n\t\tchannels = nil\n\t})\n\n\treturn channels, err\n}\n\n// fetchOpenChannels uses and existing database transaction and returns all\n// stored currently active/open channels associated with the target nodeID. In\n// the case that no active channels are known to have been created with this\n// node, then a zero-length slice is returned.",
      "length": 511,
      "tokens": 78,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) fetchOpenChannels(tx kvdb.RTx,",
      "content": "func (c *ChannelStateDB) fetchOpenChannels(tx kvdb.RTx,\n\tnodeID *btcec.PublicKey) ([]*OpenChannel, error) {\n\n\t// Get the bucket dedicated to storing the metadata for open channels.\n\topenChanBucket := tx.ReadBucket(openChannelBucket)\n\tif openChanBucket == nil {\n\t\treturn nil, nil\n\t}\n\n\t// Within this top level bucket, fetch the bucket dedicated to storing\n\t// open channel data specific to the remote node.\n\tpub := nodeID.SerializeCompressed()\n\tnodeChanBucket := openChanBucket.NestedReadBucket(pub)\n\tif nodeChanBucket == nil {\n\t\treturn nil, nil\n\t}\n\n\t// Next, we'll need to go down an additional layer in order to retrieve\n\t// the channels for each chain the node knows of.\n\tvar channels []*OpenChannel\n\terr := nodeChanBucket.ForEach(func(chainHash, v []byte) error {\n\t\t// If there's a value, it's not a bucket so ignore it.\n\t\tif v != nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// If we've found a valid chainhash bucket, then we'll retrieve\n\t\t// that so we can extract all the channels.\n\t\tchainBucket := nodeChanBucket.NestedReadBucket(chainHash)\n\t\tif chainBucket == nil {\n\t\t\treturn fmt.Errorf(\"unable to read bucket for chain=%x\",\n\t\t\t\tchainHash[:])\n\t\t}\n\n\t\t// Finally, we both of the necessary buckets retrieved, fetch\n\t\t// all the active channels related to this node.\n\t\tnodeChannels, err := c.fetchNodeChannels(chainBucket)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to read channel for \"+\n\t\t\t\t\"chain_hash=%x, node_key=%x: %v\",\n\t\t\t\tchainHash[:], pub, err)\n\t\t}\n\n\t\tchannels = append(channels, nodeChannels...)\n\t\treturn nil\n\t})\n\n\treturn channels, err\n}\n\n// fetchNodeChannels retrieves all active channels from the target chainBucket\n// which is under a node's dedicated channel bucket. This function is typically\n// used to fetch all the active channels related to a particular node.",
      "length": 1663,
      "tokens": 245,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) fetchNodeChannels(chainBucket kvdb.RBucket) (",
      "content": "func (c *ChannelStateDB) fetchNodeChannels(chainBucket kvdb.RBucket) (\n\t[]*OpenChannel, error) {\n\n\tvar channels []*OpenChannel\n\n\t// A node may have channels on several chains, so for each known chain,\n\t// we'll extract all the channels.\n\terr := chainBucket.ForEach(func(chanPoint, v []byte) error {\n\t\t// If there's a value, it's not a bucket so ignore it.\n\t\tif v != nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Once we've found a valid channel bucket, we'll extract it\n\t\t// from the node's chain bucket.\n\t\tchanBucket := chainBucket.NestedReadBucket(chanPoint)\n\n\t\tvar outPoint wire.OutPoint\n\t\terr := readOutpoint(bytes.NewReader(chanPoint), &outPoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\toChannel, err := fetchOpenChannel(chanBucket, &outPoint)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to read channel data for \"+\n\t\t\t\t\"chan_point=%v: %v\", outPoint, err)\n\t\t}\n\t\toChannel.Db = c\n\n\t\tchannels = append(channels, oChannel)\n\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn channels, nil\n}\n\n// FetchChannel attempts to locate a channel specified by the passed channel\n// point. If the channel cannot be found, then an error will be returned.\n// Optionally an existing db tx can be supplied. Optionally an existing db tx\n// can be supplied.",
      "length": 1126,
      "tokens": 178,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchChannel(tx kvdb.RTx, chanPoint wire.OutPoint) (",
      "content": "func (c *ChannelStateDB) FetchChannel(tx kvdb.RTx, chanPoint wire.OutPoint) (\n\t*OpenChannel, error) {\n\n\tvar (\n\t\ttargetChan      *OpenChannel\n\t\ttargetChanPoint bytes.Buffer\n\t)\n\n\tif err := writeOutpoint(&targetChanPoint, &chanPoint); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// chanScan will traverse the following bucket structure:\n\t//  * nodePub => chainHash => chanPoint\n\t//\n\t// At each level we go one further, ensuring that we're traversing the\n\t// proper key (that's actually a bucket). By only reading the bucket\n\t// structure and skipping fully decoding each channel, we save a good\n\t// bit of CPU as we don't need to do things like decompress public\n\t// keys.\n\tchanScan := func(tx kvdb.RTx) error {\n\t\t// Get the bucket dedicated to storing the metadata for open\n\t\t// channels.\n\t\topenChanBucket := tx.ReadBucket(openChannelBucket)\n\t\tif openChanBucket == nil {\n\t\t\treturn ErrNoActiveChannels\n\t\t}\n\n\t\t// Within the node channel bucket, are the set of node pubkeys\n\t\t// we have channels with, we don't know the entire set, so\n\t\t// we'll check them all.\n\t\treturn openChanBucket.ForEach(func(nodePub, v []byte) error {\n\t\t\t// Ensure that this is a key the same size as a pubkey,\n\t\t\t// and also that it leads directly to a bucket.\n\t\t\tif len(nodePub) != 33 || v != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tnodeChanBucket := openChanBucket.NestedReadBucket(nodePub)\n\t\t\tif nodeChanBucket == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// The next layer down is all the chains that this node\n\t\t\t// has channels on with us.\n\t\t\treturn nodeChanBucket.ForEach(func(chainHash,\n\t\t\t\tv []byte) error {\n\n\t\t\t\t// If there's a value, it's not a bucket so\n\t\t\t\t// ignore it.\n\t\t\t\tif v != nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tchainBucket := nodeChanBucket.NestedReadBucket(\n\t\t\t\t\tchainHash,\n\t\t\t\t)\n\t\t\t\tif chainBucket == nil {\n\t\t\t\t\treturn fmt.Errorf(\"unable to read \"+\n\t\t\t\t\t\t\"bucket for chain=%x\", chainHash[:])\n\t\t\t\t}\n\n\t\t\t\t// Finally we reach the leaf bucket that stores\n\t\t\t\t// all the chanPoints for this node.\n\t\t\t\tchanBucket := chainBucket.NestedReadBucket(\n\t\t\t\t\ttargetChanPoint.Bytes(),\n\t\t\t\t)\n\t\t\t\tif chanBucket == nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tchannel, err := fetchOpenChannel(\n\t\t\t\t\tchanBucket, &chanPoint,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\ttargetChan = channel\n\t\t\t\ttargetChan.Db = c\n\n\t\t\t\treturn nil\n\t\t\t})\n\t\t})\n\t}\n\n\tvar err error\n\tif tx == nil {\n\t\terr = kvdb.View(c.backend, chanScan, func() {})\n\t} else {\n\t\terr = chanScan(tx)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif targetChan != nil {\n\t\treturn targetChan, nil\n\t}\n\n\t// If we can't find the channel, then we return with an error, as we\n\t// have nothing to  backup.\n\treturn nil, ErrChannelNotFound\n}\n\n// FetchAllChannels attempts to retrieve all open channels currently stored\n// within the database, including pending open, fully open and channels waiting\n// for a closing transaction to confirm.",
      "length": 2633,
      "tokens": 415,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchAllChannels() ([]*OpenChannel, error) {",
      "content": "func (c *ChannelStateDB) FetchAllChannels() ([]*OpenChannel, error) {\n\treturn fetchChannels(c)\n}\n\n// FetchAllOpenChannels will return all channels that have the funding\n// transaction confirmed, and is not waiting for a closing transaction to be\n// confirmed.",
      "length": 184,
      "tokens": 28,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchAllOpenChannels() ([]*OpenChannel, error) {",
      "content": "func (c *ChannelStateDB) FetchAllOpenChannels() ([]*OpenChannel, error) {\n\treturn fetchChannels(\n\t\tc,\n\t\tpendingChannelFilter(false),\n\t\twaitingCloseFilter(false),\n\t)\n}\n\n// FetchPendingChannels will return channels that have completed the process of\n// generating and broadcasting funding transactions, but whose funding\n// transactions have yet to be confirmed on the blockchain.",
      "length": 295,
      "tokens": 37,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchPendingChannels() ([]*OpenChannel, error) {",
      "content": "func (c *ChannelStateDB) FetchPendingChannels() ([]*OpenChannel, error) {\n\treturn fetchChannels(c,\n\t\tpendingChannelFilter(true),\n\t\twaitingCloseFilter(false),\n\t)\n}\n\n// FetchWaitingCloseChannels will return all channels that have been opened,\n// but are now waiting for a closing transaction to be confirmed.\n//\n// NOTE: This includes channels that are also pending to be opened.",
      "length": 294,
      "tokens": 41,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchWaitingCloseChannels() ([]*OpenChannel, error) {",
      "content": "func (c *ChannelStateDB) FetchWaitingCloseChannels() ([]*OpenChannel, error) {\n\treturn fetchChannels(\n\t\tc, waitingCloseFilter(true),\n\t)\n}\n\n// fetchChannelsFilter applies a filter to channels retrieved in fetchchannels.\n// A set of filters can be combined to filter across multiple dimensions.",
      "length": 207,
      "tokens": 29,
      "embedding": []
    },
    {
      "slug": "type fetchChannelsFilter func(channel *OpenChannel) bool",
      "content": "type fetchChannelsFilter func(channel *OpenChannel) bool\n\n// pendingChannelFilter returns a filter based on whether channels are pending\n// (ie, their funding transaction still needs to confirm). If pending is false,\n// channels with confirmed funding transactions are returned.",
      "length": 218,
      "tokens": 32,
      "embedding": []
    },
    {
      "slug": "func pendingChannelFilter(pending bool) fetchChannelsFilter {",
      "content": "func pendingChannelFilter(pending bool) fetchChannelsFilter {\n\treturn func(channel *OpenChannel) bool {\n\t\treturn channel.IsPending == pending\n\t}\n}\n\n// waitingCloseFilter returns a filter which filters channels based on whether\n// they are awaiting the confirmation of their closing transaction. If waiting\n// close is true, channels that have had their closing tx broadcast are\n// included. If it is false, channels that are not awaiting confirmation of\n// their close transaction are returned.",
      "length": 423,
      "tokens": 66,
      "embedding": []
    },
    {
      "slug": "func waitingCloseFilter(waitingClose bool) fetchChannelsFilter {",
      "content": "func waitingCloseFilter(waitingClose bool) fetchChannelsFilter {\n\treturn func(channel *OpenChannel) bool {\n\t\t// If the channel is in any other state than Default,\n\t\t// then it means it is waiting to be closed.\n\t\tchannelWaitingClose :=\n\t\t\tchannel.ChanStatus() != ChanStatusDefault\n\n\t\t// Include the channel if it matches the value for\n\t\t// waiting close that we are filtering on.\n\t\treturn channelWaitingClose == waitingClose\n\t}\n}\n\n// fetchChannels attempts to retrieve channels currently stored in the\n// database. It takes a set of filters which are applied to each channel to\n// obtain a set of channels with the desired set of properties. Only channels\n// which have a true value returned for *all* of the filters will be returned.\n// If no filters are provided, every channel in the open channels bucket will\n// be returned.",
      "length": 745,
      "tokens": 126,
      "embedding": []
    },
    {
      "slug": "func fetchChannels(c *ChannelStateDB, filters ...fetchChannelsFilter) (",
      "content": "func fetchChannels(c *ChannelStateDB, filters ...fetchChannelsFilter) (\n\t[]*OpenChannel, error) {\n\n\tvar channels []*OpenChannel\n\n\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\t// Get the bucket dedicated to storing the metadata for open\n\t\t// channels.\n\t\topenChanBucket := tx.ReadBucket(openChannelBucket)\n\t\tif openChanBucket == nil {\n\t\t\treturn ErrNoActiveChannels\n\t\t}\n\n\t\t// Next, fetch the bucket dedicated to storing metadata related\n\t\t// to all nodes. All keys within this bucket are the serialized\n\t\t// public keys of all our direct counterparties.\n\t\tnodeMetaBucket := tx.ReadBucket(nodeInfoBucket)\n\t\tif nodeMetaBucket == nil {\n\t\t\treturn fmt.Errorf(\"node bucket not created\")\n\t\t}\n\n\t\t// Finally for each node public key in the bucket, fetch all\n\t\t// the channels related to this particular node.\n\t\treturn nodeMetaBucket.ForEach(func(k, v []byte) error {\n\t\t\tnodeChanBucket := openChanBucket.NestedReadBucket(k)\n\t\t\tif nodeChanBucket == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\treturn nodeChanBucket.ForEach(func(chainHash, v []byte) error {\n\t\t\t\t// If there's a value, it's not a bucket so\n\t\t\t\t// ignore it.\n\t\t\t\tif v != nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\t// If we've found a valid chainhash bucket,\n\t\t\t\t// then we'll retrieve that so we can extract\n\t\t\t\t// all the channels.\n\t\t\t\tchainBucket := nodeChanBucket.NestedReadBucket(\n\t\t\t\t\tchainHash,\n\t\t\t\t)\n\t\t\t\tif chainBucket == nil {\n\t\t\t\t\treturn fmt.Errorf(\"unable to read \"+\n\t\t\t\t\t\t\"bucket for chain=%x\", chainHash[:])\n\t\t\t\t}\n\n\t\t\t\tnodeChans, err := c.fetchNodeChannels(chainBucket)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"unable to read \"+\n\t\t\t\t\t\t\"channel for chain_hash=%x, \"+\n\t\t\t\t\t\t\"node_key=%x: %v\", chainHash[:], k, err)\n\t\t\t\t}\n\t\t\t\tfor _, channel := range nodeChans {\n\t\t\t\t\t// includeChannel indicates whether the channel\n\t\t\t\t\t// meets the criteria specified by our filters.\n\t\t\t\t\tincludeChannel := true\n\n\t\t\t\t\t// Run through each filter and check whether the\n\t\t\t\t\t// channel should be included.\n\t\t\t\t\tfor _, f := range filters {\n\t\t\t\t\t\t// If the channel fails the filter, set\n\t\t\t\t\t\t// includeChannel to false and don't bother\n\t\t\t\t\t\t// checking the remaining filters.\n\t\t\t\t\t\tif !f(channel) {\n\t\t\t\t\t\t\tincludeChannel = false\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// If the channel passed every filter, include it in\n\t\t\t\t\t// our set of channels.\n\t\t\t\t\tif includeChannel {\n\t\t\t\t\t\tchannels = append(channels, channel)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t})\n\n\t\t})\n\t}, func() {\n\t\tchannels = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn channels, nil\n}\n\n// FetchClosedChannels attempts to fetch all closed channels from the database.\n// The pendingOnly bool toggles if channels that aren't yet fully closed should\n// be returned in the response or not. When a channel was cooperatively closed,\n// it becomes fully closed after a single confirmation.  When a channel was\n// forcibly closed, it will become fully closed after _all_ the pending funds\n// (if any) have been swept.",
      "length": 2737,
      "tokens": 402,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchClosedChannels(pendingOnly bool) (",
      "content": "func (c *ChannelStateDB) FetchClosedChannels(pendingOnly bool) (\n\t[]*ChannelCloseSummary, error) {\n\n\tvar chanSummaries []*ChannelCloseSummary\n\n\tif err := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tcloseBucket := tx.ReadBucket(closedChannelBucket)\n\t\tif closeBucket == nil {\n\t\t\treturn ErrNoClosedChannels\n\t\t}\n\n\t\treturn closeBucket.ForEach(func(chanID []byte, summaryBytes []byte) error {\n\t\t\tsummaryReader := bytes.NewReader(summaryBytes)\n\t\t\tchanSummary, err := deserializeCloseChannelSummary(summaryReader)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// If the query specified to only include pending\n\t\t\t// channels, then we'll skip any channels which aren't\n\t\t\t// currently pending.\n\t\t\tif !chanSummary.IsPending && pendingOnly {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tchanSummaries = append(chanSummaries, chanSummary)\n\t\t\treturn nil\n\t\t})\n\t}, func() {\n\t\tchanSummaries = nil\n\t}); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn chanSummaries, nil\n}\n\n// ErrClosedChannelNotFound signals that a closed channel could not be found in\n// the channeldb.\nvar ErrClosedChannelNotFound = errors.New(\"unable to find closed channel summary\")\n\n// FetchClosedChannel queries for a channel close summary using the channel\n// point of the channel in question.",
      "length": 1120,
      "tokens": 144,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchClosedChannel(chanID *wire.OutPoint) (",
      "content": "func (c *ChannelStateDB) FetchClosedChannel(chanID *wire.OutPoint) (\n\t*ChannelCloseSummary, error) {\n\n\tvar chanSummary *ChannelCloseSummary\n\tif err := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tcloseBucket := tx.ReadBucket(closedChannelBucket)\n\t\tif closeBucket == nil {\n\t\t\treturn ErrClosedChannelNotFound\n\t\t}\n\n\t\tvar b bytes.Buffer\n\t\tvar err error\n\t\tif err = writeOutpoint(&b, chanID); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tsummaryBytes := closeBucket.Get(b.Bytes())\n\t\tif summaryBytes == nil {\n\t\t\treturn ErrClosedChannelNotFound\n\t\t}\n\n\t\tsummaryReader := bytes.NewReader(summaryBytes)\n\t\tchanSummary, err = deserializeCloseChannelSummary(summaryReader)\n\n\t\treturn err\n\t}, func() {\n\t\tchanSummary = nil\n\t}); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn chanSummary, nil\n}\n\n// FetchClosedChannelForID queries for a channel close summary using the\n// channel ID of the channel in question.",
      "length": 777,
      "tokens": 100,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchClosedChannelForID(cid lnwire.ChannelID) (",
      "content": "func (c *ChannelStateDB) FetchClosedChannelForID(cid lnwire.ChannelID) (\n\t*ChannelCloseSummary, error) {\n\n\tvar chanSummary *ChannelCloseSummary\n\tif err := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tcloseBucket := tx.ReadBucket(closedChannelBucket)\n\t\tif closeBucket == nil {\n\t\t\treturn ErrClosedChannelNotFound\n\t\t}\n\n\t\t// The first 30 bytes of the channel ID and outpoint will be\n\t\t// equal.\n\t\tcursor := closeBucket.ReadCursor()\n\t\top, c := cursor.Seek(cid[:30])\n\n\t\t// We scan over all possible candidates for this channel ID.\n\t\tfor ; op != nil && bytes.Compare(cid[:30], op[:30]) <= 0; op, c = cursor.Next() {\n\t\t\tvar outPoint wire.OutPoint\n\t\t\terr := readOutpoint(bytes.NewReader(op), &outPoint)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// If the found outpoint does not correspond to this\n\t\t\t// channel ID, we continue.\n\t\t\tif !cid.IsChanPoint(&outPoint) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Deserialize the close summary and return.\n\t\t\tr := bytes.NewReader(c)\n\t\t\tchanSummary, err = deserializeCloseChannelSummary(r)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn nil\n\t\t}\n\t\treturn ErrClosedChannelNotFound\n\t}, func() {\n\t\tchanSummary = nil\n\t}); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn chanSummary, nil\n}\n\n// MarkChanFullyClosed marks a channel as fully closed within the database. A\n// channel should be marked as fully closed if the channel was initially\n// cooperatively closed and it's reached a single confirmation, or after all\n// the pending funds in a channel that has been forcibly closed have been\n// swept.",
      "length": 1391,
      "tokens": 207,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) MarkChanFullyClosed(chanPoint *wire.OutPoint) error {",
      "content": "func (c *ChannelStateDB) MarkChanFullyClosed(chanPoint *wire.OutPoint) error {\n\tvar (\n\t\topenChannels  []*OpenChannel\n\t\tpruneLinkNode *btcec.PublicKey\n\t)\n\terr := kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tvar b bytes.Buffer\n\t\tif err := writeOutpoint(&b, chanPoint); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchanID := b.Bytes()\n\n\t\tclosedChanBucket, err := tx.CreateTopLevelBucket(\n\t\t\tclosedChannelBucket,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchanSummaryBytes := closedChanBucket.Get(chanID)\n\t\tif chanSummaryBytes == nil {\n\t\t\treturn fmt.Errorf(\"no closed channel for \"+\n\t\t\t\t\"chan_point=%v found\", chanPoint)\n\t\t}\n\n\t\tchanSummaryReader := bytes.NewReader(chanSummaryBytes)\n\t\tchanSummary, err := deserializeCloseChannelSummary(\n\t\t\tchanSummaryReader,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchanSummary.IsPending = false\n\n\t\tvar newSummary bytes.Buffer\n\t\terr = serializeChannelCloseSummary(&newSummary, chanSummary)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = closedChanBucket.Put(chanID, newSummary.Bytes())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Now that the channel is closed, we'll check if we have any\n\t\t// other open channels with this peer. If we don't we'll\n\t\t// garbage collect it to ensure we don't establish persistent\n\t\t// connections to peers without open channels.\n\t\tpruneLinkNode = chanSummary.RemotePub\n\t\topenChannels, err = c.fetchOpenChannels(\n\t\t\ttx, pruneLinkNode,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to fetch open channels for \"+\n\t\t\t\t\"peer %x: %v\",\n\t\t\t\tpruneLinkNode.SerializeCompressed(), err)\n\t\t}\n\n\t\treturn nil\n\t}, func() {\n\t\topenChannels = nil\n\t\tpruneLinkNode = nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Decide whether we want to remove the link node, based upon the number\n\t// of still open channels.\n\treturn c.pruneLinkNode(openChannels, pruneLinkNode)\n}\n\n// pruneLinkNode determines whether we should garbage collect a link node from\n// the database due to no longer having any open channels with it. If there are\n// any left, then this acts as a no-op.",
      "length": 1849,
      "tokens": 261,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) pruneLinkNode(openChannels []*OpenChannel,",
      "content": "func (c *ChannelStateDB) pruneLinkNode(openChannels []*OpenChannel,\n\tremotePub *btcec.PublicKey) error {\n\n\tif len(openChannels) > 0 {\n\t\treturn nil\n\t}\n\n\tlog.Infof(\"Pruning link node %x with zero open channels from database\",\n\t\tremotePub.SerializeCompressed())\n\n\treturn c.linkNodeDB.DeleteLinkNode(remotePub)\n}\n\n// PruneLinkNodes attempts to prune all link nodes found within the database\n// with whom we no longer have any open channels with.",
      "length": 360,
      "tokens": 49,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) PruneLinkNodes() error {",
      "content": "func (c *ChannelStateDB) PruneLinkNodes() error {\n\tallLinkNodes, err := c.linkNodeDB.FetchAllLinkNodes()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, linkNode := range allLinkNodes {\n\t\tvar (\n\t\t\topenChannels []*OpenChannel\n\t\t\tlinkNode     = linkNode\n\t\t)\n\t\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\t\tvar err error\n\t\t\topenChannels, err = c.fetchOpenChannels(\n\t\t\t\ttx, linkNode.IdentityPub,\n\t\t\t)\n\t\t\treturn err\n\t\t}, func() {\n\t\t\topenChannels = nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = c.pruneLinkNode(openChannels, linkNode.IdentityPub)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// ChannelShell is a shell of a channel that is meant to be used for channel\n// recovery purposes. It contains a minimal OpenChannel instance along with\n// addresses for that target node.",
      "length": 712,
      "tokens": 110,
      "embedding": []
    },
    {
      "slug": "type ChannelShell struct {",
      "content": "type ChannelShell struct {\n\t// NodeAddrs the set of addresses that this node has known to be\n\t// reachable at in the past.\n\tNodeAddrs []net.Addr\n\n\t// Chan is a shell of an OpenChannel, it contains only the items\n\t// required to restore the channel on disk.\n\tChan *OpenChannel\n}\n\n// RestoreChannelShells is a method that allows the caller to reconstruct the\n// state of an OpenChannel from the ChannelShell. We'll attempt to write the\n// new channel to disk, create a LinkNode instance with the passed node\n// addresses, and finally create an edge within the graph for the channel as\n// well. This method is idempotent, so repeated calls with the same set of\n// channel shells won't modify the database after the initial call.",
      "length": 684,
      "tokens": 122,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) RestoreChannelShells(channelShells ...*ChannelShell) error {",
      "content": "func (c *ChannelStateDB) RestoreChannelShells(channelShells ...*ChannelShell) error {\n\terr := kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tfor _, channelShell := range channelShells {\n\t\t\tchannel := channelShell.Chan\n\n\t\t\t// When we make a channel, we mark that the channel has\n\t\t\t// been restored, this will signal to other sub-systems\n\t\t\t// to not attempt to use the channel as if it was a\n\t\t\t// regular one.\n\t\t\tchannel.chanStatus |= ChanStatusRestored\n\n\t\t\t// First, we'll attempt to create a new open channel\n\t\t\t// and link node for this channel. If the channel\n\t\t\t// already exists, then in order to ensure this method\n\t\t\t// is idempotent, we'll continue to the next step.\n\t\t\tchannel.Db = c\n\t\t\terr := syncNewChannel(\n\t\t\t\ttx, channel, channelShell.NodeAddrs,\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// AddrsForNode consults the graph and channel database for all addresses known\n// to the passed node public key.",
      "length": 887,
      "tokens": 150,
      "embedding": []
    },
    {
      "slug": "func (d *DB) AddrsForNode(nodePub *btcec.PublicKey) ([]net.Addr,",
      "content": "func (d *DB) AddrsForNode(nodePub *btcec.PublicKey) ([]net.Addr,\n\terror) {\n\n\tlinkNode, err := d.channelStateDB.linkNodeDB.FetchLinkNode(nodePub)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We'll also query the graph for this peer to see if they have any\n\t// addresses that we don't currently have stored within the link node\n\t// database.\n\tpubKey, err := route.NewVertexFromBytes(nodePub.SerializeCompressed())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tgraphNode, err := d.graph.FetchLightningNode(pubKey)\n\tif err != nil && err != ErrGraphNodeNotFound {\n\t\treturn nil, err\n\t} else if err == ErrGraphNodeNotFound {\n\t\t// If the node isn't found, then that's OK, as we still have the\n\t\t// link node data. But any other error needs to be returned.\n\t\tgraphNode = &LightningNode{}\n\t}\n\n\t// Now that we have both sources of addrs for this node, we'll use a\n\t// map to de-duplicate any addresses between the two sources, and\n\t// produce a final list of the combined addrs.\n\taddrs := make(map[string]net.Addr)\n\tfor _, addr := range linkNode.Addresses {\n\t\taddrs[addr.String()] = addr\n\t}\n\tfor _, addr := range graphNode.Addresses {\n\t\taddrs[addr.String()] = addr\n\t}\n\tdedupedAddrs := make([]net.Addr, 0, len(addrs))\n\tfor _, addr := range addrs {\n\t\tdedupedAddrs = append(dedupedAddrs, addr)\n\t}\n\n\treturn dedupedAddrs, nil\n}\n\n// AbandonChannel attempts to remove the target channel from the open channel\n// database. If the channel was already removed (has a closed channel entry),\n// then we'll return a nil error. Otherwise, we'll insert a new close summary\n// into the database.",
      "length": 1450,
      "tokens": 234,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) AbandonChannel(chanPoint *wire.OutPoint,",
      "content": "func (c *ChannelStateDB) AbandonChannel(chanPoint *wire.OutPoint,\n\tbestHeight uint32) error {\n\n\t// With the chanPoint constructed, we'll attempt to find the target\n\t// channel in the database. If we can't find the channel, then we'll\n\t// return the error back to the caller.\n\tdbChan, err := c.FetchChannel(nil, *chanPoint)\n\tswitch {\n\t// If the channel wasn't found, then it's possible that it was already\n\t// abandoned from the database.\n\tcase err == ErrChannelNotFound:\n\t\t_, closedErr := c.FetchClosedChannel(chanPoint)\n\t\tif closedErr != nil {\n\t\t\treturn closedErr\n\t\t}\n\n\t\t// If the channel was already closed, then we don't return an\n\t\t// error as we'd like this step to be repeatable.\n\t\treturn nil\n\tcase err != nil:\n\t\treturn err\n\t}\n\n\t// Now that we've found the channel, we'll populate a close summary for\n\t// the channel, so we can store as much information for this abounded\n\t// channel as possible. We also ensure that we set Pending to false, to\n\t// indicate that this channel has been \"fully\" closed.\n\tsummary := &ChannelCloseSummary{\n\t\tCloseType:               Abandoned,\n\t\tChanPoint:               *chanPoint,\n\t\tChainHash:               dbChan.ChainHash,\n\t\tCloseHeight:             bestHeight,\n\t\tRemotePub:               dbChan.IdentityPub,\n\t\tCapacity:                dbChan.Capacity,\n\t\tSettledBalance:          dbChan.LocalCommitment.LocalBalance.ToSatoshis(),\n\t\tShortChanID:             dbChan.ShortChanID(),\n\t\tRemoteCurrentRevocation: dbChan.RemoteCurrentRevocation,\n\t\tRemoteNextRevocation:    dbChan.RemoteNextRevocation,\n\t\tLocalChanConfig:         dbChan.LocalChanCfg,\n\t}\n\n\t// Finally, we'll close the channel in the DB, and return back to the\n\t// caller. We set ourselves as the close initiator because we abandoned\n\t// the channel.\n\treturn dbChan.CloseChannel(summary, ChanStatusLocalCloseInitiator)\n}\n\n// SaveInitialFwdingPolicy saves the serialized forwarding policy for the\n// provided permanent channel id to the initialChannelFwdingPolicyBucket.",
      "length": 1852,
      "tokens": 233,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) SaveInitialFwdingPolicy(chanID,",
      "content": "func (c *ChannelStateDB) SaveInitialFwdingPolicy(chanID,\n\tforwardingPolicy []byte) error {\n\n\treturn kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tbucket, err := tx.CreateTopLevelBucket(\n\t\t\tinitialChannelFwdingPolicyBucket,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn bucket.Put(chanID, forwardingPolicy)\n\t}, func() {})\n}\n\n// GetInitialFwdingPolicy fetches the serialized forwarding policy for the\n// provided channel id from the database, or returns ErrChannelNotFound if\n// a forwarding policy for this channel id is not found.",
      "length": 467,
      "tokens": 62,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) GetInitialFwdingPolicy(chanID []byte) ([]byte, error) {",
      "content": "func (c *ChannelStateDB) GetInitialFwdingPolicy(chanID []byte) ([]byte, error) {\n\tvar serializedState []byte\n\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tbucket := tx.ReadBucket(initialChannelFwdingPolicyBucket)\n\t\tif bucket == nil {\n\t\t\t// If the bucket does not exist, it means we\n\t\t\t// never added a channel fees to the db, so\n\t\t\t// return ErrChannelNotFound.\n\t\t\treturn ErrChannelNotFound\n\t\t}\n\n\t\tstateBytes := bucket.Get(chanID)\n\t\tif stateBytes == nil {\n\t\t\treturn ErrChannelNotFound\n\t\t}\n\n\t\tserializedState = append(serializedState, stateBytes...)\n\n\t\treturn nil\n\t}, func() {\n\t\tserializedState = nil\n\t})\n\treturn serializedState, err\n}\n\n// DeleteInitialFwdingPolicy removes the forwarding policy for a given channel\n// from the database.",
      "length": 641,
      "tokens": 86,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) DeleteInitialFwdingPolicy(chanID []byte) error {",
      "content": "func (c *ChannelStateDB) DeleteInitialFwdingPolicy(chanID []byte) error {\n\treturn kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tbucket := tx.ReadWriteBucket(initialChannelFwdingPolicyBucket)\n\t\tif bucket == nil {\n\t\t\treturn ErrChannelNotFound\n\t\t}\n\n\t\treturn bucket.Delete(chanID)\n\t}, func() {})\n}\n\n// SaveChannelOpeningState saves the serialized channel state for the provided\n// chanPoint to the channelOpeningStateBucket.",
      "length": 341,
      "tokens": 38,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) SaveChannelOpeningState(outPoint,",
      "content": "func (c *ChannelStateDB) SaveChannelOpeningState(outPoint,\n\tserializedState []byte) error {\n\n\treturn kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tbucket, err := tx.CreateTopLevelBucket(channelOpeningStateBucket)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn bucket.Put(outPoint, serializedState)\n\t}, func() {})\n}\n\n// GetChannelOpeningState fetches the serialized channel state for the provided\n// outPoint from the database, or returns ErrChannelNotFound if the channel\n// is not found.",
      "length": 420,
      "tokens": 54,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) GetChannelOpeningState(outPoint []byte) ([]byte,",
      "content": "func (c *ChannelStateDB) GetChannelOpeningState(outPoint []byte) ([]byte,\n\terror) {\n\n\tvar serializedState []byte\n\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tbucket := tx.ReadBucket(channelOpeningStateBucket)\n\t\tif bucket == nil {\n\t\t\t// If the bucket does not exist, it means we never added\n\t\t\t//  a channel to the db, so return ErrChannelNotFound.\n\t\t\treturn ErrChannelNotFound\n\t\t}\n\n\t\tstateBytes := bucket.Get(outPoint)\n\t\tif stateBytes == nil {\n\t\t\treturn ErrChannelNotFound\n\t\t}\n\n\t\tserializedState = append(serializedState, stateBytes...)\n\n\t\treturn nil\n\t}, func() {\n\t\tserializedState = nil\n\t})\n\treturn serializedState, err\n}\n\n// DeleteChannelOpeningState removes any state for outPoint from the database.",
      "length": 615,
      "tokens": 82,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) DeleteChannelOpeningState(outPoint []byte) error {",
      "content": "func (c *ChannelStateDB) DeleteChannelOpeningState(outPoint []byte) error {\n\treturn kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tbucket := tx.ReadWriteBucket(channelOpeningStateBucket)\n\t\tif bucket == nil {\n\t\t\treturn ErrChannelNotFound\n\t\t}\n\n\t\treturn bucket.Delete(outPoint)\n\t}, func() {})\n}\n\n// syncVersions function is used for safe db version synchronization. It\n// applies migration functions to the current database and recovers the\n// previous state of db if at least one error/panic appeared during migration.",
      "length": 433,
      "tokens": 58,
      "embedding": []
    },
    {
      "slug": "func (d *DB) syncVersions(versions []mandatoryVersion) error {",
      "content": "func (d *DB) syncVersions(versions []mandatoryVersion) error {\n\tmeta, err := d.FetchMeta()\n\tif err != nil {\n\t\tif err == ErrMetaNotFound {\n\t\t\tmeta = &Meta{}\n\t\t} else {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlatestVersion := getLatestDBVersion(versions)\n\tlog.Infof(\"Checking for schema update: latest_version=%v, \"+\n\t\t\"db_version=%v\", latestVersion, meta.DbVersionNumber)\n\n\tswitch {\n\n\t// If the database reports a higher version that we are aware of, the\n\t// user is probably trying to revert to a prior version of lnd. We fail\n\t// here to prevent reversions and unintended corruption.\n\tcase meta.DbVersionNumber > latestVersion:\n\t\tlog.Errorf(\"Refusing to revert from db_version=%d to \"+\n\t\t\t\"lower version=%d\", meta.DbVersionNumber,\n\t\t\tlatestVersion)\n\t\treturn ErrDBReversion\n\n\t// If the current database version matches the latest version number,\n\t// then we don't need to perform any migrations.\n\tcase meta.DbVersionNumber == latestVersion:\n\t\treturn nil\n\t}\n\n\tlog.Infof(\"Performing database schema migration\")\n\n\t// Otherwise, we fetch the migrations which need to applied, and\n\t// execute them serially within a single database transaction to ensure\n\t// the migration is atomic.\n\tmigrations, migrationVersions := getMigrationsToApply(\n\t\tversions, meta.DbVersionNumber,\n\t)\n\treturn kvdb.Update(d, func(tx kvdb.RwTx) error {\n\t\tfor i, migration := range migrations {\n\t\t\tif migration == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tlog.Infof(\"Applying migration #%v\",\n\t\t\t\tmigrationVersions[i])\n\n\t\t\tif err := migration(tx); err != nil {\n\t\t\t\tlog.Infof(\"Unable to apply migration #%v\",\n\t\t\t\t\tmigrationVersions[i])\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tmeta.DbVersionNumber = latestVersion\n\t\terr := putMeta(meta, tx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// In dry-run mode, return an error to prevent the transaction\n\t\t// from committing.\n\t\tif d.dryRun {\n\t\t\treturn ErrDryRunMigrationOK\n\t\t}\n\n\t\treturn nil\n\t}, func() {})\n}\n\n// applyOptionalVersions takes a config to determine whether the optional\n// migrations will be applied.\n//\n// NOTE: only support the prune_revocation_log optional migration atm.",
      "length": 1910,
      "tokens": 265,
      "embedding": []
    },
    {
      "slug": "func (d *DB) applyOptionalVersions(cfg OptionalMiragtionConfig) error {",
      "content": "func (d *DB) applyOptionalVersions(cfg OptionalMiragtionConfig) error {\n\t// TODO(yy): need to design the db to support dry run for optional\n\t// migrations.\n\tif d.dryRun {\n\t\tlog.Info(\"Skipped optional migrations as dry run mode is not \" +\n\t\t\t\"supported yet\")\n\t\treturn nil\n\t}\n\n\tom, err := d.fetchOptionalMeta()\n\tif err != nil {\n\t\tif err == ErrMetaNotFound {\n\t\t\tom = &OptionalMeta{\n\t\t\t\tVersions: make(map[uint64]string),\n\t\t\t}\n\t\t} else {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Infof(\"Checking for optional update: prune_revocation_log=%v, \"+\n\t\t\"db_version=%s\", cfg.PruneRevocationLog, om)\n\n\t// Exit early if the optional migration is not specified.\n\tif !cfg.PruneRevocationLog {\n\t\treturn nil\n\t}\n\n\t// Exit early if the optional migration has already been applied.\n\tif _, ok := om.Versions[0]; ok {\n\t\treturn nil\n\t}\n\n\t// Get the optional version.\n\tversion := optionalVersions[0]\n\tlog.Infof(\"Performing database optional migration: %s\", version.name)\n\n\tmigrationCfg := &MigrationConfigImpl{\n\t\tmigration30.MigrateRevLogConfigImpl{\n\t\t\tNoAmountData: d.noRevLogAmtData,\n\t\t},\n\t}\n\n\t// Migrate the data.\n\tif err := version.migration(d, migrationCfg); err != nil {\n\t\tlog.Errorf(\"Unable to apply optional migration: %s, error: %v\",\n\t\t\tversion.name, err)\n\t\treturn err\n\t}\n\n\t// Update the optional meta. Notice that unlike the mandatory db\n\t// migrations where we perform the migration and updating meta in a\n\t// single db transaction, we use different transactions here. Even when\n\t// the following update is failed, we should be fine here as we would\n\t// re-run the optional migration again, which is a noop, during next\n\t// startup.\n\tom.Versions[0] = version.name\n\tif err := d.putOptionalMeta(om); err != nil {\n\t\tlog.Errorf(\"Unable to update optional meta: %v\", err)\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// ChannelGraph returns the current instance of the directed channel graph.",
      "length": 1709,
      "tokens": 252,
      "embedding": []
    },
    {
      "slug": "func (d *DB) ChannelGraph() *ChannelGraph {",
      "content": "func (d *DB) ChannelGraph() *ChannelGraph {\n\treturn d.graph\n}\n\n// ChannelStateDB returns the sub database that is concerned with the channel\n// state.",
      "length": 102,
      "tokens": 17,
      "embedding": []
    },
    {
      "slug": "func (d *DB) ChannelStateDB() *ChannelStateDB {",
      "content": "func (d *DB) ChannelStateDB() *ChannelStateDB {\n\treturn d.channelStateDB\n}\n\n// LatestDBVersion returns the number of the latest database version currently\n// known to the channel DB.",
      "length": 130,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func LatestDBVersion() uint32 {",
      "content": "func LatestDBVersion() uint32 {\n\treturn getLatestDBVersion(dbVersions)\n}\n",
      "length": 39,
      "tokens": 3,
      "embedding": []
    },
    {
      "slug": "func getLatestDBVersion(versions []mandatoryVersion) uint32 {",
      "content": "func getLatestDBVersion(versions []mandatoryVersion) uint32 {\n\treturn versions[len(versions)-1].number\n}\n\n// getMigrationsToApply retrieves the migration function that should be\n// applied to the database.",
      "length": 139,
      "tokens": 17,
      "embedding": []
    },
    {
      "slug": "func getMigrationsToApply(versions []mandatoryVersion,",
      "content": "func getMigrationsToApply(versions []mandatoryVersion,\n\tversion uint32) ([]migration, []uint32) {\n\n\tmigrations := make([]migration, 0, len(versions))\n\tmigrationVersions := make([]uint32, 0, len(versions))\n\n\tfor _, v := range versions {\n\t\tif v.number > version {\n\t\t\tmigrations = append(migrations, v.migration)\n\t\t\tmigrationVersions = append(migrationVersions, v.number)\n\t\t}\n\t}\n\n\treturn migrations, migrationVersions\n}\n\n// fetchHistoricalChanBucket returns a the channel bucket for a given outpoint\n// from the historical channel bucket. If the bucket does not exist,\n// ErrNoHistoricalBucket is returned.",
      "length": 531,
      "tokens": 68,
      "embedding": []
    },
    {
      "slug": "func fetchHistoricalChanBucket(tx kvdb.RTx,",
      "content": "func fetchHistoricalChanBucket(tx kvdb.RTx,\n\toutPoint *wire.OutPoint) (kvdb.RBucket, error) {\n\n\t// First fetch the top level bucket which stores all data related to\n\t// historically stored channels.\n\thistoricalChanBucket := tx.ReadBucket(historicalChannelBucket)\n\tif historicalChanBucket == nil {\n\t\treturn nil, ErrNoHistoricalBucket\n\t}\n\n\t// With the bucket for the node and chain fetched, we can now go down\n\t// another level, for the channel itself.\n\tvar chanPointBuf bytes.Buffer\n\tif err := writeOutpoint(&chanPointBuf, outPoint); err != nil {\n\t\treturn nil, err\n\t}\n\tchanBucket := historicalChanBucket.NestedReadBucket(\n\t\tchanPointBuf.Bytes(),\n\t)\n\tif chanBucket == nil {\n\t\treturn nil, ErrChannelNotFound\n\t}\n\n\treturn chanBucket, nil\n}\n\n// FetchHistoricalChannel fetches open channel data from the historical channel\n// bucket.",
      "length": 756,
      "tokens": 102,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) FetchHistoricalChannel(outPoint *wire.OutPoint) (",
      "content": "func (c *ChannelStateDB) FetchHistoricalChannel(outPoint *wire.OutPoint) (\n\t*OpenChannel, error) {\n\n\tvar channel *OpenChannel\n\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tchanBucket, err := fetchHistoricalChanBucket(tx, outPoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel, err = fetchOpenChannel(chanBucket, outPoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchannel.Db = c\n\t\treturn nil\n\t}, func() {\n\t\tchannel = nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn channel, nil\n}\n",
      "length": 397,
      "tokens": 64,
      "embedding": []
    },
    {
      "slug": "func fetchFinalHtlcsBucket(tx kvdb.RTx,",
      "content": "func fetchFinalHtlcsBucket(tx kvdb.RTx,\n\tchanID lnwire.ShortChannelID) (kvdb.RBucket, error) {\n\n\tfinalHtlcsBucket := tx.ReadBucket(finalHtlcsBucket)\n\tif finalHtlcsBucket == nil {\n\t\treturn nil, ErrFinalHtlcsBucketNotFound\n\t}\n\n\tvar chanIDBytes [8]byte\n\tbyteOrder.PutUint64(chanIDBytes[:], chanID.ToUint64())\n\n\tchanBucket := finalHtlcsBucket.NestedReadBucket(chanIDBytes[:])\n\tif chanBucket == nil {\n\t\treturn nil, ErrFinalChannelBucketNotFound\n\t}\n\n\treturn chanBucket, nil\n}\n\nvar ErrHtlcUnknown = errors.New(\"htlc unknown\")\n\n// LookupFinalHtlc retrieves a final htlc resolution from the database. If the\n// htlc has no final resolution yet, ErrHtlcUnknown is returned.",
      "length": 602,
      "tokens": 65,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) LookupFinalHtlc(chanID lnwire.ShortChannelID,",
      "content": "func (c *ChannelStateDB) LookupFinalHtlc(chanID lnwire.ShortChannelID,\n\thtlcIndex uint64) (*FinalHtlcInfo, error) {\n\n\tvar idBytes [8]byte\n\tbyteOrder.PutUint64(idBytes[:], htlcIndex)\n\n\tvar settledByte byte\n\n\terr := kvdb.View(c.backend, func(tx kvdb.RTx) error {\n\t\tfinalHtlcsBucket, err := fetchFinalHtlcsBucket(\n\t\t\ttx, chanID,\n\t\t)\n\t\tswitch {\n\t\tcase errors.Is(err, ErrFinalHtlcsBucketNotFound):\n\t\t\tfallthrough\n\n\t\tcase errors.Is(err, ErrFinalChannelBucketNotFound):\n\t\t\treturn ErrHtlcUnknown\n\n\t\tcase err != nil:\n\t\t\treturn fmt.Errorf(\"cannot fetch final htlcs bucket: %w\",\n\t\t\t\terr)\n\t\t}\n\n\t\tvalue := finalHtlcsBucket.Get(idBytes[:])\n\t\tif value == nil {\n\t\t\treturn ErrHtlcUnknown\n\t\t}\n\n\t\tif len(value) != 1 {\n\t\t\treturn errors.New(\"unexpected final htlc value length\")\n\t\t}\n\n\t\tsettledByte = value[0]\n\n\t\treturn nil\n\t}, func() {\n\t\tsettledByte = 0\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinfo := FinalHtlcInfo{\n\t\tSettled:  settledByte&byte(FinalHtlcSettledBit) != 0,\n\t\tOffchain: settledByte&byte(FinalHtlcOffchainBit) != 0,\n\t}\n\n\treturn &info, nil\n}\n\n// PutOnchainFinalHtlcOutcome stores the final on-chain outcome of an htlc in\n// the database.",
      "length": 1011,
      "tokens": 125,
      "embedding": []
    },
    {
      "slug": "func (c *ChannelStateDB) PutOnchainFinalHtlcOutcome(",
      "content": "func (c *ChannelStateDB) PutOnchainFinalHtlcOutcome(\n\tchanID lnwire.ShortChannelID, htlcID uint64, settled bool) error {\n\n\t// Skip if the user did not opt in to storing final resolutions.\n\tif !c.parent.storeFinalHtlcResolutions {\n\t\treturn nil\n\t}\n\n\treturn kvdb.Update(c.backend, func(tx kvdb.RwTx) error {\n\t\tfinalHtlcsBucket, err := fetchFinalHtlcsBucketRw(tx, chanID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn putFinalHtlc(\n\t\t\tfinalHtlcsBucket, htlcID,\n\t\t\tFinalHtlcInfo{\n\t\t\t\tSettled:  settled,\n\t\t\t\tOffchain: false,\n\t\t\t},\n\t\t)\n\t}, func() {})\n}\n\n// MakeTestDB creates a new instance of the ChannelDB for testing purposes.\n// A callback which cleans up the created temporary directories is also\n// returned and intended to be executed after the test completes.",
      "length": 682,
      "tokens": 96,
      "embedding": []
    },
    {
      "slug": "func MakeTestDB(t *testing.T, modifiers ...OptionModifier) (*DB, error) {",
      "content": "func MakeTestDB(t *testing.T, modifiers ...OptionModifier) (*DB, error) {\n\t// First, create a temporary directory to be used for the duration of\n\t// this test.\n\ttempDirName := t.TempDir()\n\n\t// Next, create channeldb for the first time.\n\tbackend, backendCleanup, err := kvdb.GetTestBackend(tempDirName, \"cdb\")\n\tif err != nil {\n\t\tbackendCleanup()\n\t\treturn nil, err\n\t}\n\n\tcdb, err := CreateWithBackend(backend, modifiers...)\n\tif err != nil {\n\t\tbackendCleanup()\n\t\treturn nil, err\n\t}\n\n\tt.Cleanup(func() {\n\t\tcdb.Close()\n\t\tbackendCleanup()\n\t})\n\n\treturn cdb, nil\n}\n",
      "length": 458,
      "tokens": 67,
      "embedding": []
    }
  ]
}