{
  "filepath": "../implementations/go/lnd/channeldb/migration21/migration.go",
  "package": "migration21",
  "sections": [
    {
      "slug": "func MigrateDatabaseWireMessages(tx kvdb.RwTx) error {",
      "content": "func MigrateDatabaseWireMessages(tx kvdb.RwTx) error {\n\t// The migration will proceed in three phases: we'll need to update any\n\t// pending commit diffs, then any unsigned acked updates for all open\n\t// channels, then finally we'll need to update all the current\n\t// stored network results for payments in the switch.\n\t//\n\t// In this phase, we'll migrate the open channel data.\n\tif err := migrateOpenChanBucket(tx); err != nil {\n\t\treturn err\n\t}\n\n\t// Next, we'll update all the present close channel summaries as well.\n\tif err := migrateCloseChanSummaries(tx); err != nil {\n\t\treturn err\n\t}\n\n\t// We'll migrate forwarding packages, which have log updates as part of\n\t// their serialized data.\n\tif err := migrateForwardingPackages(tx); err != nil {\n\t\treturn err\n\t}\n\n\t// Finally, we'll update the pending network results as well.\n\treturn migrateNetworkResults(tx)\n}\n",
      "length": 782,
      "tokens": 130,
      "embedding": []
    },
    {
      "slug": "func migrateOpenChanBucket(tx kvdb.RwTx) error {",
      "content": "func migrateOpenChanBucket(tx kvdb.RwTx) error {\n\topenChanBucket := tx.ReadWriteBucket(openChannelBucket)\n\n\t// If no bucket is found, we can exit early.\n\tif openChanBucket == nil {\n\t\treturn nil\n\t}\n\n\ttype channelPath struct {\n\t\tnodePub   []byte\n\t\tchainHash []byte\n\t\tchanPoint []byte\n\t}\n\tvar channelPaths []channelPath\n\terr := openChanBucket.ForEach(func(nodePub, v []byte) error {\n\t\t// Ensure that this is a key the same size as a pubkey, and\n\t\t// also that it leads directly to a bucket.\n\t\tif len(nodePub) != 33 || v != nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tnodeChanBucket := openChanBucket.NestedReadBucket(nodePub)\n\t\tif nodeChanBucket == nil {\n\t\t\treturn fmt.Errorf(\"no bucket for node %x\", nodePub)\n\t\t}\n\n\t\t// The next layer down is all the chains that this node\n\t\t// has channels on with us.\n\t\treturn nodeChanBucket.ForEach(func(chainHash, v []byte) error {\n\t\t\t// If there's a value, it's not a bucket so\n\t\t\t// ignore it.\n\t\t\tif v != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tchainBucket := nodeChanBucket.NestedReadBucket(\n\t\t\t\tchainHash,\n\t\t\t)\n\t\t\tif chainBucket == nil {\n\t\t\t\treturn fmt.Errorf(\"unable to read \"+\n\t\t\t\t\t\"bucket for chain=%x\", chainHash)\n\t\t\t}\n\n\t\t\treturn chainBucket.ForEach(func(chanPoint, v []byte) error {\n\t\t\t\t// If there's a value, it's not a bucket so\n\t\t\t\t// ignore it.\n\t\t\t\tif v != nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\tchannelPaths = append(channelPaths, channelPath{\n\t\t\t\t\tnodePub:   nodePub,\n\t\t\t\t\tchainHash: chainHash,\n\t\t\t\t\tchanPoint: chanPoint,\n\t\t\t\t})\n\n\t\t\t\treturn nil\n\t\t\t})\n\t\t})\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Now that we have all the paths of the channel we need to migrate,\n\t// we'll update all the state in a distinct step to avoid weird\n\t// behavior from  modifying buckets in a ForEach statement.\n\tfor _, channelPath := range channelPaths {\n\t\t// First, we'll extract it from the node's chain bucket.\n\t\tnodeChanBucket := openChanBucket.NestedReadWriteBucket(\n\t\t\tchannelPath.nodePub,\n\t\t)\n\t\tchainBucket := nodeChanBucket.NestedReadWriteBucket(\n\t\t\tchannelPath.chainHash,\n\t\t)\n\t\tchanBucket := chainBucket.NestedReadWriteBucket(\n\t\t\tchannelPath.chanPoint,\n\t\t)\n\n\t\t// At this point, we have the channel bucket now, so we'll\n\t\t// check to see if this channel has a pending commitment or\n\t\t// not.\n\t\tcommitDiffBytes := chanBucket.Get(commitDiffKey)\n\t\tif commitDiffBytes != nil {\n\t\t\t// Now that we have the commit diff in the _old_\n\t\t\t// encoding, we'll write it back to disk using the new\n\t\t\t// encoding which has a length prefix in front of the\n\t\t\t// CommitSig.\n\t\t\tcommitDiff, err := legacy.DeserializeCommitDiff(\n\t\t\t\tbytes.NewReader(commitDiffBytes),\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tvar b bytes.Buffer\n\t\t\terr = current.SerializeCommitDiff(&b, commitDiff)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\terr = chanBucket.Put(commitDiffKey, b.Bytes())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// With the commit diff migrated, we'll now check to see if\n\t\t// there're any un-acked updates we need to migrate as well.\n\t\tupdateBytes := chanBucket.Get(unsignedAckedUpdatesKey)\n\t\tif updateBytes != nil {\n\t\t\t// We have un-acked updates we need to migrate so we'll\n\t\t\t// decode then re-encode them here using the new\n\t\t\t// format.\n\t\t\tlegacyUnackedUpdates, err := legacy.DeserializeLogUpdates(\n\t\t\t\tbytes.NewReader(updateBytes),\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tvar b bytes.Buffer\n\t\t\terr = current.SerializeLogUpdates(&b, legacyUnackedUpdates)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\terr = chanBucket.Put(unsignedAckedUpdatesKey, b.Bytes())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// Remote unsigned updates as well.\n\t\tupdateBytes = chanBucket.Get(remoteUnsignedLocalUpdatesKey)\n\t\tif updateBytes != nil {\n\t\t\tlegacyUnsignedUpdates, err := legacy.DeserializeLogUpdates(\n\t\t\t\tbytes.NewReader(updateBytes),\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tvar b bytes.Buffer\n\t\t\terr = current.SerializeLogUpdates(&b, legacyUnsignedUpdates)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\terr = chanBucket.Put(remoteUnsignedLocalUpdatesKey, b.Bytes())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n",
      "length": 3822,
      "tokens": 544,
      "embedding": []
    },
    {
      "slug": "func migrateCloseChanSummaries(tx kvdb.RwTx) error {",
      "content": "func migrateCloseChanSummaries(tx kvdb.RwTx) error {\n\tclosedChanBucket := tx.ReadWriteBucket(closedChannelBucket)\n\n\t// Exit early if bucket is not found.\n\tif closedChannelBucket == nil {\n\t\treturn nil\n\t}\n\n\ttype closedChan struct {\n\t\tchanKey      []byte\n\t\tsummaryBytes []byte\n\t}\n\tvar closedChans []closedChan\n\terr := closedChanBucket.ForEach(func(k, v []byte) error {\n\t\tclosedChans = append(closedChans, closedChan{\n\t\t\tchanKey:      k,\n\t\t\tsummaryBytes: v,\n\t\t})\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, closedChan := range closedChans {\n\t\toldSummary, err := legacy.DeserializeCloseChannelSummary(\n\t\t\tbytes.NewReader(closedChan.summaryBytes),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar newSummaryBytes bytes.Buffer\n\t\terr = current.SerializeChannelCloseSummary(\n\t\t\t&newSummaryBytes, oldSummary,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = closedChanBucket.Put(\n\t\t\tclosedChan.chanKey, newSummaryBytes.Bytes(),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n",
      "length": 887,
      "tokens": 114,
      "embedding": []
    },
    {
      "slug": "func migrateForwardingPackages(tx kvdb.RwTx) error {",
      "content": "func migrateForwardingPackages(tx kvdb.RwTx) error {\n\tfwdPkgBkt := tx.ReadWriteBucket(fwdPackagesKey)\n\n\t// Exit early if bucket is not found.\n\tif fwdPkgBkt == nil {\n\t\treturn nil\n\t}\n\n\t// We Go through the bucket and fetches all short channel IDs.\n\tvar sources []lnwire.ShortChannelID\n\terr := fwdPkgBkt.ForEach(func(k, v []byte) error {\n\t\tsource := lnwire.NewShortChanIDFromInt(byteOrder.Uint64(k))\n\t\tsources = append(sources, source)\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Now load all forwarding packages using the legacy encoding.\n\tvar pkgsToMigrate []*common.FwdPkg\n\tfor _, source := range sources {\n\t\tpackager := legacy.NewChannelPackager(source)\n\t\tfwdPkgs, err := packager.LoadFwdPkgs(tx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpkgsToMigrate = append(pkgsToMigrate, fwdPkgs...)\n\t}\n\n\t// Add back the packages using the current encoding.\n\tfor _, pkg := range pkgsToMigrate {\n\t\tpackager := current.NewChannelPackager(pkg.Source)\n\t\terr := packager.AddFwdPkg(tx, pkg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n",
      "length": 943,
      "tokens": 134,
      "embedding": []
    },
    {
      "slug": "func migrateNetworkResults(tx kvdb.RwTx) error {",
      "content": "func migrateNetworkResults(tx kvdb.RwTx) error {\n\tnetworkResults := tx.ReadWriteBucket(networkResultStoreBucketKey)\n\n\t// Exit early if bucket is not found.\n\tif networkResults == nil {\n\t\treturn nil\n\t}\n\n\t// Similar to the prior migrations, we'll do this one in two phases:\n\t// we'll first grab all the keys we need to migrate in one loop, then\n\t// update them all in another loop.\n\tvar netResultsToMigrate [][2][]byte\n\terr := networkResults.ForEach(func(k, v []byte) error {\n\t\tnetResultsToMigrate = append(netResultsToMigrate, [2][]byte{\n\t\t\tk, v,\n\t\t})\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, netResult := range netResultsToMigrate {\n\t\tresKey := netResult[0]\n\t\tresBytes := netResult[1]\n\t\toldResult, err := legacy.DeserializeNetworkResult(\n\t\t\tbytes.NewReader(resBytes),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvar newResultBuf bytes.Buffer\n\t\terr = current.SerializeNetworkResult(&newResultBuf, oldResult)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = networkResults.Put(resKey, newResultBuf.Bytes())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n",
      "length": 977,
      "tokens": 140,
      "embedding": []
    }
  ]
}