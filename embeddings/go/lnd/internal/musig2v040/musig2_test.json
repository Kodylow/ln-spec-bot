{
  "filepath": "../implementations/go/lnd/internal/musig2v040/musig2_test.go",
  "package": "Copyright",
  "sections": [
    {
      "slug": "func getInfinityTweak() KeyTweakDesc {",
      "content": "func getInfinityTweak() KeyTweakDesc {\n\tgenerator := btcec.Generator()\n\n\tkeySet := []*btcec.PublicKey{generator}\n\n\tkeysHash := keyHashFingerprint(keySet, true)\n\tuniqueKeyIndex := secondUniqueKeyIndex(keySet, true)\n\n\tn := &btcec.ModNScalar{}\n\n\tn.SetByteSlice(invalidTweak)\n\n\tcoeff := aggregationCoefficient(\n\t\tkeySet, generator, keysHash, uniqueKeyIndex,\n\t).Negate().Add(n)\n\n\treturn KeyTweakDesc{\n\t\tTweak:   coeff.Bytes(),\n\t\tIsXOnly: false,\n\t}\n}\n\nconst (\n\tkeyAggTestVectorName = \"key_agg_vectors.json\"\n\n\tnonceAggTestVectorName = \"nonce_agg_vectors.json\"\n\n\tsignTestVectorName = \"sign_vectors.json\"\n)\n\nvar dumpJson = flag.Bool(\"dumpjson\", false, \"if true, a JSON version of the \"+\n\t\"test vectors will be written to the cwd\")\n",
      "length": 652,
      "tokens": 67,
      "embedding": []
    },
    {
      "slug": "type jsonKeyAggTestCase struct {",
      "content": "type jsonKeyAggTestCase struct {\n\tKeys          []string    `json:\"keys\"`\n\tTweaks        []jsonTweak `json:\"tweaks\"`\n\tExpectedKey   string      `json:\"expected_key\"`\n\tExpectedError string      `json:\"expected_error\"`\n}\n\n// TestMuSig2KeyAggTestVectors tests that this implementation of musig2 key\n// aggregation lines up with the secp256k1-zkp test vectors.",
      "length": 316,
      "tokens": 31,
      "embedding": []
    },
    {
      "slug": "func TestMuSig2KeyAggTestVectors(t *testing.T) {",
      "content": "func TestMuSig2KeyAggTestVectors(t *testing.T) {\n\tt.Parallel()\n\n\tvar jsonCases []jsonKeyAggTestCase\n\n\ttestCases := []struct {\n\t\tkeyOrder      []int\n\t\texplicitKeys  []*btcec.PublicKey\n\t\ttweaks        []KeyTweakDesc\n\t\texpectedKey   []byte\n\t\texpectedError error\n\t}{\n\t\t// Keys in backwards lexicographical order.\n\t\t{\n\t\t\tkeyOrder:    []int{0, 1, 2},\n\t\t\texpectedKey: keyCombo1,\n\t\t},\n\n\t\t// Keys in sorted order.\n\t\t{\n\t\t\tkeyOrder:    []int{2, 1, 0},\n\t\t\texpectedKey: keyCombo2,\n\t\t},\n\n\t\t// Only the first key.\n\t\t{\n\t\t\tkeyOrder:    []int{0, 0, 0},\n\t\t\texpectedKey: keyCombo3,\n\t\t},\n\n\t\t// Duplicate the first key and second keys.\n\t\t{\n\t\t\tkeyOrder:    []int{0, 0, 1, 1},\n\t\t\texpectedKey: keyCombo4,\n\t\t},\n\n\t\t// Invalid public key.\n\t\t{\n\t\t\tkeyOrder:      []int{0, 3},\n\t\t\texpectedError: secp256k1.ErrPubKeyNotOnCurve,\n\t\t},\n\n\t\t// Public key exceeds field size.\n\t\t{\n\t\t\tkeyOrder:      []int{0, 4},\n\t\t\texpectedError: secp256k1.ErrPubKeyXTooBig,\n\t\t},\n\n\t\t//  Tweak is out of range.\n\t\t{\n\t\t\tkeyOrder: []int{0, 1},\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\t{\n\t\t\t\t\tTweak:   to32ByteSlice(invalidTweak),\n\t\t\t\t\tIsXOnly: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: ErrTweakedKeyOverflows,\n\t\t},\n\n\t\t// Intermediate tweaking result is point at infinity.\n\t\t{\n\t\t\texplicitKeys: []*secp256k1.PublicKey{btcec.Generator()},\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\tgetInfinityTweak(),\n\t\t\t},\n\t\t\texpectedError: ErrTweakedKeyIsInfinity,\n\t\t},\n\t}\n\tfor i, testCase := range testCases {\n\t\ttestName := fmt.Sprintf(\"%v\", testCase.keyOrder)\n\t\tt.Run(testName, func(t *testing.T) {\n\t\t\tvar (\n\t\t\t\tkeys      []*btcec.PublicKey\n\t\t\t\tstrKeys   []string\n\t\t\t\tstrTweaks []jsonTweak\n\t\t\t\tjsonError string\n\t\t\t)\n\t\t\tfor _, keyIndex := range testCase.keyOrder {\n\t\t\t\tkeyBytes := testKeys[keyIndex]\n\t\t\t\tpub, err := schnorr.ParsePubKey(keyBytes)\n\n\t\t\t\tswitch {\n\t\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\t\terrors.Is(err, testCase.expectedError):\n\t\t\t\t\treturn\n\t\t\t\tcase err != nil:\n\t\t\t\t\tt.Fatalf(\"unable to parse pubkeys: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tkeys = append(keys, pub)\n\t\t\t\tstrKeys = append(strKeys, hex.EncodeToString(keyBytes))\n\t\t\t}\n\n\t\t\tfor _, explicitKey := range testCase.explicitKeys {\n\t\t\t\tkeys = append(keys, explicitKey)\n\t\t\t\tstrKeys = append(\n\t\t\t\t\tstrKeys,\n\t\t\t\t\thex.EncodeToString(\n\t\t\t\t\t\texplicitKey.SerializeCompressed(),\n\t\t\t\t\t))\n\t\t\t}\n\n\t\t\tfor _, tweak := range testCase.tweaks {\n\t\t\t\tstrTweaks = append(\n\t\t\t\t\tstrTweaks,\n\t\t\t\t\tjsonTweak{\n\t\t\t\t\t\tTweak: hex.EncodeToString(\n\t\t\t\t\t\t\ttweak.Tweak[:],\n\t\t\t\t\t\t),\n\t\t\t\t\t\tXOnly: tweak.IsXOnly,\n\t\t\t\t\t})\n\t\t\t}\n\n\t\t\tif testCase.expectedError != nil {\n\t\t\t\tjsonError = testCase.expectedError.Error()\n\t\t\t}\n\n\t\t\tjsonCases = append(\n\t\t\t\tjsonCases,\n\t\t\t\tjsonKeyAggTestCase{\n\t\t\t\t\tKeys:   strKeys,\n\t\t\t\t\tTweaks: strTweaks,\n\t\t\t\t\tExpectedKey: hex.EncodeToString(\n\t\t\t\t\t\ttestCase.expectedKey),\n\t\t\t\t\tExpectedError: jsonError,\n\t\t\t\t})\n\n\t\t\tuniqueKeyIndex := secondUniqueKeyIndex(keys, false)\n\t\t\topts := []KeyAggOption{WithUniqueKeyIndex(uniqueKeyIndex)}\n\t\t\tif len(testCase.tweaks) > 0 {\n\t\t\t\topts = append(opts, WithKeyTweaks(testCase.tweaks...))\n\t\t\t}\n\n\t\t\tcombinedKey, _, _, err := AggregateKeys(\n\t\t\t\tkeys, false, opts...,\n\t\t\t)\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\t\t\t\treturn\n\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatalf(\"case #%v, got error %v\", i, err)\n\t\t\t}\n\n\t\t\tcombinedKeyBytes := schnorr.SerializePubKey(combinedKey.FinalKey)\n\t\t\tif !bytes.Equal(combinedKeyBytes, testCase.expectedKey) {\n\t\t\t\tt.Fatalf(\"case: #%v, invalid aggregation: \"+\n\t\t\t\t\t\"expected %x, got %x\", i, testCase.expectedKey,\n\t\t\t\t\tcombinedKeyBytes)\n\t\t\t}\n\t\t})\n\t}\n\n\tif *dumpJson {\n\t\tjsonBytes, err := json.Marshal(jsonCases)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to encode json: %v\", err)\n\t\t}\n\n\t\tvar formattedJson bytes.Buffer\n\t\tjson.Indent(&formattedJson, jsonBytes, \"\", \"\\t\")\n\t\terr = ioutil.WriteFile(\n\t\t\tkeyAggTestVectorName, formattedJson.Bytes(), 0644,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to write file: %v\", err)\n\t\t}\n\t}\n}\n",
      "length": 3638,
      "tokens": 392,
      "embedding": []
    },
    {
      "slug": "func mustParseHex(str string) []byte {",
      "content": "func mustParseHex(str string) []byte {\n\tb, err := hex.DecodeString(str)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"unable to parse hex: %v\", err))\n\t}\n\n\treturn b\n}\n",
      "length": 111,
      "tokens": 19,
      "embedding": []
    },
    {
      "slug": "func parseKey(xHex string) *btcec.PublicKey {",
      "content": "func parseKey(xHex string) *btcec.PublicKey {\n\txB, err := hex.DecodeString(xHex)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tvar x, y btcec.FieldVal\n\tx.SetByteSlice(xB)\n\tif !btcec.DecompressY(&x, false, &y) {\n\t\tpanic(\"x not on curve\")\n\t}\n\ty.Normalize()\n\n\treturn btcec.NewPublicKey(&x, &y)\n}\n\nvar (\n\tsignSetPrivKey, _ = btcec.PrivKeyFromBytes(\n\t\tmustParseHex(\"7FB9E0E687ADA1EEBF7ECFE2F21E73EBDB51A7D450948DF\" +\n\t\t\t\"E8D76D7F2D1007671\"),\n\t)\n\tsignSetPubKey = schnorr.SerializePubKey(signSetPrivKey.PubKey())\n\n\tsignTestMsg = mustParseHex(\"F95466D086770E689964664219266FE5ED215C92A\" +\n\t\t\"E20BAB5C9D79ADDDDF3C0CF\")\n\n\tsignSetKey2 = mustParseHex(\"F9308A019258C31049344F85F89D5229B531C8458\" +\n\t\t\"36F99B08601F113BCE036F9\")\n\n\tsignSetKey3 = mustParseHex(\"DFF1D77F2A671C5F36183726DB2341BE58FEAE1DA\" +\n\t\t\"2DECED843240F7B502BA659\")\n\n\tinvalidSetKey1 = mustParseHex(\"00000000000000000000000000000000\" +\n\t\t\"00000000000000000000000000000007\")\n\n\tsignExpected1 = mustParseHex(\"68537CC5234E505BD14061F8DA9E90C220A1818\" +\n\t\t\"55FD8BDB7F127BB12403B4D3B\")\n\tsignExpected2 = mustParseHex(\"2DF67BFFF18E3DE797E13C6475C963048138DAE\" +\n\t\t\"C5CB20A357CECA7C8424295EA\")\n\tsignExpected3 = mustParseHex(\"0D5B651E6DE34A29A12DE7A8B4183B4AE6A7F7F\" +\n\t\t\"BE15CDCAFA4A3D1BCAABC7517\")\n\n\tsignExpected4 = mustParseHex(\"8D5E0407FB4756EEBCD86264C32D792EE36EEB6\" +\n\t\t\"9E952BBB30B8E41BEBC4D22FA\")\n\n\tsignSetKeys = [][]byte{signSetPubKey, signSetKey2, signSetKey3, invalidPk1}\n\n\taggregatedNonce = toPubNonceSlice(mustParseHex(\"028465FCF0BBDBCF443AA\" +\n\t\t\"BCCE533D42B4B5A10966AC09A49655E8C42DAAB8FCD61037496A3CC86926\" +\n\t\t\"D452CAFCFD55D25972CA1675D549310DE296BFF42F72EEEA8C9\"))\n\tverifyPnonce1 = mustParsePubNonce(\"0337C87821AFD50A8644D820A8F3E02E49\" +\n\t\t\"9C931865C2360FB43D0A0D20DAFE07EA0287BF891D2A6DEAEBADC909352A\" +\n\t\t\"A9405D1428C15F4B75F04DAE642A95C2548480\")\n\tverifyPnonce2 = mustParsePubNonce(\"0279BE667EF9DCBBAC55A06295CE870B07\" +\n\t\t\"029BFCDB2DCE28D959F2815B16F817980279BE667EF9DCBBAC55A06295CE\" +\n\t\t\"870B07029BFCDB2DCE28D959F2815B16F81798\")\n\tverifyPnonce3 = mustParsePubNonce(\"032DE2662628C90B03F5E720284EB52FF7\" +\n\t\t\"D71F4284F627B68A853D78C78E1FFE9303E4C5524E83FFE1493B9077CF1C\" +\n\t\t\"A6BEB2090C93D930321071AD40B2F44E599046\")\n\tverifyPnonce4 = mustParsePubNonce(\"0237C87821AFD50A8644D820A8F3E02E49\" +\n\t\t\"9C931865C2360FB43D0A0D20DAFE07EA0387BF891D2A6DEAEBADC909352A\" +\n\t\t\"A9405D1428C15F4B75F04DAE642A95C2548480\")\n\n\ttweak1 = KeyTweakDesc{\n\t\tTweak: [32]byte{\n\t\t\t0xE8, 0xF7, 0x91, 0xFF, 0x92, 0x25, 0xA2, 0xAF,\n\t\t\t0x01, 0x02, 0xAF, 0xFF, 0x4A, 0x9A, 0x72, 0x3D,\n\t\t\t0x96, 0x12, 0xA6, 0x82, 0xA2, 0x5E, 0xBE, 0x79,\n\t\t\t0x80, 0x2B, 0x26, 0x3C, 0xDF, 0xCD, 0x83, 0xBB,\n\t\t},\n\t}\n\ttweak2 = KeyTweakDesc{\n\t\tTweak: [32]byte{\n\t\t\t0xae, 0x2e, 0xa7, 0x97, 0xcc, 0xf, 0xe7, 0x2a,\n\t\t\t0xc5, 0xb9, 0x7b, 0x97, 0xf3, 0xc6, 0x95, 0x7d,\n\t\t\t0x7e, 0x41, 0x99, 0xa1, 0x67, 0xa5, 0x8e, 0xb0,\n\t\t\t0x8b, 0xca, 0xff, 0xda, 0x70, 0xac, 0x4, 0x55,\n\t\t},\n\t}\n\ttweak3 = KeyTweakDesc{\n\t\tTweak: [32]byte{\n\t\t\t0xf5, 0x2e, 0xcb, 0xc5, 0x65, 0xb3, 0xd8, 0xbe,\n\t\t\t0xa2, 0xdf, 0xd5, 0xb7, 0x5a, 0x4f, 0x45, 0x7e,\n\t\t\t0x54, 0x36, 0x98, 0x9, 0x32, 0x2e, 0x41, 0x20,\n\t\t\t0x83, 0x16, 0x26, 0xf2, 0x90, 0xfa, 0x87, 0xe0,\n\t\t},\n\t}\n\ttweak4 = KeyTweakDesc{\n\t\tTweak: [32]byte{\n\t\t\t0x19, 0x69, 0xad, 0x73, 0xcc, 0x17, 0x7f, 0xa0,\n\t\t\t0xb4, 0xfc, 0xed, 0x6d, 0xf1, 0xf7, 0xbf, 0x99,\n\t\t\t0x7, 0xe6, 0x65, 0xfd, 0xe9, 0xba, 0x19, 0x6a,\n\t\t\t0x74, 0xfe, 0xd0, 0xa3, 0xcf, 0x5a, 0xef, 0x9d,\n\t\t},\n\t}\n)\n",
      "length": 3232,
      "tokens": 282,
      "embedding": []
    },
    {
      "slug": "func formatTweakParity(tweaks []KeyTweakDesc) string {",
      "content": "func formatTweakParity(tweaks []KeyTweakDesc) string {\n\tvar s string\n\tfor _, tweak := range tweaks {\n\t\ts += fmt.Sprintf(\"%v/\", tweak.IsXOnly)\n\t}\n\n\t// Snip off that last '/'.\n\ts = s[:len(s)-1]\n\n\treturn s\n}\n",
      "length": 140,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func genTweakParity(tweak KeyTweakDesc, isXOnly bool) KeyTweakDesc {",
      "content": "func genTweakParity(tweak KeyTweakDesc, isXOnly bool) KeyTweakDesc {\n\ttweak.IsXOnly = isXOnly\n\treturn tweak\n}\n",
      "length": 38,
      "tokens": 6,
      "embedding": []
    },
    {
      "slug": "type jsonTweak struct {",
      "content": "type jsonTweak struct {\n\tTweak string `json:\"tweak\"`\n\tXOnly bool   `json:\"x_only\"`\n}\n",
      "length": 58,
      "tokens": 7,
      "embedding": []
    },
    {
      "slug": "type jsonTweakSignCase struct {",
      "content": "type jsonTweakSignCase struct {\n\tKeys     []string    `json:\"keys\"`\n\tTweaks   []jsonTweak `json:\"tweaks,omitempty\"`\n\tAggNonce string      `json:\"agg_nonce\"`\n\n\tExpectedSig   string `json:\"expected_sig\"`\n\tExpectedError string `json:\"expected_error`\n}\n",
      "length": 210,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "type jsonSignTestCase struct {",
      "content": "type jsonSignTestCase struct {\n\tSecNonce   string `json:\"secret_nonce\"`\n\tSigningKey string `json:\"signing_key\"`\n\tMsg        string `json:\"msg\"`\n\n\tTestCases []jsonTweakSignCase `json:\"test_cases\"`\n}\n\n// TestMuSig2SigningTestVectors tests that the musig2 implementation produces\n// the same set of signatures.",
      "length": 268,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func TestMuSig2SigningTestVectors(t *testing.T) {",
      "content": "func TestMuSig2SigningTestVectors(t *testing.T) {\n\tt.Parallel()\n\n\tvar jsonCases jsonSignTestCase\n\n\tjsonCases.SigningKey = hex.EncodeToString(signSetPrivKey.Serialize())\n\tjsonCases.Msg = hex.EncodeToString(signTestMsg)\n\n\tvar secNonce [SecNonceSize]byte\n\tcopy(secNonce[:], mustParseHex(\"508B81A611F100A6B2B6B29656590898AF488B\"+\n\t\t\"CF2E1F55CF22E5CFB84421FE61\"))\n\tcopy(secNonce[32:], mustParseHex(\"FA27FD49B1D50085B481285E1CA205D55C82\"+\n\t\t\"CC1B31FF5CD54A489829355901F7\"))\n\n\tjsonCases.SecNonce = hex.EncodeToString(secNonce[:])\n\n\ttestCases := []struct {\n\t\tkeyOrder           []int\n\t\taggNonce           [66]byte\n\t\texpectedPartialSig []byte\n\t\ttweaks             []KeyTweakDesc\n\t\texpectedError      error\n\t}{\n\t\t// Vector 1\n\t\t{\n\t\t\tkeyOrder:           []int{0, 1, 2},\n\t\t\taggNonce:           aggregatedNonce,\n\t\t\texpectedPartialSig: signExpected1,\n\t\t},\n\n\t\t// Vector 2\n\t\t{\n\t\t\tkeyOrder:           []int{1, 0, 2},\n\t\t\taggNonce:           aggregatedNonce,\n\t\t\texpectedPartialSig: signExpected2,\n\t\t},\n\n\t\t// Vector 3\n\t\t{\n\t\t\tkeyOrder:           []int{1, 2, 0},\n\t\t\taggNonce:           aggregatedNonce,\n\t\t\texpectedPartialSig: signExpected3,\n\t\t},\n\t\t// Vector 4 Both halves of aggregate nonce correspond to point at infinity\n\t\t{\n\t\t\tkeyOrder:           []int{0, 1},\n\t\t\taggNonce:           mustNonceAgg([][66]byte{verifyPnonce1, verifyPnonce4}),\n\t\t\texpectedPartialSig: signExpected4,\n\t\t},\n\n\t\t// Vector 5: Signer 2 provided an invalid public key\n\t\t{\n\t\t\tkeyOrder:      []int{1, 0, 3},\n\t\t\taggNonce:      aggregatedNonce,\n\t\t\texpectedError: secp256k1.ErrPubKeyNotOnCurve,\n\t\t},\n\n\t\t// Vector 6: Aggregate nonce is invalid due wrong tag, 0x04,\n\t\t// in the first half.\n\t\t{\n\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: toPubNonceSlice(\n\t\t\t\tmustParseHex(\"048465FCF0BBDBCF443AABCCE533D42\" +\n\t\t\t\t\t\"B4B5A10966AC09A49655E8C42DAAB8FCD610\" +\n\t\t\t\t\t\"37496A3CC86926D452CAFCFD55D25972CA16\" +\n\t\t\t\t\t\"75D549310DE296BFF42F72EEEA8C9\")),\n\t\t\texpectedError: secp256k1.ErrPubKeyInvalidFormat,\n\t\t},\n\n\t\t// Vector 7: Aggregate nonce is invalid because the second half\n\t\t// does not correspond to an X coordinate.\n\t\t{\n\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: toPubNonceSlice(\n\t\t\t\tmustParseHex(\"028465FCF0BBDBCF443AABCCE533D42\" +\n\t\t\t\t\t\"B4B5A10966AC09A49655E8C42DAAB8FCD610\" +\n\t\t\t\t\t\"200000000000000000000000000000000000\" +\n\t\t\t\t\t\"00000000000000000000000000009\")),\n\t\t\texpectedError: secp256k1.ErrPubKeyNotOnCurve,\n\t\t},\n\n\t\t// Vector 8: Aggregate nonce is invalid because the second half\n\t\t// exceeds field size.\n\t\t{\n\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: toPubNonceSlice(\n\t\t\t\tmustParseHex(\"028465FCF0BBDBCF443AABCCE533D42\" +\n\t\t\t\t\t\"B4B5A10966AC09A49655E8C42DAAB8FCD610\" +\n\t\t\t\t\t\"2FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" +\n\t\t\t\t\t\"FFFFFFFFFFFFFFFFFFFFEFFFFFC30\")),\n\t\t\texpectedError: secp256k1.ErrPubKeyXTooBig,\n\t\t},\n\n\t\t// A single x-only tweak.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: aggregatedNonce,\n\t\t\texpectedPartialSig: mustParseHex(\"5e24c7496b565debc3b\" +\n\t\t\t\t\"9639e6f1304a21597f9603d3ab05b4913641775e1375b\"),\n\t\t\ttweaks: []KeyTweakDesc{genTweakParity(tweak1, true)},\n\t\t},\n\n\t\t// A single ordinary tweak.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: aggregatedNonce,\n\t\t\texpectedPartialSig: mustParseHex(\"78408ddcab4813d1394c\" +\n\t\t\t\t\"97d493ef1084195c1d4b52e63ecd7bc5991644e44ddd\"),\n\t\t\ttweaks: []KeyTweakDesc{genTweakParity(tweak1, false)},\n\t\t},\n\n\t\t// An ordinary tweak then an x-only tweak.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: aggregatedNonce,\n\t\t\texpectedPartialSig: mustParseHex(\"C3A829A81480E36EC3A\" +\n\t\t\t\t\"B052964509A94EBF34210403D16B226A6F16EC85B7357\"),\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\tgenTweakParity(tweak1, false),\n\t\t\t\tgenTweakParity(tweak2, true),\n\t\t\t},\n\t\t},\n\n\t\t// Four tweaks, in the order: x-only, ordinary, x-only, ordinary.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\taggNonce: aggregatedNonce,\n\t\t\texpectedPartialSig: mustParseHex(\"8C4473C6A382BD3C4AD\" +\n\t\t\t\t\"7BE59818DA5ED7CF8CEC4BC21996CFDA08BB4316B8BC7\"),\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\tgenTweakParity(tweak1, true),\n\t\t\t\tgenTweakParity(tweak2, false),\n\t\t\t\tgenTweakParity(tweak3, true),\n\t\t\t\tgenTweakParity(tweak4, false),\n\t\t\t},\n\t\t},\n\t}\n\n\tvar msg [32]byte\n\tcopy(msg[:], signTestMsg)\n\n\tfor _, testCase := range testCases {\n\t\ttestName := fmt.Sprintf(\"%v/tweak=%v\", testCase.keyOrder, len(testCase.tweaks) != 0)\n\t\tif len(testCase.tweaks) != 0 {\n\t\t\ttestName += fmt.Sprintf(\"/x_only=%v\", formatTweakParity(testCase.tweaks))\n\t\t}\n\t\tt.Run(testName, func(t *testing.T) {\n\t\t\tkeySet := make([]*btcec.PublicKey, 0, len(testCase.keyOrder))\n\t\t\tfor _, keyIndex := range testCase.keyOrder {\n\t\t\t\tkeyBytes := signSetKeys[keyIndex]\n\t\t\t\tpub, err := schnorr.ParsePubKey(keyBytes)\n\n\t\t\t\tswitch {\n\t\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\t\treturn\n\t\t\t\tcase err != nil:\n\t\t\t\t\tt.Fatalf(\"unable to parse pubkeys: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tkeySet = append(keySet, pub)\n\t\t\t}\n\n\t\t\tvar opts []SignOption\n\t\t\tif len(testCase.tweaks) != 0 {\n\t\t\t\topts = append(\n\t\t\t\t\topts, WithTweaks(testCase.tweaks...),\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tpartialSig, err := Sign(\n\t\t\t\tsecNonce, signSetPrivKey, testCase.aggNonce,\n\t\t\t\tkeySet, msg, opts...,\n\t\t\t)\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\treturn\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatalf(\"unable to generate partial sig: %v\", err)\n\t\t\t}\n\n\t\t\tvar partialSigBytes [32]byte\n\t\t\tpartialSig.S.PutBytesUnchecked(partialSigBytes[:])\n\n\t\t\tif !bytes.Equal(partialSigBytes[:], testCase.expectedPartialSig) {\n\t\t\t\tt.Fatalf(\"sigs don't match: expected %x, got %x\",\n\t\t\t\t\ttestCase.expectedPartialSig, partialSigBytes,\n\t\t\t\t)\n\t\t\t}\n\n\t\t})\n\n\t\tif *dumpJson {\n\t\t\tvar (\n\t\t\t\tstrKeys   []string\n\t\t\t\tjsonError string\n\t\t\t)\n\n\t\t\tfor _, keyIndex := range testCase.keyOrder {\n\t\t\t\tkeyBytes := signSetKeys[keyIndex]\n\t\t\t\tstrKeys = append(strKeys, hex.EncodeToString(keyBytes))\n\t\t\t}\n\n\t\t\tif testCase.expectedError != nil {\n\t\t\t\tjsonError = testCase.expectedError.Error()\n\t\t\t}\n\n\t\t\ttweakSignCase := jsonTweakSignCase{\n\t\t\t\tKeys:          strKeys,\n\t\t\t\tExpectedSig:   hex.EncodeToString(testCase.expectedPartialSig),\n\t\t\t\tAggNonce:      hex.EncodeToString(testCase.aggNonce[:]),\n\t\t\t\tExpectedError: jsonError,\n\t\t\t}\n\n\t\t\tvar jsonTweaks []jsonTweak\n\t\t\tfor _, tweak := range testCase.tweaks {\n\t\t\t\tjsonTweaks = append(\n\t\t\t\t\tjsonTweaks,\n\t\t\t\t\tjsonTweak{\n\t\t\t\t\t\tTweak: hex.EncodeToString(tweak.Tweak[:]),\n\t\t\t\t\t\tXOnly: tweak.IsXOnly,\n\t\t\t\t\t})\n\t\t\t}\n\t\t\ttweakSignCase.Tweaks = jsonTweaks\n\n\t\t\tjsonCases.TestCases = append(jsonCases.TestCases, tweakSignCase)\n\t\t}\n\t}\n\n\tif *dumpJson {\n\t\tjsonBytes, err := json.Marshal(jsonCases)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to encode json: %v\", err)\n\t\t}\n\n\t\tvar formattedJson bytes.Buffer\n\t\tjson.Indent(&formattedJson, jsonBytes, \"\", \"\\t\")\n\t\terr = ioutil.WriteFile(\n\t\t\tsignTestVectorName, formattedJson.Bytes(), 0644,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to write file: %v\", err)\n\t\t}\n\t}\n}\n",
      "length": 6458,
      "tokens": 590,
      "embedding": []
    },
    {
      "slug": "func TestMusig2PartialSigVerifyTestVectors(t *testing.T) {",
      "content": "func TestMusig2PartialSigVerifyTestVectors(t *testing.T) {\n\tt.Parallel()\n\n\ttestCases := []struct {\n\t\tpartialSig    []byte\n\t\tnonces        [][66]byte\n\t\tpubnonceIndex int\n\t\tkeyOrder      []int\n\t\ttweaks        []KeyTweakDesc\n\t\texpectedError error\n\t}{\n\t\t// A single x-only tweak.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t\tverifyPnonce1,\n\t\t\t},\n\t\t\tpubnonceIndex: 2,\n\t\t\tpartialSig: mustParseHex(\"5e24c7496b565debc3b9639e\" +\n\t\t\t\t\"6f1304a21597f9603d3ab05b4913641775e1375b\"),\n\t\t\ttweaks: []KeyTweakDesc{genTweakParity(tweak1, true)},\n\t\t},\n\t\t// A single ordinary tweak.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t\tverifyPnonce1,\n\t\t\t},\n\t\t\tpubnonceIndex: 2,\n\t\t\tpartialSig: mustParseHex(\"78408ddcab4813d1394c97d4\" +\n\t\t\t\t\"93ef1084195c1d4b52e63ecd7bc5991644e44ddd\"),\n\t\t\ttweaks: []KeyTweakDesc{genTweakParity(tweak1, false)},\n\t\t},\n\t\t// An ordinary tweak then an x-only tweak.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t\tverifyPnonce1,\n\t\t\t},\n\t\t\tpubnonceIndex: 2,\n\t\t\tpartialSig: mustParseHex(\"C3A829A81480E36EC3AB0529\" +\n\t\t\t\t\"64509A94EBF34210403D16B226A6F16EC85B7357\"),\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\tgenTweakParity(tweak1, false),\n\t\t\t\tgenTweakParity(tweak2, true),\n\t\t\t},\n\t\t},\n\n\t\t// Four tweaks, in the order: x-only, ordinary, x-only, ordinary.\n\t\t{\n\t\t\tkeyOrder: []int{1, 2, 0},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t\tverifyPnonce1,\n\t\t\t},\n\t\t\tpubnonceIndex: 2,\n\t\t\tpartialSig: mustParseHex(\"8C4473C6A382BD3C4AD7BE5\" +\n\t\t\t\t\"9818DA5ED7CF8CEC4BC21996CFDA08BB4316B8BC7\"),\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\tgenTweakParity(tweak1, true),\n\t\t\t\tgenTweakParity(tweak2, false),\n\t\t\t\tgenTweakParity(tweak3, true),\n\t\t\t\tgenTweakParity(tweak4, false),\n\t\t\t},\n\t\t},\n\t\t// Vector 9.\n\t\t{\n\n\t\t\tpartialSig:    signExpected1,\n\t\t\tpubnonceIndex: 0,\n\t\t\tkeyOrder:      []int{0, 1, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t},\n\t\t// Vector 10.\n\t\t{\n\n\t\t\tpartialSig:    signExpected2,\n\t\t\tpubnonceIndex: 1,\n\t\t\tkeyOrder:      []int{1, 0, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t},\n\t\t// Vector 11.\n\t\t{\n\n\t\t\tpartialSig:    signExpected3,\n\t\t\tpubnonceIndex: 2,\n\t\t\tkeyOrder:      []int{1, 2, 0},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t\tverifyPnonce1,\n\t\t\t},\n\t\t},\n\t\t// Vector 12: Both halves of aggregate nonce correspond to\n\t\t// point at infinity.\n\t\t{\n\n\t\t\tpartialSig:    signExpected4,\n\t\t\tpubnonceIndex: 0,\n\t\t\tkeyOrder:      []int{0, 1},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce4,\n\t\t\t},\n\t\t},\n\t\t// Vector 13: Wrong signature (which is equal to the negation\n\t\t// of valid signature expected[0]).\n\t\t{\n\n\t\t\tpartialSig: mustParseHex(\"97AC833ADCB1AFA42EBF9E0\" +\n\t\t\t\t\"725616F3C9A0D5B614F6FE283CEAAA37A8FFAF406\"),\n\t\t\tpubnonceIndex: 0,\n\t\t\tkeyOrder:      []int{0, 1, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t\texpectedError: ErrPartialSigInvalid,\n\t\t},\n\t\t// Vector 12: Wrong signer.\n\t\t{\n\n\t\t\tpartialSig:    signExpected1,\n\t\t\tpubnonceIndex: 1,\n\t\t\tkeyOrder:      []int{0, 1, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t\texpectedError: ErrPartialSigInvalid,\n\t\t},\n\t\t// Vector 13: Signature exceeds group size.\n\t\t{\n\n\t\t\tpartialSig: mustParseHex(\"FFFFFFFFFFFFFFFFFFFFFFFF\" +\n\t\t\t\t\"FFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141\"),\n\t\t\tpubnonceIndex: 0,\n\t\t\tkeyOrder:      []int{0, 1, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t\texpectedError: ErrPartialSigInvalid,\n\t\t},\n\t\t// Vector 14: Invalid pubnonce.\n\t\t{\n\n\t\t\tpartialSig:    signExpected1,\n\t\t\tpubnonceIndex: 0,\n\t\t\tkeyOrder:      []int{0, 1, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tcanParsePubNonce(\"020000000000000000000000000\" +\n\t\t\t\t\t\"000000000000000000000000000000000000009\"),\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t\texpectedError: secp256k1.ErrPubKeyNotOnCurve,\n\t\t},\n\t\t// Vector 15: Invalid public key.\n\t\t{\n\n\t\t\tpartialSig:    signExpected1,\n\t\t\tpubnonceIndex: 0,\n\t\t\tkeyOrder:      []int{3, 1, 2},\n\t\t\tnonces: [][66]byte{\n\t\t\t\tverifyPnonce1,\n\t\t\t\tverifyPnonce2,\n\t\t\t\tverifyPnonce3,\n\t\t\t},\n\t\t\texpectedError: secp256k1.ErrPubKeyNotOnCurve,\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\n\t\t// todo find name\n\t\ttestName := fmt.Sprintf(\"%v/tweak=%v\", testCase.pubnonceIndex, testCase.keyOrder)\n\n\t\tt.Run(testName, func(t *testing.T) {\n\n\t\t\tcombinedNonce, err := AggregateNonces(testCase.nonces)\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\treturn\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatalf(\"unable to aggregate nonces %v\", err)\n\t\t\t}\n\n\t\t\tkeySet := make([]*btcec.PublicKey, 0, len(testCase.keyOrder))\n\t\t\tfor _, keyIndex := range testCase.keyOrder {\n\t\t\t\tkeyBytes := signSetKeys[keyIndex]\n\t\t\t\tpub, err := schnorr.ParsePubKey(keyBytes)\n\n\t\t\t\tswitch {\n\t\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\t\treturn\n\t\t\t\tcase err != nil:\n\t\t\t\t\tt.Fatalf(\"unable to parse pubkeys: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tkeySet = append(keySet, pub)\n\t\t\t}\n\n\t\t\tps := &PartialSignature{}\n\t\t\terr = ps.Decode(bytes.NewBuffer(testCase.partialSig))\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\treturn\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tvar opts []SignOption\n\t\t\tif len(testCase.tweaks) != 0 {\n\t\t\t\topts = append(\n\t\t\t\t\topts, WithTweaks(testCase.tweaks...),\n\t\t\t\t)\n\t\t\t}\n\n\t\t\terr = verifyPartialSig(\n\t\t\t\tps,\n\t\t\t\ttestCase.nonces[testCase.pubnonceIndex],\n\t\t\t\tcombinedNonce,\n\t\t\t\tkeySet,\n\t\t\t\tsignSetKeys[testCase.keyOrder[testCase.pubnonceIndex]],\n\t\t\t\tto32ByteSlice(signTestMsg),\n\t\t\t\topts...,\n\t\t\t)\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\treturn\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatalf(\"unable to aggregate nonces %v\", err)\n\t\t\t}\n\t\t})\n\t}\n}\n",
      "length": 5599,
      "tokens": 525,
      "embedding": []
    },
    {
      "slug": "type signer struct {",
      "content": "type signer struct {\n\tprivKey *btcec.PrivateKey\n\tpubKey  *btcec.PublicKey\n\n\tnonces *Nonces\n\n\tpartialSig *PartialSignature\n}\n",
      "length": 96,
      "tokens": 9,
      "embedding": []
    },
    {
      "slug": "type signerSet []signer",
      "content": "type signerSet []signer\n",
      "length": 0,
      "tokens": 0,
      "embedding": []
    },
    {
      "slug": "func (s signerSet) keys() []*btcec.PublicKey {",
      "content": "func (s signerSet) keys() []*btcec.PublicKey {\n\tkeys := make([]*btcec.PublicKey, len(s))\n\tfor i := 0; i < len(s); i++ {\n\t\tkeys[i] = s[i].pubKey\n\t}\n\n\treturn keys\n}\n",
      "length": 109,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func (s signerSet) partialSigs() []*PartialSignature {",
      "content": "func (s signerSet) partialSigs() []*PartialSignature {\n\tsigs := make([]*PartialSignature, len(s))\n\tfor i := 0; i < len(s); i++ {\n\t\tsigs[i] = s[i].partialSig\n\t}\n\n\treturn sigs\n}\n",
      "length": 114,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func (s signerSet) pubNonces() [][PubNonceSize]byte {",
      "content": "func (s signerSet) pubNonces() [][PubNonceSize]byte {\n\tnonces := make([][PubNonceSize]byte, len(s))\n\tfor i := 0; i < len(s); i++ {\n\t\tnonces[i] = s[i].nonces.PubNonce\n\t}\n\n\treturn nonces\n}\n",
      "length": 126,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func (s signerSet) combinedKey() *btcec.PublicKey {",
      "content": "func (s signerSet) combinedKey() *btcec.PublicKey {\n\tuniqueKeyIndex := secondUniqueKeyIndex(s.keys(), false)\n\tkey, _, _, _ := AggregateKeys(\n\t\ts.keys(), false, WithUniqueKeyIndex(uniqueKeyIndex),\n\t)\n\treturn key.FinalKey\n}\n\n// testMultiPartySign executes a multi-party signing context w/ 100 signers.",
      "length": 240,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func testMultiPartySign(t *testing.T, taprootTweak []byte,",
      "content": "func testMultiPartySign(t *testing.T, taprootTweak []byte,\n\ttweaks ...KeyTweakDesc) {\n\n\tconst numSigners = 100\n\n\t// First generate the set of signers along with their public keys.\n\tsignerKeys := make([]*btcec.PrivateKey, numSigners)\n\tsignSet := make([]*btcec.PublicKey, numSigners)\n\tfor i := 0; i < numSigners; i++ {\n\t\tprivKey, err := btcec.NewPrivateKey()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to gen priv key: %v\", err)\n\t\t}\n\n\t\tpubKey, err := schnorr.ParsePubKey(\n\t\t\tschnorr.SerializePubKey(privKey.PubKey()),\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to gen key: %v\", err)\n\t\t}\n\n\t\tsignerKeys[i] = privKey\n\t\tsignSet[i] = pubKey\n\t}\n\n\tvar combinedKey *btcec.PublicKey\n\n\tvar ctxOpts []ContextOption\n\tswitch {\n\tcase len(taprootTweak) == 0:\n\t\tctxOpts = append(ctxOpts, WithBip86TweakCtx())\n\tcase taprootTweak != nil:\n\t\tctxOpts = append(ctxOpts, WithTaprootTweakCtx(taprootTweak))\n\tcase len(tweaks) != 0:\n\t\tctxOpts = append(ctxOpts, WithTweakedContext(tweaks...))\n\t}\n\n\tctxOpts = append(ctxOpts, WithKnownSigners(signSet))\n\n\t// Now that we have all the signers, we'll make a new context, then\n\t// generate a new session for each of them(which handles nonce\n\t// generation).\n\tsigners := make([]*Session, numSigners)\n\tfor i, signerKey := range signerKeys {\n\t\tsignCtx, err := NewContext(\n\t\t\tsignerKey, false, ctxOpts...,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to generate context: %v\", err)\n\t\t}\n\n\t\tif combinedKey == nil {\n\t\t\tcombinedKey, err = signCtx.CombinedKey()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"combined key not available: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\tsession, err := signCtx.NewSession()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to generate new session: %v\", err)\n\t\t}\n\t\tsigners[i] = session\n\t}\n\n\t// Next, in the pre-signing phase, we'll send all the nonces to each\n\t// signer.\n\tvar wg sync.WaitGroup\n\tfor i, signCtx := range signers {\n\t\tsignCtx := signCtx\n\n\t\twg.Add(1)\n\t\tgo func(idx int, signer *Session) {\n\t\t\tdefer wg.Done()\n\n\t\t\tfor j, otherCtx := range signers {\n\t\t\t\tif idx == j {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tnonce := otherCtx.PublicNonce()\n\t\t\t\thaveAll, err := signer.RegisterPubNonce(nonce)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unable to add public nonce\")\n\t\t\t\t}\n\n\t\t\t\tif j == len(signers)-1 && !haveAll {\n\t\t\t\t\tt.Fatalf(\"all public nonces should have been detected\")\n\t\t\t\t}\n\t\t\t}\n\t\t}(i, signCtx)\n\t}\n\n\twg.Wait()\n\n\tmsg := sha256.Sum256([]byte(\"let's get taprooty\"))\n\n\t// In the final step, we'll use the first signer as our combiner, and\n\t// generate a signature for each signer, and then accumulate that with\n\t// the combiner.\n\tcombiner := signers[0]\n\tfor i := range signers {\n\t\tsigner := signers[i]\n\t\tpartialSig, err := signer.Sign(msg)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to generate partial sig: %v\", err)\n\t\t}\n\n\t\t// We don't need to combine the signature for the very first\n\t\t// signer, as it already has that partial signature.\n\t\tif i != 0 {\n\t\t\thaveAll, err := combiner.CombineSig(partialSig)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to combine sigs: %v\", err)\n\t\t\t}\n\n\t\t\tif i == len(signers)-1 && !haveAll {\n\t\t\t\tt.Fatalf(\"final sig wasn't reconstructed\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Finally we'll combined all the nonces, and ensure that it validates\n\t// as a single schnorr signature.\n\tfinalSig := combiner.FinalSig()\n\tif !finalSig.Verify(msg[:], combinedKey) {\n\t\tt.Fatalf(\"final sig is invalid!\")\n\t}\n\n\t// Verify that if we try to sign again with any of the existing\n\t// signers, then we'll get an error as the nonces have already been\n\t// used.\n\tfor _, signer := range signers {\n\t\t_, err := signer.Sign(msg)\n\t\tif err != ErrSigningContextReuse {\n\t\t\tt.Fatalf(\"expected to get signing context reuse\")\n\t\t}\n\t}\n}\n\n// TestMuSigMultiParty tests that for a given set of 100 signers, we're able to\n// properly generate valid sub signatures, which ultimately can be combined\n// into a single valid signature.",
      "length": 3574,
      "tokens": 539,
      "embedding": []
    },
    {
      "slug": "func TestMuSigMultiParty(t *testing.T) {",
      "content": "func TestMuSigMultiParty(t *testing.T) {\n\tt.Parallel()\n\n\ttestTweak := [32]byte{\n\t\t0xE8, 0xF7, 0x91, 0xFF, 0x92, 0x25, 0xA2, 0xAF,\n\t\t0x01, 0x02, 0xAF, 0xFF, 0x4A, 0x9A, 0x72, 0x3D,\n\t\t0x96, 0x12, 0xA6, 0x82, 0xA2, 0x5E, 0xBE, 0x79,\n\t\t0x80, 0x2B, 0x26, 0x3C, 0xDF, 0xCD, 0x83, 0xBB,\n\t}\n\n\tt.Run(\"no_tweak\", func(t *testing.T) {\n\t\tt.Parallel()\n\n\t\ttestMultiPartySign(t, nil)\n\t})\n\n\tt.Run(\"tweaked\", func(t *testing.T) {\n\t\tt.Parallel()\n\n\t\ttestMultiPartySign(t, nil, KeyTweakDesc{\n\t\t\tTweak: testTweak,\n\t\t})\n\t})\n\n\tt.Run(\"tweaked_x_only\", func(t *testing.T) {\n\t\tt.Parallel()\n\n\t\ttestMultiPartySign(t, nil, KeyTweakDesc{\n\t\t\tTweak:   testTweak,\n\t\t\tIsXOnly: true,\n\t\t})\n\t})\n\n\tt.Run(\"taproot_tweaked_x_only\", func(t *testing.T) {\n\t\tt.Parallel()\n\n\t\ttestMultiPartySign(t, testTweak[:])\n\t})\n\n\tt.Run(\"taproot_bip_86\", func(t *testing.T) {\n\t\tt.Parallel()\n\n\t\ttestMultiPartySign(t, []byte{})\n\t})\n}\n\n// TestMuSigEarlyNonce tests that for protocols where nonces need to be\n// exchagned before all signers are known, the context API works as expected.",
      "length": 937,
      "tokens": 112,
      "embedding": []
    },
    {
      "slug": "func TestMuSigEarlyNonce(t *testing.T) {",
      "content": "func TestMuSigEarlyNonce(t *testing.T) {\n\tt.Parallel()\n\n\tprivKey1, err := btcec.NewPrivateKey()\n\tif err != nil {\n\t\tt.Fatalf(\"unable to gen priv key: %v\", err)\n\t}\n\tprivKey2, err := btcec.NewPrivateKey()\n\tif err != nil {\n\t\tt.Fatalf(\"unable to gen priv key: %v\", err)\n\t}\n\n\t// If we try to make a context, with just the private key and sorting\n\t// value, we should get an error.\n\t_, err = NewContext(privKey1, true)\n\tif !errors.Is(err, ErrSignersNotSpecified) {\n\t\tt.Fatalf(\"unexpected ctx error: %v\", err)\n\t}\n\n\tnumSigners := 2\n\n\tctx1, err := NewContext(\n\t\tprivKey1, true, WithNumSigners(numSigners), WithEarlyNonceGen(),\n\t)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to make ctx: %v\", err)\n\t}\n\tpubKey1 := ctx1.PubKey()\n\n\tctx2, err := NewContext(\n\t\tprivKey2, true, WithNumSigners(numSigners), WithEarlyNonceGen(),\n\t)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to make ctx: %v\", err)\n\t}\n\tpubKey2 := ctx2.PubKey()\n\n\t// At this point, the combined key shouldn't be available for both\n\t// signers, since we only know of the sole signers.\n\tif _, err := ctx1.CombinedKey(); !errors.Is(err, ErrNotEnoughSigners) {\n\t\tt.Fatalf(\"unepxected error: %v\", err)\n\t}\n\tif _, err := ctx2.CombinedKey(); !errors.Is(err, ErrNotEnoughSigners) {\n\t\tt.Fatalf(\"unepxected error: %v\", err)\n\t}\n\n\t// The early nonces _should_ be available at this point.\n\tnonce1, err := ctx1.EarlySessionNonce()\n\tif err != nil {\n\t\tt.Fatalf(\"session nonce not available: %v\", err)\n\t}\n\tnonce2, err := ctx2.EarlySessionNonce()\n\tif err != nil {\n\t\tt.Fatalf(\"session nonce not available: %v\", err)\n\t}\n\n\t// The number of registered signers should still be 1 for both parties.\n\tif ctx1.NumRegisteredSigners() != 1 {\n\t\tt.Fatalf(\"expected 1 signer, instead have: %v\",\n\t\t\tctx1.NumRegisteredSigners())\n\t}\n\tif ctx2.NumRegisteredSigners() != 1 {\n\t\tt.Fatalf(\"expected 1 signer, instead have: %v\",\n\t\t\tctx2.NumRegisteredSigners())\n\t}\n\n\t// If we try to make a session, we should get an error since we dn't\n\t// have all the signers yet.\n\tif _, err := ctx1.NewSession(); !errors.Is(err, ErrNotEnoughSigners) {\n\t\tt.Fatalf(\"unexpected session key error: %v\", err)\n\t}\n\n\t// The combined key should also be unavailable as well.\n\tif _, err := ctx1.CombinedKey(); !errors.Is(err, ErrNotEnoughSigners) {\n\t\tt.Fatalf(\"unexpected combined key error: %v\", err)\n\t}\n\n\t// We'll now register the other signer for both parties.\n\tdone, err := ctx1.RegisterSigner(&pubKey2)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to register signer: %v\", err)\n\t}\n\tif !done {\n\t\tt.Fatalf(\"signer 1 doesn't have all keys\")\n\t}\n\tdone, err = ctx2.RegisterSigner(&pubKey1)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to register signer: %v\", err)\n\t}\n\tif !done {\n\t\tt.Fatalf(\"signer 2 doesn't have all keys\")\n\t}\n\n\t// If we try to register the signer again, we should get an error.\n\t_, err = ctx2.RegisterSigner(&pubKey1)\n\tif !errors.Is(err, ErrAlreadyHaveAllSigners) {\n\t\tt.Fatalf(\"should not be able to register too many signers\")\n\t}\n\n\t// We should be able to create the session at this point.\n\tsession1, err := ctx1.NewSession()\n\tif err != nil {\n\t\tt.Fatalf(\"unable to create new session: %v\", err)\n\t}\n\tsession2, err := ctx2.NewSession()\n\tif err != nil {\n\t\tt.Fatalf(\"unable to create new session: %v\", err)\n\t}\n\n\tmsg := sha256.Sum256([]byte(\"let's get taprooty, LN style\"))\n\n\t// If we try to sign before we have the combined nonce, we shoudl get\n\t// an error.\n\t_, err = session1.Sign(msg)\n\tif !errors.Is(err, ErrCombinedNonceUnavailable) {\n\t\tt.Fatalf(\"unable to gen sig: %v\", err)\n\t}\n\n\t// Now we can exchange nonces to continue with the rest of the signing\n\t// process as normal.\n\tdone, err = session1.RegisterPubNonce(nonce2.PubNonce)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to register nonce: %v\", err)\n\t}\n\tif !done {\n\t\tt.Fatalf(\"signer 1 doesn't have all nonces\")\n\t}\n\tdone, err = session2.RegisterPubNonce(nonce1.PubNonce)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to register nonce: %v\", err)\n\t}\n\tif !done {\n\t\tt.Fatalf(\"signer 2 doesn't have all nonces\")\n\t}\n\n\t// Registering the nonce again should error out.\n\t_, err = session2.RegisterPubNonce(nonce1.PubNonce)\n\tif !errors.Is(err, ErrAlredyHaveAllNonces) {\n\t\tt.Fatalf(\"shouldn't be able to register nonces twice\")\n\t}\n\n\t// Sign the message and combine the two partial sigs into one.\n\t_, err = session1.Sign(msg)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to gen sig: %v\", err)\n\t}\n\tsig2, err := session2.Sign(msg)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to gen sig: %v\", err)\n\t}\n\tdone, err = session1.CombineSig(sig2)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to combine sig: %v\", err)\n\t}\n\tif !done {\n\t\tt.Fatalf(\"all sigs should be known now: %v\", err)\n\t}\n\n\t// If we try to combine another sig, then we should get an error.\n\t_, err = session1.CombineSig(sig2)\n\tif !errors.Is(err, ErrAlredyHaveAllSigs) {\n\t\tt.Fatalf(\"shouldn't be able to combine again\")\n\t}\n\n\t// Finally, verify that the final signature is valid.\n\tcombinedKey, err := ctx1.CombinedKey()\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected combined key error: %v\", err)\n\t}\n\tfinalSig := session1.FinalSig()\n\tif !finalSig.Verify(msg[:], combinedKey) {\n\t\tt.Fatalf(\"final sig is invalid!\")\n\t}\n}\n\n// TestMusig2NonceGenTestVectors tests the nonce generation function with\n// the testvectors defined in the Musig2 BIP.",
      "length": 4931,
      "tokens": 743,
      "embedding": []
    },
    {
      "slug": "func TestMusig2NonceGenTestVectors(t *testing.T) {",
      "content": "func TestMusig2NonceGenTestVectors(t *testing.T) {\n\tt.Parallel()\n\n\tmsg := bytes.Repeat([]byte{0x01}, 32)\n\tsk := bytes.Repeat([]byte{0x02}, 32)\n\taggpk := bytes.Repeat([]byte{0x07}, 32)\n\textra_in := bytes.Repeat([]byte{0x08}, 32)\n\n\ttestCases := []struct {\n\t\topts          nonceGenOpts\n\t\texpectedNonce string\n\t}{\n\t\t{\n\t\t\topts: nonceGenOpts{\n\t\t\t\trandReader:  &memsetRandReader{i: 0},\n\t\t\t\tsecretKey:   sk[:],\n\t\t\t\tcombinedKey: aggpk[:],\n\t\t\t\tauxInput:    extra_in[:],\n\t\t\t\tmsg:         msg[:],\n\t\t\t},\n\t\t\texpectedNonce: \"E8F2E103D86800F19A4E97338D371CB885DB2\" +\n\t\t\t\t\"F19D08C0BD205BBA9B906C971D0D786A17718AAFAD6D\" +\n\t\t\t\t\"E025DDDD99DC823E2DFC1AE1DDFE920888AD53FFF423FC4\",\n\t\t},\n\t\t{\n\t\t\topts: nonceGenOpts{\n\t\t\t\trandReader:  &memsetRandReader{i: 0},\n\t\t\t\tsecretKey:   sk[:],\n\t\t\t\tcombinedKey: aggpk[:],\n\t\t\t\tauxInput:    extra_in[:],\n\t\t\t\tmsg:         nil,\n\t\t\t},\n\t\t\texpectedNonce: \"8A633F5EECBDB690A6BE4921426F41BE78D50\" +\n\t\t\t\t\"9DC1CE894C1215844C0E4C6DE7ABC9A5BE0A3BF3FE31\" +\n\t\t\t\t\"2CCB7E4817D2CB17A7CEA8382B73A99A583E323387B3C32\",\n\t\t},\n\t\t{\n\t\t\topts: nonceGenOpts{\n\t\t\t\trandReader:  &memsetRandReader{i: 0},\n\t\t\t\tsecretKey:   nil,\n\t\t\t\tcombinedKey: nil,\n\t\t\t\tauxInput:    nil,\n\t\t\t\tmsg:         nil,\n\t\t\t},\n\t\t\texpectedNonce: \"7B3B5A002356471AF0E961DE2549C121BD0D4\" +\n\t\t\t\t\"8ABCEEDC6E034BDDF86AD3E0A187ECEE674CEF7364B0\" +\n\t\t\t\t\"BC4BEEFB8B66CAD89F98DE2F8C5A5EAD5D1D1E4BD7D04CD\",\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\tnonce, err := GenNonces(withCustomOptions(testCase.opts))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err gen nonce aux bytes %v\", err)\n\t\t}\n\n\t\texpectedBytes, _ := hex.DecodeString(testCase.expectedNonce)\n\t\tif !bytes.Equal(nonce.SecNonce[:], expectedBytes) {\n\n\t\t\tt.Fatalf(\"nonces don't match: expected %x, got %x\",\n\t\t\t\texpectedBytes, nonce.SecNonce[:])\n\t\t}\n\t}\n\n}\n\nvar (\n\tpNonce1, _ = hex.DecodeString(\"020151C80F435648DF67A22B749CD798CE54E0321D034B92B709B567D60A42E666\" +\n\t\t\"03BA47FBC1834437B3212E89A84D8425E7BF12E0245D98262268EBDCB385D50641\")\n\tpNonce2, _ = hex.DecodeString(\"03FF406FFD8ADB9CD29877E4985014F66A59F6CD01C0E88CAA8E5F3166B1F676A6\" +\n\t\t\"0248C264CDD57D3C24D79990B0F865674EB62A0F9018277A95011B41BFC193B833\")\n\n\texpectedNonce, _ = hex.DecodeString(\"035FE1873B4F2967F52FEA4A06AD5A8ECCBE9D0FD73068012C894E2E87CCB5804B\" +\n\t\t\"024725377345BDE0E9C33AF3C43C0A29A9249F2F2956FA8CFEB55C8573D0262DC8\")\n\n\tinvalidNonce1, _ = hex.DecodeString(\"04FF406FFD8ADB9CD29877E4985014F66A59F6CD01C0E88CAA8E5F3166B1F676A6\" + \"0248C264CDD57D3C24D79990B0F865674EB62A0F9018277A95011B41BFC193B833\")\n\tinvalidNonce2, _ = hex.DecodeString(\"03FF406FFD8ADB9CD29877E4985014F66A59F6CD01C0E88CAA8E5F3166B1F676A6\" + \"0248C264CDD57D3C24D79990B0F865674EB62A0F9018277A95011B41BFC193B831\")\n\tinvalidNonce3, _ = hex.DecodeString(\"03FF406FFD8ADB9CD29877E4985014F66A59F6CD01C0E88CAA8E5F3166B1F676A6\" + \"02FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC30\")\n)\n",
      "length": 2688,
      "tokens": 176,
      "embedding": []
    },
    {
      "slug": "type jsonNonceAggTestCase struct {",
      "content": "type jsonNonceAggTestCase struct {\n\tNonces        []string `json:\"nonces\"`\n\tExpectedNonce string   `json:\"expected_key\"`\n\tExpectedError string   `json:\"expected_error\"`\n}\n",
      "length": 132,
      "tokens": 10,
      "embedding": []
    },
    {
      "slug": "func TestMusig2AggregateNoncesTestVectors(t *testing.T) {",
      "content": "func TestMusig2AggregateNoncesTestVectors(t *testing.T) {\n\tt.Parallel()\n\n\tvar jsonCases []jsonNonceAggTestCase\n\n\ttestCases := []struct {\n\t\tnonces        [][]byte\n\t\texpectedNonce []byte\n\t\texpectedError error\n\t}{\n\t\t// Vector 1: Valid.\n\t\t{\n\t\t\tnonces:        [][]byte{pNonce1, pNonce2},\n\t\t\texpectedNonce: expectedNonce,\n\t\t},\n\n\t\t// Vector 2: Public nonce from signer 1 is invalid due wrong\n\t\t// tag, 0x04, inthe first half.\n\t\t{\n\t\t\tnonces:        [][]byte{pNonce1, invalidNonce1},\n\t\t\texpectedError: secp256k1.ErrPubKeyInvalidFormat,\n\t\t},\n\n\t\t// Vector 3: Public nonce from signer 0 is invalid because the\n\t\t// second half does not correspond to an X coordinate.\n\t\t{\n\t\t\tnonces:        [][]byte{invalidNonce2, pNonce2},\n\t\t\texpectedError: secp256k1.ErrPubKeyNotOnCurve,\n\t\t},\n\n\t\t// Vector 4: Public nonce from signer 0 is invalid because\n\t\t// second half exceeds field size.\n\t\t{\n\t\t\tnonces:        [][]byte{invalidNonce3, pNonce2},\n\t\t\texpectedError: secp256k1.ErrPubKeyXTooBig,\n\t\t},\n\n\t\t// Vector 5: Sum of second points encoded in the nonces would\n\t\t// be point at infinity, therefore set sum to base point G.\n\t\t{\n\t\t\tnonces: [][]byte{\n\t\t\t\tappend(\n\t\t\t\t\tappend([]byte{}, pNonce1[0:33]...),\n\t\t\t\t\tgetGBytes()...,\n\t\t\t\t),\n\t\t\t\tappend(\n\t\t\t\t\tappend([]byte{}, pNonce2[0:33]...),\n\t\t\t\t\tgetNegGBytes()...,\n\t\t\t\t),\n\t\t\t},\n\t\t\texpectedNonce: append(\n\t\t\t\tappend([]byte{}, expectedNonce[0:33]...),\n\t\t\t\tgetInfinityBytes()...,\n\t\t\t),\n\t\t},\n\t}\n\tfor i, testCase := range testCases {\n\t\ttestName := fmt.Sprintf(\"Vector %v\", i+1)\n\t\tt.Run(testName, func(t *testing.T) {\n\t\t\tvar (\n\t\t\t\tnonces    [][66]byte\n\t\t\t\tstrNonces []string\n\t\t\t\tjsonError string\n\t\t\t)\n\t\t\tfor _, nonce := range testCase.nonces {\n\t\t\t\tnonces = append(nonces, toPubNonceSlice(nonce))\n\t\t\t\tstrNonces = append(strNonces, hex.EncodeToString(nonce))\n\t\t\t}\n\n\t\t\tif testCase.expectedError != nil {\n\t\t\t\tjsonError = testCase.expectedError.Error()\n\t\t\t}\n\n\t\t\tjsonCases = append(jsonCases, jsonNonceAggTestCase{\n\t\t\t\tNonces:        strNonces,\n\t\t\t\tExpectedNonce: hex.EncodeToString(expectedNonce),\n\t\t\t\tExpectedError: jsonError,\n\t\t\t})\n\n\t\t\taggregatedNonce, err := AggregateNonces(nonces)\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\treturn\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatalf(\"aggregating nonce error: %v\", err)\n\t\t\t}\n\n\t\t\tif !bytes.Equal(testCase.expectedNonce, aggregatedNonce[:]) {\n\t\t\t\tt.Fatalf(\"case: #%v, invalid nonce aggregation: \"+\n\t\t\t\t\t\"expected %x, got %x\", i, testCase.expectedNonce,\n\t\t\t\t\taggregatedNonce)\n\t\t\t}\n\n\t\t})\n\t}\n\n\tif *dumpJson {\n\t\tjsonBytes, err := json.Marshal(jsonCases)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to encode json: %v\", err)\n\t\t}\n\n\t\tvar formattedJson bytes.Buffer\n\t\tjson.Indent(&formattedJson, jsonBytes, \"\", \"\\t\")\n\t\terr = ioutil.WriteFile(\n\t\t\tnonceAggTestVectorName, formattedJson.Bytes(), 0644,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unable to write file: %v\", err)\n\t\t}\n\t}\n}\n",
      "length": 2687,
      "tokens": 302,
      "embedding": []
    },
    {
      "slug": "type memsetRandReader struct {",
      "content": "type memsetRandReader struct {\n\ti int\n}\n",
      "length": 7,
      "tokens": 3,
      "embedding": []
    },
    {
      "slug": "func (mr *memsetRandReader) Read(buf []byte) (n int, err error) {",
      "content": "func (mr *memsetRandReader) Read(buf []byte) (n int, err error) {\n\tfor i := range buf {\n\t\tbuf[i] = byte(mr.i)\n\t}\n\treturn len(buf), nil\n}\n\nvar (\n\tcombineSigKey0 = mustParseHex(\"487D1B83B41B4CBBD07A111F1BBC7BDC8864CF\" +\n\t\t\"EF5DBF96E46E51C68399B0BEF6\")\n\tcombineSigKey1 = mustParseHex(\"4795C22501BF534BC478FF619407A7EC9E8D88\" +\n\t\t\"83646D69BD43A0728944EA802F\")\n\tcombineSigKey2 = mustParseHex(\"0F5BE837F3AB7E7FEFF1FAA44D673C2017206A\" +\n\t\t\"E836D2C7893CDE4ACB7D55EDEB\")\n\tcombineSigKey3 = mustParseHex(\"0FD453223E444FCA91FB5310990AE8A0C5DAA1\" +\n\t\t\"4D2A4C8944E1C0BC80C30DF682\")\n\n\tcombineSigKeys = [][]byte{combineSigKey0, combineSigKey1,\n\t\tcombineSigKey2, combineSigKey3}\n\n\tcombineSigAggNonce0 = mustParsePubNonce(\"024FA51009A56F0D6DF737131CE1\" +\n\t\t\"FBBD833797AF3B4FE6BF0D68F4D49F68B0947E0248FB3BB9191F0CFF1380\" +\n\t\t\"6A3A2F1429C23012654FCE4E41F7EC9169EAA6056B21\")\n\tcombineSigAggNonce1 = mustParsePubNonce(\"023B11E63E2460E5E0F1561BB700\" +\n\t\t\"FEA95B991DD9CA2CBBE92A3960641FA7469F6702CA4CD38375FE8BEB857C\" +\n\t\t\"770807225BFC7D712F42BA896B83FC71138E56409B21\")\n\tcombineSigAggNonce2 = mustParsePubNonce(\"03F98BEAA32B8A38FE3797C4E813\" +\n\t\t\"DC9CE05ADBE32200035FB37EB0A030B735E9B6030E6118EC98EA2BA7A358\" +\n\t\t\"C2E38E7E13E63681EEB683E067061BF7D52DCF08E615\")\n\tcombineSigAggNonce3 = mustParsePubNonce(\"026491FBCFD47148043A0F7310E6\" +\n\t\t\"2EF898C10F2D0376EE6B232EAAD36F3C2E29E303020CB17D168908E2904D\" +\n\t\t\"E2EB571CD232CA805A6981D0F86CDBBD2F12BD91F6D0\")\n\n\tpsig0 = mustParseHex(\"E5C1CBD6E7E89FE9EE30D5F3B6D06B9C218846E4A1DEF4E\" +\n\t\t\"E851410D51ABBD850\")\n\tpsig1 = mustParseHex(\"9BC470F7F1C9BC848BDF179B0023282FFEF40908E0EF884\" +\n\t\t\"59784A4355FC86D0C\")\n\tpsig2 = mustParseHex(\"D5D8A09929BA264B2F5DF15ACA1CF2DEFA47C048DF0C323\" +\n\t\t\"2E965FFE2F2831B1D\")\n\tpsig3 = mustParseHex(\"A915197503C1051EA77DC91F01C3A0E60BFD64473BD536C\" +\n\t\t\"B613F9645BD61C843\")\n\tpsig4 = mustParseHex(\"99A144D7076A128022134E036B8BDF33811F7EAED9A1E48\" +\n\t\t\"549B46D8A63D64DC9\")\n\tpsig5 = mustParseHex(\"716A72A0C1E531EBB4555C8E29FD35C796F4F231C3B0391\" +\n\t\t\"93D7E8D7AEFBDF5F7\")\n\tpsig6 = mustParseHex(\"06B6DD04BC0F1EF740916730AD7DAC794255B1612217197\" +\n\t\t\"65BDE9686A26633DC\")\n\tpsig7 = mustParseHex(\"BF6D85D4930062726EBC6EBB184AFD68DBB3FED159C5019\" +\n\t\t\"89690A62600D6FBAB\")\n\n\tcombineSigExpected0 = mustParseHex(\"4006D4D069F3B51E968762FF8074153E2\" +\n\t\t\"78E5BCD221AABE0743CA001B77E79F581863CCED9B25C6E7A0FED8EB6F39\" +\n\t\t\"3CD65CD7306D385DCF85CC6567DAA4E041B\")\n\tcombineSigExpected1 = mustParseHex(\"98BCD40DFD94B47A3DA37D7B78EB6CCE8\" +\n\t\t\"ABEACA23C3ADE6F4678902410EB35C67EEDBA0E2D7B2B69D6DBBA79CBE09\" +\n\t\t\"3C64B9647A96B98C8C28AD3379BDFAEA21F\")\n\tcombineSigExpected2 = mustParseHex(\"3741FEDCCDD7508B58DCB9A780FF5D974\" +\n\t\t\"52EC8C0448D8C97004EA7175C14F2007A54D1DE356EBA6719278436EF111\" +\n\t\t\"DFA8F1B832368371B9B7A25001709039679\")\n\tcombineSigExpected3 = mustParseHex(\"F4B3DA3CF0D0F7CF5C1840593BF1A1A41\" +\n\t\t\"5DA341619AE848F2210696DC8C7512540962C84EF7F0CEC491065F2D5772\" +\n\t\t\"13CF10E8A63D153297361B3B172BE27B61F\")\n\n\tcombineSigTweak0 = mustParseHex32(\"B511DA492182A91B0FFB9A98020D55F260\" +\n\t\t\"AE86D7ECBD0399C7383D59A5F2AF7C\")\n\tcombineSigTweak1 = mustParseHex32(\"A815FE049EE3C5AAB66310477FBC8BCCCA\" +\n\t\t\"C2F3395F59F921C364ACD78A2F48DC\")\n\tcombineSigTweak2 = mustParseHex32(\"75448A87274B056468B977BE06EB1E9F65\" +\n\t\t\"7577B7320B0A3376EA51FD420D18A8\")\n\ttweak0False = KeyTweakDesc{\n\t\tTweak:   combineSigTweak0,\n\t\tIsXOnly: false,\n\t}\n\ttweak0True = KeyTweakDesc{\n\t\tTweak:   combineSigTweak0,\n\t\tIsXOnly: true,\n\t}\n\ttweak1False = KeyTweakDesc{\n\t\tTweak:   combineSigTweak1,\n\t\tIsXOnly: false,\n\t}\n\ttweak2True = KeyTweakDesc{\n\t\tTweak:   combineSigTweak2,\n\t\tIsXOnly: true,\n\t}\n\tcombineSigsMsg = mustParseHex32(\"599C67EA410D005B9DA90817CF03ED3B1C86\" +\n\t\t\"8E4DA4EDF00A5880B0082C237869\")\n)\n",
      "length": 3533,
      "tokens": 191,
      "embedding": []
    },
    {
      "slug": "func TestMusig2CombineSigsTestVectors(t *testing.T) {",
      "content": "func TestMusig2CombineSigsTestVectors(t *testing.T) {\n\n\ttestCases := []struct {\n\t\tpartialSigs   [][]byte\n\t\taggNonce      [66]byte\n\t\tkeyOrder      []int\n\t\texpected      []byte\n\t\ttweaks        []KeyTweakDesc\n\t\texpectedError error\n\t}{\n\t\t// Vector 1\n\t\t{\n\t\t\tpartialSigs: [][]byte{psig0, psig1},\n\t\t\taggNonce:    combineSigAggNonce0,\n\t\t\tkeyOrder:    []int{0, 1},\n\t\t\texpected:    combineSigExpected0,\n\t\t},\n\t\t// Vector 2\n\t\t{\n\t\t\tpartialSigs: [][]byte{psig2, psig3},\n\t\t\taggNonce:    combineSigAggNonce1,\n\t\t\tkeyOrder:    []int{0, 2},\n\t\t\texpected:    combineSigExpected1,\n\t\t},\n\t\t// Vector 3\n\t\t{\n\t\t\tpartialSigs: [][]byte{psig4, psig5},\n\t\t\taggNonce:    combineSigAggNonce2,\n\t\t\tkeyOrder:    []int{0, 2},\n\t\t\texpected:    combineSigExpected2,\n\t\t\ttweaks:      []KeyTweakDesc{tweak0False},\n\t\t},\n\t\t// Vector 4\n\t\t{\n\t\t\tpartialSigs: [][]byte{psig6, psig7},\n\t\t\taggNonce:    combineSigAggNonce3,\n\t\t\tkeyOrder:    []int{0, 3},\n\t\t\texpected:    combineSigExpected3,\n\t\t\ttweaks: []KeyTweakDesc{\n\t\t\t\ttweak0True,\n\t\t\t\ttweak1False,\n\t\t\t\ttweak2True,\n\t\t\t},\n\t\t},\n\t\t// Vector 5: Partial signature is invalid because it exceeds group size\n\t\t{\n\t\t\tpartialSigs: [][]byte{\n\t\t\t\tpsig7,\n\t\t\t\tmustParseHex(\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" +\n\t\t\t\t\t\"EBAAEDCE6AF48A03BBFD25E8CD0364141\"),\n\t\t\t},\n\t\t\taggNonce:      combineSigAggNonce3,\n\t\t\texpectedError: ErrPartialSigInvalid,\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\tvar pSigs []*PartialSignature\n\t\tfor _, partialSig := range testCase.partialSigs {\n\t\t\tpSig := &PartialSignature{}\n\t\t\terr := pSig.Decode(bytes.NewReader(partialSig))\n\n\t\t\tswitch {\n\t\t\tcase testCase.expectedError != nil &&\n\t\t\t\terrors.Is(err, testCase.expectedError):\n\n\t\t\t\treturn\n\t\t\tcase err != nil:\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tpSigs = append(pSigs, pSig)\n\t\t}\n\n\t\tkeySet := make([]*btcec.PublicKey, 0, len(testCase.keyOrder))\n\t\tfor _, keyIndex := range testCase.keyOrder {\n\t\t\tkeyBytes := combineSigKeys[keyIndex]\n\t\t\tpub, err := schnorr.ParsePubKey(keyBytes)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unable to parse pubkeys: %v\", err)\n\t\t\t}\n\t\t\tkeySet = append(keySet, pub)\n\t\t}\n\n\t\tuniqueKeyIndex := secondUniqueKeyIndex(keySet, false)\n\t\taggOpts := []KeyAggOption{\n\t\t\tWithUniqueKeyIndex(uniqueKeyIndex),\n\t\t}\n\t\tif len(testCase.tweaks) > 0 {\n\t\t\taggOpts = append(aggOpts, WithKeyTweaks(testCase.tweaks...))\n\t\t}\n\n\t\tcombinedKey, _, _, err := AggregateKeys(\n\t\t\tkeySet, false, aggOpts...,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\taggPubkey, err := aggNonceToPubkey(\n\t\t\ttestCase.aggNonce, combinedKey, combineSigsMsg,\n\t\t)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tvar opts []CombineOption\n\t\tif len(testCase.tweaks) > 0 {\n\t\t\topts = append(opts, WithTweakedCombine(\n\t\t\t\tcombineSigsMsg, keySet, testCase.tweaks, false,\n\t\t\t))\n\t\t}\n\n\t\tsig := CombineSigs(aggPubkey, pSigs, opts...)\n\t\texpectedSig, err := schnorr.ParseSignature(testCase.expected)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tif !bytes.Equal(sig.Serialize(), expectedSig.Serialize()) {\n\t\t\tt.Fatalf(\"sigs not expected %x \\n got %x\", expectedSig.Serialize(), sig.Serialize())\n\t\t}\n\n\t\tif !sig.Verify(combineSigsMsg[:], combinedKey.FinalKey) {\n\t\t\tt.Fatal(\"sig not valid for m\")\n\t\t}\n\t}\n}\n\n// aggNonceToPubkey gets a nonce as a public key for the TestMusig2CombineSigsTestVectors\n// test.\n// TODO(sputn1ck): build into intermediate routine.",
      "length": 3045,
      "tokens": 322,
      "embedding": []
    },
    {
      "slug": "func aggNonceToPubkey(combinedNonce [66]byte, combinedKey *AggregateKey,",
      "content": "func aggNonceToPubkey(combinedNonce [66]byte, combinedKey *AggregateKey,\n\tmsg [32]byte) (*btcec.PublicKey, error) {\n\n\t// b = int_from_bytes(tagged_hash('MuSig/noncecoef', aggnonce + bytes_from_point(Q) + msg)) % n\n\tvar (\n\t\tnonceMsgBuf  bytes.Buffer\n\t\tnonceBlinder btcec.ModNScalar\n\t)\n\tnonceMsgBuf.Write(combinedNonce[:])\n\tnonceMsgBuf.Write(schnorr.SerializePubKey(combinedKey.FinalKey))\n\tnonceMsgBuf.Write(msg[:])\n\tnonceBlindHash := chainhash.TaggedHash(NonceBlindTag, nonceMsgBuf.Bytes())\n\tnonceBlinder.SetByteSlice(nonceBlindHash[:])\n\n\tr1, err := btcec.ParsePubKey(\n\t\tcombinedNonce[:btcec.PubKeyBytesLenCompressed],\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tr2, err := btcec.ParsePubKey(\n\t\tcombinedNonce[btcec.PubKeyBytesLenCompressed:],\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar nonce, r1J, r2J btcec.JacobianPoint\n\tr1.AsJacobian(&r1J)\n\tr2.AsJacobian(&r2J)\n\n\t// With our nonce blinding value, we'll now combine both the public\n\t// nonces, using the blinding factor to tweak the second nonce:\n\t//  * R = R_1 + b*R_2\n\tbtcec.ScalarMultNonConst(&nonceBlinder, &r2J, &r2J)\n\tbtcec.AddNonConst(&r1J, &r2J, &nonce)\n\n\tnonce.ToAffine()\n\n\treturn btcec.NewPublicKey(\n\t\t&nonce.X, &nonce.Y,\n\t), nil\n\n}\n",
      "length": 1080,
      "tokens": 112,
      "embedding": []
    },
    {
      "slug": "func mustNonceAgg(nonces [][66]byte) [66]byte {",
      "content": "func mustNonceAgg(nonces [][66]byte) [66]byte {\n\taggNonce, err := AggregateNonces(nonces)\n\tif err != nil {\n\t\tpanic(\"can't aggregate nonces\")\n\t}\n\treturn aggNonce\n}\n",
      "length": 109,
      "tokens": 16,
      "embedding": []
    },
    {
      "slug": "func memsetLoop(a []byte, v uint8) {",
      "content": "func memsetLoop(a []byte, v uint8) {\n\tfor i := range a {\n\t\ta[i] = byte(v)\n\t}\n}\n",
      "length": 38,
      "tokens": 11,
      "embedding": []
    },
    {
      "slug": "func to32ByteSlice(input []byte) [32]byte {",
      "content": "func to32ByteSlice(input []byte) [32]byte {\n\tif len(input) != 32 {\n\t\tpanic(\"input byte slice has invalid length\")\n\t}\n\tvar output [32]byte\n\tcopy(output[:], input)\n\treturn output\n}\n",
      "length": 128,
      "tokens": 20,
      "embedding": []
    },
    {
      "slug": "func toPubNonceSlice(input []byte) [PubNonceSize]byte {",
      "content": "func toPubNonceSlice(input []byte) [PubNonceSize]byte {\n\tvar output [PubNonceSize]byte\n\tcopy(output[:], input)\n\n\treturn output\n}\n",
      "length": 68,
      "tokens": 8,
      "embedding": []
    },
    {
      "slug": "func getGBytes() []byte {",
      "content": "func getGBytes() []byte {\n\treturn btcec.Generator().SerializeCompressed()\n}\n",
      "length": 48,
      "tokens": 3,
      "embedding": []
    },
    {
      "slug": "func getNegGBytes() []byte {",
      "content": "func getNegGBytes() []byte {\n\tpk := getGBytes()\n\tpk[0] = 0x3\n\n\treturn pk\n}\n",
      "length": 41,
      "tokens": 9,
      "embedding": []
    },
    {
      "slug": "func getInfinityBytes() []byte {",
      "content": "func getInfinityBytes() []byte {\n\treturn make([]byte, 33)\n}\n",
      "length": 25,
      "tokens": 4,
      "embedding": []
    },
    {
      "slug": "func mustParseHex32(str string) [32]byte {",
      "content": "func mustParseHex32(str string) [32]byte {\n\tb, err := hex.DecodeString(str)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"unable to parse hex: %v\", err))\n\t}\n\tif len(b) != 32 {\n\t\tpanic(fmt.Errorf(\"not a 32 byte slice: %v\", err))\n\t}\n\n\treturn to32ByteSlice(b)\n}\n",
      "length": 197,
      "tokens": 32,
      "embedding": []
    },
    {
      "slug": "func mustParsePubNonce(str string) [PubNonceSize]byte {",
      "content": "func mustParsePubNonce(str string) [PubNonceSize]byte {\n\tb, err := hex.DecodeString(str)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"unable to parse hex: %v\", err))\n\t}\n\tif len(b) != PubNonceSize {\n\t\tpanic(fmt.Errorf(\"not a public nonce: %v\", err))\n\t}\n\treturn toPubNonceSlice(b)\n}\n",
      "length": 208,
      "tokens": 31,
      "embedding": []
    },
    {
      "slug": "func canParsePubNonce(str string) [PubNonceSize]byte {",
      "content": "func canParsePubNonce(str string) [PubNonceSize]byte {\n\tb, err := hex.DecodeString(str)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"unable to parse hex: %v\", err))\n\t}\n\treturn toPubNonceSlice(b)\n}\n",
      "length": 128,
      "tokens": 19,
      "embedding": []
    }
  ]
}