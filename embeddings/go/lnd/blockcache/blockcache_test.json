{
  "filepath": "../implementations/go/lnd/blockcache/blockcache_test.go",
  "package": "blockcache",
  "sections": [
    {
      "slug": "type mockChainBackend struct {",
      "content": "type mockChainBackend struct {\n\tblocks         map[chainhash.Hash]*wire.MsgBlock\n\tchainCallCount int\n\n\tsync.RWMutex\n}\n",
      "length": 82,
      "tokens": 6,
      "embedding": []
    },
    {
      "slug": "func newMockChain() *mockChainBackend {",
      "content": "func newMockChain() *mockChainBackend {\n\treturn &mockChainBackend{\n\t\tblocks: make(map[chainhash.Hash]*wire.MsgBlock),\n\t}\n}\n\n// GetBlock is a mock implementation of block fetching that tracks the number\n// of backend calls and returns the block found for the given hash or an error.",
      "length": 235,
      "tokens": 35,
      "embedding": []
    },
    {
      "slug": "func (m *mockChainBackend) GetBlock(blockHash *chainhash.Hash) (*wire.MsgBlock, error) {",
      "content": "func (m *mockChainBackend) GetBlock(blockHash *chainhash.Hash) (*wire.MsgBlock, error) {\n\tm.Lock()\n\tdefer m.Unlock()\n\n\tm.chainCallCount++\n\n\tblock, ok := m.blocks[*blockHash]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"block not found\")\n\t}\n\n\treturn block, nil\n}\n",
      "length": 152,
      "tokens": 21,
      "embedding": []
    },
    {
      "slug": "func (m *mockChainBackend) getChainCallCount() int {",
      "content": "func (m *mockChainBackend) getChainCallCount() int {\n\tm.RLock()\n\tdefer m.RUnlock()\n\n\treturn m.chainCallCount\n}\n",
      "length": 53,
      "tokens": 6,
      "embedding": []
    },
    {
      "slug": "func (m *mockChainBackend) addBlock(block *wire.MsgBlock, nonce uint32) {",
      "content": "func (m *mockChainBackend) addBlock(block *wire.MsgBlock, nonce uint32) {\n\tm.Lock()\n\tdefer m.Unlock()\n\n\tblock.Header.Nonce = nonce\n\thash := block.Header.BlockHash()\n\tm.blocks[hash] = block\n}\n",
      "length": 110,
      "tokens": 13,
      "embedding": []
    },
    {
      "slug": "func (m *mockChainBackend) resetChainCallCount() {",
      "content": "func (m *mockChainBackend) resetChainCallCount() {\n\tm.Lock()\n\tdefer m.Unlock()\n\n\tm.chainCallCount = 0\n}\n\n// TestBlockCacheGetBlock tests that the block Cache works correctly as a LFU block\n// Cache for the given max capacity.",
      "length": 167,
      "tokens": 27,
      "embedding": []
    },
    {
      "slug": "func TestBlockCacheGetBlock(t *testing.T) {",
      "content": "func TestBlockCacheGetBlock(t *testing.T) {\n\tmc := newMockChain()\n\tgetBlockImpl := mc.GetBlock\n\n\tblock1 := &wire.MsgBlock{Header: wire.BlockHeader{Nonce: 1}}\n\tblock2 := &wire.MsgBlock{Header: wire.BlockHeader{Nonce: 2}}\n\tblock3 := &wire.MsgBlock{Header: wire.BlockHeader{Nonce: 3}}\n\n\tblockhash1 := block1.BlockHash()\n\tblockhash2 := block2.BlockHash()\n\tblockhash3 := block3.BlockHash()\n\n\tinv1 := wire.NewInvVect(wire.InvTypeWitnessBlock, &blockhash1)\n\tinv2 := wire.NewInvVect(wire.InvTypeWitnessBlock, &blockhash2)\n\tinv3 := wire.NewInvVect(wire.InvTypeWitnessBlock, &blockhash3)\n\n\t// Determine the size of one of the blocks.\n\tsz, _ := (&neutrino.CacheableBlock{\n\t\tBlock: btcutil.NewBlock(block1),\n\t}).Size()\n\n\t// A new Cache is set up with a capacity of 2 blocks\n\tbc := NewBlockCache(2 * sz)\n\n\tmc.addBlock(&wire.MsgBlock{}, 1)\n\tmc.addBlock(&wire.MsgBlock{}, 2)\n\tmc.addBlock(&wire.MsgBlock{}, 3)\n\n\t// We expect the initial Cache to be empty\n\trequire.Equal(t, 0, bc.Cache.Len())\n\n\t// After calling getBlock for block1, it is expected that the Cache\n\t// will have a size of 1 and will contain block1. One chain backends\n\t// call is expected to fetch the block.\n\t_, err := bc.GetBlock(&blockhash1, getBlockImpl)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 1, bc.Cache.Len())\n\trequire.Equal(t, 1, mc.getChainCallCount())\n\tmc.resetChainCallCount()\n\n\t_, err = bc.Cache.Get(*inv1)\n\trequire.NoError(t, err)\n\n\t// After calling getBlock for block2, it is expected that the Cache\n\t// will have a size of 2 and will contain both block1 and block2.\n\t// One chain backends call is expected to fetch the block.\n\t_, err = bc.GetBlock(&blockhash2, getBlockImpl)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 2, bc.Cache.Len())\n\trequire.Equal(t, 1, mc.getChainCallCount())\n\tmc.resetChainCallCount()\n\n\t_, err = bc.Cache.Get(*inv1)\n\trequire.NoError(t, err)\n\n\t_, err = bc.Cache.Get(*inv2)\n\trequire.NoError(t, err)\n\n\t// getBlock is called again for block1 to make block2 the LFU block.\n\t// No call to the chain backend is expected since block 1 is already\n\t// in the Cache.\n\t_, err = bc.GetBlock(&blockhash1, getBlockImpl)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 2, bc.Cache.Len())\n\trequire.Equal(t, 0, mc.getChainCallCount())\n\tmc.resetChainCallCount()\n\n\t// Since the Cache is now at its max capacity, it is expected that when\n\t// getBlock is called for a new block then the LFU block will be\n\t// evicted. It is expected that block2 will be evicted. After calling\n\t// Getblock for block3, it is expected that the Cache will have a\n\t// length of 2 and will contain block 1 and 3.\n\t_, err = bc.GetBlock(&blockhash3, getBlockImpl)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 2, bc.Cache.Len())\n\trequire.Equal(t, 1, mc.getChainCallCount())\n\tmc.resetChainCallCount()\n\n\t_, err = bc.Cache.Get(*inv1)\n\trequire.NoError(t, err)\n\n\t_, err = bc.Cache.Get(*inv2)\n\trequire.True(t, errors.Is(err, cache.ErrElementNotFound))\n\n\t_, err = bc.Cache.Get(*inv3)\n\trequire.NoError(t, err)\n}\n\n// TestBlockCacheMutexes is used to test that concurrent calls to GetBlock with\n// the same block hash does not result in multiple calls to the chain backend.\n// In other words this tests the HashMutex.",
      "length": 3010,
      "tokens": 390,
      "embedding": []
    },
    {
      "slug": "func TestBlockCacheMutexes(t *testing.T) {",
      "content": "func TestBlockCacheMutexes(t *testing.T) {\n\tmc := newMockChain()\n\tgetBlockImpl := mc.GetBlock\n\n\tblock1 := &wire.MsgBlock{Header: wire.BlockHeader{Nonce: 1}}\n\tblock2 := &wire.MsgBlock{Header: wire.BlockHeader{Nonce: 2}}\n\n\tblockhash1 := block1.BlockHash()\n\tblockhash2 := block2.BlockHash()\n\n\t// Determine the size of the block.\n\tsz, _ := (&neutrino.CacheableBlock{\n\t\tBlock: btcutil.NewBlock(block1),\n\t}).Size()\n\n\t// A new Cache is set up with a capacity of 2 blocks\n\tbc := NewBlockCache(2 * sz)\n\n\tmc.addBlock(&wire.MsgBlock{}, 1)\n\tmc.addBlock(&wire.MsgBlock{}, 2)\n\n\t// Spin off multiple go routines and ensure that concurrent calls to the\n\t// GetBlock method does not result in multiple calls to the chain\n\t// backend.\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 100; i++ {\n\t\twg.Add(1)\n\t\tgo func(e int) {\n\t\t\tif e%2 == 0 {\n\t\t\t\t_, err := bc.GetBlock(&blockhash1, getBlockImpl)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t} else {\n\t\t\t\t_, err := bc.GetBlock(&blockhash2, getBlockImpl)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\n\t\t\twg.Done()\n\t\t}(i)\n\t}\n\n\twg.Wait()\n\trequire.Equal(t, 2, mc.getChainCallCount())\n}\n",
      "length": 993,
      "tokens": 133,
      "embedding": []
    }
  ]
}