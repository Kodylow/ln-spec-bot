{
  "BIP": "158",
  "Layer": "Peer Services",
  "Title": "Compact Block Filters for Light Clients",
  "Author": "Olaoluwa Osuntokun <laolu32@gmail.com>",
  "Comments-Summary": "None yet",
  "Comments-URI": "https://github.com/bitcoin/bips/wiki/Comments:BIP-0158",
  "Status": "Draft",
  "Type": "Standards Track",
  "Created": "2017-05-24",
  "License": "CC0-1.0",
  "sections": [
    {
      "header": "Abstract",
      "content": "This BIP describes a structure for compact filters on block data, for\nuse in the BIP 157 light client protocol[^1]. The filter construction\nproposed is an alternative to Bloom filters, as used in BIP 37, that\nminimizes filter size by using Golomb-Rice coding for compression. This\ndocument specifies one initial filter type based on this construction\nthat enables basic wallets and applications with more advanced smart\ncontracts."
    },
    {
      "header": "Motivation",
      "content": "[BIP 157](bip-0157.mediawiki \"wikilink\") defines a light client protocol\nbased on deterministic filters of block content. The filters are\ndesigned to minimize the expected bandwidth consumed by light clients,\ndownloading filters and full blocks. This document defines the initial\nfilter type *basic* that is designed to reduce the filter size for\nregular wallets."
    },
    {
      "header": "Definitions",
      "content": "`[]byte` represents a vector of bytes.\n\n`[N]byte` represents a fixed-size byte array with length N.\n\n*CompactSize* is a compact encoding of unsigned integers used in the\nBitcoin P2P protocol.\n\n*Data pushes* are byte vectors pushed to the stack according to the\nrules of Bitcoin script.\n\n*Bit streams* are readable and writable streams of individual bits. The\nfollowing functions are used in the pseudocode in this document:\n\n-   `new_bit_stream` instantiates a new writable bit stream\n-   `new_bit_stream(vector)` instantiates a new bit stream reading data\nfrom `vector`\n-   `write_bit(stream, b)` appends the bit `b` to the end of the stream\n-   `read_bit(stream)` reads the next available bit from the stream\n-   `write_bits_big_endian(stream, n, k)` appends the `k` least\nsignificant bits of integer `n` to the end of the stream in\nbig-endian bit order\n-   `read_bits_big_endian(stream, k)` reads the next available `k` bits\nfrom the stream and interprets them as the least significant bits of\na big-endian integer\n\nThe key words \\\"MUST\\\", \\\"MUST NOT\\\", \\\"REQUIRED\\\", \\\"SHALL\\\", \\\"SHALL\nNOT\\\", \\\"SHOULD\\\", \\\"SHOULD NOT\\\", \\\"RECOMMENDED\\\", \\\"MAY\\\", and\n\\\"OPTIONAL\\\" in this document are to be interpreted as described in RFC\n2119."
    },
    {
      "header": "Specification",
      "content": "### Golomb-Coded Sets {#golomb_coded_sets}\n\nFor each block, compact filters are derived containing sets of items\nassociated with the block (eg. addresses sent to, outpoints spent,\netc.). A set of such data objects is compressed into a probabilistic\nstructure called a *Golomb-coded set* (GCS), which matches all items in\nthe set with probability 1, and matches other items with probability\n`1/M` for some integer parameter `M`. The encoding is also parameterized\nby `P`, the bit length of the remainder code. Each filter defined\nspecifies values for `P` and `M`.\n\nAt a high level, a GCS is constructed from a set of `N` items by:\n\n1.  hashing all items to 64-bit integers in the range `[0, N * M)`\n2.  sorting the hashed values in ascending order\n3.  computing the differences between each value and the previous one\n4.  writing the differences sequentially, compressed with Golomb-Rice\ncoding\n\nThe following sections describe each step in greater detail."
    },
    {
      "header": "Hashing Data Objects {#hashing_data_objects}",
      "content": "The first step in the filter construction is hashing the variable-sized\nraw items in the set to the range `[0, F)`, where `F = N * M`.\nCustomarily, `M` is set to `2^P`. However, if one is able to select both\nParameters independently, then more optimal values can be selected[^2].\nSet membership queries against the hash outputs will have a false\npositive rate of `M`. To avoid integer overflow, the number of items `N`\nMUST be \\<2\\^32 and `M` MUST be \\<2\\^32.\n\nThe items are first passed through the pseudorandom function *SipHash*,\nwhich takes a 128-bit key `k` and a variable-sized byte vector and\nproduces a uniformly random 64-bit output. Implementations of this BIP\nMUST use the SipHash parameters `c = 2` and `d = 4`.\n\nThe 64-bit SipHash outputs are then mapped uniformly over the desired\nrange by multiplying with F and taking the top 64 bits of the 128-bit\nresult. This algorithm is a faster alternative to modulo reduction, as\nit avoids the expensive division operation[^3]. Note that care must be\ntaken when implementing this reduction to ensure the upper 64 bits of\nthe integer multiplication are not truncated; certain architectures and\nhigh level languages may require code that decomposes the 64-bit\nmultiplication into four 32-bit multiplications and recombines into the\nresult.\n\nhash_to_range(item: []byte, F: uint64, k: [16]byte) -> uint64:\nreturn (siphash(k, item) * F) >> 64\n\nhashed_set_construct(raw_items: [][]byte, k: [16]byte, M: uint) -> []uint64:\nlet N = len(raw_items)\nlet F = N * M\n\nlet set_items = []\n\nfor item in raw_items:\nlet set_value = hash_to_range(item, F, k)\nset_items.append(set_value)\n\nreturn set_items"
    },
    {
      "header": "Golomb-Rice Coding {#golomb_rice_coding}",
      "content": "Instead of writing the items in the hashed set directly to the filter,\ngreater compression is achieved by only writing the differences between\nsuccessive items in sorted order. Since the items are distributed\nuniformly, it can be shown that the differences resemble a geometric\ndistribution[^4]. *Golomb-Rice* *coding*[^5] is a technique that\noptimally compresses geometrically distributed values.\n\nWith Golomb-Rice, a value is split into a quotient and remainder modulo\n`2^P`, which are encoded separately. The quotient `q` is encoded as\n*unary*, with a string of `q` 1\\'s followed by one 0. The remainder `r`\nis represented in big-endian by P bits. For example, this is a table of\nGolomb-Rice coded values using `P=2`:\n\nn   (q, r)   c\n--- -------- ----------\n0   (0, 0)   `0 00`\n1   (0, 1)   `0 01`\n2   (0, 2)   `0 10`\n3   (0, 3)   `0 11`\n4   (1, 0)   `10 00`\n5   (1, 1)   `10 01`\n6   (1, 2)   `10 10`\n7   (1, 3)   `10 11`\n8   (2, 0)   `110 00`\n9   (2, 1)   `110 01`\n\ngolomb_encode(stream, x: uint64, P: uint):\nlet q = x >> P\n\nwhile q > 0:\nwrite_bit(stream, 1)\nq--\nwrite_bit(stream, 0)\n\nwrite_bits_big_endian(stream, x, P)\n\ngolomb_decode(stream, P: uint) -> uint64:\nlet q = 0\nwhile read_bit(stream) == 1:\nq++\n\nlet r = read_bits_big_endian(stream, P)\n\nlet x = (q << P) + r\nreturn x"
    },
    {
      "header": "Set Construction {#set_construction}",
      "content": "A GCS is constructed from four parameters:\n\n-   `L`, a vector of `N` raw items\n-   `P`, the bit parameter of the Golomb-Rice coding\n-   `M`, the target false positive rate\n-   `k`, the 128-bit key used to randomize the SipHash outputs\n\nThe result is a byte vector with a minimum size of `N * (P + 1)` bits.\n\nThe raw items in `L` are first hashed to 64-bit unsigned integers as\nspecified above and sorted. The differences between consecutive values,\nhereafter referred to as *deltas*, are encoded sequentially to a bit\nstream with Golomb-Rice coding. Finally, the bit stream is padded with\n0\\'s to the nearest byte boundary and serialized to the output byte\nvector.\n\nconstruct_gcs(L: [][]byte, P: uint, k: [16]byte, M: uint) -> []byte:\nlet set_items = hashed_set_construct(L, k, M)\n\nset_items.sort()\n\nlet output_stream = new_bit_stream()\n\nlet last_value = 0\nfor item in set_items:\nlet delta = item - last_value\ngolomb_encode(output_stream, delta, P)\nlast_value = item\n\nreturn output_stream.bytes()"
    },
    {
      "header": "Set Querying/Decompression {#set_queryingdecompression}",
      "content": "To check membership of an item in a compressed GCS, one must reconstruct\nthe hashed set members from the encoded deltas. The procedure to do so\nis the reverse of the compression: deltas are decoded one by one and\nadded to a cumulative sum. Each intermediate sum represents a hashed\nvalue in the original set. The queried item is hashed in the same way as\nthe set members and compared against the reconstructed values. Note that\nquerying does not require the entire decompressed set be held in memory\nat once.\n\ngcs_match(key: [16]byte, compressed_set: []byte, target: []byte, P: uint, N: uint, M: uint) -> bool:\nlet F = N * M\nlet target_hash = hash_to_range(target, F, k)\n\nstream = new_bit_stream(compressed_set)\n\nlet last_value = 0\n\nloop N times:\nlet delta = golomb_decode(stream, P)\nlet set_item = last_value + delta\n\nif set_item == target_hash:\nreturn true\n\n// Since the values in the set are sorted, terminate the search once\n// the decoded value exceeds the target.\nif set_item > target_hash:\nbreak\n\nlast_value = set_item\n\nreturn false\n\nSome applications may need to check for set intersection instead of\nmembership of a single item. This can be performed far more efficiently\nthan checking each item individually by leveraging the sorted structure\nof the compressed GCS. First the query elements are all hashed and\nsorted, then compared in order against the decompressed GCS contents.\nSee [Appendix B](#golomb-coded-set-multi-match \"wikilink\") for\npseudocode."
    },
    {
      "header": "Block Filters {#block_filters}",
      "content": "This BIP defines one initial filter type:\n\n-   Basic (`0x00`)\n-   `M = 784931`\n-   `P = 19`"
    },
    {
      "header": "Contents",
      "content": "The basic filter is designed to contain everything that a light client\nneeds to sync a regular Bitcoin wallet. A basic filter MUST contain\nexactly the following items for each transaction in a block:\n\n-   The previous output script (the script being spent) for each input,\nexcept for the coinbase transaction.\n-   The scriptPubKey of each output, aside from all `OP_RETURN` output\nscripts.\n\nAny \\\"nil\\\" items MUST NOT be included into the final set of filter\nelements.\n\nWe exclude all outputs that start with `OP_RETURN` in order to allow\nfilters to easily be committed to in the future via a soft-fork. A\nlikely area for future commitments is an additional `OP_RETURN` output\nin the coinbase transaction similar to the current witness commitment\n[^6]. By excluding all `OP_RETURN` outputs we avoid a circular\ndependency between the commitment, and the item being committed to."
    },
    {
      "header": "Construction",
      "content": "The basic type is constructed as Golomb-coded sets with the following\nparameters.\n\nThe parameter `P` MUST be set to `19`, and the parameter `M` MUST be set\nto `784931`. Analysis has shown that if one is able to select `P` and\n`M` independently, then setting `M=1.497137 * 2^P` is close to optimal\n[^7].\n\nEmpirical analysis also shows that these parameters minimize the\nbandwidth utilized, considering both the expected number of blocks\ndownloaded due to false positives and the size of the filters\nthemselves.\n\nThe parameter `k` MUST be set to the first 16 bytes of the hash (in\nstandard little-endian representation) of the block for which the filter\nis constructed. This ensures the key is deterministic while still\nvarying from block to block.\n\nSince the value `N` is required to decode a GCS, a serialized GCS\nincludes it as a prefix, written as a `CompactSize`. Thus, the complete\nserialization of a filter is:\n\n-   `N`, encoded as a `CompactSize`\n-   The bytes of the compressed filter itself"
    },
    {
      "header": "Signaling",
      "content": "This BIP allocates a new service bit:\n\n---------------------- ---------- ----------------------------------------------------------------------------------\nNODE_COMPACT_FILTERS   `1 << 6`   If enabled, the node MUST respond to all BIP 157 messages for filter type `0x00`\n---------------------- ---------- ----------------------------------------------------------------------------------"
    },
    {
      "header": "Compatibility",
      "content": "This block filter construction is not incompatible with existing\nsoftware, though it requires implementation of the new filters."
    },
    {
      "header": "Acknowledgments",
      "content": "We would like to thank bfd (from the bitcoin-dev mailing list) for\nbringing the basis of this BIP to our attention, Greg Maxwell for\npointing us in the direction of Golomb-Rice coding and fast range\noptimization, Pieter Wullie for his analysis of optimal GCS parameters,\nand Pedro Martelletto for writing the initial indexing code for `btcd`.\n\nWe would also like to thank Dave Collins, JJ Jeffrey, and Eric Lombrozo\nfor useful discussions."
    },
    {
      "header": "Reference Implementation {#reference_implementation}",
      "content": "Light client: [1](https://github.com/lightninglabs/neutrino)\n\nFull-node indexing: <https://github.com/Roasbeef/btcd/tree/segwit-cbf>\n\nGolomb-Rice Coded sets:\n<https://github.com/btcsuite/btcutil/blob/master/gcs>"
    },
    {
      "header": "Appendix A: Alternatives {#appendix_a_alternatives}",
      "content": "A number of alternative set encodings were considered before\nGolomb-coded sets were settled upon. In this appendix section, we\\'ll\nlist a few of the alternatives along with our rationale for not pursuing\nthem."
    },
    {
      "header": "Bloom Filters {#bloom_filters}",
      "content": "Bloom Filters are perhaps the best known probabilistic data structure\nfor testing set membership, and were introduced into the Bitcoin\nprotocol with BIP 37. The size of a Bloom filter is larger than the\nexpected size of a GCS with the same false positive rate, which is the\nmain reason the option was rejected."
    },
    {
      "header": "Cryptographic Accumulators {#cryptographic_accumulators}",
      "content": "Cryptographic accumulators[^8] are a cryptographic data structures that\nenable (amongst other operations) a one way membership test. One\nadvantage of accumulators are that they are constant size, independent\nof the number of elements inserted into the accumulator. However,\ncurrent constructions of cryptographic accumulators require an initial\ntrusted set up. Additionally, accumulators based on the Strong-RSA\nAssumption require mapping set items to prime representatives in the\nassociated group which can be preemptively expensive."
    },
    {
      "header": "Matrix Based Probabilistic Set Data Structures {#matrix_based_probabilistic_set_data_structures}",
      "content": "There exist data structures based on matrix solving which are even more\nspace efficient compared to Bloom filters[^9]. We instead opted for our\nGCS-based filters as they have a much lower implementation complexity\nand are easier to understand."
    },
    {
      "header": "Appendix B: Pseudocode {#appendix_b_pseudocode}",
      "content": "### Golomb-Coded Set Multi-Match {#golomb_coded_set_multi_match}\n\ngcs_match_any(key: [16]byte, compressed_set: []byte, targets: [][]byte, P: uint, N: uint, M: uint) -> bool:\nlet F = N * M\n\n// Map targets to the same range as the set hashes.\nlet target_hashes = []\nfor target in targets:\nlet target_hash = hash_to_range(target, F, k)\ntarget_hashes.append(target_hash)\n\n// Sort targets so matching can be checked in linear time.\ntarget_hashes.sort()\n\nstream = new_bit_stream(compressed_set)\n\nlet value = 0\nlet target_idx = 0\nlet target_val = target_hashes[target_idx]\n\nloop N times:\nlet delta = golomb_decode(stream, P)\nvalue += delta\n\ninner loop:\nif target_val == value:\nreturn true\n\n// Move on to the next set value.\nelse if target_val > value:\nbreak inner loop\n\n// Move on to the next target value.\nelse if target_val < value:\ntarget_idx++\n\n// If there are no targets left, then there are no matches.\nif target_idx == len(targets):\nbreak outer loop\n\ntarget_val = target_hashes[target_idx]\n\nreturn false"
    },
    {
      "header": "Appendix C: Test Vectors {#appendix_c_test_vectors}",
      "content": "Test vectors for basic block filters on five testnet blocks, including\nthe filters and filter headers, can be found\n[here](bip-0158/testnet-19.json \"wikilink\"). The code to generate them\ncan be found [here](bip-0158/gentestvectors.go \"wikilink\")."
    },
    {
      "header": "References",
      "content": "```{=html}\n<references/>\n```"
    },
    {
      "header": "Copyright",
      "content": "This document is licensed under the Creative Commons CC0 1.0 Universal\nlicense.\n\n[^1]: bip-0157.mediawiki\n\n[^2]: <https://gist.github.com/sipa/576d5f09c3b86c3b1b75598d799fc845>\n\n[^3]: <https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/>\n\n[^4]: <https://en.wikipedia.org/wiki/Geometric_distribution>\n\n[^5]: <https://en.wikipedia.org/wiki/Golomb_coding#Rice_coding>\n\n[^6]: <https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki>\n\n[^7]: <https://gist.github.com/sipa/576d5f09c3b86c3b1b75598d799fc845>\n\n[^8]: <https://en.wikipedia.org/wiki/Accumulator_(cryptography)>\n\n[^9]: <https://arxiv.org/pdf/0804.1845.pdf>"
    }
  ]
}